{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9836e372-7b88-487e-90d9-59211e08fd2e",
   "metadata": {},
   "source": [
    "<H1>Filter Method</H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e001512-837d-467c-a9e5-096df4abbfc5",
   "metadata": {},
   "source": [
    "<H2>Variance Threshold</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d83d4a5-758b-4c95-a015-dac87fe08fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected by Variance Threshold:\n",
      "Breathing Problem\n",
      "Sore throat\n",
      "Running Nose\n",
      "Asthma\n",
      "Chronic Lung Disease\n",
      "Headache\n",
      "Heart Disease\n",
      "Diabetes\n",
      "Hyper Tension\n",
      "Fatigue \n",
      "Gastrointestinal \n",
      "Abroad travel\n",
      "Contact with COVID Patient\n",
      "Attended Large Gathering\n",
      "Visited Public Exposed Places\n",
      "Family working in Public Exposed Places\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9894\n",
      "Average Accuracy across 4 folds: 0.9892\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Flatten, Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the 'source' feature if it exists\n",
    "# df = df.drop(columns=['data_source'], errors='ignore')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19'])\n",
    "y = df['COVID-19']\n",
    "\n",
    "# Variance Threshold Function\n",
    "def variance_threshold(X, threshold=0.1):\n",
    "    selector = VarianceThreshold(threshold)\n",
    "    selector.fit(X)\n",
    "    return X.columns[selector.get_support()]\n",
    "\n",
    "# Apply Variance Threshold\n",
    "selected_features = variance_threshold(X)\n",
    "\n",
    "# Print the features selected by Variance Threshold\n",
    "print(\"Features Selected by Variance Threshold:\")\n",
    "for feature in selected_features:\n",
    "    print(feature)\n",
    "\n",
    "# Filter the dataset to keep only the selected features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Prepare Data for 1D CNN\n",
    "X_selected = X_selected.values.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Reshape for CNN\n",
    "y = y.values  # Convert target variable to numpy array\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\n",
    "\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Build and Train the 1D CNN Model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_selected.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on your problem\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, validation_split=0.2, callbacks=[early_stop])  # Adjust epochs and batch size as needed\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dac7b60-380c-44b8-9db2-d6dedc814fa5",
   "metadata": {},
   "source": [
    "<H2>Chi Squared Test</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e174d972-2cec-4887-af8d-7c9b7c62308a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected by Chi-Squared Test:\n",
      "Breathing Problem\n",
      "Sore throat\n",
      "Heart Disease\n",
      "Diabetes\n",
      "Hyper Tension\n",
      "Gastrointestinal \n",
      "Abroad travel\n",
      "Contact with COVID Patient\n",
      "Attended Large Gathering\n",
      "Family working in Public Exposed Places\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9866\n",
      "Average Accuracy across 4 folds: 0.9852\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Flatten, Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the 'source' feature if it exists\n",
    "# df = df.drop(columns=['data_source'], errors='ignore')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19'])\n",
    "y = df['COVID-19']\n",
    "\n",
    "# Chi-Squared Feature Selection\n",
    "def chi_squared_selection(X, y, k=10):\n",
    "    # Select the top k features based on the Chi-Squared test\n",
    "    selector = SelectKBest(score_func=chi2, k=k)\n",
    "    X_new = selector.fit_transform(X, y)\n",
    "    return X.columns[selector.get_support()]\n",
    "\n",
    "# Apply Chi-Squared Feature Selection\n",
    "selected_features = chi_squared_selection(X, y, k=10)  # Adjust k as needed\n",
    "\n",
    "# Print the features selected by Chi-Squared test\n",
    "print(\"Features Selected by Chi-Squared Test:\")\n",
    "for feature in selected_features:\n",
    "    print(feature)\n",
    "\n",
    "# Filter the dataset to keep only the selected features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Prepare Data for 1D CNN\n",
    "X_selected = X_selected.values.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Reshape for CNN\n",
    "y = y.values  # Convert target variable to numpy array\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\n",
    "\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Build and Train the 1D CNN Model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_selected.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on your problem\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, validation_split=0.2, callbacks=[early_stop])  # Adjust epochs and batch size as needed\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939bc8d8-ac53-40e2-802e-199726ea034f",
   "metadata": {},
   "source": [
    "<H1>Mutual Information</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00ebba8d-7ec2-4a70-9d2d-a919b72eef9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected by Mutual Information:\n",
      "Breathing Problem\n",
      "Sore throat\n",
      "Heart Disease\n",
      "Diabetes\n",
      "Hyper Tension\n",
      "Gastrointestinal \n",
      "Abroad travel\n",
      "Contact with COVID Patient\n",
      "Attended Large Gathering\n",
      "Family working in Public Exposed Places\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9872\n",
      "Average Accuracy across 4 folds: 0.9847\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Flatten, Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the 'source' feature if it exists\n",
    "# df = df.drop(columns=['data_source'], errors='ignore')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19'])\n",
    "y = df['COVID-19']\n",
    "\n",
    "# Mutual Information Feature Selection\n",
    "def mutual_information_selection(X, y, k=10):\n",
    "    # Select the top k features based on Mutual Information\n",
    "    selector = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "    X_new = selector.fit_transform(X, y)\n",
    "    return X.columns[selector.get_support()]\n",
    "\n",
    "# Apply Mutual Information Feature Selection\n",
    "selected_features = mutual_information_selection(X, y, k=10)  # Adjust k as needed\n",
    "\n",
    "# Print the features selected by Mutual Information\n",
    "print(\"Features Selected by Mutual Information:\")\n",
    "for feature in selected_features:\n",
    "    print(feature)\n",
    "\n",
    "# Filter the dataset to keep only the selected features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Prepare Data for 1D CNN\n",
    "X_selected = X_selected.values.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Reshape for CNN\n",
    "y = y.values  # Convert target variable to numpy array\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\n",
    "\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Build and Train the 1D CNN Model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_selected.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on your problem\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, validation_split=0.2, callbacks=[early_stop])  # Adjust epochs and batch size as needed\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2359760a-c053-4f23-ac94-e80c631369b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected by Information Gain:\n",
      "Breathing Problem\n",
      "Sore throat\n",
      "Running Nose\n",
      "Heart Disease\n",
      "Diabetes\n",
      "Gastrointestinal \n",
      "Abroad travel\n",
      "Contact with COVID Patient\n",
      "Attended Large Gathering\n",
      "Family working in Public Exposed Places\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9823\n",
      "Average Accuracy across 4 folds: 0.9815\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Flatten, Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the 'source' feature if it exists\n",
    "# df = df.drop(columns=['data_source'], errors='ignore')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19'])\n",
    "y = df['COVID-19']\n",
    "\n",
    "# Information Gain Feature Selection (using Mutual Information)\n",
    "def information_gain_selection(X, y, k=10):\n",
    "    # Select the top k features based on Information Gain (Mutual Information)\n",
    "    selector = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "    X_new = selector.fit_transform(X, y)\n",
    "    return X.columns[selector.get_support()]\n",
    "\n",
    "# Apply Information Gain Feature Selection\n",
    "selected_features = information_gain_selection(X, y, k=10)  # Adjust k as needed\n",
    "\n",
    "# Print the features selected by Information Gain\n",
    "print(\"Features Selected by Information Gain:\")\n",
    "for feature in selected_features:\n",
    "    print(feature)\n",
    "\n",
    "# Filter the dataset to keep only the selected features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Prepare Data for 1D CNN\n",
    "X_selected = X_selected.values.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Reshape for CNN\n",
    "y = y.values  # Convert target variable to numpy array\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\n",
    "\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Build and Train the 1D CNN Model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_selected.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on your problem\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, validation_split=0.2, callbacks=[early_stop])  # Adjust epochs and batch size as needed\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ea45ee-614c-4c5a-845f-1369930ff9d4",
   "metadata": {},
   "source": [
    "<H1>Wrapper</H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0098c11b-4fab-4f73-ba98-bbb4fa12ed90",
   "metadata": {},
   "source": [
    "<H2>Backward Elimination</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c45ddf5a-1389-461d-86d7-3bc37db11ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected by Backward Elimination:\n",
      "Breathing Problem\n",
      "Fever\n",
      "Dry Cough\n",
      "Sore throat\n",
      "Running Nose\n",
      "Headache\n",
      "Heart Disease\n",
      "Diabetes\n",
      "Hyper Tension\n",
      "Fatigue \n",
      "Gastrointestinal \n",
      "Abroad travel\n",
      "Contact with COVID Patient\n",
      "Attended Large Gathering\n",
      "Visited Public Exposed Places\n",
      "Family working in Public Exposed Places\n",
      "Wearing Masks\n",
      "Sanitization from Market\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9868\n",
      "Average Accuracy across 4 folds: 0.9849\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Flatten, Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the 'source' feature if it exists\n",
    "# df = df.drop(columns=['data_source'], errors='ignore')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19'])\n",
    "y = df['COVID-19']\n",
    "\n",
    "# Backward Elimination Function\n",
    "def backward_elimination(X, y, threshold_in=0.05):\n",
    "    X_with_const = sm.add_constant(X)  # Add constant term for intercept\n",
    "    model = sm.OLS(y, X_with_const).fit()  # Fit the model\n",
    "    p_values = model.pvalues  # Get p-values\n",
    "    while p_values.max() > threshold_in:  # While the max p-value is greater than the threshold\n",
    "        remove_feature = p_values.idxmax()  # Get the feature with the highest p-value\n",
    "        X = X.drop(columns=remove_feature)  # Drop the feature\n",
    "        X_with_const = sm.add_constant(X)  # Re-add constant term\n",
    "        model = sm.OLS(y, X_with_const).fit()  # Fit the model again\n",
    "        p_values = model.pvalues  # Update p-values\n",
    "    return X.columns.tolist()  # Return the remaining features\n",
    "\n",
    "# Apply Backward Elimination\n",
    "selected_features = backward_elimination(X, y, threshold_in=0.05)  # Adjust threshold as needed\n",
    "\n",
    "# Print the features selected by Backward Elimination\n",
    "print(\"Features Selected by Backward Elimination:\")\n",
    "for feature in selected_features:\n",
    "    print(feature)\n",
    "\n",
    "# Filter the dataset to keep only the selected features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Prepare Data for 1D CNN\n",
    "X_selected = X_selected.values.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Reshape for CNN\n",
    "y = y.values  # Convert target variable to numpy array\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\n",
    "\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Build and Train the 1D CNN Model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_selected.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on your problem\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, validation_split=0.2, callbacks=[early_stop])  # Adjust epochs and batch size as needed\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53ca9b8d-5383-4bfc-a16e-b6609af6343e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected by Forward Selection:\n",
      "Breathing Problem\n",
      "Sore throat\n",
      "Abroad travel\n",
      "Attended Large Gathering\n",
      "Contact with COVID Patient\n",
      "Family working in Public Exposed Places\n",
      "Headache\n",
      "Fever\n",
      "Dry Cough\n",
      "Fatigue \n",
      "Visited Public Exposed Places\n",
      "Running Nose\n",
      "Hyper Tension\n",
      "Diabetes\n",
      "Gastrointestinal \n",
      "Heart Disease\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9818\n",
      "Average Accuracy across 4 folds: 0.9839\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Flatten, Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the 'source' feature if it exists\n",
    "# df = df.drop(columns=['data_source'], errors='ignore')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19'])\n",
    "y = df['COVID-19']\n",
    "\n",
    "# Forward Selection Function\n",
    "def forward_selection(X, y, threshold_in=0.05):\n",
    "    selected_features = []\n",
    "    remaining_features = list(X.columns)\n",
    "    \n",
    "    while remaining_features:\n",
    "        best_feature = None\n",
    "        best_p_value = float('inf')\n",
    "        \n",
    "        for feature in remaining_features:\n",
    "            # Fit the model with the selected features plus the candidate feature\n",
    "            X_temp = X[selected_features + [feature]]\n",
    "            X_temp_with_const = sm.add_constant(X_temp)  # Add constant term for intercept\n",
    "            model = sm.OLS(y, X_temp_with_const).fit()  # Fit the model\n",
    "            p_value = model.pvalues[feature]  # Get p-value for the candidate feature\n",
    "            \n",
    "            if p_value < best_p_value:\n",
    "                best_p_value = p_value\n",
    "                best_feature = feature\n",
    "        \n",
    "        if best_p_value < threshold_in:  # If the best feature is significant\n",
    "            selected_features.append(best_feature)  # Add it to the selected features\n",
    "            remaining_features.remove(best_feature)  # Remove it from the remaining features\n",
    "        else:\n",
    "            break  # Stop if no more significant features can be added\n",
    "    \n",
    "    return selected_features  # Return the selected features\n",
    "\n",
    "# Apply Forward Selection\n",
    "selected_features = forward_selection(X, y, threshold_in=0.05)  # Adjust threshold as needed\n",
    "\n",
    "# Print the features selected by Forward Selection\n",
    "print(\"Features Selected by Forward Selection:\")\n",
    "for feature in selected_features:\n",
    "    print(feature)\n",
    "\n",
    "# Filter the dataset to keep only the selected features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Prepare Data for 1D CNN\n",
    "X_selected = X_selected.values.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Reshape for CNN\n",
    "y = y.values  # Convert target variable to numpy array\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\n",
    "\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Build and Train the 1D CNN Model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_selected.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on your problem\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, validation_split=0.2, callbacks=[early_stop])  # Adjust epochs and batch size as needed\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0660ec34-b7cf-4d97-98ba-01bc4cf99ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected by RFE:\n",
      "Breathing Problem\n",
      "Sore throat\n",
      "Chronic Lung Disease\n",
      "Hyper Tension\n",
      "Fatigue \n",
      "Abroad travel\n",
      "Contact with COVID Patient\n",
      "Attended Large Gathering\n",
      "Visited Public Exposed Places\n",
      "Family working in Public Exposed Places\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9861\n",
      "Average Accuracy across 4 folds: 0.9836\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Flatten, Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the 'source' feature if it exists\n",
    "# df = df.drop(columns=['data_source'], errors='ignore')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19'])\n",
    "y = df['COVID-19']\n",
    "\n",
    "# RFE Feature Selection\n",
    "def rfe_selection(X, y, n_features_to_select=10):\n",
    "    model = LogisticRegression(max_iter=1000)  # Logistic Regression model\n",
    "    rfe = RFE(estimator=model, n_features_to_select=n_features_to_select)  # RFE with the model\n",
    "    rfe.fit(X, y)  # Fit RFE\n",
    "    return X.columns[rfe.support_].tolist()  # Return selected features\n",
    "\n",
    "# Apply RFE Feature Selection\n",
    "selected_features = rfe_selection(X, y, n_features_to_select=10)  # Adjust number of features as needed\n",
    "\n",
    "# Print the features selected by RFE\n",
    "print(\"Features Selected by RFE:\")\n",
    "for feature in selected_features:\n",
    "    print(feature)\n",
    "\n",
    "# Filter the dataset to keep only the selected features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Prepare Data for 1D CNN\n",
    "X_selected = X_selected.values.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Reshape for CNN\n",
    "y = y.values  # Convert target variable to numpy array\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\n",
    "\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Build and Train the 1D CNN Model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_selected.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on your problem\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, validation_split=0.2, callbacks=[early_stop])  # Adjust epochs and batch size as needed\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cffaf3-446c-4f69-80c3-078a7cfb8816",
   "metadata": {},
   "source": [
    "<H1>Embedded</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b51b0cd2-c00c-4dae-8810-b55966872862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected by Lasso:\n",
      "Breathing Problem\n",
      "Sore throat\n",
      "Fatigue \n",
      "Abroad travel\n",
      "Contact with COVID Patient\n",
      "Attended Large Gathering\n",
      "Visited Public Exposed Places\n",
      "Family working in Public Exposed Places\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9833\n",
      "Average Accuracy across 4 folds: 0.9782\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Flatten, Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the 'source' feature if it exists\n",
    "# df = df.drop(columns=['data_source'], errors='ignore')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19'])\n",
    "y = df['COVID-19']\n",
    "\n",
    "# Lasso Feature Selection\n",
    "def lasso_selection(X, y, alpha=0.01):\n",
    "    model = Lasso(alpha=alpha)  # Lasso model with specified alpha\n",
    "    model.fit(X, y)  # Fit the model\n",
    "    selected_features = X.columns[model.coef_ != 0]  # Select features with non-zero coefficients\n",
    "    return selected_features.tolist()  # Return selected features\n",
    "\n",
    "# Apply Lasso Feature Selection\n",
    "selected_features = lasso_selection(X, y, alpha=0.01)  # Adjust alpha as needed\n",
    "\n",
    "# Print the features selected by Lasso\n",
    "print(\"Features Selected by Lasso:\")\n",
    "for feature in selected_features:\n",
    "    print(feature)\n",
    "\n",
    "# Filter the dataset to keep only the selected features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Prepare Data for 1D CNN\n",
    "X_selected = X_selected.values.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Reshape for CNN\n",
    "y = y.values  # Convert target variable to numpy array\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\n",
    "\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Build and Train the 1D CNN Model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_selected.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on your problem\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, validation_split=0.2, callbacks=[early_stop])  # Adjust epochs and batch size as needed\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e484a101-4990-4d68-ac4b-b989802365ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected by Ridge:\n",
      "Breathing Problem\n",
      "Sore throat\n",
      "Running Nose\n",
      "Headache\n",
      "Heart Disease\n",
      "Diabetes\n",
      "Hyper Tension\n",
      "Fatigue \n",
      "Gastrointestinal \n",
      "Abroad travel\n",
      "Contact with COVID Patient\n",
      "Attended Large Gathering\n",
      "Visited Public Exposed Places\n",
      "Family working in Public Exposed Places\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9890\n",
      "Average Accuracy across 4 folds: 0.9881\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Flatten, Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the 'source' feature if it exists\n",
    "# df = df.drop(columns=['data_source'], errors='ignore')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19'])\n",
    "y = df['COVID-19']\n",
    "\n",
    "# Ridge Feature Selection\n",
    "def ridge_selection(X, y, alpha=1.0, threshold=0.01):\n",
    "    model = Ridge(alpha=alpha)  # Ridge model with specified alpha\n",
    "    model.fit(X, y)  # Fit the model\n",
    "    # Select features with coefficients above the threshold\n",
    "    selected_features = X.columns[np.abs(model.coef_) > threshold]  \n",
    "    return selected_features.tolist()  # Return selected features\n",
    "\n",
    "# Apply Ridge Feature Selection\n",
    "selected_features = ridge_selection(X, y, alpha=1.0, threshold=0.01)  # Adjust alpha and threshold as needed\n",
    "\n",
    "# Print the features selected by Ridge\n",
    "print(\"Features Selected by Ridge:\")\n",
    "for feature in selected_features:\n",
    "    print(feature)\n",
    "\n",
    "# Filter the dataset to keep only the selected features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Prepare Data for 1D CNN\n",
    "X_selected = X_selected.values.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Reshape for CNN\n",
    "y = y.values  # Convert target variable to numpy array\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\n",
    "\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Build and Train the 1D CNN Model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_selected.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on your problem\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, validation_split=0.2, callbacks=[early_stop])  # Adjust epochs and batch size as needed\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53acbc3f-8915-4ad0-a593-885783ff6a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected by Elastic Net:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Computed output size would be negative. Received `inputs shape=(None, 0, 1)`, `kernel shape=(3, 1, 64)`, `dilation_rate=[1]`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 59\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Build and Train the 1D CNN Model\u001b[39;00m\n\u001b[0;32m     58\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m---> 59\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv1D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(X_selected\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m)))\n\u001b[0;32m     60\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Flatten())\n\u001b[0;32m     61\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))  \u001b[38;5;66;03m# Adjust output layer based on your problem\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\sequential.py:120\u001b[0m, in \u001b[0;36mSequential.add\u001b[1;34m(self, layer, rebuild)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers\u001b[38;5;241m.\u001b[39mappend(layer)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rebuild:\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_rebuild()\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\sequential.py:139\u001b[0m, in \u001b[0;36mSequential._maybe_rebuild\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], InputLayer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    138\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch_shape\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild(input_shape)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py:225\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[0;32m    224\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m current_path()\n\u001b[1;32m--> 225\u001b[0m     original_build_method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[0;32m    227\u001b[0m signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\sequential.py:183\u001b[0m, in \u001b[0;36mSequential.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m         x \u001b[38;5;241m=\u001b[39m layer(x)\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m         \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation_utils.py:221\u001b[0m, in \u001b[0;36mcompute_conv_output_shape\u001b[1;34m(input_shape, filters, kernel_size, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(output_spatial_shape)):\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m none_dims \u001b[38;5;129;01mand\u001b[39;00m output_spatial_shape[i] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    222\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputed output size would be negative. Received \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`inputs shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`kernel shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkernel_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    225\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`dilation_rate=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdilation_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    226\u001b[0m             )\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m padding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m padding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcausal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    228\u001b[0m     output_spatial_shape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor((spatial_shape \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m strides) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Computed output size would be negative. Received `inputs shape=(None, 0, 1)`, `kernel shape=(3, 1, 64)`, `dilation_rate=[1]`."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Flatten, Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the 'source' feature if it exists\n",
    "# df = df.drop(columns=['data_source'], errors='ignore')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19'])\n",
    "y = df['COVID-19']\n",
    "\n",
    "# Elastic Net Feature Selection\n",
    "def elastic_net_selection(X, y, alpha=1.0, l1_ratio=0.5, threshold=0.01):\n",
    "    model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)  # Elastic Net model with specified alpha and l1_ratio\n",
    "    model.fit(X, y)  # Fit the model\n",
    "    # Select features with coefficients above the threshold\n",
    "    selected_features = X.columns[np.abs(model.coef_) > threshold]  \n",
    "    return selected_features.tolist()  # Return selected features\n",
    "\n",
    "# Apply Elastic Net Feature Selection\n",
    "selected_features = elastic_net_selection(X, y, alpha=1.0, l1_ratio=0.5, threshold=0.01)  # Adjust alpha, l1_ratio, and threshold as needed\n",
    "\n",
    "# Print the features selected by Elastic Net\n",
    "print(\"Features Selected by Elastic Net:\")\n",
    "for feature in selected_features:\n",
    "    print(feature)\n",
    "\n",
    "# Filter the dataset to keep only the selected features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Prepare Data for 1D CNN\n",
    "X_selected = X_selected.values.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Reshape for CNN\n",
    "y = y.values  # Convert target variable to numpy array\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\n",
    "\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Build and Train the 1D CNN Model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_selected.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on your problem\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, validation_split=0.2, callbacks=[early_stop])  # Adjust epochs and batch size as needed\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1fc6d5e-f030-44d9-b7b1-1681e508b7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected by Tree-Based Method:\n",
      "Breathing Problem\n",
      "Sore throat\n",
      "Running Nose\n",
      "Asthma\n",
      "Chronic Lung Disease\n",
      "Headache\n",
      "Heart Disease\n",
      "Diabetes\n",
      "Hyper Tension\n",
      "Fatigue \n",
      "Gastrointestinal \n",
      "Abroad travel\n",
      "Contact with COVID Patient\n",
      "Attended Large Gathering\n",
      "Visited Public Exposed Places\n",
      "Family working in Public Exposed Places\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9914\n",
      "Average Accuracy across 4 folds: 0.9892\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Flatten, Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the 'source' feature if it exists\n",
    "# df = df.drop(columns=['data_source'], errors='ignore')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19'])\n",
    "y = df['COVID-19']\n",
    "\n",
    "# Tree-Based Feature Selection\n",
    "def tree_based_selection(X, y, n_estimators=100, threshold=0.01):\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, random_state=42)  # Random Forest model\n",
    "    model.fit(X, y)  # Fit the model\n",
    "    importances = model.feature_importances_  # Get feature importances\n",
    "    # Select features with importances above the threshold\n",
    "    selected_features = X.columns[importances > threshold]  \n",
    "    return selected_features.tolist()  # Return selected features\n",
    "\n",
    "# Apply Tree-Based Feature Selection\n",
    "selected_features = tree_based_selection(X, y, n_estimators=100, threshold=0.01)  # Adjust n_estimators and threshold as needed\n",
    "\n",
    "# Print the features selected by Tree-Based method\n",
    "print(\"Features Selected by Tree-Based Method:\")\n",
    "for feature in selected_features:\n",
    "    print(feature)\n",
    "\n",
    "# Filter the dataset to keep only the selected features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Prepare Data for 1D CNN\n",
    "X_selected = X_selected.values.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Reshape for CNN\n",
    "y = y.values  # Convert target variable to numpy array\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\n",
    "\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Build and Train the 1D CNN Model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_selected.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on your problem\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, validation_split=0.2, callbacks=[early_stop])  # Adjust epochs and batch size as needed\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f080156-ddb0-480b-a767-63e45d67c6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected by Hybrid Method:\n",
      "Breathing Problem\n",
      "Sore throat\n",
      "Running Nose\n",
      "Headache\n",
      "Heart Disease\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9303\n",
      "Average Accuracy across 4 folds: 0.9335\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Flatten, Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the 'source' feature if it exists\n",
    "# df = df.drop(columns=['data_source'], errors='ignore')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19'])\n",
    "y = df['COVID-19']\n",
    "\n",
    "# Hybrid Feature Selection Function\n",
    "def hybrid_feature_selection(X, y, n_features_to_select=5):\n",
    "    # Step 1: Variance Threshold\n",
    "    variance_threshold = VarianceThreshold(threshold=0.1)  # Adjust threshold as needed\n",
    "    X_var = variance_threshold.fit_transform(X)\n",
    "    var_features = X.columns[variance_threshold.get_support()]\n",
    "\n",
    "    # Step 2: Ridge Regression\n",
    "    ridge_model = Ridge(alpha=1.0)\n",
    "    ridge_model.fit(X[var_features], y)\n",
    "    ridge_features = var_features[np.abs(ridge_model.coef_) > 0.01]  # Adjust threshold as needed\n",
    "\n",
    "    # Step 3: Tree-Based Feature Selection\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X[ridge_features], y)\n",
    "    tree_features = ridge_features[rf_model.feature_importances_ > 0.01]  # Adjust threshold as needed\n",
    "\n",
    "    # Consolidate selected features\n",
    "    selected_features = tree_features[:n_features_to_select]  # Ensure we only return the top n features\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "# Apply Hybrid Feature Selection\n",
    "selected_features = hybrid_feature_selection(X, y, n_features_to_select=5)  # Specify the number of features to select\n",
    "\n",
    "# Print the features selected by Hybrid method\n",
    "print(\"Features Selected by Hybrid Method:\")\n",
    "for feature in selected_features:\n",
    "    print(feature)\n",
    "\n",
    "# Filter the dataset to keep only the selected features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Prepare Data for 1D CNN\n",
    "X_selected = X_selected.values.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Reshape for CNN\n",
    "y = y.values  # Convert target variable to numpy array\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Build and Train the 1D CNN Model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_selected.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on your problem\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Fit the model with early stopping\n",
    "    model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_split=0.2, callbacks=[early_stop], verbose=0)  # Adjust epochs and batch size as needed\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c69388ba-99df-4f73-8807-aeef05b26c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected by Hybrid Method:\n",
      "Breathing Problem\n",
      "Fatigue \n",
      "Contact with COVID Patient\n",
      "Asthma\n",
      "Gastrointestinal \n",
      "Visited Public Exposed Places\n",
      "Diabetes\n",
      "Headache\n",
      "Attended Large Gathering\n",
      "Heart Disease\n",
      "Abroad travel\n",
      "Hyper Tension\n",
      "Running Nose\n",
      "Family working in Public Exposed Places\n",
      "Sore throat\n",
      "Chronic Lung Disease\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Fold Accuracy: 0.9848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Fold Accuracy: 0.9869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Fold Accuracy: 0.9733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Fold Accuracy: 0.9726\n",
      "Average Accuracy across 4 folds: 0.9794\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Flatten, Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the 'source' feature if it exists\n",
    "# df = df.drop(columns=['data_source'], errors='ignore')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19'])\n",
    "y = df['COVID-19']\n",
    "\n",
    "# Hybrid Feature Selection Function\n",
    "def hybrid_feature_selection(X, y):\n",
    "    # Step 1: Variance Threshold\n",
    "    variance_threshold = VarianceThreshold(threshold=0.1)  # Adjust threshold as needed\n",
    "    X_var = variance_threshold.fit_transform(X)\n",
    "    var_features = set(X.columns[variance_threshold.get_support()])\n",
    "\n",
    "    # Convert var_features to a list for indexing\n",
    "    var_features_list = list(var_features)\n",
    "\n",
    "    # Step 2: Ridge Regression\n",
    "    ridge_model = Ridge(alpha=1.0)\n",
    "    ridge_model.fit(X[var_features_list], y)  # Use the list for indexing\n",
    "    \n",
    "    # Create a boolean mask for features with significant coefficients\n",
    "    significant_mask = np.abs(ridge_model.coef_) > 0.01  # Adjust threshold as needed\n",
    "    ridge_features = set(np.array(var_features_list)[significant_mask])  # Use the mask to filter features\n",
    "\n",
    "    # Step 3: Tree-Based Feature Selection\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X[list(ridge_features)], y)  # Convert set to list for indexing\n",
    "    tree_features = set(np.array(list(ridge_features))[rf_model.feature_importances_ > 0.01])  # Adjust threshold as needed\n",
    "\n",
    "    # Intersection of all selected features\n",
    "    selected_features = var_features | tree_features \n",
    "\n",
    "    return list(selected_features)  # Return all selected features based on intersection\n",
    "\n",
    "# Apply Hybrid Feature Selection\n",
    "selected_features = hybrid_feature_selection(X, y)  # No limit on the number of features\n",
    "\n",
    "# Print the features selected by Hybrid method\n",
    "print(\"Features Selected by Hybrid Method:\")\n",
    "for feature in selected_features:\n",
    "    print(feature)\n",
    "\n",
    "# Filter the dataset to keep only the selected features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Prepare Data for 1D CNN\n",
    "X_selected = X_selected.values.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Reshape for CNN\n",
    "y = y.values  # Convert target variable to numpy array\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Build and Train the 1D CNN Model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_selected.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on your problem\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Fit the model with early stopping\n",
    "    model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_split=0.2, callbacks=[early_stop], verbose=0)  # Adjust epochs and batch size as needed\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "90e4e73b-313a-409a-a9e8-3dff192c95b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected by Hybrid Method:\n",
      "Breathing Problem\n",
      "Sore throat\n",
      "Abroad travel\n",
      "Contact with COVID Patient\n",
      "Attended Large Gathering\n",
      "Family working in Public Exposed Places\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9714\n",
      "Average Accuracy across 4 folds: 0.9711\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Flatten, Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19'])\n",
    "y = df['COVID-19']\n",
    "\n",
    "# Hybrid Feature Selection Function\n",
    "def hybrid_feature_selection(X, y):\n",
    "    # Step 1: Variance Threshold\n",
    "    variance_threshold = VarianceThreshold(threshold=0.1)\n",
    "    X_var = variance_threshold.fit_transform(X)\n",
    "    var_features = X.columns[variance_threshold.get_support()]\n",
    "\n",
    "    # Step 2: Univariate Feature Selection\n",
    "    chi2_selector = SelectKBest(chi2, k=10)  # Adjust k as needed\n",
    "    X_chi2 = chi2_selector.fit_transform(X[var_features], y)\n",
    "    chi2_features = var_features[chi2_selector.get_support()]\n",
    "\n",
    "    # Step 3: Recursive Feature Elimination (RFE)\n",
    "    rfe_model = LogisticRegression(max_iter=1000)\n",
    "    rfe = RFE(estimator=rfe_model, n_features_to_select=10)  # Adjust n_features_to_select as needed\n",
    "    rfe.fit(X[chi2_features], y)\n",
    "    rfe_features = chi2_features[rfe.support_]\n",
    "\n",
    "    # Step 4: Tree-Based Feature Importance\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X[rfe_features], y)\n",
    "    tree_features = rfe_features[rf_model.feature_importances_ > 0.01]  # Adjust threshold as needed\n",
    "\n",
    "    # Step 5: L1 Regularization (Lasso)\n",
    "    lasso_model = Lasso(alpha=0.01)\n",
    "    lasso_model.fit(X[tree_features], y)\n",
    "    lasso_features = tree_features[np.abs(lasso_model.coef_) > 0.01]  # Adjust threshold as needed\n",
    "\n",
    "    return list(lasso_features)\n",
    "\n",
    "# Apply Hybrid Feature Selection\n",
    "selected_features = hybrid_feature_selection(X, y)\n",
    "\n",
    "# Print the features selected by Hybrid method\n",
    "print(\"Features Selected by Hybrid Method:\")\n",
    "for feature in selected_features:\n",
    "    print(feature)\n",
    "\n",
    "# Filter the dataset to keep only the selected features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Prepare Data for 1D CNN\n",
    "X_selected = X_selected.values.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Reshape for CNN\n",
    "y = y.values  # Convert target variable to numpy array\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Build and Train the 1D CNN Model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_selected.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on your problem\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Fit the model with early stopping\n",
    "    model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_split=0.2, callbacks=[early_stop], verbose=0)  # Adjust epochs and batch size as needed\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d871efd5-3a56-4272-96f9-cda68297c145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9894\n",
      "Average Accuracy across 4 folds: 0.9906\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Flatten, Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the 'source' feature if it exists\n",
    "# df = df.drop(columns=['data_source'], errors='ignore')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19'])\n",
    "y = df['COVID-19']\n",
    "\n",
    "# PCA Dimensionality Reduction\n",
    "def pca_selection(X, n_components=10):\n",
    "    pca = PCA(n_components=n_components)  # Specify the number of components\n",
    "    X_pca = pca.fit_transform(X)  # Fit and transform the data\n",
    "    return X_pca  # Return the transformed data\n",
    "\n",
    "# Apply PCA Dimensionality Reduction\n",
    "X_selected = pca_selection(X, n_components=10)  # Adjust n_components as needed\n",
    "\n",
    "# Prepare Data for 1D CNN\n",
    "X_selected = X_selected.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Reshape for CNN\n",
    "y = y.values  # Convert target variable to numpy array\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\n",
    "\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Build and Train the 1D CNN Model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_selected.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on your problem\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, validation_split=0.2, callbacks=[early_stop])  # Adjust epochs and batch size as needed\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecf4fb8a-e9f9-4630-baff-eb8403414eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/899\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 649us/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step\n",
      "Fold Accuracy: 0.9924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step\n",
      "Fold Accuracy: 0.9925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step\n",
      "Fold Accuracy: 0.9904\n",
      "Average Accuracy across 4 folds: 0.9909\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the 'source' feature if it exists\n",
    "# df = df.drop(columns=['data_source'], errors='ignore')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19'])\n",
    "y = df['COVID-19']\n",
    "\n",
    "# Autoencoder for Dimensionality Reduction\n",
    "def build_autoencoder(input_dim, encoding_dim):\n",
    "    # Define the autoencoder model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(encoding_dim, activation='relu', input_shape=(input_dim,)))  # Encoder\n",
    "    model.add(Dense(input_dim, activation='sigmoid'))  # Decoder\n",
    "    return model\n",
    "\n",
    "# Set parameters\n",
    "input_dim = X.shape[1]  # Number of features\n",
    "encoding_dim = 10  # Desired dimensionality after reduction\n",
    "\n",
    "# Build and compile the autoencoder\n",
    "autoencoder = build_autoencoder(input_dim, encoding_dim)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fit the autoencoder\n",
    "autoencoder.fit(X, X, epochs=100, batch_size=32, verbose=0)  # Train on the same data\n",
    "\n",
    "# Transform the data using the encoder part of the autoencoder\n",
    "encoder = Sequential()\n",
    "encoder.add(Dense(encoding_dim, activation='relu', input_shape=(input_dim,)))  # Encoder layer\n",
    "encoder.layers[0].set_weights(autoencoder.layers[0].get_weights())  # Copy weights from the autoencoder encoder\n",
    "# No need to set weights for the decoder layer\n",
    "\n",
    "# Transform the data\n",
    "X_selected = encoder.predict(X)\n",
    "\n",
    "# Prepare Data for 1D CNN\n",
    "X_selected = X_selected.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Reshape for CNN\n",
    "y = y.values  # Convert target variable to numpy array\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\n",
    "\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Build and Train the 1D CNN Model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_selected.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on your problem\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, validation_split=0.2, callbacks=[early_stop])  # Adjust epochs and batch size as needed\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8043c1ae-88ce-4506-8238-bf7c727b348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Flatten, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Placeholder for HLLE function\n",
    "def hlle_selection(X, n_components=10, n_neighbors=5):\n",
    "    # Implement HLLE here or use a library that provides it\n",
    "    # For now, we will just return the input as a placeholder\n",
    "    # Replace this with actual HLLE implementation\n",
    "    from sklearn.manifold import LocallyLinearEmbedding\n",
    "    lle = LocallyLinearEmbedding(n_components=n_components, n_neighbors=n_neighbors, method='standard')\n",
    "    return lle.fit_transform(X)\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the 'source' feature if it exists\n",
    "# df = df.drop(columns=['data_source'], errors='ignore')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19'])\n",
    "y = df['COVID-19']\n",
    "\n",
    "# Apply HLLE Dimensionality Reduction\n",
    "X_selected = hlle_selection(X, n_components=10, n_neighbors=5)  # Adjust n_components and n_neighbors as needed\n",
    "\n",
    "# Prepare Data for 1D CNN\n",
    "X_selected = X_selected.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Reshape for CNN\n",
    "y = y.values  # Convert target variable to numpy array\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\n",
    "\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Build and Train the 1D CNN Model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_selected.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on your problem\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, validation_split=0.2, callbacks=[early_stop])  # Adjust epochs and batch size as needed\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98d9f526-e468-4009-8600-915aa88dbbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.1245 - val_loss: 0.8096\n",
      "Epoch 2/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8109 - val_loss: 0.7926\n",
      "Epoch 3/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7803 - val_loss: 0.7841\n",
      "Epoch 4/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7641 - val_loss: 0.7789\n",
      "Epoch 5/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7570 - val_loss: 0.7781\n",
      "Epoch 6/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7598 - val_loss: 0.7781\n",
      "Epoch 7/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7594 - val_loss: 0.7775\n",
      "Epoch 8/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7557 - val_loss: 0.7770\n",
      "Epoch 9/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7577 - val_loss: 0.7766\n",
      "Epoch 10/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7528 - val_loss: 0.7767\n",
      "Epoch 11/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7519 - val_loss: 0.7767\n",
      "Epoch 12/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7557 - val_loss: 0.7764\n",
      "Epoch 13/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7528 - val_loss: 0.7764\n",
      "Epoch 14/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7520 - val_loss: 0.7763\n",
      "Epoch 15/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7509 - val_loss: 0.7762\n",
      "Epoch 16/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7474 - val_loss: 0.7762\n",
      "Epoch 17/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7515 - val_loss: 0.7762\n",
      "Epoch 18/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7529 - val_loss: 0.7761\n",
      "Epoch 19/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7499 - val_loss: 0.7761\n",
      "Epoch 20/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7503 - val_loss: 0.7762\n",
      "Epoch 21/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7475 - val_loss: 0.7761\n",
      "Epoch 22/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7508 - val_loss: 0.7760\n",
      "Epoch 23/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7519 - val_loss: 0.7759\n",
      "Epoch 24/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7515 - val_loss: 0.7761\n",
      "Epoch 25/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7508 - val_loss: 0.7760\n",
      "Epoch 26/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7509 - val_loss: 0.7759\n",
      "Epoch 27/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7491 - val_loss: 0.7760\n",
      "Epoch 28/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7499 - val_loss: 0.7758\n",
      "Epoch 29/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7491 - val_loss: 0.7758\n",
      "Epoch 30/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7514 - val_loss: 0.7758\n",
      "Epoch 31/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7482 - val_loss: 0.7758\n",
      "Epoch 32/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7494 - val_loss: 0.7759\n",
      "Epoch 33/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7486 - val_loss: 0.7758\n",
      "Epoch 34/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7467 - val_loss: 0.7757\n",
      "Epoch 35/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7461 - val_loss: 0.7758\n",
      "Epoch 36/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7476 - val_loss: 0.7757\n",
      "Epoch 37/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7480 - val_loss: 0.7757\n",
      "Epoch 38/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7502 - val_loss: 0.7757\n",
      "Epoch 39/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7491 - val_loss: 0.7757\n",
      "Epoch 40/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7492 - val_loss: 0.7757\n",
      "Epoch 41/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7458 - val_loss: 0.7757\n",
      "Epoch 42/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7471 - val_loss: 0.7757\n",
      "Epoch 43/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7481 - val_loss: 0.7755\n",
      "Epoch 44/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7463 - val_loss: 0.7756\n",
      "Epoch 45/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7483 - val_loss: 0.7758\n",
      "Epoch 46/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7494 - val_loss: 0.7757\n",
      "Epoch 47/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7479 - val_loss: 0.7756\n",
      "Epoch 48/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7454 - val_loss: 0.7755\n",
      "Epoch 49/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7476 - val_loss: 0.7757\n",
      "Epoch 50/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7472 - val_loss: 0.7755\n",
      "Epoch 51/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7455 - val_loss: 0.7756\n",
      "Epoch 52/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7463 - val_loss: 0.7755\n",
      "Epoch 53/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7445 - val_loss: 0.7756\n",
      "Epoch 54/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7451 - val_loss: 0.7756\n",
      "Epoch 55/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7495 - val_loss: 0.7756\n",
      "Epoch 56/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7518 - val_loss: 0.7756\n",
      "Epoch 57/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7459 - val_loss: 0.7756\n",
      "Epoch 58/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7504 - val_loss: 0.7754\n",
      "Epoch 59/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7475 - val_loss: 0.7755\n",
      "Epoch 60/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7456 - val_loss: 0.7755\n",
      "Epoch 61/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7502 - val_loss: 0.7755\n",
      "Epoch 62/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7488 - val_loss: 0.7755\n",
      "Epoch 63/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7477 - val_loss: 0.7755\n",
      "Epoch 64/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7505 - val_loss: 0.7754\n",
      "Epoch 65/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7462 - val_loss: 0.7754\n",
      "Epoch 66/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7490 - val_loss: 0.7754\n",
      "Epoch 67/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7481 - val_loss: 0.7754\n",
      "Epoch 68/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7459 - val_loss: 0.7754\n",
      "Epoch 69/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7477 - val_loss: 0.7755\n",
      "Epoch 70/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7479 - val_loss: 0.7754\n",
      "Epoch 71/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7445 - val_loss: 0.7754\n",
      "Epoch 72/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7493 - val_loss: 0.7756\n",
      "Epoch 73/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7444 - val_loss: 0.7755\n",
      "Epoch 74/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7480 - val_loss: 0.7755\n",
      "Epoch 75/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7462 - val_loss: 0.7754\n",
      "Epoch 76/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7467 - val_loss: 0.7755\n",
      "Epoch 77/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7475 - val_loss: 0.7754\n",
      "Epoch 78/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7491 - val_loss: 0.7753\n",
      "Epoch 79/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7478 - val_loss: 0.7754\n",
      "Epoch 80/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7453 - val_loss: 0.7754\n",
      "Epoch 81/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7465 - val_loss: 0.7754\n",
      "Epoch 82/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7454 - val_loss: 0.7754\n",
      "Epoch 83/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7446 - val_loss: 0.7754\n",
      "Epoch 84/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7452 - val_loss: 0.7753\n",
      "Epoch 85/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7490 - val_loss: 0.7753\n",
      "Epoch 86/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7489 - val_loss: 0.7755\n",
      "Epoch 87/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7443 - val_loss: 0.7754\n",
      "Epoch 88/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7484 - val_loss: 0.7753\n",
      "Epoch 89/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7490 - val_loss: 0.7754\n",
      "Epoch 90/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7458 - val_loss: 0.7754\n",
      "Epoch 91/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7461 - val_loss: 0.7753\n",
      "Epoch 92/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7478 - val_loss: 0.7753\n",
      "Epoch 93/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7480 - val_loss: 0.7754\n",
      "Epoch 94/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7478 - val_loss: 0.7754\n",
      "Epoch 95/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7464 - val_loss: 0.7754\n",
      "Epoch 96/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7453 - val_loss: 0.7753\n",
      "Epoch 97/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7465 - val_loss: 0.7753\n",
      "Epoch 98/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7472 - val_loss: 0.7754\n",
      "Epoch 99/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7486 - val_loss: 0.7754\n",
      "Epoch 100/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7492 - val_loss: 0.7754\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step\n",
      "Fold Accuracy: 0.9951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step\n",
      "Fold Accuracy: 0.9936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step\n",
      "Fold Accuracy: 0.9946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step\n",
      "Fold Accuracy: 0.9950\n",
      "Average Accuracy across 4 folds: 0.9946\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load your dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19']).values\n",
    "y = df['COVID-19'].values\n",
    "\n",
    "# Step 1: Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 2: Apply PCA\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Step 3: Build Autoencoder\n",
    "def create_autoencoder(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation='relu', input_shape=(input_dim,)))  # Increased neurons\n",
    "    model.add(Dropout(0.2))  # Dropout layer\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))  # Dropout layer\n",
    "    model.add(Dense(64, activation='relu'))  # Bottleneck layer\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(input_dim, activation='sigmoid'))  # Output layer\n",
    "    return model\n",
    "\n",
    "# Step 4: Train the Autoencoder\n",
    "autoencoder = create_autoencoder(X_pca.shape[1])\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\n",
    "\n",
    "# Fit the Autoencoder\n",
    "autoencoder.fit(X_pca, X_pca, epochs=100, batch_size=256, shuffle=True, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "# Step 5: Use the encoder part of the Autoencoder for further dimensionality reduction\n",
    "encoder = Sequential()\n",
    "encoder.add(Dense(256, activation='relu', input_shape=(X_pca.shape[1],)))  # Increased neurons\n",
    "encoder.add(Dropout(0.2))  # Dropout layer\n",
    "encoder.add(Dense(128, activation='relu'))\n",
    "encoder.add(Dropout(0.2))  # Dropout layer\n",
    "encoder.add(Dense(64, activation='relu'))  # Final reduced representation\n",
    "\n",
    "# Get the reduced features\n",
    "X_reduced = encoder.predict(X_pca)\n",
    "\n",
    "# Step 6: K-Fold Cross-Validation for Model Evaluation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_reduced):\n",
    "    X_train, X_test = X_reduced[train_index], X_reduced[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Build and Train the Classifier Model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(0.2))  # Dropout layer\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on your problem\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac6c5542-71e6-40b4-ad93-a9b36271632a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step\n",
      "Fold Accuracy: 0.9481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Early Stopping\u001b[39;00m\n\u001b[0;32m     46\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[early_stop])\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Evaluate the Model\u001b[39;00m\n\u001b[0;32m     51\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1553\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1554\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1555\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1556\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1557\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1558\u001b[0m   )\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load your dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19']).values\n",
    "y = df['COVID-19'].values\n",
    "\n",
    "# Step 1: Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 2: Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)  # Reduce to 2 dimensions for visualization\n",
    "X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "# Step 3: K-Fold Cross-Validation for Model Evaluation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_tsne):\n",
    "    X_train, X_test = X_tsne[train_index], X_tsne[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Build and Train the Classifier Model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))  # Adjusted neurons\n",
    "    model.add(Dropout(0.3))  # Dropout layer\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on your problem\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Early Stopping\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=120, batch_size=32, verbose=0, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2b3c222-a2b6-4eb8-8b82-054f14c25548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.8009 - val_loss: 0.3801\n",
      "Epoch 2/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4825 - val_loss: 0.3571\n",
      "Epoch 3/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4442 - val_loss: 0.3541\n",
      "Epoch 4/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4348 - val_loss: 0.3519\n",
      "Epoch 5/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4300 - val_loss: 0.3512\n",
      "Epoch 6/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4288 - val_loss: 0.3506\n",
      "Epoch 7/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4231 - val_loss: 0.3488\n",
      "Epoch 8/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4205 - val_loss: 0.3484\n",
      "Epoch 9/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4201 - val_loss: 0.3481\n",
      "Epoch 10/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4180 - val_loss: 0.3480\n",
      "Epoch 11/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4180 - val_loss: 0.3479\n",
      "Epoch 12/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4160 - val_loss: 0.3478\n",
      "Epoch 13/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4171 - val_loss: 0.3478\n",
      "Epoch 14/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4178 - val_loss: 0.3479\n",
      "Epoch 15/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4175 - val_loss: 0.3476\n",
      "Epoch 16/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4159 - val_loss: 0.3477\n",
      "Epoch 17/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4171 - val_loss: 0.3476\n",
      "Epoch 18/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4161 - val_loss: 0.3475\n",
      "Epoch 19/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4140 - val_loss: 0.3476\n",
      "Epoch 20/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4144 - val_loss: 0.3477\n",
      "Epoch 21/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4157 - val_loss: 0.3477\n",
      "Epoch 22/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4139 - val_loss: 0.3475\n",
      "Epoch 23/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4149 - val_loss: 0.3479\n",
      "Epoch 24/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4143 - val_loss: 0.3474\n",
      "Epoch 25/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4138 - val_loss: 0.3474\n",
      "Epoch 26/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4143 - val_loss: 0.3475\n",
      "Epoch 27/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4137 - val_loss: 0.3475\n",
      "Epoch 28/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4143 - val_loss: 0.3473\n",
      "Epoch 29/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4140 - val_loss: 0.3474\n",
      "Epoch 30/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4132 - val_loss: 0.3474\n",
      "Epoch 31/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4139 - val_loss: 0.3474\n",
      "Epoch 32/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4127 - val_loss: 0.3474\n",
      "Epoch 33/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4132 - val_loss: 0.3474\n",
      "Epoch 34/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4135 - val_loss: 0.3473\n",
      "Epoch 35/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4131 - val_loss: 0.3472\n",
      "Epoch 36/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4124 - val_loss: 0.3473\n",
      "Epoch 37/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4131 - val_loss: 0.3473\n",
      "Epoch 38/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4119 - val_loss: 0.3473\n",
      "Epoch 39/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4135 - val_loss: 0.3472\n",
      "Epoch 40/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4124 - val_loss: 0.3473\n",
      "Epoch 41/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4135 - val_loss: 0.3475\n",
      "Epoch 42/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4138 - val_loss: 0.3474\n",
      "Epoch 43/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4088 - val_loss: 0.3472\n",
      "Epoch 44/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4130 - val_loss: 0.3471\n",
      "Epoch 45/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4120 - val_loss: 0.3473\n",
      "Epoch 46/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4135 - val_loss: 0.3474\n",
      "Epoch 47/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4095 - val_loss: 0.3472\n",
      "Epoch 48/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4127 - val_loss: 0.3472\n",
      "Epoch 49/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4121 - val_loss: 0.3472\n",
      "Epoch 50/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4120 - val_loss: 0.3472\n",
      "Epoch 51/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4131 - val_loss: 0.3472\n",
      "Epoch 52/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4136 - val_loss: 0.3472\n",
      "Epoch 53/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4137 - val_loss: 0.3472\n",
      "Epoch 54/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4100 - val_loss: 0.3474\n",
      "Epoch 55/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4118 - val_loss: 0.3472\n",
      "Epoch 56/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4103 - val_loss: 0.3472\n",
      "Epoch 57/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4118 - val_loss: 0.3472\n",
      "Epoch 58/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4111 - val_loss: 0.3472\n",
      "Epoch 59/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4111 - val_loss: 0.3473\n",
      "Epoch 60/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4135 - val_loss: 0.3472\n",
      "Epoch 61/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4117 - val_loss: 0.3472\n",
      "Epoch 62/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4123 - val_loss: 0.3473\n",
      "Epoch 63/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4109 - val_loss: 0.3472\n",
      "Epoch 64/120\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4119 - val_loss: 0.3472\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step\n",
      "Fold Accuracy: 0.9953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step\n",
      "Fold Accuracy: 0.9937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step\n",
      "Fold Accuracy: 0.9943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step\n",
      "Fold Accuracy: 0.9947\n",
      "Average Accuracy across 4 folds: 0.9945\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "\n",
    "# Load your dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19']).values\n",
    "y = df['COVID-19'].values\n",
    "\n",
    "# Step 1: Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 2: Create Contrastive Loss Function\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1.0\n",
    "    square_pred = K.square(y_pred)\n",
    "    square_margin = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * square_margin)\n",
    "\n",
    "# Step 3: Build Contrastive Autoencoder\n",
    "def create_contrastive_autoencoder(input_dim):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(256, activation='relu')(input_layer)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    encoded = Dense(64, activation='relu')(x)  # Bottleneck layer\n",
    "\n",
    "    # Decoder\n",
    "    x = Dense(128, activation='relu')(encoded)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=decoded)\n",
    "    return model\n",
    "\n",
    "# Step 4: Train the Contrastive Autoencoder\n",
    "autoencoder = create_contrastive_autoencoder(X_scaled.shape[1])\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\n",
    "\n",
    "# Fit the Autoencoder\n",
    "autoencoder.fit(X_scaled, X_scaled, epochs=120, batch_size=256, shuffle=True, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "# Step 5: Use the encoder part of the Autoencoder for further dimensionality reduction\n",
    "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.layers[2].output)  # Get the encoder part\n",
    "\n",
    "# Get the reduced features\n",
    "X_reduced = encoder.predict(X_scaled)\n",
    "\n",
    "# Step 6: K-Fold Cross-Validation for Model Evaluation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_reduced):\n",
    "    X_train, X_test = X_reduced[train_index], X_reduced[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Build and Train the Classifier Model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))  # Adjusted neurons\n",
    "    model.add(Dropout(0.3))  # Dropout layer\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on your problem\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=120, batch_size=32, verbose=0, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "130bb3e7-20bb-4bf8-9a2c-7488755d93ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 1.1292 - val_loss: 0.8297\n",
      "Epoch 2/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8418 - val_loss: 0.7986\n",
      "Epoch 3/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7935 - val_loss: 0.7882\n",
      "Epoch 4/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7779 - val_loss: 0.7817\n",
      "Epoch 5/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7698 - val_loss: 0.7799\n",
      "Epoch 6/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7621 - val_loss: 0.7793\n",
      "Epoch 7/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7589 - val_loss: 0.7788\n",
      "Epoch 8/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7586 - val_loss: 0.7782\n",
      "Epoch 9/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7610 - val_loss: 0.7776\n",
      "Epoch 10/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7582 - val_loss: 0.7774\n",
      "Epoch 11/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7593 - val_loss: 0.7771\n",
      "Epoch 12/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7517 - val_loss: 0.7771\n",
      "Epoch 13/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7570 - val_loss: 0.7772\n",
      "Epoch 14/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7563 - val_loss: 0.7768\n",
      "Epoch 15/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7532 - val_loss: 0.7765\n",
      "Epoch 16/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7559 - val_loss: 0.7764\n",
      "Epoch 17/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7538 - val_loss: 0.7765\n",
      "Epoch 18/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7537 - val_loss: 0.7764\n",
      "Epoch 19/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7539 - val_loss: 0.7763\n",
      "Epoch 20/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7569 - val_loss: 0.7766\n",
      "Epoch 21/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7528 - val_loss: 0.7762\n",
      "Epoch 22/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7540 - val_loss: 0.7763\n",
      "Epoch 23/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7511 - val_loss: 0.7763\n",
      "Epoch 24/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7522 - val_loss: 0.7762\n",
      "Epoch 25/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7554 - val_loss: 0.7762\n",
      "Epoch 26/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7546 - val_loss: 0.7763\n",
      "Epoch 27/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7474 - val_loss: 0.7761\n",
      "Epoch 28/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7521 - val_loss: 0.7762\n",
      "Epoch 29/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7505 - val_loss: 0.7762\n",
      "Epoch 30/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7526 - val_loss: 0.7760\n",
      "Epoch 31/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7514 - val_loss: 0.7760\n",
      "Epoch 32/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7504 - val_loss: 0.7761\n",
      "Epoch 33/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7479 - val_loss: 0.7760\n",
      "Epoch 34/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7523 - val_loss: 0.7760\n",
      "Epoch 35/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7499 - val_loss: 0.7760\n",
      "Epoch 36/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7540 - val_loss: 0.7758\n",
      "Epoch 37/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7507 - val_loss: 0.7760\n",
      "Epoch 38/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7505 - val_loss: 0.7759\n",
      "Epoch 39/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7504 - val_loss: 0.7759\n",
      "Epoch 40/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7535 - val_loss: 0.7760\n",
      "Epoch 41/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7527 - val_loss: 0.7760\n",
      "Epoch 42/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7475 - val_loss: 0.7759\n",
      "Epoch 43/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7505 - val_loss: 0.7759\n",
      "Epoch 44/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7478 - val_loss: 0.7761\n",
      "Epoch 45/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7489 - val_loss: 0.7759\n",
      "Epoch 46/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7497 - val_loss: 0.7758\n",
      "Epoch 47/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7539 - val_loss: 0.7759\n",
      "Epoch 48/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7498 - val_loss: 0.7759\n",
      "Epoch 49/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7514 - val_loss: 0.7757\n",
      "Epoch 50/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7493 - val_loss: 0.7758\n",
      "Epoch 51/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7479 - val_loss: 0.7759\n",
      "Epoch 52/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7510 - val_loss: 0.7760\n",
      "Epoch 53/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7506 - val_loss: 0.7760\n",
      "Epoch 54/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7517 - val_loss: 0.7758\n",
      "Epoch 55/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7499 - val_loss: 0.7757\n",
      "Epoch 56/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7461 - val_loss: 0.7756\n",
      "Epoch 57/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7474 - val_loss: 0.7757\n",
      "Epoch 58/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7480 - val_loss: 0.7758\n",
      "Epoch 59/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7490 - val_loss: 0.7759\n",
      "Epoch 60/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7539 - val_loss: 0.7757\n",
      "Epoch 61/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7491 - val_loss: 0.7758\n",
      "Epoch 62/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7516 - val_loss: 0.7757\n",
      "Epoch 63/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7493 - val_loss: 0.7758\n",
      "Epoch 64/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7480 - val_loss: 0.7758\n",
      "Epoch 65/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7519 - val_loss: 0.7757\n",
      "Epoch 66/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7497 - val_loss: 0.7759\n",
      "Epoch 67/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7476 - val_loss: 0.7757\n",
      "Epoch 68/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7465 - val_loss: 0.7757\n",
      "Epoch 69/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7505 - val_loss: 0.7757\n",
      "Epoch 70/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7501 - val_loss: 0.7757\n",
      "Epoch 71/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7472 - val_loss: 0.7756\n",
      "Epoch 72/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7522 - val_loss: 0.7755\n",
      "Epoch 73/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7491 - val_loss: 0.7756\n",
      "Epoch 74/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7496 - val_loss: 0.7756\n",
      "Epoch 75/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7492 - val_loss: 0.7757\n",
      "Epoch 76/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7475 - val_loss: 0.7756\n",
      "Epoch 77/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7483 - val_loss: 0.7756\n",
      "Epoch 78/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7479 - val_loss: 0.7756\n",
      "Epoch 79/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7512 - val_loss: 0.7756\n",
      "Epoch 80/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7477 - val_loss: 0.7756\n",
      "Epoch 81/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7482 - val_loss: 0.7755\n",
      "Epoch 82/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7474 - val_loss: 0.7757\n",
      "Epoch 83/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7485 - val_loss: 0.7755\n",
      "Epoch 84/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7477 - val_loss: 0.7756\n",
      "Epoch 85/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7477 - val_loss: 0.7756\n",
      "Epoch 86/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7463 - val_loss: 0.7756\n",
      "Epoch 87/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7478 - val_loss: 0.7756\n",
      "Epoch 88/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7481 - val_loss: 0.7755\n",
      "Epoch 89/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7494 - val_loss: 0.7754\n",
      "Epoch 90/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7460 - val_loss: 0.7755\n",
      "Epoch 91/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7470 - val_loss: 0.7755\n",
      "Epoch 92/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7481 - val_loss: 0.7755\n",
      "Epoch 93/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7509 - val_loss: 0.7755\n",
      "Epoch 94/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7471 - val_loss: 0.7755\n",
      "Epoch 95/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7485 - val_loss: 0.7755\n",
      "Epoch 96/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7473 - val_loss: 0.7756\n",
      "Epoch 97/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7447 - val_loss: 0.7754\n",
      "Epoch 98/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7446 - val_loss: 0.7754\n",
      "Epoch 99/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7489 - val_loss: 0.7755\n",
      "Epoch 100/100\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7472 - val_loss: 0.7755\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold Accuracy: 0.9950\n",
      "Average Accuracy across 4 folds: 0.9947\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Conv1D, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "\n",
    "# Load your dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19']).values\n",
    "y = df['COVID-19'].values\n",
    "\n",
    "# Step 1: Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 2: Apply PCA\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Step 3: Create Contrastive Loss Function\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1.0\n",
    "    square_pred = K.square(y_pred)\n",
    "    square_margin = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * square_margin)\n",
    "\n",
    "# Step 4: Build Contrastive Autoencoder\n",
    "def create_contrastive_autoencoder(input_dim):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(256, activation='relu')(input_layer)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    encoded = Dense(64, activation='relu')(x)  # Bottleneck layer\n",
    "\n",
    "    # Decoder\n",
    "    x = Dense(128, activation='relu')(encoded)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=decoded)\n",
    "    return model\n",
    "\n",
    "# Step 5: Train the Contrastive Autoencoder\n",
    "autoencoder = create_contrastive_autoencoder(X_pca.shape[1])\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\n",
    "\n",
    "# Fit the Autoencoder\n",
    "autoencoder.fit(X_pca, X_pca, epochs=100, batch_size=256, shuffle=True, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "# Step 6: Use the encoder part of the Autoencoder for further dimensionality reduction\n",
    "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.layers[2].output)  # Get the encoder part\n",
    "\n",
    "# Get the reduced features\n",
    "X_reduced = encoder.predict(X_pca)\n",
    "\n",
    "# Reshape the data for 1D CNN\n",
    "X_reduced = X_reduced.reshape(X_reduced.shape[0], X_reduced.shape[1], 1)  # Reshape for 1D CNN\n",
    "\n",
    "# Step 7: K-Fold Cross-Validation for Model Evaluation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_reduced):\n",
    "    X_train, X_test = X_reduced[train_index], X_reduced[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Build and Train the 1D CNN Model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))  # 1D CNN layer\n",
    "    model.add(Dropout(0.3))  # Dropout layer\n",
    "    model.add(Flatten())  # Flatten the output\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))  # Dropout layer\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on your problem\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Early Stopping\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605ae169-e2fe-4fcf-9421-b74e37170557",
   "metadata": {},
   "source": [
    "<H1>Final Attempt</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4633ad2-5839-4a32-b9e0-da5ee3003d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features from variance threshold and tree-based selection: [ 1  0 11 13 15 12  6  9  7  8]\n",
      "Epoch 1/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 1.7511 - val_loss: 1.5385\n",
      "Epoch 2/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.3645 - val_loss: 1.4063\n",
      "Epoch 3/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2388 - val_loss: 1.3303\n",
      "Epoch 4/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1864 - val_loss: 1.2858\n",
      "Epoch 5/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1460 - val_loss: 1.2583\n",
      "Epoch 6/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1161 - val_loss: 1.2405\n",
      "Epoch 7/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1065 - val_loss: 1.2290\n",
      "Epoch 8/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0968 - val_loss: 1.2222\n",
      "Epoch 9/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0910 - val_loss: 1.2169\n",
      "Epoch 10/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0881 - val_loss: 1.2110\n",
      "Epoch 11/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0752 - val_loss: 1.2049\n",
      "Epoch 12/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0737 - val_loss: 1.2028\n",
      "Epoch 13/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0674 - val_loss: 1.2003\n",
      "Epoch 14/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0716 - val_loss: 1.1994\n",
      "Epoch 15/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0750 - val_loss: 1.1984\n",
      "Epoch 16/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0673 - val_loss: 1.1972\n",
      "Epoch 17/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0640 - val_loss: 1.1962\n",
      "Epoch 18/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0677 - val_loss: 1.1960\n",
      "Epoch 19/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0626 - val_loss: 1.1944\n",
      "Epoch 20/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0627 - val_loss: 1.1940\n",
      "Epoch 21/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0708 - val_loss: 1.1930\n",
      "Epoch 22/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0594 - val_loss: 1.1929\n",
      "Epoch 23/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0588 - val_loss: 1.1929\n",
      "Epoch 24/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0594 - val_loss: 1.1924\n",
      "Epoch 25/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0648 - val_loss: 1.1922\n",
      "Epoch 26/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0649 - val_loss: 1.1921\n",
      "Epoch 27/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0659 - val_loss: 1.1920\n",
      "Epoch 28/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0597 - val_loss: 1.1917\n",
      "Epoch 29/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0623 - val_loss: 1.1919\n",
      "Epoch 30/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0575 - val_loss: 1.1912\n",
      "Epoch 31/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0620 - val_loss: 1.1910\n",
      "Epoch 32/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0592 - val_loss: 1.1912\n",
      "Epoch 33/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0614 - val_loss: 1.1910\n",
      "Epoch 34/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0711 - val_loss: 1.1913\n",
      "Epoch 35/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0518 - val_loss: 1.1908\n",
      "Epoch 36/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0628 - val_loss: 1.1908\n",
      "Epoch 37/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0532 - val_loss: 1.1907\n",
      "Epoch 38/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0599 - val_loss: 1.1906\n",
      "Epoch 39/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0613 - val_loss: 1.1906\n",
      "Epoch 40/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0607 - val_loss: 1.1906\n",
      "Epoch 41/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0613 - val_loss: 1.1905\n",
      "Epoch 42/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0567 - val_loss: 1.1904\n",
      "Epoch 43/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0617 - val_loss: 1.1903\n",
      "Epoch 44/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0573 - val_loss: 1.1903\n",
      "Epoch 45/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0661 - val_loss: 1.1902\n",
      "Epoch 46/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0549 - val_loss: 1.1903\n",
      "Epoch 47/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.0615 - val_loss: 1.1903\n",
      "Epoch 48/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0579 - val_loss: 1.1903\n",
      "Epoch 49/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0627 - val_loss: 1.1901\n",
      "Epoch 50/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0515 - val_loss: 1.1901\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Encoded features from Autoencoder: [[0.         0.         0.04219176]\n",
      " [0.7110331  0.         1.3459703 ]\n",
      " [1.1241491  1.9770992  2.1872923 ]\n",
      " ...\n",
      " [0.9531751  1.4089651  0.        ]\n",
      " [0.         0.10160914 0.        ]\n",
      " [0.         0.         0.43296948]]\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7778 - loss: 0.4563 - val_accuracy: 0.9625 - val_loss: 0.1447\n",
      "Epoch 2/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8778 - loss: 0.2955 - val_accuracy: 0.9625 - val_loss: 0.1088\n",
      "Epoch 3/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8684 - loss: 0.2765 - val_accuracy: 0.9622 - val_loss: 0.0951\n",
      "Epoch 4/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8723 - loss: 0.2659 - val_accuracy: 0.9625 - val_loss: 0.0888\n",
      "Epoch 5/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8795 - loss: 0.2567 - val_accuracy: 0.9625 - val_loss: 0.0878\n",
      "Epoch 6/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8721 - loss: 0.2587 - val_accuracy: 0.9625 - val_loss: 0.0816\n",
      "Epoch 7/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8740 - loss: 0.2528 - val_accuracy: 0.9625 - val_loss: 0.0741\n",
      "Epoch 8/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8741 - loss: 0.2469 - val_accuracy: 0.9625 - val_loss: 0.0730\n",
      "Epoch 9/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8818 - loss: 0.2459 - val_accuracy: 0.9625 - val_loss: 0.0684\n",
      "Epoch 10/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8695 - loss: 0.2539 - val_accuracy: 0.9625 - val_loss: 0.0696\n",
      "Epoch 11/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8758 - loss: 0.2390 - val_accuracy: 0.9625 - val_loss: 0.0649\n",
      "Epoch 12/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8753 - loss: 0.2414 - val_accuracy: 0.9625 - val_loss: 0.0638\n",
      "Epoch 13/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8802 - loss: 0.2388 - val_accuracy: 0.9625 - val_loss: 0.0586\n",
      "Epoch 14/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8729 - loss: 0.2445 - val_accuracy: 0.9622 - val_loss: 0.0588\n",
      "Epoch 15/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8767 - loss: 0.2388 - val_accuracy: 0.9625 - val_loss: 0.0565\n",
      "Epoch 16/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8731 - loss: 0.2309 - val_accuracy: 0.9625 - val_loss: 0.0529\n",
      "Epoch 17/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8765 - loss: 0.2355 - val_accuracy: 0.9940 - val_loss: 0.0517\n",
      "Epoch 18/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8748 - loss: 0.2310 - val_accuracy: 0.9625 - val_loss: 0.0516\n",
      "Epoch 19/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8783 - loss: 0.2324 - val_accuracy: 0.9940 - val_loss: 0.0497\n",
      "Epoch 20/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8781 - loss: 0.2313 - val_accuracy: 0.9625 - val_loss: 0.0522\n",
      "Epoch 21/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8740 - loss: 0.2308 - val_accuracy: 0.9622 - val_loss: 0.0490\n",
      "Epoch 22/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8841 - loss: 0.2246 - val_accuracy: 0.9940 - val_loss: 0.0476\n",
      "Epoch 23/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8740 - loss: 0.2282 - val_accuracy: 0.9940 - val_loss: 0.0465\n",
      "Epoch 24/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8735 - loss: 0.2366 - val_accuracy: 0.9627 - val_loss: 0.0503\n",
      "Epoch 25/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8803 - loss: 0.2281 - val_accuracy: 0.9942 - val_loss: 0.0451\n",
      "Epoch 26/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8731 - loss: 0.2335 - val_accuracy: 0.9629 - val_loss: 0.0502\n",
      "Epoch 27/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8792 - loss: 0.2244 - val_accuracy: 0.9940 - val_loss: 0.0455\n",
      "Epoch 28/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8748 - loss: 0.2254 - val_accuracy: 0.9632 - val_loss: 0.0477\n",
      "Epoch 29/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8711 - loss: 0.2290 - val_accuracy: 0.9632 - val_loss: 0.0474\n",
      "Epoch 30/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8759 - loss: 0.2252 - val_accuracy: 0.9629 - val_loss: 0.0469\n",
      "Epoch 31/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8812 - loss: 0.2196 - val_accuracy: 0.9627 - val_loss: 0.0463\n",
      "Epoch 32/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8785 - loss: 0.2270 - val_accuracy: 0.9944 - val_loss: 0.0441\n",
      "Epoch 33/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8767 - loss: 0.2308 - val_accuracy: 0.9942 - val_loss: 0.0420\n",
      "Epoch 34/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8777 - loss: 0.2219 - val_accuracy: 0.9632 - val_loss: 0.0446\n",
      "Epoch 35/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8758 - loss: 0.2259 - val_accuracy: 0.9942 - val_loss: 0.0427\n",
      "Epoch 36/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8759 - loss: 0.2224 - val_accuracy: 0.9944 - val_loss: 0.0422\n",
      "Epoch 37/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8843 - loss: 0.2160 - val_accuracy: 0.9632 - val_loss: 0.0459\n",
      "Epoch 38/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8759 - loss: 0.2260 - val_accuracy: 0.9632 - val_loss: 0.0431\n",
      "Epoch 39/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8790 - loss: 0.2195 - val_accuracy: 0.9942 - val_loss: 0.0426\n",
      "Epoch 40/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8807 - loss: 0.2179 - val_accuracy: 0.9949 - val_loss: 0.0414\n",
      "Epoch 41/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8838 - loss: 0.2173 - val_accuracy: 0.9629 - val_loss: 0.0436\n",
      "Epoch 42/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8715 - loss: 0.2249 - val_accuracy: 0.9947 - val_loss: 0.0404\n",
      "Epoch 43/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8783 - loss: 0.2236 - val_accuracy: 0.9949 - val_loss: 0.0398\n",
      "Epoch 44/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8758 - loss: 0.2255 - val_accuracy: 0.9947 - val_loss: 0.0399\n",
      "Epoch 45/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8701 - loss: 0.2157 - val_accuracy: 0.9629 - val_loss: 0.0450\n",
      "Epoch 46/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8791 - loss: 0.2130 - val_accuracy: 0.9949 - val_loss: 0.0386\n",
      "Epoch 47/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8802 - loss: 0.2165 - val_accuracy: 0.9632 - val_loss: 0.0453\n",
      "Epoch 48/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8832 - loss: 0.2080 - val_accuracy: 0.9944 - val_loss: 0.0417\n",
      "Epoch 49/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8761 - loss: 0.2183 - val_accuracy: 0.9947 - val_loss: 0.0413\n",
      "Epoch 50/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8755 - loss: 0.2184 - val_accuracy: 0.9634 - val_loss: 0.0442\n",
      "Epoch 51/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8848 - loss: 0.2114 - val_accuracy: 0.9634 - val_loss: 0.0458\n",
      "Epoch 52/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8756 - loss: 0.2092 - val_accuracy: 0.9947 - val_loss: 0.0408\n",
      "Epoch 53/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8819 - loss: 0.2055 - val_accuracy: 0.9634 - val_loss: 0.0437\n",
      "Epoch 54/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8784 - loss: 0.2093 - val_accuracy: 0.9627 - val_loss: 0.0425\n",
      "Epoch 55/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8799 - loss: 0.2232 - val_accuracy: 0.9632 - val_loss: 0.0419\n",
      "Epoch 56/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8800 - loss: 0.2090 - val_accuracy: 0.9949 - val_loss: 0.0408\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8447 - loss: 0.2746\n",
      "Epoch 1/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7898 - loss: 0.4911 - val_accuracy: 0.9627 - val_loss: 0.1131\n",
      "Epoch 2/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8640 - loss: 0.2861 - val_accuracy: 0.9694 - val_loss: 0.0804\n",
      "Epoch 3/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8735 - loss: 0.2473 - val_accuracy: 0.9694 - val_loss: 0.0652\n",
      "Epoch 4/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8782 - loss: 0.2390 - val_accuracy: 0.9692 - val_loss: 0.0634\n",
      "Epoch 5/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8757 - loss: 0.2338 - val_accuracy: 0.9692 - val_loss: 0.0602\n",
      "Epoch 6/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8722 - loss: 0.2362 - val_accuracy: 0.9692 - val_loss: 0.0593\n",
      "Epoch 7/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8813 - loss: 0.2226 - val_accuracy: 0.9958 - val_loss: 0.0543\n",
      "Epoch 8/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8731 - loss: 0.2287 - val_accuracy: 0.9694 - val_loss: 0.0563\n",
      "Epoch 9/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8786 - loss: 0.2214 - val_accuracy: 0.9692 - val_loss: 0.0543\n",
      "Epoch 10/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8822 - loss: 0.2167 - val_accuracy: 0.9694 - val_loss: 0.0522\n",
      "Epoch 11/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8784 - loss: 0.2212 - val_accuracy: 0.9694 - val_loss: 0.0498\n",
      "Epoch 12/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8804 - loss: 0.2158 - val_accuracy: 0.9692 - val_loss: 0.0489\n",
      "Epoch 13/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8837 - loss: 0.2121 - val_accuracy: 0.9958 - val_loss: 0.0455\n",
      "Epoch 14/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8762 - loss: 0.2201 - val_accuracy: 0.9692 - val_loss: 0.0514\n",
      "Epoch 15/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8784 - loss: 0.2155 - val_accuracy: 0.9692 - val_loss: 0.0460\n",
      "Epoch 16/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8787 - loss: 0.2116 - val_accuracy: 0.9692 - val_loss: 0.0463\n",
      "Epoch 17/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8769 - loss: 0.2184 - val_accuracy: 0.9692 - val_loss: 0.0437\n",
      "Epoch 18/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8807 - loss: 0.2194 - val_accuracy: 0.9692 - val_loss: 0.0438\n",
      "Epoch 19/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8754 - loss: 0.2118 - val_accuracy: 0.9689 - val_loss: 0.0412\n",
      "Epoch 20/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8816 - loss: 0.2158 - val_accuracy: 0.9692 - val_loss: 0.0381\n",
      "Epoch 21/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8784 - loss: 0.2186 - val_accuracy: 0.9692 - val_loss: 0.0414\n",
      "Epoch 22/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8828 - loss: 0.2043 - val_accuracy: 0.9692 - val_loss: 0.0401\n",
      "Epoch 23/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8850 - loss: 0.2032 - val_accuracy: 0.9689 - val_loss: 0.0418\n",
      "Epoch 24/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8849 - loss: 0.2035 - val_accuracy: 0.9956 - val_loss: 0.0389\n",
      "Epoch 25/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8820 - loss: 0.2066 - val_accuracy: 0.9692 - val_loss: 0.0413\n",
      "Epoch 26/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8877 - loss: 0.2023 - val_accuracy: 0.9692 - val_loss: 0.0380\n",
      "Epoch 27/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8844 - loss: 0.2071 - val_accuracy: 0.9689 - val_loss: 0.0402\n",
      "Epoch 28/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8836 - loss: 0.2090 - val_accuracy: 0.9689 - val_loss: 0.0365\n",
      "Epoch 29/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8813 - loss: 0.2062 - val_accuracy: 0.9689 - val_loss: 0.0370\n",
      "Epoch 30/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8863 - loss: 0.1969 - val_accuracy: 0.9689 - val_loss: 0.0357\n",
      "Epoch 31/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8798 - loss: 0.2085 - val_accuracy: 0.9692 - val_loss: 0.0393\n",
      "Epoch 32/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8850 - loss: 0.2034 - val_accuracy: 0.9692 - val_loss: 0.0393\n",
      "Epoch 33/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8828 - loss: 0.2022 - val_accuracy: 0.9956 - val_loss: 0.0346\n",
      "Epoch 34/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8837 - loss: 0.2038 - val_accuracy: 0.9956 - val_loss: 0.0333\n",
      "Epoch 35/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8833 - loss: 0.1995 - val_accuracy: 0.9954 - val_loss: 0.0338\n",
      "Epoch 36/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8746 - loss: 0.2067 - val_accuracy: 0.9689 - val_loss: 0.0353\n",
      "Epoch 37/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8831 - loss: 0.2045 - val_accuracy: 0.9692 - val_loss: 0.0359\n",
      "Epoch 38/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8791 - loss: 0.2045 - val_accuracy: 0.9692 - val_loss: 0.0350\n",
      "Epoch 39/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8888 - loss: 0.2002 - val_accuracy: 0.9692 - val_loss: 0.0390\n",
      "Epoch 40/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8841 - loss: 0.1980 - val_accuracy: 0.9692 - val_loss: 0.0411\n",
      "Epoch 41/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8808 - loss: 0.2038 - val_accuracy: 0.9692 - val_loss: 0.0386\n",
      "Epoch 42/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8920 - loss: 0.1945 - val_accuracy: 0.9692 - val_loss: 0.0358\n",
      "Epoch 43/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8839 - loss: 0.1991 - val_accuracy: 0.9692 - val_loss: 0.0381\n",
      "Epoch 44/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8836 - loss: 0.1988 - val_accuracy: 0.9692 - val_loss: 0.0367\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8323 - loss: 0.2891\n",
      "Epoch 1/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7755 - loss: 0.4958 - val_accuracy: 0.9662 - val_loss: 0.1208\n",
      "Epoch 2/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8621 - loss: 0.2830 - val_accuracy: 0.9664 - val_loss: 0.0883\n",
      "Epoch 3/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8634 - loss: 0.2601 - val_accuracy: 0.9659 - val_loss: 0.0815\n",
      "Epoch 4/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8680 - loss: 0.2560 - val_accuracy: 0.9664 - val_loss: 0.0712\n",
      "Epoch 5/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8691 - loss: 0.2464 - val_accuracy: 0.9664 - val_loss: 0.0703\n",
      "Epoch 6/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8719 - loss: 0.2404 - val_accuracy: 0.9664 - val_loss: 0.0711\n",
      "Epoch 7/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8657 - loss: 0.2416 - val_accuracy: 0.9662 - val_loss: 0.0694\n",
      "Epoch 8/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8640 - loss: 0.2419 - val_accuracy: 0.9664 - val_loss: 0.0675\n",
      "Epoch 9/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8720 - loss: 0.2362 - val_accuracy: 0.9664 - val_loss: 0.0636\n",
      "Epoch 10/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8663 - loss: 0.2321 - val_accuracy: 0.9662 - val_loss: 0.0630\n",
      "Epoch 11/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8721 - loss: 0.2295 - val_accuracy: 0.9664 - val_loss: 0.0647\n",
      "Epoch 12/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8670 - loss: 0.2330 - val_accuracy: 0.9662 - val_loss: 0.0604\n",
      "Epoch 13/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8757 - loss: 0.2247 - val_accuracy: 0.9664 - val_loss: 0.0592\n",
      "Epoch 14/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8708 - loss: 0.2309 - val_accuracy: 0.9664 - val_loss: 0.0584\n",
      "Epoch 15/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8677 - loss: 0.2306 - val_accuracy: 0.9664 - val_loss: 0.0592\n",
      "Epoch 16/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8722 - loss: 0.2270 - val_accuracy: 0.9662 - val_loss: 0.0571\n",
      "Epoch 17/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8672 - loss: 0.2376 - val_accuracy: 0.9951 - val_loss: 0.0512\n",
      "Epoch 18/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8686 - loss: 0.2275 - val_accuracy: 0.9664 - val_loss: 0.0519\n",
      "Epoch 19/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8696 - loss: 0.2221 - val_accuracy: 0.9951 - val_loss: 0.0493\n",
      "Epoch 20/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8703 - loss: 0.2226 - val_accuracy: 0.9664 - val_loss: 0.0521\n",
      "Epoch 21/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8667 - loss: 0.2258 - val_accuracy: 0.9664 - val_loss: 0.0497\n",
      "Epoch 22/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8692 - loss: 0.2242 - val_accuracy: 0.9664 - val_loss: 0.0490\n",
      "Epoch 23/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8711 - loss: 0.2199 - val_accuracy: 0.9664 - val_loss: 0.0457\n",
      "Epoch 24/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8773 - loss: 0.2124 - val_accuracy: 0.9664 - val_loss: 0.0471\n",
      "Epoch 25/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8695 - loss: 0.2246 - val_accuracy: 0.9662 - val_loss: 0.0459\n",
      "Epoch 26/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8707 - loss: 0.2180 - val_accuracy: 0.9662 - val_loss: 0.0470\n",
      "Epoch 27/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8657 - loss: 0.2231 - val_accuracy: 0.9662 - val_loss: 0.0493\n",
      "Epoch 28/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8691 - loss: 0.2177 - val_accuracy: 0.9662 - val_loss: 0.0446\n",
      "Epoch 29/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8694 - loss: 0.2215 - val_accuracy: 0.9662 - val_loss: 0.0463\n",
      "Epoch 30/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8737 - loss: 0.2130 - val_accuracy: 0.9664 - val_loss: 0.0468\n",
      "Epoch 31/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8737 - loss: 0.2114 - val_accuracy: 0.9662 - val_loss: 0.0441\n",
      "Epoch 32/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8689 - loss: 0.2118 - val_accuracy: 0.9662 - val_loss: 0.0440\n",
      "Epoch 33/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8721 - loss: 0.2116 - val_accuracy: 0.9664 - val_loss: 0.0442\n",
      "Epoch 34/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8714 - loss: 0.2200 - val_accuracy: 0.9662 - val_loss: 0.0451\n",
      "Epoch 35/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8716 - loss: 0.2135 - val_accuracy: 0.9664 - val_loss: 0.0455\n",
      "Epoch 36/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8737 - loss: 0.2113 - val_accuracy: 0.9662 - val_loss: 0.0476\n",
      "Epoch 37/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8757 - loss: 0.2129 - val_accuracy: 0.9949 - val_loss: 0.0437\n",
      "Epoch 38/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8649 - loss: 0.2213 - val_accuracy: 0.9662 - val_loss: 0.0475\n",
      "Epoch 39/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8689 - loss: 0.2167 - val_accuracy: 0.9662 - val_loss: 0.0450\n",
      "Epoch 40/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8712 - loss: 0.2137 - val_accuracy: 0.9664 - val_loss: 0.0449\n",
      "Epoch 41/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8718 - loss: 0.2159 - val_accuracy: 0.9662 - val_loss: 0.0451\n",
      "Epoch 42/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8745 - loss: 0.2113 - val_accuracy: 0.9662 - val_loss: 0.0446\n",
      "Epoch 43/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8718 - loss: 0.2160 - val_accuracy: 0.9664 - val_loss: 0.0448\n",
      "Epoch 44/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8708 - loss: 0.2096 - val_accuracy: 0.9662 - val_loss: 0.0472\n",
      "Epoch 45/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8743 - loss: 0.2224 - val_accuracy: 0.9662 - val_loss: 0.0470\n",
      "Epoch 46/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8717 - loss: 0.2125 - val_accuracy: 0.9664 - val_loss: 0.0439\n",
      "Epoch 47/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8700 - loss: 0.2137 - val_accuracy: 0.9662 - val_loss: 0.0460\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8480 - loss: 0.2756\n",
      "Epoch 1/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7850 - loss: 0.4842 - val_accuracy: 0.9632 - val_loss: 0.1290\n",
      "Epoch 2/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8567 - loss: 0.2964 - val_accuracy: 0.9634 - val_loss: 0.0971\n",
      "Epoch 3/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8633 - loss: 0.2721 - val_accuracy: 0.9634 - val_loss: 0.0887\n",
      "Epoch 4/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8680 - loss: 0.2618 - val_accuracy: 0.9636 - val_loss: 0.0850\n",
      "Epoch 5/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8642 - loss: 0.2644 - val_accuracy: 0.9636 - val_loss: 0.0803\n",
      "Epoch 6/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8655 - loss: 0.2537 - val_accuracy: 0.9636 - val_loss: 0.0796\n",
      "Epoch 7/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8674 - loss: 0.2551 - val_accuracy: 0.9636 - val_loss: 0.0790\n",
      "Epoch 8/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8702 - loss: 0.2433 - val_accuracy: 0.9634 - val_loss: 0.0768\n",
      "Epoch 9/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8727 - loss: 0.2418 - val_accuracy: 0.9634 - val_loss: 0.0737\n",
      "Epoch 10/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8683 - loss: 0.2381 - val_accuracy: 0.9634 - val_loss: 0.0751\n",
      "Epoch 11/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8658 - loss: 0.2477 - val_accuracy: 0.9634 - val_loss: 0.0746\n",
      "Epoch 12/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8660 - loss: 0.2426 - val_accuracy: 0.9632 - val_loss: 0.0726\n",
      "Epoch 13/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8699 - loss: 0.2368 - val_accuracy: 0.9632 - val_loss: 0.0744\n",
      "Epoch 14/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8727 - loss: 0.2329 - val_accuracy: 0.9634 - val_loss: 0.0692\n",
      "Epoch 15/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8689 - loss: 0.2372 - val_accuracy: 0.9632 - val_loss: 0.0719\n",
      "Epoch 16/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8739 - loss: 0.2290 - val_accuracy: 0.9935 - val_loss: 0.0672\n",
      "Epoch 17/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8680 - loss: 0.2331 - val_accuracy: 0.9634 - val_loss: 0.0682\n",
      "Epoch 18/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8729 - loss: 0.2353 - val_accuracy: 0.9632 - val_loss: 0.0676\n",
      "Epoch 19/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8631 - loss: 0.2397 - val_accuracy: 0.9632 - val_loss: 0.0668\n",
      "Epoch 20/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8738 - loss: 0.2287 - val_accuracy: 0.9935 - val_loss: 0.0643\n",
      "Epoch 21/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8671 - loss: 0.2298 - val_accuracy: 0.9634 - val_loss: 0.0691\n",
      "Epoch 22/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8694 - loss: 0.2289 - val_accuracy: 0.9634 - val_loss: 0.0668\n",
      "Epoch 23/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8736 - loss: 0.2288 - val_accuracy: 0.9632 - val_loss: 0.0655\n",
      "Epoch 24/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8763 - loss: 0.2331 - val_accuracy: 0.9634 - val_loss: 0.0682\n",
      "Epoch 25/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8702 - loss: 0.2226 - val_accuracy: 0.9634 - val_loss: 0.0630\n",
      "Epoch 26/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8663 - loss: 0.2328 - val_accuracy: 0.9634 - val_loss: 0.0598\n",
      "Epoch 27/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8717 - loss: 0.2248 - val_accuracy: 0.9632 - val_loss: 0.0613\n",
      "Epoch 28/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8717 - loss: 0.2234 - val_accuracy: 0.9632 - val_loss: 0.0610\n",
      "Epoch 29/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8690 - loss: 0.2206 - val_accuracy: 0.9634 - val_loss: 0.0588\n",
      "Epoch 30/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8672 - loss: 0.2273 - val_accuracy: 0.9632 - val_loss: 0.0562\n",
      "Epoch 31/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8729 - loss: 0.2221 - val_accuracy: 0.9632 - val_loss: 0.0562\n",
      "Epoch 32/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8693 - loss: 0.2239 - val_accuracy: 0.9634 - val_loss: 0.0559\n",
      "Epoch 33/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8714 - loss: 0.2212 - val_accuracy: 0.9634 - val_loss: 0.0590\n",
      "Epoch 34/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8695 - loss: 0.2249 - val_accuracy: 0.9634 - val_loss: 0.0578\n",
      "Epoch 35/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8702 - loss: 0.2193 - val_accuracy: 0.9632 - val_loss: 0.0570\n",
      "Epoch 36/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8679 - loss: 0.2236 - val_accuracy: 0.9634 - val_loss: 0.0548\n",
      "Epoch 37/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8681 - loss: 0.2222 - val_accuracy: 0.9632 - val_loss: 0.0575\n",
      "Epoch 38/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8688 - loss: 0.2159 - val_accuracy: 0.9634 - val_loss: 0.0590\n",
      "Epoch 39/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8685 - loss: 0.2216 - val_accuracy: 0.9634 - val_loss: 0.0543\n",
      "Epoch 40/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8701 - loss: 0.2159 - val_accuracy: 0.9634 - val_loss: 0.0554\n",
      "Epoch 41/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8699 - loss: 0.2115 - val_accuracy: 0.9634 - val_loss: 0.0554\n",
      "Epoch 42/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8751 - loss: 0.2140 - val_accuracy: 0.9634 - val_loss: 0.0566\n",
      "Epoch 43/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8729 - loss: 0.2205 - val_accuracy: 0.9634 - val_loss: 0.0542\n",
      "Epoch 44/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8694 - loss: 0.2228 - val_accuracy: 0.9634 - val_loss: 0.0539\n",
      "Epoch 45/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8724 - loss: 0.2175 - val_accuracy: 0.9632 - val_loss: 0.0555\n",
      "Epoch 46/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8710 - loss: 0.2168 - val_accuracy: 0.9634 - val_loss: 0.0517\n",
      "Epoch 47/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8690 - loss: 0.2220 - val_accuracy: 0.9937 - val_loss: 0.0506\n",
      "Epoch 48/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8679 - loss: 0.2191 - val_accuracy: 0.9634 - val_loss: 0.0515\n",
      "Epoch 49/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8693 - loss: 0.2254 - val_accuracy: 0.9634 - val_loss: 0.0540\n",
      "Epoch 50/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8739 - loss: 0.2188 - val_accuracy: 0.9634 - val_loss: 0.0543\n",
      "Epoch 51/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8726 - loss: 0.2169 - val_accuracy: 0.9632 - val_loss: 0.0517\n",
      "Epoch 52/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8703 - loss: 0.2258 - val_accuracy: 0.9634 - val_loss: 0.0544\n",
      "Epoch 53/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8731 - loss: 0.2197 - val_accuracy: 0.9634 - val_loss: 0.0527\n",
      "Epoch 54/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8688 - loss: 0.2194 - val_accuracy: 0.9638 - val_loss: 0.0522\n",
      "Epoch 55/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8723 - loss: 0.2142 - val_accuracy: 0.9634 - val_loss: 0.0533\n",
      "Epoch 56/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8715 - loss: 0.2219 - val_accuracy: 0.9634 - val_loss: 0.0533\n",
      "Epoch 57/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8711 - loss: 0.2216 - val_accuracy: 0.9634 - val_loss: 0.0518\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8464 - loss: 0.2745\n",
      "Average accuracy across folds: 0.9032541066408157\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Flatten, Dense, Dropout, Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "\n",
    "# Load your dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19']).values\n",
    "y = df['COVID-19'].values\n",
    "# Step 1: Feature Selection\n",
    "# Variance Threshold\n",
    "var_thresh = VarianceThreshold(threshold=0.1)\n",
    "X_var = var_thresh.fit_transform(X)\n",
    "\n",
    "# Tree-based feature selection\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_var, y)\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Select top features based on importance\n",
    "n_top_features = 10  # Adjust as needed\n",
    "top_features = indices[:n_top_features]\n",
    "X_selected = X_var[:, top_features]\n",
    "\n",
    "# Print selected features\n",
    "print(\"Selected features from variance threshold and tree-based selection:\", top_features)\n",
    "\n",
    "# Step 2: Dimensionality Reduction\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_selected)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=5)  # Adjust number of components as needed\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Autoencoder\n",
    "input_dim = X_pca.shape[1]\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(Input(shape=(input_dim,)))\n",
    "autoencoder.add(Dense(3, activation='relu'))  # Bottleneck layer\n",
    "autoencoder.add(Dense(input_dim, activation='sigmoid'))  # Output layer\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoencoder.fit(X_pca, X_pca, epochs=50, batch_size=32, shuffle=True, validation_split=0.2)\n",
    "\n",
    "# Get encoded features\n",
    "encoder = Sequential()\n",
    "encoder.add(Input(shape=(input_dim,)))\n",
    "encoder.add(Dense(3, activation='relu'))  # Bottleneck layer\n",
    "encoded_features = encoder.predict(X_pca)\n",
    "\n",
    "# Print encoded features\n",
    "print(\"Encoded features from Autoencoder:\", encoded_features)\n",
    "\n",
    "# Step 3: 1D CNN with k-fold validation\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(encoded_features):\n",
    "    X_train, X_test = encoded_features[train_index], encoded_features[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Reshape for 1D CNN\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    # Build 1D CNN model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Print average accuracy across folds\n",
    "print(\"Average accuracy across folds:\", np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9ac8b6-6047-4605-9e16-0bfb9f9d3744",
   "metadata": {},
   "source": [
    "# Claude Improveed CNN Architecture Variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71429672-f8d3-453e-9aaa-9ace8037174f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected by Variance Threshold:\n",
      "Breathing Problem\n",
      "Sore throat\n",
      "Running Nose\n",
      "Asthma\n",
      "Chronic Lung Disease\n",
      "Headache\n",
      "Heart Disease\n",
      "Diabetes\n",
      "Hyper Tension\n",
      "Fatigue \n",
      "Gastrointestinal \n",
      "Abroad travel\n",
      "Contact with COVID Patient\n",
      "Attended Large Gathering\n",
      "Visited Public Exposed Places\n",
      "Family working in Public Exposed Places\n",
      "Training fold 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │             \u001b[38;5;34m128\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m6,208\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │          \u001b[38;5;34m24,704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m16,448\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,881</span> (198.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,881\u001b[0m (198.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,241</span> (196.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,241\u001b[0m (196.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.8645 - loss: 0.3087 - val_accuracy: 0.9956 - val_loss: 0.0239\n",
      "Epoch 2/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9569 - loss: 0.1175 - val_accuracy: 0.9963 - val_loss: 0.0148\n",
      "Epoch 3/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9695 - loss: 0.0931 - val_accuracy: 0.9961 - val_loss: 0.0143\n",
      "Epoch 4/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9746 - loss: 0.0743 - val_accuracy: 0.9965 - val_loss: 0.0135\n",
      "Epoch 5/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9755 - loss: 0.0784 - val_accuracy: 0.9968 - val_loss: 0.0131\n",
      "Epoch 6/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9791 - loss: 0.0638 - val_accuracy: 0.9965 - val_loss: 0.0139\n",
      "Epoch 7/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9808 - loss: 0.0621 - val_accuracy: 0.9965 - val_loss: 0.0128\n",
      "Epoch 8/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9809 - loss: 0.0590 - val_accuracy: 0.9963 - val_loss: 0.0125\n",
      "Epoch 9/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9847 - loss: 0.0481 - val_accuracy: 0.9965 - val_loss: 0.0122\n",
      "Epoch 10/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9825 - loss: 0.0554 - val_accuracy: 0.9963 - val_loss: 0.0139\n",
      "Epoch 11/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9834 - loss: 0.0462 - val_accuracy: 0.9970 - val_loss: 0.0123\n",
      "Epoch 12/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9871 - loss: 0.0460 - val_accuracy: 0.9970 - val_loss: 0.0130\n",
      "Epoch 13/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9876 - loss: 0.0397 - val_accuracy: 0.9972 - val_loss: 0.0128\n",
      "Epoch 14/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9870 - loss: 0.0451 - val_accuracy: 0.9972 - val_loss: 0.0129\n",
      "Epoch 15/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9870 - loss: 0.0413 - val_accuracy: 0.9972 - val_loss: 0.0120\n",
      "Epoch 16/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9880 - loss: 0.0398 - val_accuracy: 0.9975 - val_loss: 0.0117\n",
      "Epoch 17/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9894 - loss: 0.0389 - val_accuracy: 0.9972 - val_loss: 0.0124\n",
      "Epoch 18/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9890 - loss: 0.0377 - val_accuracy: 0.9970 - val_loss: 0.0119\n",
      "Epoch 19/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9883 - loss: 0.0383 - val_accuracy: 0.9970 - val_loss: 0.0135\n",
      "Epoch 20/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9904 - loss: 0.0322 - val_accuracy: 0.9965 - val_loss: 0.0130\n",
      "Epoch 21/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9896 - loss: 0.0358 - val_accuracy: 0.9965 - val_loss: 0.0137\n",
      "Epoch 22/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9899 - loss: 0.0360 - val_accuracy: 0.9972 - val_loss: 0.0148\n",
      "Epoch 23/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9899 - loss: 0.0319 - val_accuracy: 0.9965 - val_loss: 0.0139\n",
      "Epoch 24/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9903 - loss: 0.0320 - val_accuracy: 0.9965 - val_loss: 0.0140\n",
      "Epoch 25/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9899 - loss: 0.0349 - val_accuracy: 0.9972 - val_loss: 0.0121\n",
      "Epoch 26/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9901 - loss: 0.0323 - val_accuracy: 0.9963 - val_loss: 0.0135\n",
      "Epoch 27/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9903 - loss: 0.0342 - val_accuracy: 0.9965 - val_loss: 0.0152\n",
      "Epoch 28/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9912 - loss: 0.0308 - val_accuracy: 0.9968 - val_loss: 0.0152\n",
      "Epoch 29/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9892 - loss: 0.0370 - val_accuracy: 0.9956 - val_loss: 0.0152\n",
      "Epoch 30/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9917 - loss: 0.0317 - val_accuracy: 0.9965 - val_loss: 0.0148\n",
      "Epoch 31/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9915 - loss: 0.0296 - val_accuracy: 0.9963 - val_loss: 0.0144\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "Fold 1 Results:\n",
      "Accuracy: 0.9953\n",
      "Precision: 0.9984\n",
      "Recall: 0.9882\n",
      "F1 Score: 0.9933\n",
      "AUC: 0.9996\n",
      "----------------------------------------\n",
      "Training fold 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.8782 - loss: 0.2803 - val_accuracy: 0.9954 - val_loss: 0.0266\n",
      "Epoch 2/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9656 - loss: 0.0986 - val_accuracy: 0.9968 - val_loss: 0.0125\n",
      "Epoch 3/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9717 - loss: 0.0817 - val_accuracy: 0.9965 - val_loss: 0.0121\n",
      "Epoch 4/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9723 - loss: 0.0756 - val_accuracy: 0.9977 - val_loss: 0.0085\n",
      "Epoch 5/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9770 - loss: 0.0671 - val_accuracy: 0.9979 - val_loss: 0.0077\n",
      "Epoch 6/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9799 - loss: 0.0598 - val_accuracy: 0.9977 - val_loss: 0.0098\n",
      "Epoch 7/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9832 - loss: 0.0543 - val_accuracy: 0.9981 - val_loss: 0.0066\n",
      "Epoch 8/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9831 - loss: 0.0523 - val_accuracy: 0.9981 - val_loss: 0.0078\n",
      "Epoch 9/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9820 - loss: 0.0525 - val_accuracy: 0.9979 - val_loss: 0.0071\n",
      "Epoch 10/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9845 - loss: 0.0474 - val_accuracy: 0.9979 - val_loss: 0.0091\n",
      "Epoch 11/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.0477 - val_accuracy: 0.9981 - val_loss: 0.0070\n",
      "Epoch 12/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9847 - loss: 0.0483 - val_accuracy: 0.9979 - val_loss: 0.0098\n",
      "Epoch 13/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9865 - loss: 0.0434 - val_accuracy: 0.9981 - val_loss: 0.0084\n",
      "Epoch 14/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9882 - loss: 0.0405 - val_accuracy: 0.9984 - val_loss: 0.0063\n",
      "Epoch 15/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9867 - loss: 0.0409 - val_accuracy: 0.9981 - val_loss: 0.0086\n",
      "Epoch 16/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9876 - loss: 0.0385 - val_accuracy: 0.9984 - val_loss: 0.0077\n",
      "Epoch 17/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9890 - loss: 0.0402 - val_accuracy: 0.9981 - val_loss: 0.0075\n",
      "Epoch 18/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9900 - loss: 0.0352 - val_accuracy: 0.9984 - val_loss: 0.0073\n",
      "Epoch 19/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9900 - loss: 0.0338 - val_accuracy: 0.9986 - val_loss: 0.0072\n",
      "Epoch 20/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9889 - loss: 0.0348 - val_accuracy: 0.9984 - val_loss: 0.0072\n",
      "Epoch 21/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9894 - loss: 0.0373 - val_accuracy: 0.9984 - val_loss: 0.0082\n",
      "Epoch 22/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9891 - loss: 0.0365 - val_accuracy: 0.9984 - val_loss: 0.0082\n",
      "Epoch 23/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9896 - loss: 0.0357 - val_accuracy: 0.9986 - val_loss: 0.0067\n",
      "Epoch 24/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9900 - loss: 0.0341 - val_accuracy: 0.9986 - val_loss: 0.0079\n",
      "Epoch 25/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9918 - loss: 0.0290 - val_accuracy: 0.9984 - val_loss: 0.0072\n",
      "Epoch 26/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9926 - loss: 0.0273 - val_accuracy: 0.9984 - val_loss: 0.0079\n",
      "Epoch 27/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9911 - loss: 0.0335 - val_accuracy: 0.9984 - val_loss: 0.0075\n",
      "Epoch 28/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9897 - loss: 0.0322 - val_accuracy: 0.9986 - val_loss: 0.0074\n",
      "Epoch 29/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9909 - loss: 0.0333 - val_accuracy: 0.9986 - val_loss: 0.0071\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "Fold 2 Results:\n",
      "Accuracy: 0.9918\n",
      "Precision: 0.9984\n",
      "Recall: 0.9785\n",
      "F1 Score: 0.9884\n",
      "AUC: 0.9989\n",
      "----------------------------------------\n",
      "Training fold 3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8691 - loss: 0.2992 - val_accuracy: 0.9972 - val_loss: 0.0187\n",
      "Epoch 2/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9599 - loss: 0.1148 - val_accuracy: 0.9965 - val_loss: 0.0117\n",
      "Epoch 3/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9696 - loss: 0.0845 - val_accuracy: 0.9977 - val_loss: 0.0089\n",
      "Epoch 4/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9738 - loss: 0.0721 - val_accuracy: 0.9975 - val_loss: 0.0101\n",
      "Epoch 5/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9760 - loss: 0.0699 - val_accuracy: 0.9979 - val_loss: 0.0091\n",
      "Epoch 6/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9784 - loss: 0.0600 - val_accuracy: 0.9972 - val_loss: 0.0094\n",
      "Epoch 7/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0550 - val_accuracy: 0.9979 - val_loss: 0.0093\n",
      "Epoch 8/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9841 - loss: 0.0508 - val_accuracy: 0.9981 - val_loss: 0.0091\n",
      "Epoch 9/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9826 - loss: 0.0525 - val_accuracy: 0.9977 - val_loss: 0.0092\n",
      "Epoch 10/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9820 - loss: 0.0529 - val_accuracy: 0.9975 - val_loss: 0.0101\n",
      "Epoch 11/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9860 - loss: 0.0458 - val_accuracy: 0.9979 - val_loss: 0.0108\n",
      "Epoch 12/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9849 - loss: 0.0513 - val_accuracy: 0.9975 - val_loss: 0.0108\n",
      "Epoch 13/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9879 - loss: 0.0422 - val_accuracy: 0.9977 - val_loss: 0.0105\n",
      "Epoch 14/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9883 - loss: 0.0395 - val_accuracy: 0.9977 - val_loss: 0.0117\n",
      "Epoch 15/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9881 - loss: 0.0431 - val_accuracy: 0.9981 - val_loss: 0.0104\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "Fold 3 Results:\n",
      "Accuracy: 0.9797\n",
      "Precision: 0.9664\n",
      "Recall: 0.9782\n",
      "F1 Score: 0.9723\n",
      "AUC: 0.9983\n",
      "----------------------------------------\n",
      "Training fold 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurok\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8913 - loss: 0.2654 - val_accuracy: 0.9949 - val_loss: 0.0260\n",
      "Epoch 2/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9655 - loss: 0.1008 - val_accuracy: 0.9961 - val_loss: 0.0178\n",
      "Epoch 3/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9717 - loss: 0.0843 - val_accuracy: 0.9942 - val_loss: 0.0170\n",
      "Epoch 4/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9756 - loss: 0.0768 - val_accuracy: 0.9963 - val_loss: 0.0146\n",
      "Epoch 5/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9762 - loss: 0.0717 - val_accuracy: 0.9963 - val_loss: 0.0151\n",
      "Epoch 6/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9807 - loss: 0.0581 - val_accuracy: 0.9961 - val_loss: 0.0141\n",
      "Epoch 7/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9825 - loss: 0.0618 - val_accuracy: 0.9970 - val_loss: 0.0130\n",
      "Epoch 8/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9822 - loss: 0.0550 - val_accuracy: 0.9965 - val_loss: 0.0144\n",
      "Epoch 9/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9855 - loss: 0.0497 - val_accuracy: 0.9968 - val_loss: 0.0131\n",
      "Epoch 10/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9850 - loss: 0.0509 - val_accuracy: 0.9968 - val_loss: 0.0139\n",
      "Epoch 11/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9854 - loss: 0.0484 - val_accuracy: 0.9963 - val_loss: 0.0140\n",
      "Epoch 12/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9876 - loss: 0.0414 - val_accuracy: 0.9968 - val_loss: 0.0125\n",
      "Epoch 13/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9889 - loss: 0.0389 - val_accuracy: 0.9965 - val_loss: 0.0134\n",
      "Epoch 14/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9876 - loss: 0.0436 - val_accuracy: 0.9970 - val_loss: 0.0128\n",
      "Epoch 15/100\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9878 - loss: 0.0399 - val_accuracy: 0.9972 - val_loss: 0.0138\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "Fold 4 Results:\n",
      "Accuracy: 0.9835\n",
      "Precision: 0.9926\n",
      "Recall: 0.9600\n",
      "F1 Score: 0.9761\n",
      "AUC: 0.9985\n",
      "----------------------------------------\n",
      "\n",
      "Average Metrics across all folds:\n",
      "Average Accuracy: 0.9876 ± 0.0062\n",
      "Average Precision: 0.9890 ± 0.0132\n",
      "Average Recall: 0.9762 ± 0.0102\n",
      "Average F1: 0.9825 ± 0.0086\n",
      "Average Auc: 0.9988 ± 0.0005\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Flatten, Dense, MaxPooling1D, Dropout, BatchNormalization\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with the correct path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['COVID-19'])\n",
    "y = df['COVID-19']\n",
    "\n",
    "# Variance Threshold Function\n",
    "def variance_threshold(X, threshold=0.1):\n",
    "    selector = VarianceThreshold(threshold)\n",
    "    selector.fit(X)\n",
    "    return X.columns[selector.get_support()]\n",
    "\n",
    "# Apply Variance Threshold\n",
    "selected_features = variance_threshold(X)\n",
    "\n",
    "# Print the features selected by Variance Threshold\n",
    "print(\"Features Selected by Variance Threshold:\")\n",
    "for feature in selected_features:\n",
    "    print(feature)\n",
    "\n",
    "# Filter the dataset to keep only the selected features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Prepare Data for 1D CNN\n",
    "X_selected = X_selected.values.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Reshape for CNN\n",
    "y = y.values  # Convert target variable to numpy array\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "metrics = {\n",
    "    'accuracy': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'f1': [],\n",
    "    'auc': []\n",
    "}\n",
    "\n",
    "# Early Stopping with improved patience\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_selected)):\n",
    "    print(f\"Training fold {fold+1}/{k}\")\n",
    "    \n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Build and Train an improved 1D CNN Model\n",
    "    model = Sequential([\n",
    "        # First Conv Block\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu', padding='same', \n",
    "               input_shape=(X_selected.shape[1], 1)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2, padding='same'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Second Conv Block\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2, padding='same'),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Third Conv Block (optional, depending on your feature size)\n",
    "        Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2, padding='same'),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        # Flattening and Dense layers\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(32, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compile model with binary classification setup\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Print model summary for the first fold\n",
    "    if fold == 0:\n",
    "        model.summary()\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        verbose=1,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "    \n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "    \n",
    "    # Calculate and store metrics\n",
    "    metrics['accuracy'].append(accuracy_score(y_test, y_pred_classes))\n",
    "    metrics['precision'].append(precision_score(y_test, y_pred_classes))\n",
    "    metrics['recall'].append(recall_score(y_test, y_pred_classes))\n",
    "    metrics['f1'].append(f1_score(y_test, y_pred_classes))\n",
    "    metrics['auc'].append(roc_auc_score(y_test, y_pred))\n",
    "    \n",
    "    # Print fold results\n",
    "    print(f\"Fold {fold+1} Results:\")\n",
    "    print(f\"Accuracy: {metrics['accuracy'][-1]:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision'][-1]:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall'][-1]:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1'][-1]:.4f}\")\n",
    "    print(f\"AUC: {metrics['auc'][-1]:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Calculate and print average metrics across all folds\n",
    "print(\"\\nAverage Metrics across all folds:\")\n",
    "for metric, values in metrics.items():\n",
    "    print(f\"Average {metric.capitalize()}: {np.mean(values):.4f} ± {np.std(values):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149608b3-4e86-46d7-8ddc-436aad486d1d",
   "metadata": {},
   "source": [
    "# Suitable FS comparitive analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3d709ec-0f09-4617-8281-74e30730010f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded: 28766 samples, 20 features\n",
      "Class distribution: {0: 18514, 1: 10252}\n",
      "Initializing feature selection techniques...\n",
      "\n",
      "==================================================\n",
      "Processing 1. Chi-Square\n",
      "==================================================\n",
      "Selecting features using 1. Chi-Square...\n",
      "Top 10 features selected by 1. Chi-Square:\n",
      "1. Breathing Problem: 9964.0393\n",
      "2. Sore throat: 13201.1649\n",
      "3. Heart Disease: 3552.0005\n",
      "4. Diabetes: 1929.1672\n",
      "5. Hyper Tension: 3089.5719\n",
      "6. Gastrointestinal : 1693.0652\n",
      "7. Abroad travel: 11288.4346\n",
      "8. Contact with COVID Patient: 8194.1488\n",
      "9. Attended Large Gathering: 9140.5020\n",
      "10. Family working in Public Exposed Places: 7781.7278\n",
      "\n",
      "Training CNN with features selected by 1. Chi-Square\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "\n",
      "Results for 1. Chi-Square:\n",
      "Average accuracy: 0.9833 ± 0.0040\n",
      "Average precision: 0.9941 ± 0.0036\n",
      "Average recall: 0.9592 ± 0.0123\n",
      "Average f1: 0.9763 ± 0.0055\n",
      "Average auc: 0.9987 ± 0.0003\n",
      "\n",
      "==================================================\n",
      "Processing 2. Mutual Information\n",
      "==================================================\n",
      "Selecting features using 2. Mutual Information...\n",
      "Top 10 features selected by 2. Mutual Information:\n",
      "1. Breathing Problem: 0.3088\n",
      "2. Sore throat: 0.4123\n",
      "3. Heart Disease: 0.0913\n",
      "4. Diabetes: 0.1108\n",
      "5. Hyper Tension: 0.0735\n",
      "6. Gastrointestinal : 0.0817\n",
      "7. Abroad travel: 0.2871\n",
      "8. Contact with COVID Patient: 0.1847\n",
      "9. Attended Large Gathering: 0.2381\n",
      "10. Family working in Public Exposed Places: 0.2183\n",
      "\n",
      "Training CNN with features selected by 2. Mutual Information\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "Results for 2. Mutual Information:\n",
      "Average accuracy: 0.9845 ± 0.0023\n",
      "Average precision: 0.9956 ± 0.0035\n",
      "Average recall: 0.9608 ± 0.0061\n",
      "Average f1: 0.9778 ± 0.0029\n",
      "Average auc: 0.9986 ± 0.0003\n",
      "\n",
      "==================================================\n",
      "Processing 3. Recursive Feature Elimination\n",
      "==================================================\n",
      "Selecting features using 3. Recursive Feature Elimination...\n",
      "Top 10 features selected by 3. Recursive Feature Elimination:\n",
      "1. Breathing Problem: 1.0000\n",
      "2. Fever: 1.0000\n",
      "3. Dry Cough: 1.0000\n",
      "4. Sore throat: 1.0000\n",
      "5. Hyper Tension: 1.0000\n",
      "6. Abroad travel: 1.0000\n",
      "7. Contact with COVID Patient: 1.0000\n",
      "8. Attended Large Gathering: 1.0000\n",
      "9. Visited Public Exposed Places: 1.0000\n",
      "10. Family working in Public Exposed Places: 1.0000\n",
      "\n",
      "Training CNN with features selected by 3. Recursive Feature Elimination\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Results for 3. Recursive Feature Elimination:\n",
      "Average accuracy: 0.9787 ± 0.0013\n",
      "Average precision: 0.9789 ± 0.0063\n",
      "Average recall: 0.9609 ± 0.0064\n",
      "Average f1: 0.9698 ± 0.0015\n",
      "Average auc: 0.9979 ± 0.0004\n",
      "\n",
      "==================================================\n",
      "Processing 4. Lasso\n",
      "==================================================\n",
      "Selecting features using 4. Lasso...\n",
      "Top 10 features selected by 4. Lasso:\n",
      "1. Breathing Problem: 1.0000\n",
      "2. Sore throat: 1.0000\n",
      "3. Fatigue : 1.0000\n",
      "4. Abroad travel: 1.0000\n",
      "5. Contact with COVID Patient: 1.0000\n",
      "6. Attended Large Gathering: 1.0000\n",
      "7. Visited Public Exposed Places: 1.0000\n",
      "8. Family working in Public Exposed Places: 1.0000\n",
      "9. Fever: 0.0000\n",
      "10. Dry Cough: 0.0000\n",
      "\n",
      "Training CNN with features selected by 4. Lasso\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "Results for 4. Lasso:\n",
      "Average accuracy: 0.9780 ± 0.0032\n",
      "Average precision: 0.9728 ± 0.0135\n",
      "Average recall: 0.9657 ± 0.0081\n",
      "Average f1: 0.9691 ± 0.0038\n",
      "Average auc: 0.9979 ± 0.0003\n",
      "\n",
      "==================================================\n",
      "Processing 5. Random Forest Importance\n",
      "==================================================\n",
      "Selecting features using 5. Random Forest Importance...\n",
      "Top 10 features selected by 5. Random Forest Importance:\n",
      "1. Breathing Problem: 0.1560\n",
      "2. Sore throat: 0.2333\n",
      "3. Abroad travel: 0.1637\n",
      "4. Contact with COVID Patient: 0.0630\n",
      "5. Attended Large Gathering: 0.1179\n",
      "6. Family working in Public Exposed Places: 0.0940\n",
      "7. Fever: 0.0000\n",
      "8. Dry Cough: 0.0000\n",
      "9. Running Nose: 0.0000\n",
      "10. Asthma: 0.0000\n",
      "\n",
      "Training CNN with features selected by 5. Random Forest Importance\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Results for 5. Random Forest Importance:\n",
      "Average accuracy: 0.9822 ± 0.0016\n",
      "Average precision: 0.9845 ± 0.0080\n",
      "Average recall: 0.9654 ± 0.0057\n",
      "Average f1: 0.9748 ± 0.0021\n",
      "Average auc: 0.9981 ± 0.0003\n",
      "\n",
      "==================================================\n",
      "Processing 6. Boruta\n",
      "==================================================\n",
      "Selecting features using 6. Boruta...\n",
      "Top 10 features selected by 6. Boruta:\n",
      "1. Breathing Problem: 1.0000\n",
      "2. Sore throat: 1.0000\n",
      "3. Running Nose: 1.0000\n",
      "4. Asthma: 1.0000\n",
      "5. Chronic Lung Disease: 1.0000\n",
      "6. Headache: 1.0000\n",
      "7. Heart Disease: 1.0000\n",
      "8. Diabetes: 1.0000\n",
      "9. Hyper Tension: 1.0000\n",
      "10. Fatigue : 1.0000\n",
      "\n",
      "Training CNN with features selected by 6. Boruta\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Results for 6. Boruta:\n",
      "Average accuracy: 0.9724 ± 0.0111\n",
      "Average precision: 0.9707 ± 0.0297\n",
      "Average recall: 0.9523 ± 0.0027\n",
      "Average f1: 0.9612 ± 0.0149\n",
      "Average auc: 0.9952 ± 0.0027\n",
      "\n",
      "==================================================\n",
      "Processing 7. Correlation-based\n",
      "==================================================\n",
      "Selecting features using 7. Correlation-based...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11248\\1519029093.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_selected_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbest_technique\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{i+1}. {feature}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11248\\1519029093.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    408\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Processing {technique_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"=\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[1;31m# Select features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m         \u001b[0mselected_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtechnique_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m         \u001b[0mall_selected_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtechnique_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselected_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;31m# Train and evaluate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11248\\1519029093.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(X, y, technique_name, selector, n_features)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtechnique_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"7. Correlation-based\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;31m# Calculate correlation of each feature with target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mcorrelations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m             corr = np.abs(pd.crosstab(X[col], y, normalize='columns').iloc[1, 1] - \n\u001b[0m\u001b[0;32m     94\u001b[0m                           pd.crosstab(X[col], y, normalize='columns').iloc[1, 0])\n\u001b[0;32m     95\u001b[0m             \u001b[0mcorrelations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1146\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1147\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   3999\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mCaller\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mresponsible\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchecking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4000\u001b[0m         \"\"\"\n\u001b[0;32m   4001\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4002\u001b[0m             \u001b[0mseries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4003\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4005\u001b[0m         \u001b[0mseries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4006\u001b[0m         \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "# Dependencies installation (run these commands in your terminal)\n",
    "# pip install pandas numpy scikit-learn tensorflow keras matplotlib seaborn xgboost lightgbm boruta\n",
    "# pip install imbalanced-learn statsmodels scipy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Feature Selection Libraries\n",
    "from sklearn.feature_selection import (\n",
    "    VarianceThreshold, chi2, f_classif, mutual_info_classif, \n",
    "    SelectKBest, RFE, SelectFromModel\n",
    ")\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from boruta import BorutaPy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# ML and Evaluation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Conv1D, MaxPooling1D, Dropout, Flatten, Dense, BatchNormalization\n",
    ")\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "def load_data(file_path):\n",
    "    print(\"Loading dataset...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=['COVID-19'])\n",
    "    y = df['COVID-19']\n",
    "    print(f\"Dataset loaded: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "    print(f\"Class distribution: {dict(y.value_counts())}\")\n",
    "    return X, y\n",
    "\n",
    "# Define all feature selection techniques\n",
    "def get_feature_selectors(X, y, n_features=10):\n",
    "    print(\"Initializing feature selection techniques...\")\n",
    "    feature_selectors = {\n",
    "        \"1. Chi-Square\": SelectKBest(chi2, k=n_features),\n",
    "        \"2. Mutual Information\": SelectKBest(mutual_info_classif, k=n_features),\n",
    "        \"3. Recursive Feature Elimination\": RFE(\n",
    "            estimator=LogisticRegression(solver='liblinear', max_iter=1000, random_state=42),\n",
    "            n_features_to_select=n_features\n",
    "        ),\n",
    "        \"4. Lasso\": SelectFromModel(\n",
    "            Lasso(alpha=0.01, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"5. Random Forest Importance\": SelectFromModel(\n",
    "            RandomForestClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"6. Boruta\": BorutaPy(\n",
    "            RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            n_estimators='auto', verbose=0, random_state=42\n",
    "        ),\n",
    "        \"7. Correlation-based\": None,  # Custom implementation\n",
    "        \"8. Sequential Forward Selection\": SequentialFeatureSelector(\n",
    "            RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "            n_features_to_select=n_features,\n",
    "            direction='forward'\n",
    "        ),\n",
    "        \"9. XGBoost Importance\": SelectFromModel(\n",
    "            XGBClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"10. LightGBM Importance\": SelectFromModel(\n",
    "            LGBMClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        )\n",
    "    }\n",
    "    return feature_selectors\n",
    "\n",
    "# Function to select top features using each technique\n",
    "def select_features(X, y, technique_name, selector, n_features=10):\n",
    "    print(f\"Selecting features using {technique_name}...\")\n",
    "    feature_names = X.columns.tolist()\n",
    "    \n",
    "    # Handle special case for Correlation-based selection\n",
    "    if technique_name == \"7. Correlation-based\":\n",
    "        # Calculate correlation of each feature with target\n",
    "        correlations = []\n",
    "        for col in X.columns:\n",
    "            corr = np.abs(pd.crosstab(X[col], y, normalize='columns').iloc[1, 1] - \n",
    "                          pd.crosstab(X[col], y, normalize='columns').iloc[1, 0])\n",
    "            correlations.append((col, corr))\n",
    "        \n",
    "        # Sort by correlation and select top n_features\n",
    "        correlations.sort(key=lambda x: x[1], reverse=True)\n",
    "        selected_features = [item[0] for item in correlations[:n_features]]\n",
    "        feature_importances = [item[1] for item in correlations[:n_features]]\n",
    "        \n",
    "    # Handle special case for Boruta\n",
    "    elif technique_name == \"6. Boruta\":\n",
    "        # Boruta requires array input\n",
    "        X_array = X.values\n",
    "        selector.fit(X_array, y)\n",
    "        \n",
    "        # Get the selected features\n",
    "        selected_mask = selector.support_\n",
    "        ranking = selector.ranking_\n",
    "        \n",
    "        # Sort by ranking and select top features\n",
    "        feature_ranking = [(feature, rank) for feature, rank, mask in \n",
    "                          zip(feature_names, ranking, selected_mask) if mask]\n",
    "        feature_ranking.sort(key=lambda x: x[1])\n",
    "        \n",
    "        # If Boruta selected fewer than n_features, add more by ranking\n",
    "        if len(feature_ranking) < n_features:\n",
    "            additional = [(f, r) for f, r, m in \n",
    "                         zip(feature_names, ranking, selected_mask) if not m]\n",
    "            additional.sort(key=lambda x: x[1])\n",
    "            feature_ranking.extend(additional[:n_features-len(feature_ranking)])\n",
    "        \n",
    "        feature_ranking = feature_ranking[:n_features]\n",
    "        selected_features = [item[0] for item in feature_ranking]\n",
    "        feature_importances = [1.0/item[1] for item in feature_ranking]  # Invert ranking for visualization\n",
    "    \n",
    "    else:\n",
    "        # Standard scikit-learn selectors\n",
    "        try:\n",
    "            selector.fit(X, y)\n",
    "            \n",
    "            # Different selector types have different ways to get selected features\n",
    "            if hasattr(selector, 'get_support'):\n",
    "                selected_mask = selector.get_support()\n",
    "                selected_features = [f for f, selected in zip(feature_names, selected_mask) if selected]\n",
    "                \n",
    "                # Get feature importances if available\n",
    "                if hasattr(selector, 'estimator_') and hasattr(selector.estimator_, 'feature_importances_'):\n",
    "                    feature_importances = selector.estimator_.feature_importances_[selected_mask]\n",
    "                elif hasattr(selector, 'scores_'):\n",
    "                    feature_importances = selector.scores_[selected_mask]\n",
    "                else:\n",
    "                    feature_importances = np.ones(len(selected_features))\n",
    "                    \n",
    "            elif hasattr(selector, 'coef_'):\n",
    "                # For models with coefficients like Lasso\n",
    "                coefs = np.abs(selector.coef_)\n",
    "                indices = np.argsort(coefs)[::-1][:n_features]\n",
    "                selected_features = [feature_names[i] for i in indices]\n",
    "                feature_importances = [coefs[i] for i in indices]\n",
    "                \n",
    "            else:\n",
    "                # Get features from the model itself\n",
    "                try:\n",
    "                    importances = getattr(selector, 'feature_importances_', \n",
    "                                         getattr(selector, 'coef_', None))\n",
    "                    if importances is None:\n",
    "                        importances = np.ones(len(feature_names))\n",
    "                    \n",
    "                    # For 2D coefficients (like in multiclass), take the mean\n",
    "                    if importances.ndim > 1:\n",
    "                        importances = np.mean(np.abs(importances), axis=0)\n",
    "                    \n",
    "                    # Select top features\n",
    "                    indices = np.argsort(np.abs(importances))[::-1][:n_features]\n",
    "                    selected_features = [feature_names[i] for i in indices]\n",
    "                    feature_importances = [np.abs(importances)[i] for i in indices]\n",
    "                    \n",
    "                except:\n",
    "                    # Fallback for other selectors\n",
    "                    indices = getattr(selector, 'support_', np.arange(min(n_features, len(feature_names))))\n",
    "                    if len(indices) > n_features:\n",
    "                        indices = indices[:n_features]\n",
    "                    selected_features = [feature_names[i] for i in indices]\n",
    "                    feature_importances = np.ones(len(selected_features))\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error with {technique_name}: {str(e)}\")\n",
    "            # Default to the first n_features if there's an error\n",
    "            selected_features = feature_names[:n_features]\n",
    "            feature_importances = np.ones(n_features)\n",
    "    \n",
    "    # Ensure exactly n_features are selected (truncate or pad if necessary)\n",
    "    if len(selected_features) > n_features:\n",
    "        selected_features = selected_features[:n_features]\n",
    "        feature_importances = feature_importances[:n_features]\n",
    "    elif len(selected_features) < n_features:\n",
    "        # Add remaining features based on variance\n",
    "        remaining = [f for f in feature_names if f not in selected_features]\n",
    "        selected_features.extend(remaining[:n_features-len(selected_features)])\n",
    "        feature_importances = list(feature_importances) + [0] * (n_features - len(feature_importances))\n",
    "    \n",
    "    # Print selected features\n",
    "    print(f\"Top {len(selected_features)} features selected by {technique_name}:\")\n",
    "    for i, (feature, importance) in enumerate(zip(selected_features, feature_importances)):\n",
    "        print(f\"{i+1}. {feature}: {importance:.4f}\")\n",
    "    \n",
    "    return selected_features, feature_importances\n",
    "\n",
    "# Build the CNN model for a specific set of features\n",
    "def build_cnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        # First Conv Block\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu', padding='same', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2, padding='same'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Second Conv Block\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2, padding='same'),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Flattening and Dense layers\n",
    "        Flatten(),\n",
    "        Dense(32, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train and evaluate model with k-fold cross validation\n",
    "def train_and_evaluate(X, y, selected_features, technique_name, k=5):\n",
    "    print(f\"\\nTraining CNN with features selected by {technique_name}\")\n",
    "    \n",
    "    # Prepare data for CNN\n",
    "    X_selected = X[selected_features].values\n",
    "    X_selected = X_selected.reshape(X_selected.shape[0], X_selected.shape[1], 1)\n",
    "    y_values = y.values\n",
    "    \n",
    "    # K-Fold validation\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    metrics = {\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': [],\n",
    "        'auc': []\n",
    "    }\n",
    "    \n",
    "    # Define early stopping\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Train and evaluate for each fold\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X_selected)):\n",
    "        print(f\"Training fold {fold+1}/{k}...\")\n",
    "        \n",
    "        X_train, X_test = X_selected[train_idx], X_selected[test_idx]\n",
    "        y_train, y_test = y_values[train_idx], y_values[test_idx]\n",
    "        \n",
    "        # Build and train model\n",
    "        model = build_cnn_model((X_selected.shape[1], 1))\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=50,  # Reduced from 100 for faster execution\n",
    "            batch_size=32,\n",
    "            verbose=0,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[early_stop]\n",
    "        )\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics['accuracy'].append(accuracy_score(y_test, y_pred_classes))\n",
    "        metrics['precision'].append(precision_score(y_test, y_pred_classes))\n",
    "        metrics['recall'].append(recall_score(y_test, y_pred_classes))\n",
    "        metrics['f1'].append(f1_score(y_test, y_pred_classes))\n",
    "        try:\n",
    "            metrics['auc'].append(roc_auc_score(y_test, y_pred))\n",
    "        except:\n",
    "            metrics['auc'].append(0.5)  # Default for failed AUC calculation\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {metric: np.mean(values) for metric, values in metrics.items()}\n",
    "    std_metrics = {metric: np.std(values) for metric, values in metrics.items()}\n",
    "    \n",
    "    print(f\"\\nResults for {technique_name}:\")\n",
    "    for metric, value in avg_metrics.items():\n",
    "        print(f\"Average {metric}: {value:.4f} ± {std_metrics[metric]:.4f}\")\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "# Plot comparison bar chart\n",
    "def plot_comparison(all_results):\n",
    "    metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
    "    \n",
    "    # Sort techniques by accuracy\n",
    "    sorted_techniques = sorted(\n",
    "        all_results.keys(),\n",
    "        key=lambda x: all_results[x]['accuracy'],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Set width of bars\n",
    "    bar_width = 0.15\n",
    "    index = np.arange(len(sorted_techniques))\n",
    "    \n",
    "    # Colors for different metrics\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    \n",
    "    # Plot bars for each metric\n",
    "    for i, metric in enumerate(metrics_to_plot):\n",
    "        values = [all_results[technique][metric] for technique in sorted_techniques]\n",
    "        plt.bar(\n",
    "            index + i * bar_width, \n",
    "            values, \n",
    "            bar_width, \n",
    "            label=metric.capitalize(),\n",
    "            color=colors[i]\n",
    "        )\n",
    "    \n",
    "    # Add labels and legend\n",
    "    plt.xlabel('Feature Selection Technique', fontsize=12)\n",
    "    plt.ylabel('Score', fontsize=12)\n",
    "    plt.title('Comparison of Feature Selection Techniques', fontsize=14)\n",
    "    plt.xticks(\n",
    "        index + bar_width * 2, \n",
    "        [t.split('. ')[1] if '. ' in t else t for t in sorted_techniques],\n",
    "        rotation=45,\n",
    "        ha='right'\n",
    "    )\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=5)\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig('feature_selection_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Comparison chart saved as 'feature_selection_comparison.png'\")\n",
    "    plt.close()\n",
    "\n",
    "# Plot feature heatmap\n",
    "def plot_feature_heatmap(all_features, X):\n",
    "    # Create a matrix of features vs techniques\n",
    "    techniques = list(all_features.keys())\n",
    "    all_unique_features = list(set(feature for features in all_features.values() for feature in features))\n",
    "    \n",
    "    # Create a matrix with 1 if feature is selected by technique, 0 otherwise\n",
    "    matrix = np.zeros((len(techniques), len(all_unique_features)))\n",
    "    \n",
    "    for i, technique in enumerate(techniques):\n",
    "        for j, feature in enumerate(all_unique_features):\n",
    "            if feature in all_features[technique]:\n",
    "                matrix[i, j] = 1\n",
    "    \n",
    "    # Sort features by frequency of selection\n",
    "    feature_counts = matrix.sum(axis=0)\n",
    "    sorted_indices = np.argsort(feature_counts)[::-1]\n",
    "    sorted_features = [all_unique_features[i] for i in sorted_indices]\n",
    "    sorted_matrix = matrix[:, sorted_indices]\n",
    "    \n",
    "    # Create heatmap\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    sns.heatmap(\n",
    "        sorted_matrix,\n",
    "        cmap='Blues',\n",
    "        xticklabels=sorted_features,\n",
    "        yticklabels=[t.split('. ')[1] if '. ' in t else t for t in techniques],\n",
    "        cbar_kws={'label': 'Selected'}\n",
    "    )\n",
    "    plt.title('Feature Selection by Different Techniques', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig('feature_selection_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Heatmap saved as 'feature_selection_heatmap.png'\")\n",
    "    plt.close()\n",
    "\n",
    "# Main function to run the whole process\n",
    "def main():\n",
    "    # Load data\n",
    "    file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with your path\n",
    "    X, y = load_data(file_path)\n",
    "    \n",
    "    # Get feature selectors\n",
    "    feature_selectors = get_feature_selectors(X, y)\n",
    "    \n",
    "    # Store results\n",
    "    all_results = {}\n",
    "    all_selected_features = {}\n",
    "    \n",
    "    # For each technique, select features and train model\n",
    "    for technique_name, selector in feature_selectors.items():\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Processing {technique_name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Select features\n",
    "        selected_features, _ = select_features(X, y, technique_name, selector)\n",
    "        all_selected_features[technique_name] = selected_features\n",
    "        \n",
    "        # Train and evaluate\n",
    "        results = train_and_evaluate(X, y, selected_features, technique_name)\n",
    "        all_results[technique_name] = results\n",
    "    \n",
    "    # Plot comparison\n",
    "    plot_comparison(all_results)\n",
    "    \n",
    "    # Plot feature heatmap\n",
    "    plot_feature_heatmap(all_selected_features, X)\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Sort techniques by accuracy\n",
    "    sorted_techniques = sorted(\n",
    "        all_results.keys(),\n",
    "        key=lambda x: all_results[x]['accuracy'],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTechniques ranked by accuracy:\")\n",
    "    for i, technique in enumerate(sorted_techniques):\n",
    "        print(f\"{i+1}. {technique}: {all_results[technique]['accuracy']:.4f}\")\n",
    "    \n",
    "    best_technique = sorted_techniques[0]\n",
    "    print(f\"\\nBest performing technique: {best_technique}\")\n",
    "    print(f\"Top 10 features selected by {best_technique}:\")\n",
    "    for i, feature in enumerate(all_selected_features[best_technique]):\n",
    "        print(f\"{i+1}. {feature}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1aa8e034-5da3-42b7-85c6-7b4e35532114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded: 28766 samples, 20 features\n",
      "Class distribution: {0: 18514, 1: 10252}\n",
      "Initializing feature selection techniques...\n",
      "\n",
      "==================================================\n",
      "Processing 7. Correlation-based\n",
      "==================================================\n",
      "Selecting features using 7. Correlation-based...\n",
      "Top 10 features selected by 7. Correlation-based:\n",
      "1. Sore throat: 0.8628\n",
      "2. Breathing Problem: 0.7620\n",
      "3. Attended Large Gathering: 0.6493\n",
      "4. Family working in Public Exposed Places: 0.6421\n",
      "5. Abroad travel: 0.6099\n",
      "6. Contact with COVID Patient: 0.5177\n",
      "7. Diabetes: 0.4520\n",
      "8. Heart Disease: 0.4011\n",
      "9. Gastrointestinal : 0.3945\n",
      "10. Hyper Tension: 0.3857\n",
      "\n",
      "Training CNN with features selected by 7. Correlation-based\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Results for 7. Correlation-based:\n",
      "Average accuracy: 0.9837 ± 0.0035\n",
      "Average precision: 0.9884 ± 0.0098\n",
      "Average recall: 0.9659 ± 0.0095\n",
      "Average f1: 0.9769 ± 0.0046\n",
      "Average auc: 0.9986 ± 0.0004\n",
      "\n",
      "==================================================\n",
      "Processing 8. Sequential Forward Selection\n",
      "==================================================\n",
      "Selecting features using 8. Sequential Forward Selection...\n",
      "Top 10 features selected by 8. Sequential Forward Selection:\n",
      "1. Fever: 1.0000\n",
      "2. Dry Cough: 1.0000\n",
      "3. Sore throat: 1.0000\n",
      "4. Running Nose: 1.0000\n",
      "5. Asthma: 1.0000\n",
      "6. Chronic Lung Disease: 1.0000\n",
      "7. Abroad travel: 1.0000\n",
      "8. Attended Large Gathering: 1.0000\n",
      "9. Wearing Masks: 1.0000\n",
      "10. Sanitization from Market: 1.0000\n",
      "\n",
      "Training CNN with features selected by 8. Sequential Forward Selection\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "Results for 8. Sequential Forward Selection:\n",
      "Average accuracy: 0.9586 ± 0.0044\n",
      "Average precision: 0.9814 ± 0.0122\n",
      "Average recall: 0.9015 ± 0.0190\n",
      "Average f1: 0.9395 ± 0.0064\n",
      "Average auc: 0.9912 ± 0.0006\n",
      "\n",
      "==================================================\n",
      "Processing 9. XGBoost Importance\n",
      "==================================================\n",
      "Selecting features using 9. XGBoost Importance...\n",
      "Top 10 features selected by 9. XGBoost Importance:\n",
      "1. Sore throat: 0.5873\n",
      "2. Abroad travel: 0.2135\n",
      "3. Attended Large Gathering: 0.0666\n",
      "4. Breathing Problem: 0.0000\n",
      "5. Fever: 0.0000\n",
      "6. Dry Cough: 0.0000\n",
      "7. Running Nose: 0.0000\n",
      "8. Asthma: 0.0000\n",
      "9. Chronic Lung Disease: 0.0000\n",
      "10. Headache: 0.0000\n",
      "\n",
      "Training CNN with features selected by 9. XGBoost Importance\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Results for 9. XGBoost Importance:\n",
      "Average accuracy: 0.9761 ± 0.0046\n",
      "Average precision: 0.9819 ± 0.0080\n",
      "Average recall: 0.9508 ± 0.0163\n",
      "Average f1: 0.9659 ± 0.0067\n",
      "Average auc: 0.9976 ± 0.0006\n",
      "\n",
      "==================================================\n",
      "Processing 10. LightGBM Importance\n",
      "==================================================\n",
      "Selecting features using 10. LightGBM Importance...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10252, number of negative: 18514\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32\n",
      "[LightGBM] [Info] Number of data points in the train set: 28766, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.356393 -> initscore=-0.591054\n",
      "[LightGBM] [Info] Start training from score -0.591054\n",
      "Top 10 features selected by 10. LightGBM Importance:\n",
      "1. Breathing Problem: 266.0000\n",
      "2. Sore throat: 212.0000\n",
      "3. Asthma: 220.0000\n",
      "4. Chronic Lung Disease: 240.0000\n",
      "5. Heart Disease: 207.0000\n",
      "6. Hyper Tension: 207.0000\n",
      "7. Abroad travel: 169.0000\n",
      "8. Contact with COVID Patient: 216.0000\n",
      "9. Attended Large Gathering: 183.0000\n",
      "10. Family working in Public Exposed Places: 199.0000\n",
      "\n",
      "Training CNN with features selected by 10. LightGBM Importance\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "Results for 10. LightGBM Importance:\n",
      "Average accuracy: 0.9858 ± 0.0021\n",
      "Average precision: 0.9890 ± 0.0064\n",
      "Average recall: 0.9711 ± 0.0035\n",
      "Average f1: 0.9800 ± 0.0026\n",
      "Average auc: 0.9986 ± 0.0003\n",
      "Comparison chart saved as 'feature_selection_comparison.png'\n",
      "Heatmap saved as 'feature_selection_heatmap.png'\n",
      "\n",
      "==================================================\n",
      "FINAL SUMMARY\n",
      "==================================================\n",
      "\n",
      "Techniques ranked by accuracy:\n",
      "1. 10. LightGBM Importance: 0.9858\n",
      "2. 2. Mutual Information: 0.9845\n",
      "3. 7. Correlation-based: 0.9837\n",
      "4. 1. Chi-Square: 0.9833\n",
      "5. 5. Random Forest Importance: 0.9822\n",
      "6. 3. Recursive Feature Elimination: 0.9787\n",
      "7. 4. Lasso: 0.9780\n",
      "8. 9. XGBoost Importance: 0.9761\n",
      "9. 6. Boruta: 0.9724\n",
      "10. 8. Sequential Forward Selection: 0.9586\n",
      "\n",
      "Best performing technique: 10. LightGBM Importance\n",
      "Top 10 features selected by 10. LightGBM Importance:\n",
      "1. Breathing Problem\n",
      "2. Sore throat\n",
      "3. Asthma\n",
      "4. Chronic Lung Disease\n",
      "5. Heart Disease\n",
      "6. Hyper Tension\n",
      "7. Abroad travel\n",
      "8. Contact with COVID Patient\n",
      "9. Attended Large Gathering\n",
      "10. Family working in Public Exposed Places\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Feature Selection Libraries\n",
    "from sklearn.feature_selection import (\n",
    "    VarianceThreshold, chi2, f_classif, mutual_info_classif, \n",
    "    SelectKBest, RFE, SelectFromModel\n",
    ")\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from boruta import BorutaPy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# ML and Evaluation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Conv1D, MaxPooling1D, Dropout, Flatten, Dense, BatchNormalization\n",
    ")\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "def load_data(file_path):\n",
    "    print(\"Loading dataset...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=['COVID-19'])\n",
    "    y = df['COVID-19']\n",
    "    print(f\"Dataset loaded: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "    print(f\"Class distribution: {dict(y.value_counts())}\")\n",
    "    return X, y\n",
    "\n",
    "# Define all feature selection techniques\n",
    "def get_feature_selectors(X, y, n_features=10):\n",
    "    print(\"Initializing feature selection techniques...\")\n",
    "    feature_selectors = {\n",
    "        \"7. Correlation-based\": None,  # Custom implementation\n",
    "        \"8. Sequential Forward Selection\": SequentialFeatureSelector(\n",
    "            RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "            n_features_to_select=n_features,\n",
    "            direction='forward'\n",
    "        ),\n",
    "        \"9. XGBoost Importance\": SelectFromModel(\n",
    "            XGBClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"10. LightGBM Importance\": SelectFromModel(\n",
    "            LGBMClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        )\n",
    "    }\n",
    "    return feature_selectors\n",
    "\n",
    "# Function to select top features using each technique\n",
    "def select_features(X, y, technique_name, selector, n_features=10):\n",
    "    print(f\"Selecting features using {technique_name}...\")\n",
    "    feature_names = X.columns.tolist()\n",
    "    \n",
    "    # Handle special case for Correlation-based selection\n",
    "    if technique_name == \"7. Correlation-based\":\n",
    "        # Calculate correlation of each feature with target (safer implementation)\n",
    "        correlations = []\n",
    "        for col in X.columns:\n",
    "            # Create a contingency table\n",
    "            contingency = pd.crosstab(X[col], y)\n",
    "            # If binary feature, use direct correlation\n",
    "            if contingency.shape[0] == 2 and contingency.shape[1] == 2:\n",
    "                # Calculate correlation coefficient (normalize to have sum=1 for each column)\n",
    "                normalized = contingency.apply(lambda x: x / x.sum(), axis=0)\n",
    "                try:\n",
    "                    corr = abs(normalized.iloc[1, 1] - normalized.iloc[1, 0])\n",
    "                except:\n",
    "                    corr = 0\n",
    "            else:\n",
    "                # For non-binary features, use chi-squared statistic\n",
    "                from scipy.stats import chi2_contingency\n",
    "                try:\n",
    "                    chi2_stat, p_val, _, _ = chi2_contingency(contingency)\n",
    "                    corr = chi2_stat\n",
    "                except:\n",
    "                    corr = 0\n",
    "            correlations.append((col, corr))\n",
    "        \n",
    "        # Sort by correlation and select top n_features\n",
    "        correlations.sort(key=lambda x: x[1], reverse=True)\n",
    "        selected_features = [item[0] for item in correlations[:n_features]]\n",
    "        feature_importances = [item[1] for item in correlations[:n_features]]\n",
    "    else:\n",
    "        # Standard scikit-learn selectors\n",
    "        try:\n",
    "            selector.fit(X, y)\n",
    "            \n",
    "            # Different selector types have different ways to get selected features\n",
    "            if hasattr(selector, 'get_support'):\n",
    "                selected_mask = selector.get_support()\n",
    "                selected_features = [f for f, selected in zip(feature_names, selected_mask) if selected]\n",
    "                \n",
    "                # Get feature importances if available\n",
    "                if hasattr(selector, 'estimator_') and hasattr(selector.estimator_, 'feature_importances_'):\n",
    "                    feature_importances = selector.estimator_.feature_importances_[selected_mask]\n",
    "                elif hasattr(selector, 'scores_'):\n",
    "                    feature_importances = selector.scores_[selected_mask]\n",
    "                else:\n",
    "                    feature_importances = np.ones(len(selected_features))\n",
    "                    \n",
    "            elif hasattr(selector, 'coef_'):\n",
    "                # For models with coefficients like Lasso\n",
    "                coefs = np.abs(selector.coef_)\n",
    "                indices = np.argsort(coefs)[::-1][:n_features]\n",
    "                selected_features = [feature_names[i] for i in indices]\n",
    "                feature_importances = [coefs[i] for i in indices]\n",
    "                \n",
    "            else:\n",
    "                # Get features from the model itself\n",
    "                try:\n",
    "                    importances = getattr(selector, 'feature_importances_', \n",
    "                                         getattr(selector, 'coef_', None))\n",
    "                    if importances is None:\n",
    "                        importances = np.ones(len(feature_names))\n",
    "                    \n",
    "                    # For 2D coefficients (like in multiclass), take the mean\n",
    "                    if importances.ndim > 1:\n",
    "                        importances = np.mean(np.abs(importances), axis=0)\n",
    "                    \n",
    "                    # Select top features\n",
    "                    indices = np.argsort(np.abs(importances))[::-1][:n_features]\n",
    "                    selected_features = [feature_names[i] for i in indices]\n",
    "                    feature_importances = [np.abs(importances)[i] for i in indices]\n",
    "                    \n",
    "                except:\n",
    "                    # Fallback for other selectors\n",
    "                    indices = getattr(selector, 'support_', np.arange(min(n_features, len(feature_names))))\n",
    "                    if len(indices) > n_features:\n",
    "                        indices = indices[:n_features]\n",
    "                    selected_features = [feature_names[i] for i in indices]\n",
    "                    feature_importances = np.ones(len(selected_features))\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error with {technique_name}: {str(e)}\")\n",
    "            # Default to the first n_features if there's an error\n",
    "            selected_features = feature_names[:n_features]\n",
    "            feature_importances = np.ones(n_features)\n",
    "    \n",
    "    # Ensure exactly n_features are selected (truncate or pad if necessary)\n",
    "    if len(selected_features) > n_features:\n",
    "        selected_features = selected_features[:n_features]\n",
    "        feature_importances = feature_importances[:n_features]\n",
    "    elif len(selected_features) < n_features:\n",
    "        # Add remaining features based on variance\n",
    "        remaining = [f for f in feature_names if f not in selected_features]\n",
    "        selected_features.extend(remaining[:n_features-len(selected_features)])\n",
    "        feature_importances = list(feature_importances) + [0] * (n_features - len(feature_importances))\n",
    "    \n",
    "    # Print selected features\n",
    "    print(f\"Top {len(selected_features)} features selected by {technique_name}:\")\n",
    "    for i, (feature, importance) in enumerate(zip(selected_features, feature_importances)):\n",
    "        print(f\"{i+1}. {feature}: {importance:.4f}\")\n",
    "    \n",
    "    return selected_features, feature_importances\n",
    "\n",
    "# Build the CNN model for a specific set of features\n",
    "def build_cnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        # First Conv Block\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu', padding='same', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2, padding='same'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Second Conv Block\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2, padding='same'),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Flattening and Dense layers\n",
    "        Flatten(),\n",
    "        Dense(32, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train and evaluate model with k-fold cross validation\n",
    "def train_and_evaluate(X, y, selected_features, technique_name, k=5):\n",
    "    print(f\"\\nTraining CNN with features selected by {technique_name}\")\n",
    "    \n",
    "    # Prepare data for CNN\n",
    "    X_selected = X[selected_features].values\n",
    "    X_selected = X_selected.reshape(X_selected.shape[0], X_selected.shape[1], 1)\n",
    "    y_values = y.values\n",
    "    \n",
    "    # K-Fold validation\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    metrics = {\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': [],\n",
    "        'auc': []\n",
    "    }\n",
    "    \n",
    "    # Define early stopping\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Train and evaluate for each fold\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X_selected)):\n",
    "        print(f\"Training fold {fold+1}/{k}...\")\n",
    "        \n",
    "        X_train, X_test = X_selected[train_idx], X_selected[test_idx]\n",
    "        y_train, y_test = y_values[train_idx], y_values[test_idx]\n",
    "        \n",
    "        # Build and train model\n",
    "        model = build_cnn_model((X_selected.shape[1], 1))\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=50,  # Reduced from 100 for faster execution\n",
    "            batch_size=32,\n",
    "            verbose=0,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[early_stop]\n",
    "        )\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics['accuracy'].append(accuracy_score(y_test, y_pred_classes))\n",
    "        metrics['precision'].append(precision_score(y_test, y_pred_classes))\n",
    "        metrics['recall'].append(recall_score(y_test, y_pred_classes))\n",
    "        metrics['f1'].append(f1_score(y_test, y_pred_classes))\n",
    "        try:\n",
    "            metrics['auc'].append(roc_auc_score(y_test, y_pred))\n",
    "        except:\n",
    "            metrics['auc'].append(0.5)  # Default for failed AUC calculation\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {metric: np.mean(values) for metric, values in metrics.items()}\n",
    "    std_metrics = {metric: np.std(values) for metric, values in metrics.items()}\n",
    "    \n",
    "    print(f\"\\nResults for {technique_name}:\")\n",
    "    for metric, value in avg_metrics.items():\n",
    "        print(f\"Average {metric}: {value:.4f} ± {std_metrics[metric]:.4f}\")\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "# Plot comparison bar chart\n",
    "def plot_comparison(all_results):\n",
    "    metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
    "    \n",
    "    # Sort techniques by accuracy\n",
    "    sorted_techniques = sorted(\n",
    "        all_results.keys(),\n",
    "        key=lambda x: all_results[x]['accuracy'],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Set width of bars\n",
    "    bar_width = 0.15\n",
    "    index = np.arange(len(sorted_techniques))\n",
    "    \n",
    "    # Colors for different metrics\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    \n",
    "    # Plot bars for each metric\n",
    "    for i, metric in enumerate(metrics_to_plot):\n",
    "        values = [all_results[technique][metric] for technique in sorted_techniques]\n",
    "        plt.bar(\n",
    "            index + i * bar_width, \n",
    "            values, \n",
    "            bar_width, \n",
    "            label=metric.capitalize(),\n",
    "            color=colors[i]\n",
    "        )\n",
    "    \n",
    "    # Add labels and legend\n",
    "    plt.xlabel('Feature Selection Technique', fontsize=12)\n",
    "    plt.ylabel('Score', fontsize=12)\n",
    "    plt.title('Comparison of Feature Selection Techniques', fontsize=14)\n",
    "    plt.xticks(\n",
    "        index + bar_width * 2, \n",
    "        [t.split('. ')[1] if '. ' in t else t for t in sorted_techniques],\n",
    "        rotation=45,\n",
    "        ha='right'\n",
    "    )\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=5)\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig('feature_selection_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Comparison chart saved as 'feature_selection_comparison.png'\")\n",
    "    plt.close()\n",
    "\n",
    "# Plot feature heatmap\n",
    "def plot_feature_heatmap(all_features, X):\n",
    "    # Create a matrix of features vs techniques\n",
    "    techniques = list(all_features.keys())\n",
    "    all_unique_features = list(set(feature for features in all_features.values() for feature in features))\n",
    "    \n",
    "    # Create a matrix with 1 if feature is selected by technique, 0 otherwise\n",
    "    matrix = np.zeros((len(techniques), len(all_unique_features)))\n",
    "    \n",
    "    for i, technique in enumerate(techniques):\n",
    "        for j, feature in enumerate(all_unique_features):\n",
    "            if feature in all_features[technique]:\n",
    "                matrix[i, j] = 1\n",
    "    \n",
    "    # Sort features by frequency of selection\n",
    "    feature_counts = matrix.sum(axis=0)\n",
    "    sorted_indices = np.argsort(feature_counts)[::-1]\n",
    "    sorted_features = [all_unique_features[i] for i in sorted_indices]\n",
    "    sorted_matrix = matrix[:, sorted_indices]\n",
    "    \n",
    "    # Create heatmap\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    sns.heatmap(\n",
    "        sorted_matrix,\n",
    "        cmap='Blues',\n",
    "        xticklabels=sorted_features,\n",
    "        yticklabels=[t.split('. ')[1] if '. ' in t else t for t in techniques],\n",
    "        cbar_kws={'label': 'Selected'}\n",
    "    )\n",
    "    plt.title('Feature Selection by Different Techniques', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac32ce3-4a73-4078-aa8e-460dd9afd452",
   "metadata": {},
   "source": [
    "<H1>ANN</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1f83322-13db-47b7-a6df-0b8ed4c12fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded: 28766 samples, 20 features\n",
      "Class distribution: {0: 18514, 1: 10252}\n",
      "Initializing feature selection techniques...\n",
      "\n",
      "==================================================\n",
      "Processing 1. Chi-Square\n",
      "==================================================\n",
      "Selecting features using 1. Chi-Square...\n",
      "Top 10 features selected by 1. Chi-Square:\n",
      "1. Breathing Problem: 9964.0393\n",
      "2. Sore throat: 13201.1649\n",
      "3. Heart Disease: 3552.0005\n",
      "4. Diabetes: 1929.1672\n",
      "5. Hyper Tension: 3089.5719\n",
      "6. Gastrointestinal : 1693.0652\n",
      "7. Abroad travel: 11288.4346\n",
      "8. Contact with COVID Patient: 8194.1488\n",
      "9. Attended Large Gathering: 9140.5020\n",
      "10. Family working in Public Exposed Places: 7781.7278\n",
      "\n",
      "Training ANN with features selected by 1. Chi-Square\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Results for 1. Chi-Square:\n",
      "Average accuracy: 0.9831 ± 0.0058\n",
      "Average precision: 0.9823 ± 0.0190\n",
      "Average recall: 0.9705 ± 0.0072\n",
      "Average f1: 0.9762 ± 0.0078\n",
      "Average auc: 0.9984 ± 0.0004\n",
      "\n",
      "==================================================\n",
      "Processing 2. Mutual Information\n",
      "==================================================\n",
      "Selecting features using 2. Mutual Information...\n",
      "Top 10 features selected by 2. Mutual Information:\n",
      "1. Breathing Problem: 0.3084\n",
      "2. Sore throat: 0.4156\n",
      "3. Running Nose: 0.0737\n",
      "4. Heart Disease: 0.0845\n",
      "5. Diabetes: 0.1129\n",
      "6. Gastrointestinal : 0.0782\n",
      "7. Abroad travel: 0.2876\n",
      "8. Contact with COVID Patient: 0.1868\n",
      "9. Attended Large Gathering: 0.2374\n",
      "10. Family working in Public Exposed Places: 0.2160\n",
      "\n",
      "Training ANN with features selected by 2. Mutual Information\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Results for 2. Mutual Information:\n",
      "Average accuracy: 0.9849 ± 0.0030\n",
      "Average precision: 0.9907 ± 0.0092\n",
      "Average recall: 0.9669 ± 0.0019\n",
      "Average f1: 0.9786 ± 0.0041\n",
      "Average auc: 0.9985 ± 0.0003\n",
      "\n",
      "==================================================\n",
      "Processing 3. Recursive Feature Elimination\n",
      "==================================================\n",
      "Selecting features using 3. Recursive Feature Elimination...\n",
      "Top 10 features selected by 3. Recursive Feature Elimination:\n",
      "1. Breathing Problem: 1.0000\n",
      "2. Fever: 1.0000\n",
      "3. Dry Cough: 1.0000\n",
      "4. Sore throat: 1.0000\n",
      "5. Hyper Tension: 1.0000\n",
      "6. Abroad travel: 1.0000\n",
      "7. Contact with COVID Patient: 1.0000\n",
      "8. Attended Large Gathering: 1.0000\n",
      "9. Visited Public Exposed Places: 1.0000\n",
      "10. Family working in Public Exposed Places: 1.0000\n",
      "\n",
      "Training ANN with features selected by 3. Recursive Feature Elimination\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Results for 3. Recursive Feature Elimination:\n",
      "Average accuracy: 0.9776 ± 0.0026\n",
      "Average precision: 0.9721 ± 0.0061\n",
      "Average recall: 0.9649 ± 0.0020\n",
      "Average f1: 0.9685 ± 0.0038\n",
      "Average auc: 0.9979 ± 0.0004\n",
      "\n",
      "==================================================\n",
      "Processing 4. Lasso\n",
      "==================================================\n",
      "Selecting features using 4. Lasso...\n",
      "Top 10 features selected by 4. Lasso:\n",
      "1. Breathing Problem: 1.0000\n",
      "2. Sore throat: 1.0000\n",
      "3. Fatigue : 1.0000\n",
      "4. Abroad travel: 1.0000\n",
      "5. Contact with COVID Patient: 1.0000\n",
      "6. Attended Large Gathering: 1.0000\n",
      "7. Visited Public Exposed Places: 1.0000\n",
      "8. Family working in Public Exposed Places: 1.0000\n",
      "9. Fever: 0.0000\n",
      "10. Dry Cough: 0.0000\n",
      "\n",
      "Training ANN with features selected by 4. Lasso\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Results for 4. Lasso:\n",
      "Average accuracy: 0.9791 ± 0.0022\n",
      "Average precision: 0.9747 ± 0.0064\n",
      "Average recall: 0.9665 ± 0.0037\n",
      "Average f1: 0.9706 ± 0.0033\n",
      "Average auc: 0.9978 ± 0.0003\n",
      "\n",
      "==================================================\n",
      "Processing 5. Random Forest Importance\n",
      "==================================================\n",
      "Selecting features using 5. Random Forest Importance...\n",
      "Top 10 features selected by 5. Random Forest Importance:\n",
      "1. Breathing Problem: 0.1560\n",
      "2. Sore throat: 0.2333\n",
      "3. Abroad travel: 0.1637\n",
      "4. Contact with COVID Patient: 0.0630\n",
      "5. Attended Large Gathering: 0.1179\n",
      "6. Family working in Public Exposed Places: 0.0940\n",
      "7. Fever: 0.0000\n",
      "8. Dry Cough: 0.0000\n",
      "9. Running Nose: 0.0000\n",
      "10. Asthma: 0.0000\n",
      "\n",
      "Training ANN with features selected by 5. Random Forest Importance\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Results for 5. Random Forest Importance:\n",
      "Average accuracy: 0.9784 ± 0.0039\n",
      "Average precision: 0.9879 ± 0.0063\n",
      "Average recall: 0.9512 ± 0.0102\n",
      "Average f1: 0.9691 ± 0.0055\n",
      "Average auc: 0.9978 ± 0.0004\n",
      "\n",
      "==================================================\n",
      "Processing 6. Boruta\n",
      "==================================================\n",
      "Selecting features using 6. Boruta...\n",
      "Top 10 features selected by 6. Boruta:\n",
      "1. Breathing Problem: 1.0000\n",
      "2. Sore throat: 1.0000\n",
      "3. Running Nose: 1.0000\n",
      "4. Asthma: 1.0000\n",
      "5. Chronic Lung Disease: 1.0000\n",
      "6. Headache: 1.0000\n",
      "7. Heart Disease: 1.0000\n",
      "8. Diabetes: 1.0000\n",
      "9. Hyper Tension: 1.0000\n",
      "10. Fatigue : 1.0000\n",
      "\n",
      "Training ANN with features selected by 6. Boruta\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Results for 6. Boruta:\n",
      "Average accuracy: 0.9689 ± 0.0166\n",
      "Average precision: 0.9557 ± 0.0382\n",
      "Average recall: 0.9585 ± 0.0078\n",
      "Average f1: 0.9568 ± 0.0221\n",
      "Average auc: 0.9933 ± 0.0052\n",
      "\n",
      "==================================================\n",
      "Processing 7. Correlation-based\n",
      "==================================================\n",
      "Selecting features using 7. Correlation-based...\n",
      "Top 10 features selected by 7. Correlation-based:\n",
      "1. Breathing Problem: 0.7502\n",
      "2. Fever: nan\n",
      "3. Dry Cough: nan\n",
      "4. Sore throat: 0.8549\n",
      "5. Abroad travel: 0.7081\n",
      "6. Attended Large Gathering: 0.6758\n",
      "7. Family working in Public Exposed Places: 0.6449\n",
      "8. Contact with COVID Patient: 0.6027\n",
      "9. Diabetes: 0.4719\n",
      "10. Heart Disease: 0.4197\n",
      "\n",
      "Training ANN with features selected by 7. Correlation-based\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Results for 7. Correlation-based:\n",
      "Average accuracy: 0.9763 ± 0.0025\n",
      "Average precision: 0.9761 ± 0.0044\n",
      "Average recall: 0.9571 ± 0.0083\n",
      "Average f1: 0.9665 ± 0.0034\n",
      "Average auc: 0.9977 ± 0.0003\n",
      "\n",
      "==================================================\n",
      "Processing 8. Sequential Forward Selection\n",
      "==================================================\n",
      "Selecting features using 8. Sequential Forward Selection...\n",
      "Top 10 features selected by 8. Sequential Forward Selection:\n",
      "1. Fever: 1.0000\n",
      "2. Dry Cough: 1.0000\n",
      "3. Sore throat: 1.0000\n",
      "4. Running Nose: 1.0000\n",
      "5. Asthma: 1.0000\n",
      "6. Chronic Lung Disease: 1.0000\n",
      "7. Abroad travel: 1.0000\n",
      "8. Attended Large Gathering: 1.0000\n",
      "9. Wearing Masks: 1.0000\n",
      "10. Sanitization from Market: 1.0000\n",
      "\n",
      "Training ANN with features selected by 8. Sequential Forward Selection\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Results for 8. Sequential Forward Selection:\n",
      "Average accuracy: 0.9570 ± 0.0031\n",
      "Average precision: 0.9658 ± 0.0331\n",
      "Average recall: 0.9139 ± 0.0324\n",
      "Average f1: 0.9380 ± 0.0042\n",
      "Average auc: 0.9907 ± 0.0009\n",
      "\n",
      "==================================================\n",
      "Processing 9. XGBoost Importance\n",
      "==================================================\n",
      "Selecting features using 9. XGBoost Importance...\n",
      "Top 10 features selected by 9. XGBoost Importance:\n",
      "1. Sore throat: 0.5873\n",
      "2. Abroad travel: 0.2135\n",
      "3. Attended Large Gathering: 0.0666\n",
      "4. Breathing Problem: 0.0000\n",
      "5. Fever: 0.0000\n",
      "6. Dry Cough: 0.0000\n",
      "7. Running Nose: 0.0000\n",
      "8. Asthma: 0.0000\n",
      "9. Chronic Lung Disease: 0.0000\n",
      "10. Headache: 0.0000\n",
      "\n",
      "Training ANN with features selected by 9. XGBoost Importance\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\n",
      "Results for 9. XGBoost Importance:\n",
      "Average accuracy: 0.9742 ± 0.0044\n",
      "Average precision: 0.9803 ± 0.0233\n",
      "Average recall: 0.9475 ± 0.0175\n",
      "Average f1: 0.9632 ± 0.0061\n",
      "Average auc: 0.9975 ± 0.0006\n",
      "\n",
      "==================================================\n",
      "Processing 10. LightGBM Importance\n",
      "==================================================\n",
      "Selecting features using 10. LightGBM Importance...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10252, number of negative: 18514\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32\n",
      "[LightGBM] [Info] Number of data points in the train set: 28766, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.356393 -> initscore=-0.591054\n",
      "[LightGBM] [Info] Start training from score -0.591054\n",
      "Top 10 features selected by 10. LightGBM Importance:\n",
      "1. Breathing Problem: 266.0000\n",
      "2. Sore throat: 212.0000\n",
      "3. Asthma: 220.0000\n",
      "4. Chronic Lung Disease: 240.0000\n",
      "5. Heart Disease: 207.0000\n",
      "6. Hyper Tension: 207.0000\n",
      "7. Abroad travel: 169.0000\n",
      "8. Contact with COVID Patient: 216.0000\n",
      "9. Attended Large Gathering: 183.0000\n",
      "10. Family working in Public Exposed Places: 199.0000\n",
      "\n",
      "Training ANN with features selected by 10. LightGBM Importance\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Results for 10. LightGBM Importance:\n",
      "Average accuracy: 0.9861 ± 0.0032\n",
      "Average precision: 0.9865 ± 0.0105\n",
      "Average recall: 0.9746 ± 0.0035\n",
      "Average f1: 0.9805 ± 0.0042\n",
      "Average auc: 0.9987 ± 0.0003\n",
      "Comparison chart saved as 'feature_selection_comparison_ANN.png'\n",
      "Heatmap saved as 'feature_selection_heatmap_ANN.png'\n",
      "\n",
      "==================================================\n",
      "FINAL SUMMARY\n",
      "==================================================\n",
      "\n",
      "Techniques ranked by accuracy:\n",
      "1. 10. LightGBM Importance: 0.9861\n",
      "2. 2. Mutual Information: 0.9849\n",
      "3. 1. Chi-Square: 0.9831\n",
      "4. 4. Lasso: 0.9791\n",
      "5. 5. Random Forest Importance: 0.9784\n",
      "6. 3. Recursive Feature Elimination: 0.9776\n",
      "7. 7. Correlation-based: 0.9763\n",
      "8. 9. XGBoost Importance: 0.9742\n",
      "9. 6. Boruta: 0.9689\n",
      "10. 8. Sequential Forward Selection: 0.9570\n",
      "\n",
      "Best performing technique: 10. LightGBM Importance\n",
      "Top 10 features selected by 10. LightGBM Importance:\n",
      "1. Breathing Problem\n",
      "2. Sore throat\n",
      "3. Asthma\n",
      "4. Chronic Lung Disease\n",
      "5. Heart Disease\n",
      "6. Hyper Tension\n",
      "7. Abroad travel\n",
      "8. Contact with COVID Patient\n",
      "9. Attended Large Gathering\n",
      "10. Family working in Public Exposed Places\n"
     ]
    }
   ],
   "source": [
    "# Dependencies installation (run these commands in your terminal)\n",
    "# pip install pandas numpy scikit-learn tensorflow keras matplotlib seaborn xgboost lightgbm boruta\n",
    "# pip install imbalanced-learn statsmodels scipy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Feature Selection Libraries\n",
    "from sklearn.feature_selection import (\n",
    "    VarianceThreshold, chi2, f_classif, mutual_info_classif, \n",
    "    SelectKBest, RFE, SelectFromModel\n",
    ")\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from boruta import BorutaPy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# ML and Evaluation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Dense, Dropout, BatchNormalization\n",
    ")\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "def load_data(file_path):\n",
    "    print(\"Loading dataset...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=['COVID-19'])\n",
    "    y = df['COVID-19']\n",
    "    print(f\"Dataset loaded: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "    print(f\"Class distribution: {dict(y.value_counts())}\")\n",
    "    return X, y\n",
    "\n",
    "# Define all feature selection techniques\n",
    "def get_feature_selectors(X, y, n_features=10):\n",
    "    print(\"Initializing feature selection techniques...\")\n",
    "    feature_selectors = {\n",
    "        \"1. Chi-Square\": SelectKBest(chi2, k=n_features),\n",
    "        \"2. Mutual Information\": SelectKBest(mutual_info_classif, k=n_features),\n",
    "        \"3. Recursive Feature Elimination\": RFE(\n",
    "            estimator=LogisticRegression(solver='liblinear', max_iter=1000, random_state=42),\n",
    "            n_features_to_select=n_features\n",
    "        ),\n",
    "        \"4. Lasso\": SelectFromModel(\n",
    "            Lasso(alpha=0.01, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"5. Random Forest Importance\": SelectFromModel(\n",
    "            RandomForestClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"6. Boruta\": BorutaPy(\n",
    "            RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            n_estimators='auto', verbose=0, random_state=42\n",
    "        ),\n",
    "        \"7. Correlation-based\": None,  # Custom implementation\n",
    "        \"8. Sequential Forward Selection\": SequentialFeatureSelector(\n",
    "            RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "            n_features_to_select=n_features,\n",
    "            direction='forward'\n",
    "        ),\n",
    "        \"9. XGBoost Importance\": SelectFromModel(\n",
    "            XGBClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"10. LightGBM Importance\": SelectFromModel(\n",
    "            LGBMClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        )\n",
    "    }\n",
    "    return feature_selectors\n",
    "\n",
    "# Function to select top features using each technique\n",
    "def select_features(X, y, technique_name, selector, n_features=10):\n",
    "    print(f\"Selecting features using {technique_name}...\")\n",
    "    feature_names = X.columns.tolist()\n",
    "    \n",
    "    # Handle special case for Correlation-based selection\n",
    "    if technique_name == \"7. Correlation-based\":\n",
    "        # Calculate correlation of each feature with target\n",
    "        correlations = []\n",
    "        for col in X.columns:\n",
    "            corr = np.abs(X[col].corr(y))\n",
    "            correlations.append((col, corr))\n",
    "        \n",
    "        # Sort by correlation and select top n_features\n",
    "        correlations.sort(key=lambda x: x[1], reverse=True)\n",
    "        selected_features = [item[0] for item in correlations[:n_features]]\n",
    "        feature_importances = [item[1] for item in correlations[:n_features]]\n",
    "        \n",
    "    # Handle special case for Boruta\n",
    "    elif technique_name == \"6. Boruta\":\n",
    "        # Boruta requires array input\n",
    "        X_array = X.values\n",
    "        selector.fit(X_array, y)\n",
    "        \n",
    "        # Get the selected features\n",
    "        selected_mask = selector.support_\n",
    "        ranking = selector.ranking_\n",
    "        \n",
    "        # Sort by ranking and select top features\n",
    "        feature_ranking = [(feature, rank) for feature, rank, mask in \n",
    "                          zip(feature_names, ranking, selected_mask) if mask]\n",
    "        feature_ranking.sort(key=lambda x: x[1])\n",
    "        \n",
    "        # If Boruta selected fewer than n_features, add more by ranking\n",
    "        if len(feature_ranking) < n_features:\n",
    "            additional = [(f, r) for f, r, m in \n",
    "                         zip(feature_names, ranking, selected_mask) if not m]\n",
    "            additional.sort(key=lambda x: x[1])\n",
    "            feature_ranking.extend(additional[:n_features-len(feature_ranking)])\n",
    "        \n",
    "        feature_ranking = feature_ranking[:n_features]\n",
    "        selected_features = [item[0] for item in feature_ranking]\n",
    "        feature_importances = [1.0/item[1] for item in feature_ranking]  # Invert ranking for visualization\n",
    "    \n",
    "    else:\n",
    "        # Standard scikit-learn selectors\n",
    "        try:\n",
    "            selector.fit(X, y)\n",
    "            \n",
    "            # Different selector types have different ways to get selected features\n",
    "            if hasattr(selector, 'get_support'):\n",
    "                selected_mask = selector.get_support()\n",
    "                selected_features = [f for f, selected in zip(feature_names, selected_mask) if selected]\n",
    "                \n",
    "                # Get feature importances if available\n",
    "                if hasattr(selector, 'estimator_') and hasattr(selector.estimator_, 'feature_importances_'):\n",
    "                    feature_importances = selector.estimator_.feature_importances_[selected_mask]\n",
    "                elif hasattr(selector, 'scores_'):\n",
    "                    feature_importances = selector.scores_[selected_mask]\n",
    "                else:\n",
    "                    feature_importances = np.ones(len(selected_features))\n",
    "                    \n",
    "            elif hasattr(selector, 'coef_'):\n",
    "                # For models with coefficients like Lasso\n",
    "                coefs = np.abs(selector.coef_)\n",
    "                indices = np.argsort(coefs)[::-1][:n_features]\n",
    "                selected_features = [feature_names[i] for i in indices]\n",
    "                feature_importances = [coefs[i] for i in indices]\n",
    "                \n",
    "            else:\n",
    "                # Get features from the model itself\n",
    "                try:\n",
    "                    importances = getattr(selector, 'feature_importances_', \n",
    "                                         getattr(selector, 'coef_', None))\n",
    "                    if importances is None:\n",
    "                        importances = np.ones(len(feature_names))\n",
    "                    \n",
    "                    # For 2D coefficients (like in multiclass), take the mean\n",
    "                    if importances.ndim > 1:\n",
    "                        importances = np.mean(np.abs(importances), axis=0)\n",
    "                    \n",
    "                    # Select top features\n",
    "                    indices = np.argsort(np.abs(importances))[::-1][:n_features]\n",
    "                    selected_features = [feature_names[i] for i in indices]\n",
    "                    feature_importances = [np.abs(importances)[i] for i in indices]\n",
    "                    \n",
    "                except:\n",
    "                    # Fallback for other selectors\n",
    "                    indices = getattr(selector, 'support_', np.arange(min(n_features, len(feature_names))))\n",
    "                    if len(indices) > n_features:\n",
    "                        indices = indices[:n_features]\n",
    "                    selected_features = [feature_names[i] for i in indices]\n",
    "                    feature_importances = np.ones(len(selected_features))\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error with {technique_name}: {str(e)}\")\n",
    "            # Default to the first n_features if there's an error\n",
    "            selected_features = feature_names[:n_features]\n",
    "            feature_importances = np.ones(n_features)\n",
    "    \n",
    "    # Ensure exactly n_features are selected (truncate or pad if necessary)\n",
    "    if len(selected_features) > n_features:\n",
    "        selected_features = selected_features[:n_features]\n",
    "        feature_importances = feature_importances[:n_features]\n",
    "    elif len(selected_features) < n_features:\n",
    "        # Add remaining features based on variance\n",
    "        remaining = [f for f in feature_names if f not in selected_features]\n",
    "        selected_features.extend(remaining[:n_features-len(selected_features)])\n",
    "        feature_importances = list(feature_importances) + [0] * (n_features - len(feature_importances))\n",
    "    \n",
    "    # Print selected features\n",
    "    print(f\"Top {len(selected_features)} features selected by {technique_name}:\")\n",
    "    for i, (feature, importance) in enumerate(zip(selected_features, feature_importances)):\n",
    "        print(f\"{i+1}. {feature}: {importance:.4f}\")\n",
    "    \n",
    "    return selected_features, feature_importances\n",
    "\n",
    "# Build the ANN model for a specific set of features\n",
    "def build_ann_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        BatchNormalization(),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        BatchNormalization(),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train and evaluate model with k-fold cross validation\n",
    "def train_and_evaluate(X, y, selected_features, technique_name, k=5):\n",
    "    print(f\"\\nTraining ANN with features selected by {technique_name}\")\n",
    "    \n",
    "    # Prepare data for ANN\n",
    "    X_selected = X[selected_features].values\n",
    "    y_values = y.values\n",
    "    \n",
    "    # K-Fold validation\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    metrics = {\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': [],\n",
    "        'auc': []\n",
    "    }\n",
    "    \n",
    "    # Define early stopping\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Train and evaluate for each fold\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X_selected)):\n",
    "        print(f\"Training fold {fold+1}/{k}...\")\n",
    "        \n",
    "        X_train, X_test = X_selected[train_idx], X_selected[test_idx]\n",
    "        y_train, y_test = y_values[train_idx], y_values[test_idx]\n",
    "        \n",
    "        # Build and train model\n",
    "        model = build_ann_model((X_selected.shape[1],))\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=50,  # Reduced from 100 for faster execution\n",
    "            batch_size=32,\n",
    "            verbose=0,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[early_stop]\n",
    "        )\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics['accuracy'].append(accuracy_score(y_test, y_pred_classes))\n",
    "        metrics['precision'].append(precision_score(y_test, y_pred_classes))\n",
    "        metrics['recall'].append(recall_score(y_test, y_pred_classes))\n",
    "        metrics['f1'].append(f1_score(y_test, y_pred_classes))\n",
    "        try:\n",
    "            metrics['auc'].append(roc_auc_score(y_test, y_pred))\n",
    "        except:\n",
    "            metrics['auc'].append(0.5)  # Default for failed AUC calculation\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {metric: np.mean(values) for metric, values in metrics.items()}\n",
    "    std_metrics = {metric: np.std(values) for metric, values in metrics.items()}\n",
    "    \n",
    "    print(f\"\\nResults for {technique_name}:\")\n",
    "    for metric, value in avg_metrics.items():\n",
    "        print(f\"Average {metric}: {value:.4f} ± {std_metrics[metric]:.4f}\")\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "# Plot comparison bar chart\n",
    "def plot_comparison(all_results):\n",
    "    metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
    "    \n",
    "    # Sort techniques by accuracy\n",
    "    sorted_techniques = sorted(\n",
    "        all_results.keys(),\n",
    "        key=lambda x: all_results[x]['accuracy'],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Set width of bars\n",
    "    bar_width = 0.15\n",
    "    index = np.arange(len(sorted_techniques))\n",
    "    \n",
    "    # Colors for different metrics\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    \n",
    "    # Plot bars for each metric\n",
    "    for i, metric in enumerate(metrics_to_plot):\n",
    "        values = [all_results[technique][metric] for technique in sorted_techniques]\n",
    "        plt.bar(\n",
    "            index + i * bar_width, \n",
    "            values, \n",
    "            bar_width, \n",
    "            label=metric.capitalize(),\n",
    "            color=colors[i]\n",
    "        )\n",
    "    \n",
    "    # Add labels and legend\n",
    "    plt.xlabel('Feature Selection Technique', fontsize=12)\n",
    "    plt.ylabel('Score', fontsize=12)\n",
    "    plt.title('Comparison of Feature Selection Techniques', fontsize=14)\n",
    "    plt.xticks(\n",
    "        index + bar_width * 2, \n",
    "        [t.split('. ')[1] if '. ' in t else t for t in sorted_techniques],\n",
    "        rotation=45,\n",
    "        ha='right'\n",
    "    )\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=5)\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig('feature_selection_comparison_ANN.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Comparison chart saved as 'feature_selection_comparison_ANN.png'\")\n",
    "    plt.close()\n",
    "\n",
    "# Plot feature heatmap\n",
    "def plot_feature_heatmap(all_features, X):\n",
    "    # Create a matrix of features vs techniques\n",
    "    techniques = list(all_features.keys())\n",
    "    all_unique_features = list(set(feature for features in all_features.values() for feature in features))\n",
    "    \n",
    "    # Create a matrix with 1 if feature is selected by technique, 0 otherwise\n",
    "    matrix = np.zeros((len(techniques), len(all_unique_features)))\n",
    "    \n",
    "    for i, technique in enumerate(techniques):\n",
    "        for j, feature in enumerate(all_unique_features):\n",
    "            if feature in all_features[technique]:\n",
    "                matrix[i, j] = 1\n",
    "    \n",
    "    # Sort features by frequency of selection\n",
    "    feature_counts = matrix.sum(axis=0)\n",
    "    sorted_indices = np.argsort(feature_counts)[::-1]\n",
    "    sorted_features = [all_unique_features[i] for i in sorted_indices]\n",
    "    sorted_matrix = matrix[:, sorted_indices]\n",
    "    \n",
    "    # Create heatmap\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    sns.heatmap(\n",
    "        sorted_matrix,\n",
    "        cmap='Blues',\n",
    "        xticklabels=sorted_features,\n",
    "        yticklabels=[t.split('. ')[1] if '. ' in t else t for t in techniques],\n",
    "        cbar_kws={'label': 'Selected'}\n",
    "    )\n",
    "    plt.title('Feature Selection by Different Techniques', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig('feature_selection_heatmap_ANN.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Heatmap saved as 'feature_selection_heatmap_ANN.png'\")\n",
    "    plt.close()\n",
    "\n",
    "# Main function to run the whole process\n",
    "def main():\n",
    "    # Load data\n",
    "    file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with your path\n",
    "    X, y = load_data(file_path)\n",
    "    \n",
    "    # Get feature selectors\n",
    "    feature_selectors = get_feature_selectors(X, y)\n",
    "    \n",
    "    # Store results\n",
    "    all_results = {}\n",
    "    all_selected_features = {}\n",
    "    \n",
    "    # For each technique, select features and train model\n",
    "    for technique_name, selector in feature_selectors.items():\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Processing {technique_name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Select features\n",
    "        selected_features, _ = select_features(X, y, technique_name, selector)\n",
    "        all_selected_features[technique_name] = selected_features\n",
    "        \n",
    "        # Train and evaluate\n",
    "        results = train_and_evaluate(X, y, selected_features, technique_name)\n",
    "        all_results[technique_name] = results\n",
    "    \n",
    "    # Plot comparison\n",
    "    plot_comparison(all_results)\n",
    "    \n",
    "    # Plot feature heatmap\n",
    "    plot_feature_heatmap(all_selected_features, X)\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Sort techniques by accuracy\n",
    "    sorted_techniques = sorted(\n",
    "        all_results.keys(),\n",
    "        key=lambda x: all_results[x]['accuracy'],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTechniques ranked by accuracy:\")\n",
    "    for i, technique in enumerate(sorted_techniques):\n",
    "        print(f\"{i+1}. {technique}: {all_results[technique]['accuracy']:.4f}\")\n",
    "    \n",
    "    best_technique = sorted_techniques[0]\n",
    "    print(f\"\\nBest performing technique: {best_technique}\")\n",
    "    print(f\"Top 10 features selected by {best_technique}:\")\n",
    "    for i, feature in enumerate(all_selected_features[best_technique]):\n",
    "        print(f\"{i+1}. {feature}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7031ef37-e517-48d8-ad78-e980f229aab8",
   "metadata": {},
   "source": [
    "<H1>Multi Layer Perceptron</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "234db81d-f833-4d2c-a71e-9b71ce134b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded: 28766 samples, 20 features\n",
      "Class distribution: {0: 18514, 1: 10252}\n",
      "Initializing feature selection techniques...\n",
      "\n",
      "==================================================\n",
      "Processing 1. Chi-Square\n",
      "==================================================\n",
      "Selecting features using 1. Chi-Square...\n",
      "Top 10 features selected by 1. Chi-Square:\n",
      "1. Breathing Problem: 9964.0393\n",
      "2. Sore throat: 13201.1649\n",
      "3. Heart Disease: 3552.0005\n",
      "4. Diabetes: 1929.1672\n",
      "5. Hyper Tension: 3089.5719\n",
      "6. Gastrointestinal : 1693.0652\n",
      "7. Abroad travel: 11288.4346\n",
      "8. Contact with COVID Patient: 8194.1488\n",
      "9. Attended Large Gathering: 9140.5020\n",
      "10. Family working in Public Exposed Places: 7781.7278\n",
      "\n",
      "Training MLP with features selected by 1. Chi-Square\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\n",
      "Results for 1. Chi-Square:\n",
      "Average accuracy: 0.9854 ± 0.0021\n",
      "Average precision: 0.9868 ± 0.0089\n",
      "Average recall: 0.9722 ± 0.0036\n",
      "Average f1: 0.9794 ± 0.0026\n",
      "Average auc: 0.9985 ± 0.0004\n",
      "\n",
      "==================================================\n",
      "Processing 2. Mutual Information\n",
      "==================================================\n",
      "Selecting features using 2. Mutual Information...\n",
      "Top 10 features selected by 2. Mutual Information:\n",
      "1. Breathing Problem: 0.3041\n",
      "2. Sore throat: 0.4155\n",
      "3. Heart Disease: 0.0862\n",
      "4. Diabetes: 0.1087\n",
      "5. Hyper Tension: 0.0811\n",
      "6. Gastrointestinal : 0.0766\n",
      "7. Abroad travel: 0.2844\n",
      "8. Contact with COVID Patient: 0.1903\n",
      "9. Attended Large Gathering: 0.2405\n",
      "10. Family working in Public Exposed Places: 0.2199\n",
      "\n",
      "Training MLP with features selected by 2. Mutual Information\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\n",
      "Results for 2. Mutual Information:\n",
      "Average accuracy: 0.9860 ± 0.0024\n",
      "Average precision: 0.9892 ± 0.0111\n",
      "Average recall: 0.9714 ± 0.0055\n",
      "Average f1: 0.9801 ± 0.0032\n",
      "Average auc: 0.9985 ± 0.0004\n",
      "\n",
      "==================================================\n",
      "Processing 3. Recursive Feature Elimination\n",
      "==================================================\n",
      "Selecting features using 3. Recursive Feature Elimination...\n",
      "Top 10 features selected by 3. Recursive Feature Elimination:\n",
      "1. Breathing Problem: 1.0000\n",
      "2. Fever: 1.0000\n",
      "3. Dry Cough: 1.0000\n",
      "4. Sore throat: 1.0000\n",
      "5. Hyper Tension: 1.0000\n",
      "6. Abroad travel: 1.0000\n",
      "7. Contact with COVID Patient: 1.0000\n",
      "8. Attended Large Gathering: 1.0000\n",
      "9. Visited Public Exposed Places: 1.0000\n",
      "10. Family working in Public Exposed Places: 1.0000\n",
      "\n",
      "Training MLP with features selected by 3. Recursive Feature Elimination\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step\n",
      "\n",
      "Results for 3. Recursive Feature Elimination:\n",
      "Average accuracy: 0.9797 ± 0.0010\n",
      "Average precision: 0.9766 ± 0.0061\n",
      "Average recall: 0.9663 ± 0.0055\n",
      "Average f1: 0.9714 ± 0.0014\n",
      "Average auc: 0.9980 ± 0.0003\n",
      "\n",
      "==================================================\n",
      "Processing 4. Lasso\n",
      "==================================================\n",
      "Selecting features using 4. Lasso...\n",
      "Top 10 features selected by 4. Lasso:\n",
      "1. Breathing Problem: 1.0000\n",
      "2. Sore throat: 1.0000\n",
      "3. Fatigue : 1.0000\n",
      "4. Abroad travel: 1.0000\n",
      "5. Contact with COVID Patient: 1.0000\n",
      "6. Attended Large Gathering: 1.0000\n",
      "7. Visited Public Exposed Places: 1.0000\n",
      "8. Family working in Public Exposed Places: 1.0000\n",
      "9. Fever: 0.0000\n",
      "10. Dry Cough: 0.0000\n",
      "\n",
      "Training MLP with features selected by 4. Lasso\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Results for 4. Lasso:\n",
      "Average accuracy: 0.9799 ± 0.0025\n",
      "Average precision: 0.9778 ± 0.0110\n",
      "Average recall: 0.9657 ± 0.0061\n",
      "Average f1: 0.9717 ± 0.0036\n",
      "Average auc: 0.9981 ± 0.0002\n",
      "\n",
      "==================================================\n",
      "Processing 5. Random Forest Importance\n",
      "==================================================\n",
      "Selecting features using 5. Random Forest Importance...\n",
      "Top 10 features selected by 5. Random Forest Importance:\n",
      "1. Breathing Problem: 0.1560\n",
      "2. Sore throat: 0.2333\n",
      "3. Abroad travel: 0.1637\n",
      "4. Contact with COVID Patient: 0.0630\n",
      "5. Attended Large Gathering: 0.1179\n",
      "6. Family working in Public Exposed Places: 0.0940\n",
      "7. Fever: 0.0000\n",
      "8. Dry Cough: 0.0000\n",
      "9. Running Nose: 0.0000\n",
      "10. Asthma: 0.0000\n",
      "\n",
      "Training MLP with features selected by 5. Random Forest Importance\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Results for 5. Random Forest Importance:\n",
      "Average accuracy: 0.9790 ± 0.0036\n",
      "Average precision: 0.9906 ± 0.0063\n",
      "Average recall: 0.9502 ± 0.0132\n",
      "Average f1: 0.9699 ± 0.0049\n",
      "Average auc: 0.9980 ± 0.0002\n",
      "\n",
      "==================================================\n",
      "Processing 6. Boruta\n",
      "==================================================\n",
      "Selecting features using 6. Boruta...\n",
      "Top 10 features selected by 6. Boruta:\n",
      "1. Breathing Problem: 1.0000\n",
      "2. Sore throat: 1.0000\n",
      "3. Running Nose: 1.0000\n",
      "4. Asthma: 1.0000\n",
      "5. Chronic Lung Disease: 1.0000\n",
      "6. Headache: 1.0000\n",
      "7. Heart Disease: 1.0000\n",
      "8. Diabetes: 1.0000\n",
      "9. Hyper Tension: 1.0000\n",
      "10. Fatigue : 1.0000\n",
      "\n",
      "Training MLP with features selected by 6. Boruta\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\n",
      "Results for 6. Boruta:\n",
      "Average accuracy: 0.9693 ± 0.0096\n",
      "Average precision: 0.9594 ± 0.0212\n",
      "Average recall: 0.9548 ± 0.0108\n",
      "Average f1: 0.9570 ± 0.0131\n",
      "Average auc: 0.9946 ± 0.0032\n",
      "\n",
      "==================================================\n",
      "Processing 7. Correlation-based\n",
      "==================================================\n",
      "Selecting features using 7. Correlation-based...\n",
      "Top 10 features selected by 7. Correlation-based:\n",
      "1. Breathing Problem: 0.7502\n",
      "2. Fever: nan\n",
      "3. Dry Cough: nan\n",
      "4. Sore throat: 0.8549\n",
      "5. Abroad travel: 0.7081\n",
      "6. Attended Large Gathering: 0.6758\n",
      "7. Family working in Public Exposed Places: 0.6449\n",
      "8. Contact with COVID Patient: 0.6027\n",
      "9. Diabetes: 0.4719\n",
      "10. Heart Disease: 0.4197\n",
      "\n",
      "Training MLP with features selected by 7. Correlation-based\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\n",
      "Results for 7. Correlation-based:\n",
      "Average accuracy: 0.9753 ± 0.0045\n",
      "Average precision: 0.9804 ± 0.0109\n",
      "Average recall: 0.9500 ± 0.0221\n",
      "Average f1: 0.9647 ± 0.0072\n",
      "Average auc: 0.9978 ± 0.0002\n",
      "\n",
      "==================================================\n",
      "Processing 8. Sequential Forward Selection\n",
      "==================================================\n",
      "Selecting features using 8. Sequential Forward Selection...\n",
      "Top 10 features selected by 8. Sequential Forward Selection:\n",
      "1. Fever: 1.0000\n",
      "2. Dry Cough: 1.0000\n",
      "3. Sore throat: 1.0000\n",
      "4. Running Nose: 1.0000\n",
      "5. Asthma: 1.0000\n",
      "6. Chronic Lung Disease: 1.0000\n",
      "7. Abroad travel: 1.0000\n",
      "8. Attended Large Gathering: 1.0000\n",
      "9. Wearing Masks: 1.0000\n",
      "10. Sanitization from Market: 1.0000\n",
      "\n",
      "Training MLP with features selected by 8. Sequential Forward Selection\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step\n",
      "\n",
      "Results for 8. Sequential Forward Selection:\n",
      "Average accuracy: 0.9578 ± 0.0024\n",
      "Average precision: 0.9908 ± 0.0046\n",
      "Average recall: 0.8899 ± 0.0072\n",
      "Average f1: 0.9376 ± 0.0034\n",
      "Average auc: 0.9912 ± 0.0012\n",
      "\n",
      "==================================================\n",
      "Processing 9. XGBoost Importance\n",
      "==================================================\n",
      "Selecting features using 9. XGBoost Importance...\n",
      "Top 10 features selected by 9. XGBoost Importance:\n",
      "1. Sore throat: 0.5873\n",
      "2. Abroad travel: 0.2135\n",
      "3. Attended Large Gathering: 0.0666\n",
      "4. Breathing Problem: 0.0000\n",
      "5. Fever: 0.0000\n",
      "6. Dry Cough: 0.0000\n",
      "7. Running Nose: 0.0000\n",
      "8. Asthma: 0.0000\n",
      "9. Chronic Lung Disease: 0.0000\n",
      "10. Headache: 0.0000\n",
      "\n",
      "Training MLP with features selected by 9. XGBoost Importance\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\n",
      "Results for 9. XGBoost Importance:\n",
      "Average accuracy: 0.9774 ± 0.0035\n",
      "Average precision: 0.9854 ± 0.0182\n",
      "Average recall: 0.9512 ± 0.0186\n",
      "Average f1: 0.9677 ± 0.0050\n",
      "Average auc: 0.9979 ± 0.0006\n",
      "\n",
      "==================================================\n",
      "Processing 10. LightGBM Importance\n",
      "==================================================\n",
      "Selecting features using 10. LightGBM Importance...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10252, number of negative: 18514\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32\n",
      "[LightGBM] [Info] Number of data points in the train set: 28766, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.356393 -> initscore=-0.591054\n",
      "[LightGBM] [Info] Start training from score -0.591054\n",
      "Top 10 features selected by 10. LightGBM Importance:\n",
      "1. Breathing Problem: 266.0000\n",
      "2. Sore throat: 212.0000\n",
      "3. Asthma: 220.0000\n",
      "4. Chronic Lung Disease: 240.0000\n",
      "5. Heart Disease: 207.0000\n",
      "6. Hyper Tension: 207.0000\n",
      "7. Abroad travel: 169.0000\n",
      "8. Contact with COVID Patient: 216.0000\n",
      "9. Attended Large Gathering: 183.0000\n",
      "10. Family working in Public Exposed Places: 199.0000\n",
      "\n",
      "Training MLP with features selected by 10. LightGBM Importance\n",
      "Training fold 1/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\n",
      "Results for 10. LightGBM Importance:\n",
      "Average accuracy: 0.9870 ± 0.0022\n",
      "Average precision: 0.9929 ± 0.0050\n",
      "Average recall: 0.9704 ± 0.0033\n",
      "Average f1: 0.9815 ± 0.0031\n",
      "Average auc: 0.9986 ± 0.0003\n",
      "Comparison chart saved as 'feature_selection_comparison_MLP.png'\n",
      "Heatmap saved as 'feature_selection_heatmap_MLP.png'\n",
      "\n",
      "==================================================\n",
      "FINAL SUMMARY\n",
      "==================================================\n",
      "\n",
      "Techniques ranked by accuracy:\n",
      "1. 10. LightGBM Importance: 0.9870\n",
      "2. 2. Mutual Information: 0.9860\n",
      "3. 1. Chi-Square: 0.9854\n",
      "4. 4. Lasso: 0.9799\n",
      "5. 3. Recursive Feature Elimination: 0.9797\n",
      "6. 5. Random Forest Importance: 0.9790\n",
      "7. 9. XGBoost Importance: 0.9774\n",
      "8. 7. Correlation-based: 0.9753\n",
      "9. 6. Boruta: 0.9693\n",
      "10. 8. Sequential Forward Selection: 0.9578\n",
      "\n",
      "Best performing technique: 10. LightGBM Importance\n",
      "Top 10 features selected by 10. LightGBM Importance:\n",
      "1. Breathing Problem\n",
      "2. Sore throat\n",
      "3. Asthma\n",
      "4. Chronic Lung Disease\n",
      "5. Heart Disease\n",
      "6. Hyper Tension\n",
      "7. Abroad travel\n",
      "8. Contact with COVID Patient\n",
      "9. Attended Large Gathering\n",
      "10. Family working in Public Exposed Places\n"
     ]
    }
   ],
   "source": [
    "# Dependencies installation (run these commands in your terminal)\n",
    "# pip install pandas numpy scikit-learn tensorflow keras matplotlib seaborn xgboost lightgbm boruta\n",
    "# pip install imbalanced-learn statsmodels scipy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Feature Selection Libraries\n",
    "from sklearn.feature_selection import (\n",
    "    VarianceThreshold, chi2, f_classif, mutual_info_classif, \n",
    "    SelectKBest, RFE, SelectFromModel\n",
    ")\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from boruta import BorutaPy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# ML and Evaluation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Dense, Dropout, BatchNormalization\n",
    ")\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "def load_data(file_path):\n",
    "    print(\"Loading dataset...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=['COVID-19'])\n",
    "    y = df['COVID-19']\n",
    "    print(f\"Dataset loaded: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "    print(f\"Class distribution: {dict(y.value_counts())}\")\n",
    "    return X, y\n",
    "\n",
    "# Define all feature selection techniques\n",
    "def get_feature_selectors(X, y, n_features=10):\n",
    "    print(\"Initializing feature selection techniques...\")\n",
    "    feature_selectors = {\n",
    "        \"1. Chi-Square\": SelectKBest(chi2, k=n_features),\n",
    "        \"2. Mutual Information\": SelectKBest(mutual_info_classif, k=n_features),\n",
    "        \"3. Recursive Feature Elimination\": RFE(\n",
    "            estimator=LogisticRegression(solver='liblinear', max_iter=1000, random_state=42),\n",
    "            n_features_to_select=n_features\n",
    "        ),\n",
    "        \"4. Lasso\": SelectFromModel(\n",
    "            Lasso(alpha=0.01, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"5. Random Forest Importance\": SelectFromModel(\n",
    "            RandomForestClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"6. Boruta\": BorutaPy(\n",
    "            RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            n_estimators='auto', verbose=0, random_state=42\n",
    "        ),\n",
    "        \"7. Correlation-based\": None,  # Custom implementation\n",
    "        \"8. Sequential Forward Selection\": SequentialFeatureSelector(\n",
    "            RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "            n_features_to_select=n_features,\n",
    "            direction='forward'\n",
    "        ),\n",
    "        \"9. XGBoost Importance\": SelectFromModel(\n",
    "            XGBClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"10. LightGBM Importance\": SelectFromModel(\n",
    "            LGBMClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        )\n",
    "    }\n",
    "    return feature_selectors\n",
    "\n",
    "# Function to select top features using each technique\n",
    "def select_features(X, y, technique_name, selector, n_features=10):\n",
    "    print(f\"Selecting features using {technique_name}...\")\n",
    "    feature_names = X.columns.tolist()\n",
    "    \n",
    "    # Handle special case for Correlation-based selection\n",
    "    if technique_name == \"7. Correlation-based\":\n",
    "        # Calculate correlation of each feature with target\n",
    "        correlations = []\n",
    "        for col in X.columns:\n",
    "            corr = np.abs(X[col].corr(y))\n",
    "            correlations.append((col, corr))\n",
    "        \n",
    "        # Sort by correlation and select top n_features\n",
    "        correlations.sort(key=lambda x: x[1], reverse=True)\n",
    "        selected_features = [item[0] for item in correlations[:n_features]]\n",
    "        feature_importances = [item[1] for item in correlations[:n_features]]\n",
    "        \n",
    "    # Handle special case for Boruta\n",
    "    elif technique_name == \"6. Boruta\":\n",
    "        # Boruta requires array input\n",
    "        X_array = X.values\n",
    "        selector.fit(X_array, y)\n",
    "        \n",
    "        # Get the selected features\n",
    "        selected_mask = selector.support_\n",
    "        ranking = selector.ranking_\n",
    "        \n",
    "        # Sort by ranking and select top features\n",
    "        feature_ranking = [(feature, rank) for feature, rank, mask in \n",
    "                          zip(feature_names, ranking, selected_mask) if mask]\n",
    "        feature_ranking.sort(key=lambda x: x[1])\n",
    "        \n",
    "        # If Boruta selected fewer than n_features, add more by ranking\n",
    "        if len(feature_ranking) < n_features:\n",
    "            additional = [(f, r) for f, r, m in \n",
    "                         zip(feature_names, ranking, selected_mask) if not m]\n",
    "            additional.sort(key=lambda x: x[1])\n",
    "            feature_ranking.extend(additional[:n_features-len(feature_ranking)])\n",
    "        \n",
    "        feature_ranking = feature_ranking[:n_features]\n",
    "        selected_features = [item[0] for item in feature_ranking]\n",
    "        feature_importances = [1.0/item[1] for item in feature_ranking]  # Invert ranking for visualization\n",
    "    \n",
    "    else:\n",
    "        # Standard scikit-learn selectors\n",
    "        try:\n",
    "            selector.fit(X, y)\n",
    "            \n",
    "            # Different selector types have different ways to get selected features\n",
    "            if hasattr(selector, 'get_support'):\n",
    "                selected_mask = selector.get_support()\n",
    "                selected_features = [f for f, selected in zip(feature_names, selected_mask) if selected]\n",
    "                \n",
    "                # Get feature importances if available\n",
    "                if hasattr(selector, 'estimator_') and hasattr(selector.estimator_, 'feature_importances_'):\n",
    "                    feature_importances = selector.estimator_.feature_importances_[selected_mask]\n",
    "                elif hasattr(selector, 'scores_'):\n",
    "                    feature_importances = selector.scores_[selected_mask]\n",
    "                else:\n",
    "                    feature_importances = np.ones(len(selected_features))\n",
    "                    \n",
    "            elif hasattr(selector, 'coef_'):\n",
    "                # For models with coefficients like Lasso\n",
    "                coefs = np.abs(selector.coef_)\n",
    "                indices = np.argsort(coefs)[::-1][:n_features]\n",
    "                selected_features = [feature_names[i] for i in indices]\n",
    "                feature_importances = [coefs[i] for i in indices]\n",
    "                \n",
    "            else:\n",
    "                # Get features from the model itself\n",
    "                try:\n",
    "                    importances = getattr(selector, 'feature_importances_', \n",
    "                                         getattr(selector, 'coef_', None))\n",
    "                    if importances is None:\n",
    "                        importances = np.ones(len(feature_names))\n",
    "                    \n",
    "                    # For 2D coefficients (like in multiclass), take the mean\n",
    "                    if importances.ndim > 1:\n",
    "                        importances = np.mean(np.abs(importances), axis=0)\n",
    "                    \n",
    "                    # Select top features\n",
    "                    indices = np.argsort(np.abs(importances))[::-1][:n_features]\n",
    "                    selected_features = [feature_names[i] for i in indices]\n",
    "                    feature_importances = [np.abs(importances)[i] for i in indices]\n",
    "                    \n",
    "                except:\n",
    "                    # Fallback for other selectors\n",
    "                    indices = getattr(selector, 'support_', np.arange(min(n_features, len(feature_names))))\n",
    "                    if len(indices) > n_features:\n",
    "                        indices = indices[:n_features]\n",
    "                    selected_features = [feature_names[i] for i in indices]\n",
    "                    feature_importances = np.ones(len(selected_features))\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error with {technique_name}: {str(e)}\")\n",
    "            # Default to the first n_features if there's an error\n",
    "            selected_features = feature_names[:n_features]\n",
    "            feature_importances = np.ones(n_features)\n",
    "    \n",
    "    # Ensure exactly n_features are selected (truncate or pad if necessary)\n",
    "    if len(selected_features) > n_features:\n",
    "        selected_features = selected_features[:n_features]\n",
    "        feature_importances = feature_importances[:n_features]\n",
    "    elif len(selected_features) < n_features:\n",
    "        # Add remaining features based on variance\n",
    "        remaining = [f for f in feature_names if f not in selected_features]\n",
    "        selected_features.extend(remaining[:n_features-len(selected_features)])\n",
    "        feature_importances = list(feature_importances) + [0] * (n_features - len(feature_importances))\n",
    "    \n",
    "    # Print selected features\n",
    "    print(f\"Top {len(selected_features)} features selected by {technique_name}:\")\n",
    "    for i, (feature, importance) in enumerate(zip(selected_features, feature_importances)):\n",
    "        print(f\"{i+1}. {feature}: {importance:.4f}\")\n",
    "    \n",
    "    return selected_features, feature_importances\n",
    "\n",
    "# Build the MLP model for a specific set of features\n",
    "def build_mlp_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=input_shape),  # First hidden layer\n",
    "        Dropout(0.3),  # Dropout layer for regularization\n",
    "        BatchNormalization(),  # Batch normalization\n",
    "        Dense(64, activation='relu'),  # Second hidden layer\n",
    "        Dropout(0.4),  # Dropout layer for regularization\n",
    "        BatchNormalization(),  # Batch normalization\n",
    "        Dense(32, activation='relu'),  # Third hidden layer\n",
    "        Dropout(0.5),  # Dropout layer for regularization\n",
    "        Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train and evaluate model with k-fold cross validation\n",
    "def train_and_evaluate(X, y, selected_features, technique_name, k=5):\n",
    "    print(f\"\\nTraining MLP with features selected by {technique_name}\")\n",
    "    \n",
    "    # Prepare data for MLP\n",
    "    X_selected = X[selected_features].values\n",
    "    y_values = y.values\n",
    "    \n",
    "    # K-Fold validation\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    metrics = {\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': [],\n",
    "        'auc': []\n",
    "    }\n",
    "    \n",
    "    # Define early stopping\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Train and evaluate for each fold\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X_selected)):\n",
    "        print(f\"Training fold {fold+1}/{k}...\")\n",
    "        \n",
    "        X_train, X_test = X_selected[train_idx], X_selected[test_idx]\n",
    "        y_train, y_test = y_values[train_idx], y_values[test_idx]\n",
    "        \n",
    "        # Build and train model\n",
    "        model = build_mlp_model((X_selected.shape[1],))\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=50,  # Reduced from 100 for faster execution\n",
    "            batch_size=32,\n",
    "            verbose=0,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[early_stop]\n",
    "        )\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics['accuracy'].append(accuracy_score(y_test, y_pred_classes))\n",
    "        metrics['precision'].append(precision_score(y_test, y_pred_classes))\n",
    "        metrics['recall'].append(recall_score(y_test, y_pred_classes))\n",
    "        metrics['f1'].append(f1_score(y_test, y_pred_classes))\n",
    "        try:\n",
    "            metrics['auc'].append(roc_auc_score(y_test, y_pred))\n",
    "        except:\n",
    "            metrics['auc'].append(0.5)  # Default for failed AUC calculation\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {metric: np.mean(values) for metric, values in metrics.items()}\n",
    "    std_metrics = {metric: np.std(values) for metric, values in metrics.items()}\n",
    "    \n",
    "    print(f\"\\nResults for {technique_name}:\")\n",
    "    for metric, value in avg_metrics.items():\n",
    "        print(f\"Average {metric}: {value:.4f} ± {std_metrics[metric]:.4f}\")\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "# Plot comparison bar chart\n",
    "def plot_comparison(all_results):\n",
    "    metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
    "    \n",
    "    # Sort techniques by accuracy\n",
    "    sorted_techniques = sorted(\n",
    "        all_results.keys(),\n",
    "        key=lambda x: all_results[x]['accuracy'],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Set width of bars\n",
    "    bar_width = 0.15\n",
    "    index = np.arange(len(sorted_techniques))\n",
    "    \n",
    "    # Colors for different metrics\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    \n",
    "    # Plot bars for each metric\n",
    "    for i, metric in enumerate(metrics_to_plot):\n",
    "        values = [all_results[technique][metric] for technique in sorted_techniques]\n",
    "        plt.bar(\n",
    "            index + i * bar_width, \n",
    "            values, \n",
    "            bar_width, \n",
    "            label=metric.capitalize(),\n",
    "            color=colors[i]\n",
    "        )\n",
    "    \n",
    "    # Add labels and legend\n",
    "    plt.xlabel('Feature Selection Technique', fontsize=12)\n",
    "    plt.ylabel('Score', fontsize=12)\n",
    "    plt.title('Comparison of Feature Selection Techniques', fontsize=14)\n",
    "    plt.xticks(\n",
    "        index + bar_width * 2, \n",
    "        [t.split('. ')[1] if '. ' in t else t for t in sorted_techniques],\n",
    "        rotation=45,\n",
    "        ha='right'\n",
    "    )\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=5)\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig('feature_selection_comparison_MLP.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Comparison chart saved as 'feature_selection_comparison_MLP.png'\")\n",
    "    plt.close()\n",
    "\n",
    "# Plot feature heatmap\n",
    "def plot_feature_heatmap(all_features, X):\n",
    "    # Create a matrix of features vs techniques\n",
    "    techniques = list(all_features.keys())\n",
    "    all_unique_features = list(set(feature for features in all_features.values() for feature in features))\n",
    "    \n",
    "    # Create a matrix with 1 if feature is selected by technique, 0 otherwise\n",
    "    matrix = np.zeros((len(techniques), len(all_unique_features)))\n",
    "    \n",
    "    for i, technique in enumerate(techniques):\n",
    "        for j, feature in enumerate(all_unique_features):\n",
    "            if feature in all_features[technique]:\n",
    "                matrix[i, j] = 1\n",
    "    \n",
    "    # Sort features by frequency of selection\n",
    "    feature_counts = matrix.sum(axis=0)\n",
    "    sorted_indices = np.argsort(feature_counts)[::-1]\n",
    "    sorted_features = [all_unique_features[i] for i in sorted_indices]\n",
    "    sorted_matrix = matrix[:, sorted_indices]\n",
    "    \n",
    "    # Create heatmap\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    sns.heatmap(\n",
    "        sorted_matrix,\n",
    "        cmap='Blues',\n",
    "        xticklabels=sorted_features,\n",
    "        yticklabels=[t.split('. ')[1] if '. ' in t else t for t in techniques],\n",
    "        cbar_kws={'label': 'Selected'}\n",
    "    )\n",
    "    plt.title('Feature Selection by Different Techniques', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig('feature_selection_heatmap_MLP.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Heatmap saved as 'feature_selection_heatmap_MLP.png'\")\n",
    "    plt.close()\n",
    "\n",
    "# Main function to run the whole process\n",
    "def main():\n",
    "    # Load data\n",
    "    file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with your path\n",
    "    X, y = load_data(file_path)\n",
    "    \n",
    "    # Get feature selectors\n",
    "    feature_selectors = get_feature_selectors(X, y)\n",
    "    \n",
    "    # Store results\n",
    "    all_results = {}\n",
    "    all_selected_features = {}\n",
    "    \n",
    "    # For each technique, select features and train model\n",
    "    for technique_name, selector in feature_selectors.items():\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Processing {technique_name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Select features\n",
    "        selected_features, _ = select_features(X, y, technique_name, selector)\n",
    "        all_selected_features[technique_name] = selected_features\n",
    "        \n",
    "        # Train and evaluate\n",
    "        results = train_and_evaluate(X, y, selected_features, technique_name)\n",
    "        all_results[technique_name] = results\n",
    "    \n",
    "    # Plot comparison\n",
    "    plot_comparison(all_results)\n",
    "    \n",
    "    # Plot feature heatmap\n",
    "    plot_feature_heatmap(all_selected_features, X)\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Sort techniques by accuracy\n",
    "    sorted_techniques = sorted(\n",
    "        all_results.keys(),\n",
    "        key=lambda x: all_results[x]['accuracy'],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTechniques ranked by accuracy:\")\n",
    "    for i, technique in enumerate(sorted_techniques):\n",
    "        print(f\"{i+1}. {technique}: {all_results[technique]['accuracy']:.4f}\")\n",
    "    \n",
    "    best_technique = sorted_techniques[0]\n",
    "    print(f\"\\nBest performing technique: {best_technique}\")\n",
    "    print(f\"Top 10 features selected by {best_technique}:\")\n",
    "    for i, feature in enumerate(all_selected_features[best_technique]):\n",
    "        print(f\"{i+1}. {feature}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d62ebfb-356c-4747-9752-f09e31e003ce",
   "metadata": {},
   "source": [
    "<H1>TabNet</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1de74b06-124e-4c6d-9ea3-5941ac9fcd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded: 28766 samples, 20 features\n",
      "Class distribution: {0: 18514, 1: 10252}\n",
      "Initializing feature selection techniques...\n",
      "\n",
      "==================================================\n",
      "Processing 1. Chi-Square\n",
      "==================================================\n",
      "Selecting features using 1. Chi-Square...\n",
      "Top 10 features selected by 1. Chi-Square:\n",
      "1. Breathing Problem: 9964.0393\n",
      "2. Sore throat: 13201.1649\n",
      "3. Heart Disease: 3552.0005\n",
      "4. Diabetes: 1929.1672\n",
      "5. Hyper Tension: 3089.5719\n",
      "6. Gastrointestinal : 1693.0652\n",
      "7. Abroad travel: 11288.4346\n",
      "8. Contact with COVID Patient: 8194.1488\n",
      "9. Attended Large Gathering: 9140.5020\n",
      "10. Family working in Public Exposed Places: 7781.7278\n",
      "\n",
      "Training TabNet with features selected by 1. Chi-Square\n",
      "Training fold 1/5...\n",
      "epoch 0  | loss: 0.24799 | test_accuracy: 0.90615 | test_auc: 0.97363 |  0:00:02s\n",
      "epoch 1  | loss: 0.0834  | test_accuracy: 0.9178  | test_auc: 0.98947 |  0:00:05s\n",
      "epoch 2  | loss: 0.07275 | test_accuracy: 0.92353 | test_auc: 0.99245 |  0:00:08s\n",
      "epoch 3  | loss: 0.05839 | test_accuracy: 0.95447 | test_auc: 0.99543 |  0:00:11s\n",
      "epoch 4  | loss: 0.04948 | test_accuracy: 0.95916 | test_auc: 0.99635 |  0:00:14s\n",
      "epoch 5  | loss: 0.04253 | test_accuracy: 0.97636 | test_auc: 0.99809 |  0:00:17s\n",
      "epoch 6  | loss: 0.03849 | test_accuracy: 0.98019 | test_auc: 0.99838 |  0:00:20s\n",
      "epoch 7  | loss: 0.03871 | test_accuracy: 0.98262 | test_auc: 0.99894 |  0:00:23s\n",
      "epoch 8  | loss: 0.03443 | test_accuracy: 0.98436 | test_auc: 0.999   |  0:00:26s\n",
      "epoch 9  | loss: 0.03237 | test_accuracy: 0.98384 | test_auc: 0.99843 |  0:00:29s\n",
      "epoch 10 | loss: 0.03512 | test_accuracy: 0.98801 | test_auc: 0.99883 |  0:00:31s\n",
      "epoch 11 | loss: 0.03307 | test_accuracy: 0.98749 | test_auc: 0.99896 |  0:00:34s\n",
      "epoch 12 | loss: 0.03395 | test_accuracy: 0.98836 | test_auc: 0.99889 |  0:00:37s\n",
      "epoch 13 | loss: 0.03231 | test_accuracy: 0.98853 | test_auc: 0.9988  |  0:00:40s\n",
      "epoch 14 | loss: 0.03264 | test_accuracy: 0.98836 | test_auc: 0.99823 |  0:00:43s\n",
      "epoch 15 | loss: 0.03746 | test_accuracy: 0.98714 | test_auc: 0.9984  |  0:00:46s\n",
      "epoch 16 | loss: 0.04275 | test_accuracy: 0.98783 | test_auc: 0.99854 |  0:00:49s\n",
      "epoch 17 | loss: 0.03723 | test_accuracy: 0.98679 | test_auc: 0.99865 |  0:00:52s\n",
      "epoch 18 | loss: 0.03723 | test_accuracy: 0.98957 | test_auc: 0.99835 |  0:00:55s\n",
      "epoch 19 | loss: 0.03415 | test_accuracy: 0.9894  | test_auc: 0.99861 |  0:00:57s\n",
      "epoch 20 | loss: 0.03265 | test_accuracy: 0.98801 | test_auc: 0.99866 |  0:01:00s\n",
      "epoch 21 | loss: 0.03099 | test_accuracy: 0.99027 | test_auc: 0.99876 |  0:01:03s\n",
      "epoch 22 | loss: 0.03115 | test_accuracy: 0.98957 | test_auc: 0.99854 |  0:01:06s\n",
      "epoch 23 | loss: 0.03109 | test_accuracy: 0.98975 | test_auc: 0.99868 |  0:01:09s\n",
      "epoch 24 | loss: 0.03138 | test_accuracy: 0.98957 | test_auc: 0.99891 |  0:01:12s\n",
      "epoch 25 | loss: 0.02897 | test_accuracy: 0.98957 | test_auc: 0.99885 |  0:01:15s\n",
      "epoch 26 | loss: 0.02958 | test_accuracy: 0.98975 | test_auc: 0.99884 |  0:01:18s\n",
      "epoch 27 | loss: 0.02981 | test_accuracy: 0.98957 | test_auc: 0.99871 |  0:01:21s\n",
      "epoch 28 | loss: 0.02904 | test_accuracy: 0.98922 | test_auc: 0.99882 |  0:01:24s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_test_auc = 0.999\n",
      "Training fold 2/5...\n",
      "epoch 0  | loss: 0.22954 | test_accuracy: 0.53329 | test_auc: 0.92398 |  0:00:02s\n",
      "epoch 1  | loss: 0.07638 | test_accuracy: 0.55223 | test_auc: 0.9547  |  0:00:05s\n",
      "epoch 2  | loss: 0.06129 | test_accuracy: 0.90092 | test_auc: 0.97306 |  0:00:08s\n",
      "epoch 3  | loss: 0.05269 | test_accuracy: 0.95359 | test_auc: 0.98048 |  0:00:11s\n",
      "epoch 4  | loss: 0.04978 | test_accuracy: 0.97549 | test_auc: 0.99652 |  0:00:14s\n",
      "epoch 5  | loss: 0.04313 | test_accuracy: 0.98001 | test_auc: 0.99563 |  0:00:17s\n",
      "epoch 6  | loss: 0.04095 | test_accuracy: 0.98662 | test_auc: 0.99783 |  0:00:20s\n",
      "epoch 7  | loss: 0.03889 | test_accuracy: 0.98609 | test_auc: 0.99772 |  0:00:23s\n",
      "epoch 8  | loss: 0.03612 | test_accuracy: 0.98905 | test_auc: 0.99852 |  0:00:26s\n",
      "epoch 9  | loss: 0.03486 | test_accuracy: 0.98974 | test_auc: 0.9986  |  0:00:29s\n",
      "epoch 10 | loss: 0.03566 | test_accuracy: 0.98922 | test_auc: 0.9983  |  0:00:32s\n",
      "epoch 11 | loss: 0.03508 | test_accuracy: 0.99114 | test_auc: 0.99864 |  0:00:35s\n",
      "epoch 12 | loss: 0.03249 | test_accuracy: 0.99079 | test_auc: 0.99861 |  0:00:37s\n",
      "epoch 13 | loss: 0.03122 | test_accuracy: 0.99079 | test_auc: 0.99857 |  0:00:40s\n",
      "epoch 14 | loss: 0.03694 | test_accuracy: 0.98731 | test_auc: 0.99811 |  0:00:43s\n",
      "epoch 15 | loss: 0.03515 | test_accuracy: 0.99009 | test_auc: 0.99867 |  0:00:46s\n",
      "epoch 16 | loss: 0.03867 | test_accuracy: 0.99027 | test_auc: 0.99871 |  0:00:49s\n",
      "epoch 17 | loss: 0.03697 | test_accuracy: 0.99044 | test_auc: 0.99851 |  0:00:52s\n",
      "epoch 18 | loss: 0.03405 | test_accuracy: 0.99096 | test_auc: 0.99847 |  0:00:55s\n",
      "epoch 19 | loss: 0.03141 | test_accuracy: 0.99148 | test_auc: 0.99882 |  0:00:58s\n",
      "epoch 20 | loss: 0.02891 | test_accuracy: 0.99079 | test_auc: 0.99883 |  0:01:01s\n",
      "epoch 21 | loss: 0.02902 | test_accuracy: 0.99131 | test_auc: 0.99879 |  0:01:04s\n",
      "epoch 22 | loss: 0.02879 | test_accuracy: 0.99096 | test_auc: 0.99883 |  0:01:07s\n",
      "epoch 23 | loss: 0.02732 | test_accuracy: 0.99148 | test_auc: 0.99894 |  0:01:09s\n",
      "epoch 24 | loss: 0.02944 | test_accuracy: 0.98922 | test_auc: 0.99881 |  0:01:12s\n",
      "epoch 25 | loss: 0.02931 | test_accuracy: 0.99148 | test_auc: 0.99887 |  0:01:15s\n",
      "epoch 26 | loss: 0.02858 | test_accuracy: 0.99096 | test_auc: 0.99882 |  0:01:18s\n",
      "epoch 27 | loss: 0.02871 | test_accuracy: 0.99148 | test_auc: 0.99882 |  0:01:21s\n",
      "epoch 28 | loss: 0.02851 | test_accuracy: 0.99027 | test_auc: 0.99906 |  0:01:24s\n",
      "epoch 29 | loss: 0.02926 | test_accuracy: 0.98974 | test_auc: 0.99893 |  0:01:27s\n",
      "epoch 30 | loss: 0.03074 | test_accuracy: 0.99079 | test_auc: 0.99883 |  0:01:30s\n",
      "epoch 31 | loss: 0.02856 | test_accuracy: 0.99166 | test_auc: 0.99893 |  0:01:33s\n",
      "epoch 32 | loss: 0.03573 | test_accuracy: 0.98974 | test_auc: 0.99866 |  0:01:36s\n",
      "epoch 33 | loss: 0.0324  | test_accuracy: 0.99044 | test_auc: 0.9985  |  0:01:39s\n",
      "epoch 34 | loss: 0.03236 | test_accuracy: 0.99114 | test_auc: 0.99901 |  0:01:42s\n",
      "epoch 35 | loss: 0.02881 | test_accuracy: 0.99096 | test_auc: 0.99882 |  0:01:45s\n",
      "epoch 36 | loss: 0.02931 | test_accuracy: 0.99166 | test_auc: 0.99888 |  0:01:48s\n",
      "epoch 37 | loss: 0.02777 | test_accuracy: 0.99096 | test_auc: 0.99851 |  0:01:51s\n",
      "epoch 38 | loss: 0.02777 | test_accuracy: 0.99131 | test_auc: 0.999   |  0:01:53s\n",
      "epoch 39 | loss: 0.02836 | test_accuracy: 0.99114 | test_auc: 0.9987  |  0:01:56s\n",
      "epoch 40 | loss: 0.03199 | test_accuracy: 0.99044 | test_auc: 0.99865 |  0:01:59s\n",
      "epoch 41 | loss: 0.03248 | test_accuracy: 0.98992 | test_auc: 0.99886 |  0:02:02s\n",
      "epoch 42 | loss: 0.0277  | test_accuracy: 0.99096 | test_auc: 0.99885 |  0:02:05s\n",
      "epoch 43 | loss: 0.02948 | test_accuracy: 0.99096 | test_auc: 0.99904 |  0:02:08s\n",
      "epoch 44 | loss: 0.02799 | test_accuracy: 0.99096 | test_auc: 0.9989  |  0:02:11s\n",
      "epoch 45 | loss: 0.0324  | test_accuracy: 0.98905 | test_auc: 0.99884 |  0:02:14s\n",
      "epoch 46 | loss: 0.02955 | test_accuracy: 0.99079 | test_auc: 0.99871 |  0:02:17s\n",
      "epoch 47 | loss: 0.02791 | test_accuracy: 0.99114 | test_auc: 0.99888 |  0:02:20s\n",
      "epoch 48 | loss: 0.03103 | test_accuracy: 0.99061 | test_auc: 0.99896 |  0:02:23s\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_test_auc = 0.99906\n",
      "Training fold 3/5...\n",
      "epoch 0  | loss: 0.22664 | test_accuracy: 0.93673 | test_auc: 0.97085 |  0:00:02s\n",
      "epoch 1  | loss: 0.07544 | test_accuracy: 0.95585 | test_auc: 0.99227 |  0:00:05s\n",
      "epoch 2  | loss: 0.0621  | test_accuracy: 0.94977 | test_auc: 0.9925  |  0:00:08s\n",
      "epoch 3  | loss: 0.05829 | test_accuracy: 0.95203 | test_auc: 0.99072 |  0:00:11s\n",
      "epoch 4  | loss: 0.0526  | test_accuracy: 0.95654 | test_auc: 0.99391 |  0:00:14s\n",
      "epoch 5  | loss: 0.0463  | test_accuracy: 0.9668  | test_auc: 0.99514 |  0:00:17s\n",
      "epoch 6  | loss: 0.04645 | test_accuracy: 0.97341 | test_auc: 0.99694 |  0:00:20s\n",
      "epoch 7  | loss: 0.04966 | test_accuracy: 0.97792 | test_auc: 0.99662 |  0:00:23s\n",
      "epoch 8  | loss: 0.05617 | test_accuracy: 0.98036 | test_auc: 0.99768 |  0:00:26s\n",
      "epoch 9  | loss: 0.05154 | test_accuracy: 0.97827 | test_auc: 0.99789 |  0:00:29s\n",
      "epoch 10 | loss: 0.05012 | test_accuracy: 0.97254 | test_auc: 0.997   |  0:00:32s\n",
      "epoch 11 | loss: 0.05006 | test_accuracy: 0.97932 | test_auc: 0.99797 |  0:00:35s\n",
      "epoch 12 | loss: 0.0408  | test_accuracy: 0.98383 | test_auc: 0.99827 |  0:00:37s\n",
      "epoch 13 | loss: 0.03813 | test_accuracy: 0.98523 | test_auc: 0.99848 |  0:00:40s\n",
      "epoch 14 | loss: 0.0363  | test_accuracy: 0.98679 | test_auc: 0.99854 |  0:00:43s\n",
      "epoch 15 | loss: 0.03392 | test_accuracy: 0.98644 | test_auc: 0.99862 |  0:00:46s\n",
      "epoch 16 | loss: 0.03749 | test_accuracy: 0.98575 | test_auc: 0.99826 |  0:00:49s\n",
      "epoch 17 | loss: 0.03793 | test_accuracy: 0.98453 | test_auc: 0.99866 |  0:00:52s\n",
      "epoch 18 | loss: 0.03395 | test_accuracy: 0.98818 | test_auc: 0.99868 |  0:00:55s\n",
      "epoch 19 | loss: 0.03208 | test_accuracy: 0.98696 | test_auc: 0.9987  |  0:00:58s\n",
      "epoch 20 | loss: 0.034   | test_accuracy: 0.98922 | test_auc: 0.99865 |  0:01:01s\n",
      "epoch 21 | loss: 0.0325  | test_accuracy: 0.9887  | test_auc: 0.99867 |  0:01:03s\n",
      "epoch 22 | loss: 0.03293 | test_accuracy: 0.98905 | test_auc: 0.99886 |  0:01:06s\n",
      "epoch 23 | loss: 0.0334  | test_accuracy: 0.98835 | test_auc: 0.99883 |  0:01:09s\n",
      "epoch 24 | loss: 0.03494 | test_accuracy: 0.98609 | test_auc: 0.99793 |  0:01:12s\n",
      "epoch 25 | loss: 0.03616 | test_accuracy: 0.98888 | test_auc: 0.99875 |  0:01:15s\n",
      "epoch 26 | loss: 0.03709 | test_accuracy: 0.98818 | test_auc: 0.99857 |  0:01:18s\n",
      "epoch 27 | loss: 0.03443 | test_accuracy: 0.98714 | test_auc: 0.99845 |  0:01:21s\n",
      "epoch 28 | loss: 0.03097 | test_accuracy: 0.98748 | test_auc: 0.99855 |  0:01:24s\n",
      "epoch 29 | loss: 0.0305  | test_accuracy: 0.98905 | test_auc: 0.99867 |  0:01:27s\n",
      "epoch 30 | loss: 0.0289  | test_accuracy: 0.98905 | test_auc: 0.99847 |  0:01:30s\n",
      "epoch 31 | loss: 0.02951 | test_accuracy: 0.98783 | test_auc: 0.99856 |  0:01:33s\n",
      "epoch 32 | loss: 0.02787 | test_accuracy: 0.98905 | test_auc: 0.99862 |  0:01:36s\n",
      "epoch 33 | loss: 0.03275 | test_accuracy: 0.98922 | test_auc: 0.99847 |  0:01:38s\n",
      "epoch 34 | loss: 0.04018 | test_accuracy: 0.9894  | test_auc: 0.99854 |  0:01:41s\n",
      "epoch 35 | loss: 0.03567 | test_accuracy: 0.98679 | test_auc: 0.99809 |  0:01:44s\n",
      "epoch 36 | loss: 0.04445 | test_accuracy: 0.98436 | test_auc: 0.99781 |  0:01:47s\n",
      "epoch 37 | loss: 0.04223 | test_accuracy: 0.98766 | test_auc: 0.99795 |  0:01:50s\n",
      "epoch 38 | loss: 0.04113 | test_accuracy: 0.98801 | test_auc: 0.99842 |  0:01:53s\n",
      "epoch 39 | loss: 0.03771 | test_accuracy: 0.98888 | test_auc: 0.99797 |  0:01:56s\n",
      "epoch 40 | loss: 0.03489 | test_accuracy: 0.98748 | test_auc: 0.99851 |  0:01:59s\n",
      "epoch 41 | loss: 0.03226 | test_accuracy: 0.98418 | test_auc: 0.99779 |  0:02:02s\n",
      "epoch 42 | loss: 0.03269 | test_accuracy: 0.98818 | test_auc: 0.99821 |  0:02:04s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_test_auc = 0.99886\n",
      "Training fold 4/5...\n",
      "epoch 0  | loss: 0.2196  | test_accuracy: 0.88024 | test_auc: 0.95542 |  0:00:02s\n",
      "epoch 1  | loss: 0.07493 | test_accuracy: 0.52164 | test_auc: 0.9399  |  0:00:05s\n",
      "epoch 2  | loss: 0.06063 | test_accuracy: 0.53242 | test_auc: 0.96248 |  0:00:08s\n",
      "epoch 3  | loss: 0.05381 | test_accuracy: 0.97288 | test_auc: 0.99416 |  0:00:11s\n",
      "epoch 4  | loss: 0.04658 | test_accuracy: 0.97706 | test_auc: 0.99747 |  0:00:14s\n",
      "epoch 5  | loss: 0.04477 | test_accuracy: 0.98366 | test_auc: 0.99765 |  0:00:17s\n",
      "epoch 6  | loss: 0.0392  | test_accuracy: 0.98192 | test_auc: 0.99818 |  0:00:20s\n",
      "epoch 7  | loss: 0.03953 | test_accuracy: 0.98679 | test_auc: 0.99831 |  0:00:23s\n",
      "epoch 8  | loss: 0.04184 | test_accuracy: 0.9847  | test_auc: 0.99828 |  0:00:27s\n",
      "epoch 9  | loss: 0.0397  | test_accuracy: 0.9887  | test_auc: 0.99893 |  0:00:30s\n",
      "epoch 10 | loss: 0.03648 | test_accuracy: 0.98731 | test_auc: 0.9985  |  0:00:37s\n",
      "epoch 11 | loss: 0.03401 | test_accuracy: 0.98835 | test_auc: 0.99884 |  0:00:49s\n",
      "epoch 12 | loss: 0.03336 | test_accuracy: 0.98905 | test_auc: 0.99893 |  0:01:03s\n",
      "epoch 13 | loss: 0.03232 | test_accuracy: 0.98853 | test_auc: 0.99884 |  0:01:14s\n",
      "epoch 14 | loss: 0.03085 | test_accuracy: 0.9887  | test_auc: 0.9989  |  0:01:25s\n",
      "epoch 15 | loss: 0.0304  | test_accuracy: 0.99027 | test_auc: 0.99894 |  0:01:36s\n",
      "epoch 16 | loss: 0.02903 | test_accuracy: 0.99079 | test_auc: 0.99896 |  0:01:48s\n",
      "epoch 17 | loss: 0.03224 | test_accuracy: 0.9887  | test_auc: 0.99884 |  0:01:59s\n",
      "epoch 18 | loss: 0.03147 | test_accuracy: 0.9887  | test_auc: 0.99874 |  0:02:12s\n",
      "epoch 19 | loss: 0.0308  | test_accuracy: 0.99044 | test_auc: 0.999   |  0:02:23s\n",
      "epoch 20 | loss: 0.02884 | test_accuracy: 0.99044 | test_auc: 0.99872 |  0:02:37s\n",
      "epoch 21 | loss: 0.02949 | test_accuracy: 0.98957 | test_auc: 0.99872 |  0:02:47s\n",
      "epoch 22 | loss: 0.03029 | test_accuracy: 0.99044 | test_auc: 0.99899 |  0:02:59s\n",
      "epoch 23 | loss: 0.02978 | test_accuracy: 0.99079 | test_auc: 0.99873 |  0:03:10s\n",
      "epoch 24 | loss: 0.02816 | test_accuracy: 0.99061 | test_auc: 0.99899 |  0:03:24s\n",
      "epoch 25 | loss: 0.02844 | test_accuracy: 0.98957 | test_auc: 0.99898 |  0:03:38s\n",
      "epoch 26 | loss: 0.03003 | test_accuracy: 0.99027 | test_auc: 0.99893 |  0:03:51s\n",
      "epoch 27 | loss: 0.03011 | test_accuracy: 0.99044 | test_auc: 0.999   |  0:04:02s\n",
      "epoch 28 | loss: 0.03093 | test_accuracy: 0.99009 | test_auc: 0.99904 |  0:04:12s\n",
      "epoch 29 | loss: 0.03314 | test_accuracy: 0.99027 | test_auc: 0.99893 |  0:04:23s\n",
      "epoch 30 | loss: 0.02958 | test_accuracy: 0.99027 | test_auc: 0.99891 |  0:04:35s\n",
      "epoch 31 | loss: 0.02968 | test_accuracy: 0.99027 | test_auc: 0.99907 |  0:04:49s\n",
      "epoch 32 | loss: 0.02915 | test_accuracy: 0.98853 | test_auc: 0.99901 |  0:04:57s\n",
      "epoch 33 | loss: 0.02896 | test_accuracy: 0.99044 | test_auc: 0.99901 |  0:05:09s\n",
      "epoch 34 | loss: 0.02876 | test_accuracy: 0.99044 | test_auc: 0.99899 |  0:05:17s\n",
      "epoch 35 | loss: 0.02982 | test_accuracy: 0.99044 | test_auc: 0.99902 |  0:05:30s\n",
      "epoch 36 | loss: 0.02925 | test_accuracy: 0.99027 | test_auc: 0.9989  |  0:05:43s\n",
      "epoch 37 | loss: 0.02767 | test_accuracy: 0.99044 | test_auc: 0.99894 |  0:05:53s\n",
      "epoch 38 | loss: 0.02717 | test_accuracy: 0.99044 | test_auc: 0.99893 |  0:06:06s\n",
      "epoch 39 | loss: 0.02736 | test_accuracy: 0.99061 | test_auc: 0.99896 |  0:06:18s\n",
      "epoch 40 | loss: 0.02798 | test_accuracy: 0.98922 | test_auc: 0.99903 |  0:06:30s\n",
      "epoch 41 | loss: 0.03196 | test_accuracy: 0.98992 | test_auc: 0.99891 |  0:06:42s\n",
      "epoch 42 | loss: 0.03108 | test_accuracy: 0.98974 | test_auc: 0.99902 |  0:06:56s\n",
      "epoch 43 | loss: 0.03063 | test_accuracy: 0.99009 | test_auc: 0.99889 |  0:07:11s\n",
      "epoch 44 | loss: 0.02927 | test_accuracy: 0.99061 | test_auc: 0.999   |  0:07:24s\n",
      "epoch 45 | loss: 0.02746 | test_accuracy: 0.99096 | test_auc: 0.99903 |  0:07:36s\n",
      "epoch 46 | loss: 0.0274  | test_accuracy: 0.99061 | test_auc: 0.99896 |  0:07:51s\n",
      "epoch 47 | loss: 0.02718 | test_accuracy: 0.99061 | test_auc: 0.99901 |  0:08:07s\n",
      "epoch 48 | loss: 0.02624 | test_accuracy: 0.99061 | test_auc: 0.99905 |  0:08:20s\n",
      "epoch 49 | loss: 0.02632 | test_accuracy: 0.99061 | test_auc: 0.99905 |  0:08:33s\n",
      "epoch 50 | loss: 0.02645 | test_accuracy: 0.99096 | test_auc: 0.99905 |  0:08:44s\n",
      "epoch 51 | loss: 0.02599 | test_accuracy: 0.99096 | test_auc: 0.99901 |  0:08:57s\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 31 and best_test_auc = 0.99907\n",
      "Training fold 5/5...\n",
      "epoch 0  | loss: 0.22001 | test_accuracy: 0.84495 | test_auc: 0.95027 |  0:00:09s\n",
      "epoch 1  | loss: 0.07085 | test_accuracy: 0.85225 | test_auc: 0.97829 |  0:00:21s\n",
      "epoch 2  | loss: 0.05564 | test_accuracy: 0.96002 | test_auc: 0.99139 |  0:00:31s\n",
      "epoch 3  | loss: 0.0506  | test_accuracy: 0.87363 | test_auc: 0.99605 |  0:00:41s\n",
      "epoch 4  | loss: 0.05399 | test_accuracy: 0.97984 | test_auc: 0.99472 |  0:00:53s\n",
      "epoch 5  | loss: 0.04769 | test_accuracy: 0.98488 | test_auc: 0.99835 |  0:01:05s\n",
      "epoch 6  | loss: 0.04348 | test_accuracy: 0.9887  | test_auc: 0.99864 |  0:01:17s\n",
      "epoch 7  | loss: 0.0378  | test_accuracy: 0.98644 | test_auc: 0.99863 |  0:01:29s\n",
      "epoch 8  | loss: 0.04294 | test_accuracy: 0.98922 | test_auc: 0.99928 |  0:01:41s\n",
      "epoch 9  | loss: 0.03928 | test_accuracy: 0.9894  | test_auc: 0.99932 |  0:01:53s\n",
      "epoch 10 | loss: 0.03971 | test_accuracy: 0.98974 | test_auc: 0.99905 |  0:02:06s\n",
      "epoch 11 | loss: 0.03645 | test_accuracy: 0.99096 | test_auc: 0.99926 |  0:02:16s\n",
      "epoch 12 | loss: 0.03801 | test_accuracy: 0.99044 | test_auc: 0.99828 |  0:02:29s\n",
      "epoch 13 | loss: 0.0375  | test_accuracy: 0.99027 | test_auc: 0.99926 |  0:02:41s\n",
      "epoch 14 | loss: 0.03965 | test_accuracy: 0.9887  | test_auc: 0.99848 |  0:02:51s\n",
      "epoch 15 | loss: 0.03931 | test_accuracy: 0.99061 | test_auc: 0.99932 |  0:03:04s\n",
      "epoch 16 | loss: 0.03914 | test_accuracy: 0.98888 | test_auc: 0.99936 |  0:03:15s\n",
      "epoch 17 | loss: 0.03814 | test_accuracy: 0.99079 | test_auc: 0.99886 |  0:03:29s\n",
      "epoch 18 | loss: 0.03688 | test_accuracy: 0.99027 | test_auc: 0.99921 |  0:03:41s\n",
      "epoch 19 | loss: 0.03492 | test_accuracy: 0.98992 | test_auc: 0.99873 |  0:03:54s\n",
      "epoch 20 | loss: 0.03542 | test_accuracy: 0.99027 | test_auc: 0.99914 |  0:04:02s\n",
      "epoch 21 | loss: 0.03523 | test_accuracy: 0.98974 | test_auc: 0.99915 |  0:04:14s\n",
      "epoch 22 | loss: 0.03505 | test_accuracy: 0.99131 | test_auc: 0.99934 |  0:04:26s\n",
      "epoch 23 | loss: 0.03343 | test_accuracy: 0.99061 | test_auc: 0.99935 |  0:04:38s\n",
      "epoch 24 | loss: 0.03344 | test_accuracy: 0.99166 | test_auc: 0.99934 |  0:04:48s\n",
      "epoch 25 | loss: 0.03274 | test_accuracy: 0.99027 | test_auc: 0.99929 |  0:04:57s\n",
      "epoch 26 | loss: 0.03199 | test_accuracy: 0.99096 | test_auc: 0.99926 |  0:05:04s\n",
      "epoch 27 | loss: 0.0312  | test_accuracy: 0.99079 | test_auc: 0.99921 |  0:05:16s\n",
      "epoch 28 | loss: 0.03173 | test_accuracy: 0.99131 | test_auc: 0.99932 |  0:05:27s\n",
      "epoch 29 | loss: 0.03321 | test_accuracy: 0.99061 | test_auc: 0.99906 |  0:05:39s\n",
      "epoch 30 | loss: 0.03304 | test_accuracy: 0.99061 | test_auc: 0.99902 |  0:05:49s\n",
      "epoch 31 | loss: 0.03145 | test_accuracy: 0.99096 | test_auc: 0.99926 |  0:06:02s\n",
      "epoch 32 | loss: 0.03991 | test_accuracy: 0.98748 | test_auc: 0.99885 |  0:06:14s\n",
      "epoch 33 | loss: 0.04009 | test_accuracy: 0.98609 | test_auc: 0.99883 |  0:06:25s\n",
      "epoch 34 | loss: 0.0396  | test_accuracy: 0.98644 | test_auc: 0.99876 |  0:06:38s\n",
      "epoch 35 | loss: 0.03998 | test_accuracy: 0.98627 | test_auc: 0.99885 |  0:06:51s\n",
      "epoch 36 | loss: 0.03833 | test_accuracy: 0.98766 | test_auc: 0.9992  |  0:07:04s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_test_auc = 0.99936\n",
      "\n",
      "Results for 1. Chi-Square:\n",
      "Average accuracy: 0.9886 ± 0.0022\n",
      "Average precision: 0.9908 ± 0.0105\n",
      "Average recall: 0.9770 ± 0.0044\n",
      "Average f1: 0.9838 ± 0.0032\n",
      "Average auc: 0.9860 ± 0.0010\n",
      "\n",
      "==================================================\n",
      "Processing 2. Mutual Information\n",
      "==================================================\n",
      "Selecting features using 2. Mutual Information...\n",
      "Top 10 features selected by 2. Mutual Information:\n",
      "1. Breathing Problem: 0.3065\n",
      "2. Sore throat: 0.4156\n",
      "3. Heart Disease: 0.0862\n",
      "4. Diabetes: 0.1160\n",
      "5. Hyper Tension: 0.0777\n",
      "6. Gastrointestinal : 0.0755\n",
      "7. Abroad travel: 0.2829\n",
      "8. Contact with COVID Patient: 0.1895\n",
      "9. Attended Large Gathering: 0.2368\n",
      "10. Family working in Public Exposed Places: 0.2138\n",
      "\n",
      "Training TabNet with features selected by 2. Mutual Information\n",
      "Training fold 1/5...\n",
      "epoch 0  | loss: 0.24799 | test_accuracy: 0.90615 | test_auc: 0.97363 |  0:00:11s\n",
      "epoch 1  | loss: 0.0834  | test_accuracy: 0.9178  | test_auc: 0.98947 |  0:00:23s\n",
      "epoch 2  | loss: 0.07275 | test_accuracy: 0.92353 | test_auc: 0.99245 |  0:00:37s\n",
      "epoch 3  | loss: 0.05839 | test_accuracy: 0.95447 | test_auc: 0.99543 |  0:00:46s\n",
      "epoch 4  | loss: 0.04948 | test_accuracy: 0.95916 | test_auc: 0.99635 |  0:00:59s\n",
      "epoch 5  | loss: 0.04253 | test_accuracy: 0.97636 | test_auc: 0.99809 |  0:01:10s\n",
      "epoch 6  | loss: 0.03849 | test_accuracy: 0.98019 | test_auc: 0.99838 |  0:01:23s\n",
      "epoch 7  | loss: 0.03871 | test_accuracy: 0.98262 | test_auc: 0.99894 |  0:01:35s\n",
      "epoch 8  | loss: 0.03443 | test_accuracy: 0.98436 | test_auc: 0.999   |  0:01:47s\n",
      "epoch 9  | loss: 0.03237 | test_accuracy: 0.98384 | test_auc: 0.99843 |  0:01:59s\n",
      "epoch 10 | loss: 0.03512 | test_accuracy: 0.98801 | test_auc: 0.99883 |  0:02:08s\n",
      "epoch 11 | loss: 0.03307 | test_accuracy: 0.98749 | test_auc: 0.99896 |  0:02:21s\n",
      "epoch 12 | loss: 0.03395 | test_accuracy: 0.98836 | test_auc: 0.99889 |  0:02:31s\n",
      "epoch 13 | loss: 0.03231 | test_accuracy: 0.98853 | test_auc: 0.9988  |  0:02:43s\n",
      "epoch 14 | loss: 0.03264 | test_accuracy: 0.98836 | test_auc: 0.99823 |  0:02:54s\n",
      "epoch 15 | loss: 0.03746 | test_accuracy: 0.98714 | test_auc: 0.9984  |  0:03:08s\n",
      "epoch 16 | loss: 0.04275 | test_accuracy: 0.98783 | test_auc: 0.99854 |  0:03:17s\n",
      "epoch 17 | loss: 0.03723 | test_accuracy: 0.98679 | test_auc: 0.99865 |  0:03:29s\n",
      "epoch 18 | loss: 0.03723 | test_accuracy: 0.98957 | test_auc: 0.99835 |  0:03:40s\n",
      "epoch 19 | loss: 0.03415 | test_accuracy: 0.9894  | test_auc: 0.99861 |  0:03:52s\n",
      "epoch 20 | loss: 0.03265 | test_accuracy: 0.98801 | test_auc: 0.99866 |  0:04:04s\n",
      "epoch 21 | loss: 0.03099 | test_accuracy: 0.99027 | test_auc: 0.99876 |  0:04:15s\n",
      "epoch 22 | loss: 0.03115 | test_accuracy: 0.98957 | test_auc: 0.99854 |  0:04:23s\n",
      "epoch 23 | loss: 0.03109 | test_accuracy: 0.98975 | test_auc: 0.99868 |  0:04:36s\n",
      "epoch 24 | loss: 0.03138 | test_accuracy: 0.98957 | test_auc: 0.99891 |  0:04:48s\n",
      "epoch 25 | loss: 0.02897 | test_accuracy: 0.98957 | test_auc: 0.99885 |  0:05:00s\n",
      "epoch 26 | loss: 0.02958 | test_accuracy: 0.98975 | test_auc: 0.99884 |  0:05:10s\n",
      "epoch 27 | loss: 0.02981 | test_accuracy: 0.98957 | test_auc: 0.99871 |  0:05:21s\n",
      "epoch 28 | loss: 0.02904 | test_accuracy: 0.98922 | test_auc: 0.99882 |  0:05:33s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_test_auc = 0.999\n",
      "Training fold 2/5...\n",
      "epoch 0  | loss: 0.22954 | test_accuracy: 0.53329 | test_auc: 0.92398 |  0:00:11s\n",
      "epoch 1  | loss: 0.07638 | test_accuracy: 0.55223 | test_auc: 0.9547  |  0:00:24s\n",
      "epoch 2  | loss: 0.06129 | test_accuracy: 0.90092 | test_auc: 0.97306 |  0:00:36s\n",
      "epoch 3  | loss: 0.05269 | test_accuracy: 0.95359 | test_auc: 0.98048 |  0:00:47s\n",
      "epoch 4  | loss: 0.04978 | test_accuracy: 0.97549 | test_auc: 0.99652 |  0:00:57s\n",
      "epoch 5  | loss: 0.04313 | test_accuracy: 0.98001 | test_auc: 0.99563 |  0:01:08s\n",
      "epoch 6  | loss: 0.04095 | test_accuracy: 0.98662 | test_auc: 0.99783 |  0:01:20s\n",
      "epoch 7  | loss: 0.03889 | test_accuracy: 0.98609 | test_auc: 0.99772 |  0:01:35s\n",
      "epoch 8  | loss: 0.03612 | test_accuracy: 0.98905 | test_auc: 0.99852 |  0:01:51s\n",
      "epoch 9  | loss: 0.03486 | test_accuracy: 0.98974 | test_auc: 0.9986  |  0:02:02s\n",
      "epoch 10 | loss: 0.03566 | test_accuracy: 0.98922 | test_auc: 0.9983  |  0:02:15s\n",
      "epoch 11 | loss: 0.03508 | test_accuracy: 0.99114 | test_auc: 0.99864 |  0:02:28s\n",
      "epoch 12 | loss: 0.03249 | test_accuracy: 0.99079 | test_auc: 0.99861 |  0:02:40s\n",
      "epoch 13 | loss: 0.03122 | test_accuracy: 0.99079 | test_auc: 0.99857 |  0:02:48s\n",
      "epoch 14 | loss: 0.03694 | test_accuracy: 0.98731 | test_auc: 0.99811 |  0:02:58s\n",
      "epoch 15 | loss: 0.03515 | test_accuracy: 0.99009 | test_auc: 0.99867 |  0:03:09s\n",
      "epoch 16 | loss: 0.03867 | test_accuracy: 0.99027 | test_auc: 0.99871 |  0:03:21s\n",
      "epoch 17 | loss: 0.03697 | test_accuracy: 0.99044 | test_auc: 0.99851 |  0:03:32s\n",
      "epoch 18 | loss: 0.03405 | test_accuracy: 0.99096 | test_auc: 0.99847 |  0:03:40s\n",
      "epoch 19 | loss: 0.03141 | test_accuracy: 0.99148 | test_auc: 0.99882 |  0:03:52s\n",
      "epoch 20 | loss: 0.02891 | test_accuracy: 0.99079 | test_auc: 0.99883 |  0:04:03s\n",
      "epoch 21 | loss: 0.02902 | test_accuracy: 0.99131 | test_auc: 0.99879 |  0:04:15s\n",
      "epoch 22 | loss: 0.02879 | test_accuracy: 0.99096 | test_auc: 0.99883 |  0:04:25s\n",
      "epoch 23 | loss: 0.02732 | test_accuracy: 0.99148 | test_auc: 0.99894 |  0:04:35s\n",
      "epoch 24 | loss: 0.02944 | test_accuracy: 0.98922 | test_auc: 0.99881 |  0:04:48s\n",
      "epoch 25 | loss: 0.02931 | test_accuracy: 0.99148 | test_auc: 0.99887 |  0:05:01s\n",
      "epoch 26 | loss: 0.02858 | test_accuracy: 0.99096 | test_auc: 0.99882 |  0:05:14s\n",
      "epoch 27 | loss: 0.02871 | test_accuracy: 0.99148 | test_auc: 0.99882 |  0:05:25s\n",
      "epoch 28 | loss: 0.02851 | test_accuracy: 0.99027 | test_auc: 0.99906 |  0:05:38s\n",
      "epoch 29 | loss: 0.02926 | test_accuracy: 0.98974 | test_auc: 0.99893 |  0:05:52s\n",
      "epoch 30 | loss: 0.03074 | test_accuracy: 0.99079 | test_auc: 0.99883 |  0:06:05s\n",
      "epoch 31 | loss: 0.02856 | test_accuracy: 0.99166 | test_auc: 0.99893 |  0:06:17s\n",
      "epoch 32 | loss: 0.03573 | test_accuracy: 0.98974 | test_auc: 0.99866 |  0:06:28s\n",
      "epoch 33 | loss: 0.0324  | test_accuracy: 0.99044 | test_auc: 0.9985  |  0:06:40s\n",
      "epoch 34 | loss: 0.03236 | test_accuracy: 0.99114 | test_auc: 0.99901 |  0:06:54s\n",
      "epoch 35 | loss: 0.02881 | test_accuracy: 0.99096 | test_auc: 0.99882 |  0:07:07s\n",
      "epoch 36 | loss: 0.02931 | test_accuracy: 0.99166 | test_auc: 0.99888 |  0:07:18s\n",
      "epoch 37 | loss: 0.02777 | test_accuracy: 0.99096 | test_auc: 0.99851 |  0:07:29s\n",
      "epoch 38 | loss: 0.02777 | test_accuracy: 0.99131 | test_auc: 0.999   |  0:07:40s\n",
      "epoch 39 | loss: 0.02836 | test_accuracy: 0.99114 | test_auc: 0.9987  |  0:07:50s\n",
      "epoch 40 | loss: 0.03199 | test_accuracy: 0.99044 | test_auc: 0.99865 |  0:08:00s\n",
      "epoch 41 | loss: 0.03248 | test_accuracy: 0.98992 | test_auc: 0.99886 |  0:08:12s\n",
      "epoch 42 | loss: 0.0277  | test_accuracy: 0.99096 | test_auc: 0.99885 |  0:08:24s\n",
      "epoch 43 | loss: 0.02948 | test_accuracy: 0.99096 | test_auc: 0.99904 |  0:08:36s\n",
      "epoch 44 | loss: 0.02799 | test_accuracy: 0.99096 | test_auc: 0.9989  |  0:08:45s\n",
      "epoch 45 | loss: 0.0324  | test_accuracy: 0.98905 | test_auc: 0.99884 |  0:08:56s\n",
      "epoch 46 | loss: 0.02955 | test_accuracy: 0.99079 | test_auc: 0.99871 |  0:09:08s\n",
      "epoch 47 | loss: 0.02791 | test_accuracy: 0.99114 | test_auc: 0.99888 |  0:09:22s\n",
      "epoch 48 | loss: 0.03103 | test_accuracy: 0.99061 | test_auc: 0.99896 |  0:09:33s\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_test_auc = 0.99906\n",
      "Training fold 3/5...\n",
      "epoch 0  | loss: 0.22664 | test_accuracy: 0.93673 | test_auc: 0.97085 |  0:00:10s\n",
      "epoch 1  | loss: 0.07544 | test_accuracy: 0.95585 | test_auc: 0.99227 |  0:00:23s\n",
      "epoch 2  | loss: 0.0621  | test_accuracy: 0.94977 | test_auc: 0.9925  |  0:00:36s\n",
      "epoch 3  | loss: 0.05829 | test_accuracy: 0.95203 | test_auc: 0.99072 |  0:00:50s\n",
      "epoch 4  | loss: 0.0526  | test_accuracy: 0.95654 | test_auc: 0.99391 |  0:01:03s\n",
      "epoch 5  | loss: 0.0463  | test_accuracy: 0.9668  | test_auc: 0.99514 |  0:01:14s\n",
      "epoch 6  | loss: 0.04645 | test_accuracy: 0.97341 | test_auc: 0.99694 |  0:01:27s\n",
      "epoch 7  | loss: 0.04966 | test_accuracy: 0.97792 | test_auc: 0.99662 |  0:01:36s\n",
      "epoch 8  | loss: 0.05617 | test_accuracy: 0.98036 | test_auc: 0.99768 |  0:01:48s\n",
      "epoch 9  | loss: 0.05154 | test_accuracy: 0.97827 | test_auc: 0.99789 |  0:01:59s\n",
      "epoch 10 | loss: 0.05012 | test_accuracy: 0.97254 | test_auc: 0.997   |  0:02:11s\n",
      "epoch 11 | loss: 0.05006 | test_accuracy: 0.97932 | test_auc: 0.99797 |  0:02:20s\n",
      "epoch 12 | loss: 0.0408  | test_accuracy: 0.98383 | test_auc: 0.99827 |  0:02:29s\n",
      "epoch 13 | loss: 0.03813 | test_accuracy: 0.98523 | test_auc: 0.99848 |  0:02:41s\n",
      "epoch 14 | loss: 0.0363  | test_accuracy: 0.98679 | test_auc: 0.99854 |  0:02:51s\n",
      "epoch 15 | loss: 0.03392 | test_accuracy: 0.98644 | test_auc: 0.99862 |  0:03:02s\n",
      "epoch 16 | loss: 0.03749 | test_accuracy: 0.98575 | test_auc: 0.99826 |  0:03:11s\n",
      "epoch 17 | loss: 0.03793 | test_accuracy: 0.98453 | test_auc: 0.99866 |  0:03:23s\n",
      "epoch 18 | loss: 0.03395 | test_accuracy: 0.98818 | test_auc: 0.99868 |  0:03:35s\n",
      "epoch 19 | loss: 0.03208 | test_accuracy: 0.98696 | test_auc: 0.9987  |  0:03:49s\n",
      "epoch 20 | loss: 0.034   | test_accuracy: 0.98922 | test_auc: 0.99865 |  0:04:02s\n",
      "epoch 21 | loss: 0.0325  | test_accuracy: 0.9887  | test_auc: 0.99867 |  0:04:14s\n",
      "epoch 22 | loss: 0.03293 | test_accuracy: 0.98905 | test_auc: 0.99886 |  0:04:28s\n",
      "epoch 23 | loss: 0.0334  | test_accuracy: 0.98835 | test_auc: 0.99883 |  0:04:38s\n",
      "epoch 24 | loss: 0.03494 | test_accuracy: 0.98609 | test_auc: 0.99793 |  0:04:53s\n",
      "epoch 25 | loss: 0.03616 | test_accuracy: 0.98888 | test_auc: 0.99875 |  0:05:06s\n",
      "epoch 26 | loss: 0.03709 | test_accuracy: 0.98818 | test_auc: 0.99857 |  0:05:19s\n",
      "epoch 27 | loss: 0.03443 | test_accuracy: 0.98714 | test_auc: 0.99845 |  0:05:31s\n",
      "epoch 28 | loss: 0.03097 | test_accuracy: 0.98748 | test_auc: 0.99855 |  0:05:40s\n",
      "epoch 29 | loss: 0.0305  | test_accuracy: 0.98905 | test_auc: 0.99867 |  0:05:54s\n",
      "epoch 30 | loss: 0.0289  | test_accuracy: 0.98905 | test_auc: 0.99847 |  0:06:04s\n",
      "epoch 31 | loss: 0.02951 | test_accuracy: 0.98783 | test_auc: 0.99856 |  0:06:18s\n",
      "epoch 32 | loss: 0.02787 | test_accuracy: 0.98905 | test_auc: 0.99862 |  0:06:31s\n",
      "epoch 33 | loss: 0.03275 | test_accuracy: 0.98922 | test_auc: 0.99847 |  0:06:41s\n",
      "epoch 34 | loss: 0.04018 | test_accuracy: 0.9894  | test_auc: 0.99854 |  0:06:51s\n",
      "epoch 35 | loss: 0.03567 | test_accuracy: 0.98679 | test_auc: 0.99809 |  0:07:03s\n",
      "epoch 36 | loss: 0.04445 | test_accuracy: 0.98436 | test_auc: 0.99781 |  0:07:17s\n",
      "epoch 37 | loss: 0.04223 | test_accuracy: 0.98766 | test_auc: 0.99795 |  0:07:28s\n",
      "epoch 38 | loss: 0.04113 | test_accuracy: 0.98801 | test_auc: 0.99842 |  0:07:41s\n",
      "epoch 39 | loss: 0.03771 | test_accuracy: 0.98888 | test_auc: 0.99797 |  0:07:52s\n",
      "epoch 40 | loss: 0.03489 | test_accuracy: 0.98748 | test_auc: 0.99851 |  0:08:02s\n",
      "epoch 41 | loss: 0.03226 | test_accuracy: 0.98418 | test_auc: 0.99779 |  0:08:13s\n",
      "epoch 42 | loss: 0.03269 | test_accuracy: 0.98818 | test_auc: 0.99821 |  0:08:26s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_test_auc = 0.99886\n",
      "Training fold 4/5...\n",
      "epoch 0  | loss: 0.2196  | test_accuracy: 0.88024 | test_auc: 0.95542 |  0:00:12s\n",
      "epoch 1  | loss: 0.07493 | test_accuracy: 0.52164 | test_auc: 0.9399  |  0:00:23s\n",
      "epoch 2  | loss: 0.06063 | test_accuracy: 0.53242 | test_auc: 0.96248 |  0:00:34s\n",
      "epoch 3  | loss: 0.05381 | test_accuracy: 0.97288 | test_auc: 0.99416 |  0:00:48s\n",
      "epoch 4  | loss: 0.04658 | test_accuracy: 0.97706 | test_auc: 0.99747 |  0:01:00s\n",
      "epoch 5  | loss: 0.04477 | test_accuracy: 0.98366 | test_auc: 0.99765 |  0:01:13s\n",
      "epoch 6  | loss: 0.0392  | test_accuracy: 0.98192 | test_auc: 0.99818 |  0:01:24s\n",
      "epoch 7  | loss: 0.03953 | test_accuracy: 0.98679 | test_auc: 0.99831 |  0:01:33s\n",
      "epoch 8  | loss: 0.04184 | test_accuracy: 0.9847  | test_auc: 0.99828 |  0:01:45s\n",
      "epoch 9  | loss: 0.0397  | test_accuracy: 0.9887  | test_auc: 0.99893 |  0:01:58s\n",
      "epoch 10 | loss: 0.03648 | test_accuracy: 0.98731 | test_auc: 0.9985  |  0:02:08s\n",
      "epoch 11 | loss: 0.03401 | test_accuracy: 0.98835 | test_auc: 0.99884 |  0:02:21s\n",
      "epoch 12 | loss: 0.03336 | test_accuracy: 0.98905 | test_auc: 0.99893 |  0:02:34s\n",
      "epoch 13 | loss: 0.03232 | test_accuracy: 0.98853 | test_auc: 0.99884 |  0:02:43s\n",
      "epoch 14 | loss: 0.03085 | test_accuracy: 0.9887  | test_auc: 0.9989  |  0:02:56s\n",
      "epoch 15 | loss: 0.0304  | test_accuracy: 0.99027 | test_auc: 0.99894 |  0:03:08s\n",
      "epoch 16 | loss: 0.02903 | test_accuracy: 0.99079 | test_auc: 0.99896 |  0:03:20s\n",
      "epoch 17 | loss: 0.03224 | test_accuracy: 0.9887  | test_auc: 0.99884 |  0:03:34s\n",
      "epoch 18 | loss: 0.03147 | test_accuracy: 0.9887  | test_auc: 0.99874 |  0:03:45s\n",
      "epoch 19 | loss: 0.0308  | test_accuracy: 0.99044 | test_auc: 0.999   |  0:03:59s\n",
      "epoch 20 | loss: 0.02884 | test_accuracy: 0.99044 | test_auc: 0.99872 |  0:04:10s\n",
      "epoch 21 | loss: 0.02949 | test_accuracy: 0.98957 | test_auc: 0.99872 |  0:04:23s\n",
      "epoch 22 | loss: 0.03029 | test_accuracy: 0.99044 | test_auc: 0.99899 |  0:04:35s\n",
      "epoch 23 | loss: 0.02978 | test_accuracy: 0.99079 | test_auc: 0.99873 |  0:04:47s\n",
      "epoch 24 | loss: 0.02816 | test_accuracy: 0.99061 | test_auc: 0.99899 |  0:04:58s\n",
      "epoch 25 | loss: 0.02844 | test_accuracy: 0.98957 | test_auc: 0.99898 |  0:05:18s\n",
      "epoch 26 | loss: 0.03003 | test_accuracy: 0.99027 | test_auc: 0.99893 |  0:05:30s\n",
      "epoch 27 | loss: 0.03011 | test_accuracy: 0.99044 | test_auc: 0.999   |  0:05:42s\n",
      "epoch 28 | loss: 0.03093 | test_accuracy: 0.99009 | test_auc: 0.99904 |  0:05:52s\n",
      "epoch 29 | loss: 0.03314 | test_accuracy: 0.99027 | test_auc: 0.99893 |  0:06:04s\n",
      "epoch 30 | loss: 0.02958 | test_accuracy: 0.99027 | test_auc: 0.99891 |  0:06:13s\n",
      "epoch 31 | loss: 0.02968 | test_accuracy: 0.99027 | test_auc: 0.99907 |  0:06:23s\n",
      "epoch 32 | loss: 0.02915 | test_accuracy: 0.98853 | test_auc: 0.99901 |  0:06:33s\n",
      "epoch 33 | loss: 0.02896 | test_accuracy: 0.99044 | test_auc: 0.99901 |  0:06:48s\n",
      "epoch 34 | loss: 0.02876 | test_accuracy: 0.99044 | test_auc: 0.99899 |  0:06:59s\n",
      "epoch 35 | loss: 0.02982 | test_accuracy: 0.99044 | test_auc: 0.99902 |  0:07:11s\n",
      "epoch 36 | loss: 0.02925 | test_accuracy: 0.99027 | test_auc: 0.9989  |  0:07:25s\n",
      "epoch 37 | loss: 0.02767 | test_accuracy: 0.99044 | test_auc: 0.99894 |  0:07:38s\n",
      "epoch 38 | loss: 0.02717 | test_accuracy: 0.99044 | test_auc: 0.99893 |  0:07:52s\n",
      "epoch 39 | loss: 0.02736 | test_accuracy: 0.99061 | test_auc: 0.99896 |  0:08:05s\n",
      "epoch 40 | loss: 0.02798 | test_accuracy: 0.98922 | test_auc: 0.99903 |  0:08:17s\n",
      "epoch 41 | loss: 0.03196 | test_accuracy: 0.98992 | test_auc: 0.99891 |  0:08:31s\n",
      "epoch 42 | loss: 0.03108 | test_accuracy: 0.98974 | test_auc: 0.99902 |  0:08:42s\n",
      "epoch 43 | loss: 0.03063 | test_accuracy: 0.99009 | test_auc: 0.99889 |  0:08:56s\n",
      "epoch 44 | loss: 0.02927 | test_accuracy: 0.99061 | test_auc: 0.999   |  0:09:06s\n",
      "epoch 45 | loss: 0.02746 | test_accuracy: 0.99096 | test_auc: 0.99903 |  0:09:17s\n",
      "epoch 46 | loss: 0.0274  | test_accuracy: 0.99061 | test_auc: 0.99896 |  0:09:29s\n",
      "epoch 47 | loss: 0.02718 | test_accuracy: 0.99061 | test_auc: 0.99901 |  0:09:41s\n",
      "epoch 48 | loss: 0.02624 | test_accuracy: 0.99061 | test_auc: 0.99905 |  0:09:54s\n",
      "epoch 49 | loss: 0.02632 | test_accuracy: 0.99061 | test_auc: 0.99905 |  0:10:05s\n",
      "epoch 50 | loss: 0.02645 | test_accuracy: 0.99096 | test_auc: 0.99905 |  0:10:17s\n",
      "epoch 51 | loss: 0.02599 | test_accuracy: 0.99096 | test_auc: 0.99901 |  0:10:26s\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 31 and best_test_auc = 0.99907\n",
      "Training fold 5/5...\n",
      "epoch 0  | loss: 0.22001 | test_accuracy: 0.84495 | test_auc: 0.95027 |  0:00:09s\n",
      "epoch 1  | loss: 0.07085 | test_accuracy: 0.85225 | test_auc: 0.97829 |  0:00:21s\n",
      "epoch 2  | loss: 0.05564 | test_accuracy: 0.96002 | test_auc: 0.99139 |  0:00:31s\n",
      "epoch 3  | loss: 0.0506  | test_accuracy: 0.87363 | test_auc: 0.99605 |  0:00:42s\n",
      "epoch 4  | loss: 0.05399 | test_accuracy: 0.97984 | test_auc: 0.99472 |  0:00:54s\n",
      "epoch 5  | loss: 0.04769 | test_accuracy: 0.98488 | test_auc: 0.99835 |  0:01:05s\n",
      "epoch 6  | loss: 0.04348 | test_accuracy: 0.9887  | test_auc: 0.99864 |  0:01:16s\n",
      "epoch 7  | loss: 0.0378  | test_accuracy: 0.98644 | test_auc: 0.99863 |  0:01:30s\n",
      "epoch 8  | loss: 0.04294 | test_accuracy: 0.98922 | test_auc: 0.99928 |  0:01:43s\n",
      "epoch 9  | loss: 0.03928 | test_accuracy: 0.9894  | test_auc: 0.99932 |  0:01:56s\n",
      "epoch 10 | loss: 0.03971 | test_accuracy: 0.98974 | test_auc: 0.99905 |  0:02:07s\n",
      "epoch 11 | loss: 0.03645 | test_accuracy: 0.99096 | test_auc: 0.99926 |  0:02:19s\n",
      "epoch 12 | loss: 0.03801 | test_accuracy: 0.99044 | test_auc: 0.99828 |  0:02:32s\n",
      "epoch 13 | loss: 0.0375  | test_accuracy: 0.99027 | test_auc: 0.99926 |  0:02:45s\n",
      "epoch 14 | loss: 0.03965 | test_accuracy: 0.9887  | test_auc: 0.99848 |  0:02:56s\n",
      "epoch 15 | loss: 0.03931 | test_accuracy: 0.99061 | test_auc: 0.99932 |  0:03:06s\n",
      "epoch 16 | loss: 0.03914 | test_accuracy: 0.98888 | test_auc: 0.99936 |  0:03:15s\n",
      "epoch 17 | loss: 0.03814 | test_accuracy: 0.99079 | test_auc: 0.99886 |  0:03:24s\n",
      "epoch 18 | loss: 0.03688 | test_accuracy: 0.99027 | test_auc: 0.99921 |  0:03:34s\n",
      "epoch 19 | loss: 0.03492 | test_accuracy: 0.98992 | test_auc: 0.99873 |  0:03:45s\n",
      "epoch 20 | loss: 0.03542 | test_accuracy: 0.99027 | test_auc: 0.99914 |  0:03:55s\n",
      "epoch 21 | loss: 0.03523 | test_accuracy: 0.98974 | test_auc: 0.99915 |  0:04:07s\n",
      "epoch 22 | loss: 0.03505 | test_accuracy: 0.99131 | test_auc: 0.99934 |  0:04:15s\n",
      "epoch 23 | loss: 0.03343 | test_accuracy: 0.99061 | test_auc: 0.99935 |  0:04:27s\n",
      "epoch 24 | loss: 0.03344 | test_accuracy: 0.99166 | test_auc: 0.99934 |  0:04:40s\n",
      "epoch 25 | loss: 0.03274 | test_accuracy: 0.99027 | test_auc: 0.99929 |  0:04:52s\n",
      "epoch 26 | loss: 0.03199 | test_accuracy: 0.99096 | test_auc: 0.99926 |  0:05:05s\n",
      "epoch 27 | loss: 0.0312  | test_accuracy: 0.99079 | test_auc: 0.99921 |  0:05:17s\n",
      "epoch 28 | loss: 0.03173 | test_accuracy: 0.99131 | test_auc: 0.99932 |  0:05:28s\n",
      "epoch 29 | loss: 0.03321 | test_accuracy: 0.99061 | test_auc: 0.99906 |  0:05:40s\n",
      "epoch 30 | loss: 0.03304 | test_accuracy: 0.99061 | test_auc: 0.99902 |  0:05:53s\n",
      "epoch 31 | loss: 0.03145 | test_accuracy: 0.99096 | test_auc: 0.99926 |  0:06:04s\n",
      "epoch 32 | loss: 0.03991 | test_accuracy: 0.98748 | test_auc: 0.99885 |  0:06:17s\n",
      "epoch 33 | loss: 0.04009 | test_accuracy: 0.98609 | test_auc: 0.99883 |  0:06:27s\n",
      "epoch 34 | loss: 0.0396  | test_accuracy: 0.98644 | test_auc: 0.99876 |  0:06:35s\n",
      "epoch 35 | loss: 0.03998 | test_accuracy: 0.98627 | test_auc: 0.99885 |  0:06:45s\n",
      "epoch 36 | loss: 0.03833 | test_accuracy: 0.98766 | test_auc: 0.9992  |  0:06:55s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_test_auc = 0.99936\n",
      "\n",
      "Results for 2. Mutual Information:\n",
      "Average accuracy: 0.9886 ± 0.0022\n",
      "Average precision: 0.9908 ± 0.0105\n",
      "Average recall: 0.9770 ± 0.0044\n",
      "Average f1: 0.9838 ± 0.0032\n",
      "Average auc: 0.9860 ± 0.0010\n",
      "\n",
      "==================================================\n",
      "Processing 3. Recursive Feature Elimination\n",
      "==================================================\n",
      "Selecting features using 3. Recursive Feature Elimination...\n",
      "Top 10 features selected by 3. Recursive Feature Elimination:\n",
      "1. Breathing Problem: 1.0000\n",
      "2. Fever: 1.0000\n",
      "3. Dry Cough: 1.0000\n",
      "4. Sore throat: 1.0000\n",
      "5. Hyper Tension: 1.0000\n",
      "6. Abroad travel: 1.0000\n",
      "7. Contact with COVID Patient: 1.0000\n",
      "8. Attended Large Gathering: 1.0000\n",
      "9. Visited Public Exposed Places: 1.0000\n",
      "10. Family working in Public Exposed Places: 1.0000\n",
      "\n",
      "Training TabNet with features selected by 3. Recursive Feature Elimination\n",
      "Training fold 1/5...\n",
      "epoch 0  | loss: 0.18082 | test_accuracy: 0.95759 | test_auc: 0.98466 |  0:00:12s\n",
      "epoch 1  | loss: 0.07158 | test_accuracy: 0.95985 | test_auc: 0.99326 |  0:00:23s\n",
      "epoch 2  | loss: 0.06248 | test_accuracy: 0.96055 | test_auc: 0.99265 |  0:00:33s\n",
      "epoch 3  | loss: 0.05663 | test_accuracy: 0.96472 | test_auc: 0.99566 |  0:00:44s\n",
      "epoch 4  | loss: 0.05355 | test_accuracy: 0.96959 | test_auc: 0.99689 |  0:00:54s\n",
      "epoch 5  | loss: 0.05281 | test_accuracy: 0.9715  | test_auc: 0.99357 |  0:01:04s\n",
      "epoch 6  | loss: 0.05054 | test_accuracy: 0.97654 | test_auc: 0.99761 |  0:01:16s\n",
      "epoch 7  | loss: 0.04981 | test_accuracy: 0.97689 | test_auc: 0.99792 |  0:01:27s\n",
      "epoch 8  | loss: 0.04971 | test_accuracy: 0.9781  | test_auc: 0.99786 |  0:01:37s\n",
      "epoch 9  | loss: 0.04888 | test_accuracy: 0.97793 | test_auc: 0.99795 |  0:01:48s\n",
      "epoch 10 | loss: 0.04898 | test_accuracy: 0.97775 | test_auc: 0.9981  |  0:02:02s\n",
      "epoch 11 | loss: 0.04812 | test_accuracy: 0.97671 | test_auc: 0.99814 |  0:02:15s\n",
      "epoch 12 | loss: 0.04867 | test_accuracy: 0.97914 | test_auc: 0.99795 |  0:02:27s\n",
      "epoch 13 | loss: 0.05122 | test_accuracy: 0.97862 | test_auc: 0.99813 |  0:02:38s\n",
      "epoch 14 | loss: 0.05062 | test_accuracy: 0.97845 | test_auc: 0.99791 |  0:02:49s\n",
      "epoch 15 | loss: 0.0524  | test_accuracy: 0.97602 | test_auc: 0.99794 |  0:03:02s\n",
      "epoch 16 | loss: 0.04911 | test_accuracy: 0.97897 | test_auc: 0.99819 |  0:03:14s\n",
      "epoch 17 | loss: 0.04736 | test_accuracy: 0.97828 | test_auc: 0.99832 |  0:03:26s\n",
      "epoch 18 | loss: 0.04809 | test_accuracy: 0.97758 | test_auc: 0.99817 |  0:03:37s\n",
      "epoch 19 | loss: 0.04542 | test_accuracy: 0.98001 | test_auc: 0.99813 |  0:03:46s\n",
      "epoch 20 | loss: 0.04819 | test_accuracy: 0.9788  | test_auc: 0.99811 |  0:03:58s\n",
      "epoch 21 | loss: 0.04793 | test_accuracy: 0.98001 | test_auc: 0.99819 |  0:04:09s\n",
      "epoch 22 | loss: 0.04611 | test_accuracy: 0.98001 | test_auc: 0.99845 |  0:04:22s\n",
      "epoch 23 | loss: 0.04505 | test_accuracy: 0.98001 | test_auc: 0.99844 |  0:04:32s\n",
      "epoch 24 | loss: 0.04535 | test_accuracy: 0.97984 | test_auc: 0.99853 |  0:04:42s\n",
      "epoch 25 | loss: 0.04495 | test_accuracy: 0.97984 | test_auc: 0.99848 |  0:04:51s\n",
      "epoch 26 | loss: 0.04538 | test_accuracy: 0.98001 | test_auc: 0.99826 |  0:04:59s\n",
      "epoch 27 | loss: 0.04704 | test_accuracy: 0.98001 | test_auc: 0.998   |  0:05:09s\n",
      "epoch 28 | loss: 0.04923 | test_accuracy: 0.98001 | test_auc: 0.99828 |  0:05:18s\n",
      "epoch 29 | loss: 0.0466  | test_accuracy: 0.98071 | test_auc: 0.99832 |  0:05:29s\n",
      "epoch 30 | loss: 0.04554 | test_accuracy: 0.97984 | test_auc: 0.99835 |  0:05:42s\n",
      "epoch 31 | loss: 0.04517 | test_accuracy: 0.98088 | test_auc: 0.99843 |  0:05:55s\n",
      "epoch 32 | loss: 0.04458 | test_accuracy: 0.98106 | test_auc: 0.99835 |  0:06:06s\n",
      "epoch 33 | loss: 0.04436 | test_accuracy: 0.98088 | test_auc: 0.99844 |  0:06:17s\n",
      "epoch 34 | loss: 0.0451  | test_accuracy: 0.98123 | test_auc: 0.9985  |  0:06:32s\n",
      "epoch 35 | loss: 0.04497 | test_accuracy: 0.97897 | test_auc: 0.99852 |  0:06:45s\n",
      "epoch 36 | loss: 0.04452 | test_accuracy: 0.98071 | test_auc: 0.99853 |  0:06:56s\n",
      "epoch 37 | loss: 0.0444  | test_accuracy: 0.98106 | test_auc: 0.99853 |  0:07:07s\n",
      "epoch 38 | loss: 0.04578 | test_accuracy: 0.97984 | test_auc: 0.9984  |  0:07:18s\n",
      "epoch 39 | loss: 0.0445  | test_accuracy: 0.98106 | test_auc: 0.99829 |  0:07:30s\n",
      "epoch 40 | loss: 0.04454 | test_accuracy: 0.97984 | test_auc: 0.99834 |  0:07:42s\n",
      "epoch 41 | loss: 0.04468 | test_accuracy: 0.98088 | test_auc: 0.9982  |  0:07:54s\n",
      "epoch 42 | loss: 0.0444  | test_accuracy: 0.98036 | test_auc: 0.99815 |  0:08:04s\n",
      "epoch 43 | loss: 0.04488 | test_accuracy: 0.98071 | test_auc: 0.99839 |  0:08:12s\n",
      "epoch 44 | loss: 0.04387 | test_accuracy: 0.98106 | test_auc: 0.99845 |  0:08:25s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_test_auc = 0.99853\n",
      "Training fold 2/5...\n",
      "epoch 0  | loss: 0.18654 | test_accuracy: 0.93847 | test_auc: 0.98448 |  0:00:12s\n",
      "epoch 1  | loss: 0.07263 | test_accuracy: 0.90614 | test_auc: 0.98801 |  0:00:22s\n",
      "epoch 2  | loss: 0.05886 | test_accuracy: 0.96159 | test_auc: 0.99436 |  0:00:33s\n",
      "epoch 3  | loss: 0.05357 | test_accuracy: 0.91118 | test_auc: 0.99396 |  0:00:45s\n",
      "epoch 4  | loss: 0.05465 | test_accuracy: 0.97028 | test_auc: 0.99608 |  0:00:55s\n",
      "epoch 5  | loss: 0.0568  | test_accuracy: 0.95029 | test_auc: 0.99521 |  0:01:09s\n",
      "epoch 6  | loss: 0.05401 | test_accuracy: 0.96732 | test_auc: 0.99654 |  0:01:23s\n",
      "epoch 7  | loss: 0.0535  | test_accuracy: 0.96958 | test_auc: 0.99627 |  0:01:37s\n",
      "epoch 8  | loss: 0.04947 | test_accuracy: 0.97236 | test_auc: 0.99748 |  0:01:47s\n",
      "epoch 9  | loss: 0.05134 | test_accuracy: 0.97288 | test_auc: 0.99762 |  0:01:57s\n",
      "epoch 10 | loss: 0.05026 | test_accuracy: 0.98001 | test_auc: 0.99779 |  0:02:08s\n",
      "epoch 11 | loss: 0.04783 | test_accuracy: 0.97949 | test_auc: 0.99803 |  0:02:18s\n",
      "epoch 12 | loss: 0.04804 | test_accuracy: 0.97949 | test_auc: 0.99771 |  0:02:33s\n",
      "epoch 13 | loss: 0.04795 | test_accuracy: 0.98088 | test_auc: 0.99771 |  0:02:47s\n",
      "epoch 14 | loss: 0.04913 | test_accuracy: 0.98175 | test_auc: 0.99788 |  0:02:59s\n",
      "epoch 15 | loss: 0.0499  | test_accuracy: 0.9748  | test_auc: 0.99778 |  0:03:10s\n",
      "epoch 16 | loss: 0.04797 | test_accuracy: 0.98036 | test_auc: 0.99757 |  0:03:20s\n",
      "epoch 17 | loss: 0.0468  | test_accuracy: 0.98123 | test_auc: 0.9977  |  0:03:33s\n",
      "epoch 18 | loss: 0.04767 | test_accuracy: 0.98175 | test_auc: 0.9978  |  0:03:44s\n",
      "epoch 19 | loss: 0.04855 | test_accuracy: 0.98071 | test_auc: 0.99788 |  0:03:54s\n",
      "epoch 20 | loss: 0.047   | test_accuracy: 0.98105 | test_auc: 0.9979  |  0:04:04s\n",
      "epoch 21 | loss: 0.0464  | test_accuracy: 0.9814  | test_auc: 0.9978  |  0:04:15s\n",
      "epoch 22 | loss: 0.04603 | test_accuracy: 0.98123 | test_auc: 0.99784 |  0:04:26s\n",
      "epoch 23 | loss: 0.04587 | test_accuracy: 0.98123 | test_auc: 0.99785 |  0:04:39s\n",
      "epoch 24 | loss: 0.04658 | test_accuracy: 0.9814  | test_auc: 0.99772 |  0:04:50s\n",
      "epoch 25 | loss: 0.04667 | test_accuracy: 0.98123 | test_auc: 0.99787 |  0:05:04s\n",
      "epoch 26 | loss: 0.04635 | test_accuracy: 0.98157 | test_auc: 0.99767 |  0:05:14s\n",
      "epoch 27 | loss: 0.04713 | test_accuracy: 0.98123 | test_auc: 0.99803 |  0:05:27s\n",
      "epoch 28 | loss: 0.04626 | test_accuracy: 0.98123 | test_auc: 0.99786 |  0:05:41s\n",
      "epoch 29 | loss: 0.04539 | test_accuracy: 0.98157 | test_auc: 0.99805 |  0:05:54s\n",
      "epoch 30 | loss: 0.04617 | test_accuracy: 0.98123 | test_auc: 0.99807 |  0:06:07s\n",
      "epoch 31 | loss: 0.04545 | test_accuracy: 0.9814  | test_auc: 0.99839 |  0:06:19s\n",
      "epoch 32 | loss: 0.04671 | test_accuracy: 0.97984 | test_auc: 0.99821 |  0:06:32s\n",
      "epoch 33 | loss: 0.0485  | test_accuracy: 0.98018 | test_auc: 0.99814 |  0:06:47s\n",
      "epoch 34 | loss: 0.05096 | test_accuracy: 0.98036 | test_auc: 0.99799 |  0:06:59s\n",
      "epoch 35 | loss: 0.04711 | test_accuracy: 0.98105 | test_auc: 0.99812 |  0:07:10s\n",
      "epoch 36 | loss: 0.04715 | test_accuracy: 0.98175 | test_auc: 0.99787 |  0:07:22s\n",
      "epoch 37 | loss: 0.04803 | test_accuracy: 0.98123 | test_auc: 0.99776 |  0:07:32s\n",
      "epoch 38 | loss: 0.0466  | test_accuracy: 0.98105 | test_auc: 0.99767 |  0:07:44s\n",
      "epoch 39 | loss: 0.04733 | test_accuracy: 0.9814  | test_auc: 0.99778 |  0:07:59s\n",
      "epoch 40 | loss: 0.0459  | test_accuracy: 0.98175 | test_auc: 0.99782 |  0:08:10s\n",
      "epoch 41 | loss: 0.04604 | test_accuracy: 0.98192 | test_auc: 0.9979  |  0:08:23s\n",
      "epoch 42 | loss: 0.04547 | test_accuracy: 0.98192 | test_auc: 0.99799 |  0:08:33s\n",
      "epoch 43 | loss: 0.04628 | test_accuracy: 0.98192 | test_auc: 0.99809 |  0:08:45s\n",
      "epoch 44 | loss: 0.04569 | test_accuracy: 0.98192 | test_auc: 0.99815 |  0:08:54s\n",
      "epoch 45 | loss: 0.04518 | test_accuracy: 0.98157 | test_auc: 0.99828 |  0:09:04s\n",
      "epoch 46 | loss: 0.04475 | test_accuracy: 0.98192 | test_auc: 0.99821 |  0:09:19s\n",
      "epoch 47 | loss: 0.04346 | test_accuracy: 0.98018 | test_auc: 0.99826 |  0:09:33s\n",
      "epoch 48 | loss: 0.04565 | test_accuracy: 0.98175 | test_auc: 0.9982  |  0:09:43s\n",
      "epoch 49 | loss: 0.04818 | test_accuracy: 0.98157 | test_auc: 0.99801 |  0:09:56s\n",
      "epoch 50 | loss: 0.04684 | test_accuracy: 0.98157 | test_auc: 0.99818 |  0:10:10s\n",
      "epoch 51 | loss: 0.04514 | test_accuracy: 0.98157 | test_auc: 0.99807 |  0:10:22s\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 31 and best_test_auc = 0.99839\n",
      "Training fold 3/5...\n",
      "epoch 0  | loss: 0.184   | test_accuracy: 0.86372 | test_auc: 0.97552 |  0:00:13s\n",
      "epoch 1  | loss: 0.07863 | test_accuracy: 0.54198 | test_auc: 0.99055 |  0:00:25s\n",
      "epoch 2  | loss: 0.06111 | test_accuracy: 0.88371 | test_auc: 0.99395 |  0:00:37s\n",
      "epoch 3  | loss: 0.05368 | test_accuracy: 0.91726 | test_auc: 0.99113 |  0:00:48s\n",
      "epoch 4  | loss: 0.05464 | test_accuracy: 0.95915 | test_auc: 0.99451 |  0:00:59s\n",
      "epoch 5  | loss: 0.05357 | test_accuracy: 0.96072 | test_auc: 0.99272 |  0:01:12s\n",
      "epoch 6  | loss: 0.0502  | test_accuracy: 0.96298 | test_auc: 0.99337 |  0:01:24s\n",
      "epoch 7  | loss: 0.05055 | test_accuracy: 0.96089 | test_auc: 0.99644 |  0:01:37s\n",
      "epoch 8  | loss: 0.0474  | test_accuracy: 0.9708  | test_auc: 0.99645 |  0:01:47s\n",
      "epoch 9  | loss: 0.04961 | test_accuracy: 0.97671 | test_auc: 0.99664 |  0:01:57s\n",
      "epoch 10 | loss: 0.04969 | test_accuracy: 0.97688 | test_auc: 0.99744 |  0:02:11s\n",
      "epoch 11 | loss: 0.04716 | test_accuracy: 0.98053 | test_auc: 0.99767 |  0:02:24s\n",
      "epoch 12 | loss: 0.04871 | test_accuracy: 0.97879 | test_auc: 0.99744 |  0:02:35s\n",
      "epoch 13 | loss: 0.04748 | test_accuracy: 0.97845 | test_auc: 0.9973  |  0:02:47s\n",
      "epoch 14 | loss: 0.04769 | test_accuracy: 0.97949 | test_auc: 0.9977  |  0:03:01s\n",
      "epoch 15 | loss: 0.0455  | test_accuracy: 0.98053 | test_auc: 0.99766 |  0:03:14s\n",
      "epoch 16 | loss: 0.0461  | test_accuracy: 0.97949 | test_auc: 0.9978  |  0:03:29s\n",
      "epoch 17 | loss: 0.04646 | test_accuracy: 0.97949 | test_auc: 0.998   |  0:03:38s\n",
      "epoch 18 | loss: 0.04569 | test_accuracy: 0.98157 | test_auc: 0.99765 |  0:03:50s\n",
      "epoch 19 | loss: 0.04841 | test_accuracy: 0.97879 | test_auc: 0.99757 |  0:04:06s\n",
      "epoch 20 | loss: 0.04864 | test_accuracy: 0.97914 | test_auc: 0.99777 |  0:04:19s\n",
      "epoch 21 | loss: 0.04793 | test_accuracy: 0.97897 | test_auc: 0.9978  |  0:04:36s\n",
      "epoch 22 | loss: 0.04615 | test_accuracy: 0.97949 | test_auc: 0.99799 |  0:04:46s\n",
      "epoch 23 | loss: 0.04663 | test_accuracy: 0.97897 | test_auc: 0.99785 |  0:04:57s\n",
      "epoch 24 | loss: 0.04629 | test_accuracy: 0.9814  | test_auc: 0.99714 |  0:05:10s\n",
      "epoch 25 | loss: 0.04701 | test_accuracy: 0.98053 | test_auc: 0.99771 |  0:05:22s\n",
      "epoch 26 | loss: 0.04654 | test_accuracy: 0.98157 | test_auc: 0.99768 |  0:05:36s\n",
      "epoch 27 | loss: 0.04538 | test_accuracy: 0.98157 | test_auc: 0.99771 |  0:05:46s\n",
      "epoch 28 | loss: 0.04517 | test_accuracy: 0.98105 | test_auc: 0.99772 |  0:05:56s\n",
      "epoch 29 | loss: 0.04568 | test_accuracy: 0.98157 | test_auc: 0.99771 |  0:06:11s\n",
      "epoch 30 | loss: 0.04507 | test_accuracy: 0.98157 | test_auc: 0.99779 |  0:06:24s\n",
      "epoch 31 | loss: 0.04475 | test_accuracy: 0.98157 | test_auc: 0.99767 |  0:06:38s\n",
      "epoch 32 | loss: 0.04444 | test_accuracy: 0.98157 | test_auc: 0.99784 |  0:06:53s\n",
      "epoch 33 | loss: 0.0437  | test_accuracy: 0.97271 | test_auc: 0.99787 |  0:07:07s\n",
      "epoch 34 | loss: 0.04458 | test_accuracy: 0.98157 | test_auc: 0.99776 |  0:07:22s\n",
      "epoch 35 | loss: 0.04387 | test_accuracy: 0.98157 | test_auc: 0.99769 |  0:07:37s\n",
      "epoch 36 | loss: 0.0441  | test_accuracy: 0.98157 | test_auc: 0.99798 |  0:07:52s\n",
      "epoch 37 | loss: 0.04411 | test_accuracy: 0.98018 | test_auc: 0.99787 |  0:08:07s\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_test_auc = 0.998\n",
      "Training fold 4/5...\n",
      "epoch 0  | loss: 0.19889 | test_accuracy: 0.93812 | test_auc: 0.98272 |  0:00:14s\n",
      "epoch 1  | loss: 0.07751 | test_accuracy: 0.91639 | test_auc: 0.99263 |  0:00:29s\n",
      "epoch 2  | loss: 0.06713 | test_accuracy: 0.92421 | test_auc: 0.99031 |  0:00:44s\n",
      "epoch 3  | loss: 0.05996 | test_accuracy: 0.95515 | test_auc: 0.99316 |  0:00:54s\n",
      "epoch 4  | loss: 0.06123 | test_accuracy: 0.95707 | test_auc: 0.99464 |  0:01:08s\n",
      "epoch 5  | loss: 0.05673 | test_accuracy: 0.9675  | test_auc: 0.99478 |  0:01:20s\n",
      "epoch 6  | loss: 0.05632 | test_accuracy: 0.97549 | test_auc: 0.99671 |  0:01:33s\n",
      "epoch 7  | loss: 0.05311 | test_accuracy: 0.97566 | test_auc: 0.99712 |  0:01:47s\n",
      "epoch 8  | loss: 0.05183 | test_accuracy: 0.97688 | test_auc: 0.99719 |  0:01:58s\n",
      "epoch 9  | loss: 0.05108 | test_accuracy: 0.97688 | test_auc: 0.99718 |  0:02:09s\n",
      "epoch 10 | loss: 0.051   | test_accuracy: 0.97845 | test_auc: 0.99808 |  0:02:21s\n",
      "epoch 11 | loss: 0.05058 | test_accuracy: 0.97758 | test_auc: 0.9979  |  0:02:34s\n",
      "epoch 12 | loss: 0.04966 | test_accuracy: 0.97984 | test_auc: 0.99806 |  0:02:51s\n",
      "epoch 13 | loss: 0.05559 | test_accuracy: 0.97706 | test_auc: 0.99703 |  0:03:04s\n",
      "epoch 14 | loss: 0.05068 | test_accuracy: 0.97862 | test_auc: 0.99803 |  0:03:18s\n",
      "epoch 15 | loss: 0.04832 | test_accuracy: 0.98018 | test_auc: 0.9982  |  0:03:33s\n",
      "epoch 16 | loss: 0.04943 | test_accuracy: 0.98036 | test_auc: 0.99807 |  0:03:46s\n",
      "epoch 17 | loss: 0.04886 | test_accuracy: 0.97932 | test_auc: 0.99811 |  0:04:01s\n",
      "epoch 18 | loss: 0.04801 | test_accuracy: 0.98088 | test_auc: 0.99827 |  0:04:12s\n",
      "epoch 19 | loss: 0.0471  | test_accuracy: 0.98053 | test_auc: 0.99813 |  0:04:26s\n",
      "epoch 20 | loss: 0.04659 | test_accuracy: 0.98001 | test_auc: 0.99813 |  0:04:40s\n",
      "epoch 21 | loss: 0.04817 | test_accuracy: 0.98071 | test_auc: 0.99815 |  0:04:55s\n",
      "epoch 22 | loss: 0.04712 | test_accuracy: 0.98227 | test_auc: 0.99827 |  0:05:10s\n",
      "epoch 23 | loss: 0.04588 | test_accuracy: 0.98262 | test_auc: 0.99829 |  0:05:20s\n",
      "epoch 24 | loss: 0.04642 | test_accuracy: 0.98262 | test_auc: 0.99834 |  0:05:32s\n",
      "epoch 25 | loss: 0.04526 | test_accuracy: 0.98262 | test_auc: 0.99838 |  0:05:45s\n",
      "epoch 26 | loss: 0.04431 | test_accuracy: 0.98262 | test_auc: 0.99839 |  0:05:58s\n",
      "epoch 27 | loss: 0.04407 | test_accuracy: 0.98262 | test_auc: 0.99837 |  0:06:09s\n",
      "epoch 28 | loss: 0.04509 | test_accuracy: 0.98227 | test_auc: 0.99838 |  0:06:22s\n",
      "epoch 29 | loss: 0.04469 | test_accuracy: 0.98262 | test_auc: 0.99839 |  0:06:34s\n",
      "epoch 30 | loss: 0.04431 | test_accuracy: 0.98262 | test_auc: 0.99841 |  0:06:48s\n",
      "epoch 31 | loss: 0.04471 | test_accuracy: 0.98262 | test_auc: 0.99835 |  0:07:05s\n",
      "epoch 32 | loss: 0.04486 | test_accuracy: 0.98262 | test_auc: 0.99839 |  0:07:20s\n",
      "epoch 33 | loss: 0.04547 | test_accuracy: 0.98227 | test_auc: 0.99826 |  0:07:29s\n",
      "epoch 34 | loss: 0.04536 | test_accuracy: 0.98227 | test_auc: 0.99836 |  0:07:45s\n",
      "epoch 35 | loss: 0.04582 | test_accuracy: 0.98262 | test_auc: 0.99828 |  0:08:01s\n",
      "epoch 36 | loss: 0.04419 | test_accuracy: 0.98262 | test_auc: 0.9984  |  0:08:16s\n",
      "epoch 37 | loss: 0.04454 | test_accuracy: 0.98262 | test_auc: 0.9984  |  0:08:31s\n",
      "epoch 38 | loss: 0.04454 | test_accuracy: 0.98262 | test_auc: 0.99834 |  0:08:41s\n",
      "epoch 39 | loss: 0.04373 | test_accuracy: 0.98105 | test_auc: 0.99838 |  0:08:53s\n",
      "epoch 40 | loss: 0.04387 | test_accuracy: 0.98262 | test_auc: 0.9984  |  0:09:03s\n",
      "epoch 41 | loss: 0.04464 | test_accuracy: 0.98262 | test_auc: 0.99837 |  0:09:14s\n",
      "epoch 42 | loss: 0.0454  | test_accuracy: 0.98227 | test_auc: 0.99845 |  0:09:27s\n",
      "epoch 43 | loss: 0.04557 | test_accuracy: 0.98175 | test_auc: 0.99828 |  0:09:41s\n",
      "epoch 44 | loss: 0.04598 | test_accuracy: 0.98018 | test_auc: 0.99829 |  0:09:52s\n",
      "epoch 45 | loss: 0.04587 | test_accuracy: 0.98262 | test_auc: 0.99842 |  0:10:06s\n",
      "epoch 46 | loss: 0.04557 | test_accuracy: 0.98175 | test_auc: 0.9984  |  0:10:17s\n",
      "epoch 47 | loss: 0.05205 | test_accuracy: 0.9781  | test_auc: 0.99803 |  0:10:30s\n",
      "epoch 48 | loss: 0.05354 | test_accuracy: 0.98105 | test_auc: 0.99808 |  0:10:45s\n",
      "epoch 49 | loss: 0.05332 | test_accuracy: 0.98105 | test_auc: 0.99829 |  0:11:00s\n",
      "epoch 50 | loss: 0.05155 | test_accuracy: 0.9821  | test_auc: 0.99824 |  0:11:15s\n",
      "epoch 51 | loss: 0.05056 | test_accuracy: 0.98192 | test_auc: 0.99819 |  0:11:30s\n",
      "epoch 52 | loss: 0.04766 | test_accuracy: 0.98192 | test_auc: 0.99814 |  0:11:45s\n",
      "epoch 53 | loss: 0.04693 | test_accuracy: 0.97845 | test_auc: 0.99819 |  0:11:57s\n",
      "epoch 54 | loss: 0.04662 | test_accuracy: 0.97845 | test_auc: 0.99824 |  0:12:12s\n",
      "epoch 55 | loss: 0.04598 | test_accuracy: 0.98227 | test_auc: 0.99835 |  0:12:27s\n",
      "epoch 56 | loss: 0.04481 | test_accuracy: 0.98227 | test_auc: 0.99844 |  0:12:40s\n",
      "epoch 57 | loss: 0.04452 | test_accuracy: 0.98175 | test_auc: 0.99832 |  0:12:54s\n",
      "epoch 58 | loss: 0.04463 | test_accuracy: 0.98262 | test_auc: 0.99839 |  0:13:06s\n",
      "epoch 59 | loss: 0.05048 | test_accuracy: 0.98036 | test_auc: 0.99819 |  0:13:21s\n",
      "epoch 60 | loss: 0.04763 | test_accuracy: 0.98157 | test_auc: 0.99809 |  0:13:35s\n",
      "epoch 61 | loss: 0.0466  | test_accuracy: 0.98227 | test_auc: 0.99847 |  0:13:48s\n",
      "epoch 62 | loss: 0.0457  | test_accuracy: 0.98227 | test_auc: 0.99834 |  0:14:01s\n",
      "epoch 63 | loss: 0.04418 | test_accuracy: 0.98262 | test_auc: 0.99851 |  0:14:12s\n",
      "epoch 64 | loss: 0.04439 | test_accuracy: 0.98262 | test_auc: 0.99847 |  0:14:26s\n",
      "epoch 65 | loss: 0.04382 | test_accuracy: 0.98262 | test_auc: 0.99846 |  0:14:40s\n",
      "epoch 66 | loss: 0.04372 | test_accuracy: 0.98262 | test_auc: 0.99839 |  0:14:55s\n",
      "epoch 67 | loss: 0.0431  | test_accuracy: 0.98262 | test_auc: 0.99844 |  0:15:08s\n",
      "epoch 68 | loss: 0.043   | test_accuracy: 0.98262 | test_auc: 0.99846 |  0:15:23s\n",
      "epoch 69 | loss: 0.04294 | test_accuracy: 0.98262 | test_auc: 0.99838 |  0:15:37s\n",
      "epoch 70 | loss: 0.04301 | test_accuracy: 0.98262 | test_auc: 0.99848 |  0:15:53s\n",
      "epoch 71 | loss: 0.04337 | test_accuracy: 0.98262 | test_auc: 0.99846 |  0:16:09s\n",
      "epoch 72 | loss: 0.04306 | test_accuracy: 0.98262 | test_auc: 0.99849 |  0:16:20s\n",
      "epoch 73 | loss: 0.04334 | test_accuracy: 0.98262 | test_auc: 0.9985  |  0:16:35s\n",
      "epoch 74 | loss: 0.04278 | test_accuracy: 0.98262 | test_auc: 0.99848 |  0:16:47s\n",
      "epoch 75 | loss: 0.04315 | test_accuracy: 0.98262 | test_auc: 0.99852 |  0:17:02s\n",
      "epoch 76 | loss: 0.04283 | test_accuracy: 0.98262 | test_auc: 0.99851 |  0:17:16s\n",
      "epoch 77 | loss: 0.04308 | test_accuracy: 0.98262 | test_auc: 0.99847 |  0:17:26s\n",
      "epoch 78 | loss: 0.04324 | test_accuracy: 0.98262 | test_auc: 0.99849 |  0:17:39s\n",
      "epoch 79 | loss: 0.04334 | test_accuracy: 0.9821  | test_auc: 0.99845 |  0:17:52s\n",
      "epoch 80 | loss: 0.04345 | test_accuracy: 0.98227 | test_auc: 0.99852 |  0:18:07s\n",
      "epoch 81 | loss: 0.04339 | test_accuracy: 0.98262 | test_auc: 0.99848 |  0:18:22s\n",
      "epoch 82 | loss: 0.04405 | test_accuracy: 0.98227 | test_auc: 0.99846 |  0:18:35s\n",
      "epoch 83 | loss: 0.0437  | test_accuracy: 0.98192 | test_auc: 0.99851 |  0:18:52s\n",
      "epoch 84 | loss: 0.04353 | test_accuracy: 0.98227 | test_auc: 0.99843 |  0:19:08s\n",
      "epoch 85 | loss: 0.04315 | test_accuracy: 0.98227 | test_auc: 0.99846 |  0:19:22s\n",
      "epoch 86 | loss: 0.04336 | test_accuracy: 0.98227 | test_auc: 0.99853 |  0:19:34s\n",
      "epoch 87 | loss: 0.04306 | test_accuracy: 0.98227 | test_auc: 0.99851 |  0:19:50s\n",
      "epoch 88 | loss: 0.04353 | test_accuracy: 0.98227 | test_auc: 0.99846 |  0:20:06s\n",
      "epoch 89 | loss: 0.044   | test_accuracy: 0.9821  | test_auc: 0.99844 |  0:20:19s\n",
      "epoch 90 | loss: 0.04327 | test_accuracy: 0.98262 | test_auc: 0.99851 |  0:20:31s\n",
      "epoch 91 | loss: 0.04293 | test_accuracy: 0.98262 | test_auc: 0.99853 |  0:20:42s\n",
      "epoch 92 | loss: 0.04266 | test_accuracy: 0.98262 | test_auc: 0.99845 |  0:20:53s\n",
      "epoch 93 | loss: 0.0425  | test_accuracy: 0.98262 | test_auc: 0.99852 |  0:21:07s\n",
      "epoch 94 | loss: 0.04252 | test_accuracy: 0.98262 | test_auc: 0.99853 |  0:21:18s\n",
      "epoch 95 | loss: 0.0433  | test_accuracy: 0.9814  | test_auc: 0.9984  |  0:21:30s\n",
      "epoch 96 | loss: 0.04291 | test_accuracy: 0.98262 | test_auc: 0.9985  |  0:21:41s\n",
      "epoch 97 | loss: 0.04324 | test_accuracy: 0.98227 | test_auc: 0.99853 |  0:21:54s\n",
      "epoch 98 | loss: 0.04283 | test_accuracy: 0.98227 | test_auc: 0.99852 |  0:22:06s\n",
      "epoch 99 | loss: 0.04246 | test_accuracy: 0.98227 | test_auc: 0.99855 |  0:22:19s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_test_auc = 0.99855\n",
      "Training fold 5/5...\n",
      "epoch 0  | loss: 0.19936 | test_accuracy: 0.94281 | test_auc: 0.98007 |  0:00:15s\n",
      "epoch 1  | loss: 0.07912 | test_accuracy: 0.93447 | test_auc: 0.98328 |  0:00:29s\n",
      "epoch 2  | loss: 0.0639  | test_accuracy: 0.96159 | test_auc: 0.99576 |  0:00:44s\n",
      "epoch 3  | loss: 0.06354 | test_accuracy: 0.95394 | test_auc: 0.9975  |  0:01:00s\n",
      "epoch 4  | loss: 0.05809 | test_accuracy: 0.9661  | test_auc: 0.99791 |  0:01:13s\n",
      "epoch 5  | loss: 0.05354 | test_accuracy: 0.97167 | test_auc: 0.99814 |  0:01:29s\n",
      "epoch 6  | loss: 0.05068 | test_accuracy: 0.97636 | test_auc: 0.99865 |  0:01:39s\n",
      "epoch 7  | loss: 0.05094 | test_accuracy: 0.98175 | test_auc: 0.99871 |  0:01:54s\n",
      "epoch 8  | loss: 0.05332 | test_accuracy: 0.98366 | test_auc: 0.99846 |  0:02:08s\n",
      "epoch 9  | loss: 0.04968 | test_accuracy: 0.97862 | test_auc: 0.99851 |  0:02:20s\n",
      "epoch 10 | loss: 0.04973 | test_accuracy: 0.98401 | test_auc: 0.99872 |  0:02:34s\n",
      "epoch 11 | loss: 0.04802 | test_accuracy: 0.98401 | test_auc: 0.99868 |  0:02:44s\n",
      "epoch 12 | loss: 0.04749 | test_accuracy: 0.98366 | test_auc: 0.99885 |  0:02:56s\n",
      "epoch 13 | loss: 0.04885 | test_accuracy: 0.98418 | test_auc: 0.99884 |  0:03:07s\n",
      "epoch 14 | loss: 0.04815 | test_accuracy: 0.98401 | test_auc: 0.99875 |  0:03:17s\n",
      "epoch 15 | loss: 0.04836 | test_accuracy: 0.98418 | test_auc: 0.99889 |  0:03:31s\n",
      "epoch 16 | loss: 0.05306 | test_accuracy: 0.98262 | test_auc: 0.99839 |  0:03:43s\n",
      "epoch 17 | loss: 0.05339 | test_accuracy: 0.98331 | test_auc: 0.99853 |  0:03:55s\n",
      "epoch 18 | loss: 0.05217 | test_accuracy: 0.98383 | test_auc: 0.99879 |  0:04:08s\n",
      "epoch 19 | loss: 0.051   | test_accuracy: 0.98297 | test_auc: 0.99879 |  0:04:21s\n",
      "epoch 20 | loss: 0.05113 | test_accuracy: 0.98123 | test_auc: 0.99807 |  0:04:35s\n",
      "epoch 21 | loss: 0.05024 | test_accuracy: 0.98262 | test_auc: 0.99889 |  0:04:50s\n",
      "epoch 22 | loss: 0.04777 | test_accuracy: 0.98401 | test_auc: 0.99876 |  0:05:04s\n",
      "epoch 23 | loss: 0.04669 | test_accuracy: 0.98383 | test_auc: 0.99885 |  0:05:20s\n",
      "epoch 24 | loss: 0.04642 | test_accuracy: 0.98314 | test_auc: 0.99877 |  0:05:36s\n",
      "epoch 25 | loss: 0.04646 | test_accuracy: 0.98436 | test_auc: 0.99866 |  0:05:52s\n",
      "epoch 26 | loss: 0.04716 | test_accuracy: 0.98436 | test_auc: 0.99892 |  0:06:03s\n",
      "epoch 27 | loss: 0.04689 | test_accuracy: 0.98314 | test_auc: 0.99861 |  0:06:15s\n",
      "epoch 28 | loss: 0.04653 | test_accuracy: 0.98366 | test_auc: 0.99884 |  0:06:28s\n",
      "epoch 29 | loss: 0.04637 | test_accuracy: 0.98383 | test_auc: 0.99887 |  0:06:42s\n",
      "epoch 30 | loss: 0.04601 | test_accuracy: 0.98331 | test_auc: 0.99893 |  0:06:56s\n",
      "epoch 31 | loss: 0.04563 | test_accuracy: 0.98383 | test_auc: 0.99886 |  0:07:05s\n",
      "epoch 32 | loss: 0.04588 | test_accuracy: 0.98436 | test_auc: 0.99879 |  0:07:15s\n",
      "epoch 33 | loss: 0.0451  | test_accuracy: 0.98436 | test_auc: 0.99893 |  0:07:28s\n",
      "epoch 34 | loss: 0.04569 | test_accuracy: 0.98349 | test_auc: 0.99863 |  0:07:41s\n",
      "epoch 35 | loss: 0.04703 | test_accuracy: 0.98401 | test_auc: 0.99879 |  0:07:56s\n",
      "epoch 36 | loss: 0.04556 | test_accuracy: 0.98436 | test_auc: 0.99887 |  0:08:09s\n",
      "epoch 37 | loss: 0.04536 | test_accuracy: 0.98436 | test_auc: 0.99883 |  0:08:24s\n",
      "epoch 38 | loss: 0.04549 | test_accuracy: 0.98331 | test_auc: 0.99893 |  0:08:38s\n",
      "epoch 39 | loss: 0.04542 | test_accuracy: 0.98436 | test_auc: 0.99892 |  0:08:53s\n",
      "epoch 40 | loss: 0.04509 | test_accuracy: 0.98401 | test_auc: 0.99889 |  0:09:06s\n",
      "epoch 41 | loss: 0.04522 | test_accuracy: 0.98331 | test_auc: 0.99892 |  0:09:16s\n",
      "epoch 42 | loss: 0.04495 | test_accuracy: 0.98401 | test_auc: 0.99887 |  0:09:30s\n",
      "epoch 43 | loss: 0.04562 | test_accuracy: 0.98383 | test_auc: 0.99871 |  0:09:45s\n",
      "epoch 44 | loss: 0.04698 | test_accuracy: 0.98262 | test_auc: 0.99879 |  0:10:00s\n",
      "epoch 45 | loss: 0.04634 | test_accuracy: 0.98401 | test_auc: 0.99887 |  0:10:12s\n",
      "epoch 46 | loss: 0.0468  | test_accuracy: 0.98366 | test_auc: 0.99861 |  0:10:22s\n",
      "epoch 47 | loss: 0.04675 | test_accuracy: 0.98366 | test_auc: 0.99881 |  0:10:36s\n",
      "epoch 48 | loss: 0.04644 | test_accuracy: 0.98297 | test_auc: 0.99875 |  0:10:49s\n",
      "epoch 49 | loss: 0.0474  | test_accuracy: 0.98401 | test_auc: 0.99874 |  0:11:01s\n",
      "epoch 50 | loss: 0.04578 | test_accuracy: 0.98401 | test_auc: 0.99877 |  0:11:13s\n",
      "epoch 51 | loss: 0.04618 | test_accuracy: 0.98349 | test_auc: 0.9988  |  0:11:25s\n",
      "epoch 52 | loss: 0.04608 | test_accuracy: 0.98331 | test_auc: 0.99881 |  0:11:36s\n",
      "epoch 53 | loss: 0.04547 | test_accuracy: 0.98349 | test_auc: 0.99874 |  0:11:49s\n",
      "epoch 54 | loss: 0.04564 | test_accuracy: 0.98401 | test_auc: 0.99882 |  0:12:02s\n",
      "epoch 55 | loss: 0.04567 | test_accuracy: 0.98401 | test_auc: 0.99854 |  0:12:14s\n",
      "epoch 56 | loss: 0.04697 | test_accuracy: 0.98401 | test_auc: 0.99882 |  0:12:28s\n",
      "epoch 57 | loss: 0.04532 | test_accuracy: 0.98401 | test_auc: 0.99877 |  0:12:42s\n",
      "epoch 58 | loss: 0.04533 | test_accuracy: 0.98401 | test_auc: 0.99889 |  0:12:57s\n",
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 38 and best_test_auc = 0.99893\n",
      "\n",
      "Results for 3. Recursive Feature Elimination:\n",
      "Average accuracy: 0.9813 ± 0.0014\n",
      "Average precision: 0.9862 ± 0.0046\n",
      "Average recall: 0.9609 ± 0.0051\n",
      "Average f1: 0.9733 ± 0.0023\n",
      "Average auc: 0.9767 ± 0.0021\n",
      "\n",
      "==================================================\n",
      "Processing 4. Lasso\n",
      "==================================================\n",
      "Selecting features using 4. Lasso...\n",
      "Top 10 features selected by 4. Lasso:\n",
      "1. Breathing Problem: 1.0000\n",
      "2. Sore throat: 1.0000\n",
      "3. Fatigue : 1.0000\n",
      "4. Abroad travel: 1.0000\n",
      "5. Contact with COVID Patient: 1.0000\n",
      "6. Attended Large Gathering: 1.0000\n",
      "7. Visited Public Exposed Places: 1.0000\n",
      "8. Family working in Public Exposed Places: 1.0000\n",
      "9. Fever: 0.0000\n",
      "10. Dry Cough: 0.0000\n",
      "\n",
      "Training TabNet with features selected by 4. Lasso\n",
      "Training fold 1/5...\n",
      "epoch 0  | loss: 0.20495 | test_accuracy: 0.89468 | test_auc: 0.9489  |  0:00:15s\n",
      "epoch 1  | loss: 0.07051 | test_accuracy: 0.95395 | test_auc: 0.99197 |  0:00:30s\n",
      "epoch 2  | loss: 0.06297 | test_accuracy: 0.96455 | test_auc: 0.99664 |  0:00:40s\n",
      "epoch 3  | loss: 0.05861 | test_accuracy: 0.95586 | test_auc: 0.99576 |  0:00:58s\n",
      "epoch 4  | loss: 0.0558  | test_accuracy: 0.95759 | test_auc: 0.99531 |  0:01:11s\n",
      "epoch 5  | loss: 0.05227 | test_accuracy: 0.96611 | test_auc: 0.99567 |  0:01:23s\n",
      "epoch 6  | loss: 0.04872 | test_accuracy: 0.97428 | test_auc: 0.99777 |  0:01:37s\n",
      "epoch 7  | loss: 0.04832 | test_accuracy: 0.97219 | test_auc: 0.99699 |  0:01:47s\n",
      "epoch 8  | loss: 0.04743 | test_accuracy: 0.98123 | test_auc: 0.99793 |  0:01:55s\n",
      "epoch 9  | loss: 0.04549 | test_accuracy: 0.98106 | test_auc: 0.99802 |  0:01:59s\n",
      "epoch 10 | loss: 0.04778 | test_accuracy: 0.9781  | test_auc: 0.99804 |  0:02:02s\n",
      "epoch 11 | loss: 0.04606 | test_accuracy: 0.98106 | test_auc: 0.99848 |  0:02:05s\n",
      "epoch 12 | loss: 0.04451 | test_accuracy: 0.98158 | test_auc: 0.99845 |  0:02:08s\n",
      "epoch 13 | loss: 0.04417 | test_accuracy: 0.98158 | test_auc: 0.99843 |  0:02:12s\n",
      "epoch 14 | loss: 0.04407 | test_accuracy: 0.98106 | test_auc: 0.99845 |  0:02:15s\n",
      "epoch 15 | loss: 0.04485 | test_accuracy: 0.98175 | test_auc: 0.99855 |  0:02:18s\n",
      "epoch 16 | loss: 0.0434  | test_accuracy: 0.98175 | test_auc: 0.99849 |  0:02:21s\n",
      "epoch 17 | loss: 0.04516 | test_accuracy: 0.98175 | test_auc: 0.9985  |  0:02:24s\n",
      "epoch 18 | loss: 0.04369 | test_accuracy: 0.98279 | test_auc: 0.99857 |  0:02:27s\n",
      "epoch 19 | loss: 0.04397 | test_accuracy: 0.98036 | test_auc: 0.99841 |  0:02:30s\n",
      "epoch 20 | loss: 0.04359 | test_accuracy: 0.98175 | test_auc: 0.99839 |  0:02:33s\n",
      "epoch 21 | loss: 0.04517 | test_accuracy: 0.98175 | test_auc: 0.99843 |  0:02:36s\n",
      "epoch 22 | loss: 0.04432 | test_accuracy: 0.98175 | test_auc: 0.99852 |  0:02:39s\n",
      "epoch 23 | loss: 0.05384 | test_accuracy: 0.97619 | test_auc: 0.99759 |  0:02:42s\n",
      "epoch 24 | loss: 0.05774 | test_accuracy: 0.97793 | test_auc: 0.99805 |  0:02:45s\n",
      "epoch 25 | loss: 0.05272 | test_accuracy: 0.97828 | test_auc: 0.99797 |  0:02:52s\n",
      "epoch 26 | loss: 0.05059 | test_accuracy: 0.97741 | test_auc: 0.99804 |  0:02:55s\n",
      "epoch 27 | loss: 0.04787 | test_accuracy: 0.97984 | test_auc: 0.99815 |  0:02:58s\n",
      "epoch 28 | loss: 0.04741 | test_accuracy: 0.97984 | test_auc: 0.9982  |  0:03:01s\n",
      "epoch 29 | loss: 0.04753 | test_accuracy: 0.97949 | test_auc: 0.99825 |  0:03:04s\n",
      "epoch 30 | loss: 0.04824 | test_accuracy: 0.97932 | test_auc: 0.99831 |  0:03:07s\n",
      "epoch 31 | loss: 0.04677 | test_accuracy: 0.98001 | test_auc: 0.9983  |  0:03:09s\n",
      "epoch 32 | loss: 0.0459  | test_accuracy: 0.97775 | test_auc: 0.99825 |  0:03:12s\n",
      "epoch 33 | loss: 0.04619 | test_accuracy: 0.97932 | test_auc: 0.99821 |  0:03:15s\n",
      "epoch 34 | loss: 0.04715 | test_accuracy: 0.97828 | test_auc: 0.99831 |  0:03:18s\n",
      "epoch 35 | loss: 0.04706 | test_accuracy: 0.9788  | test_auc: 0.99827 |  0:03:21s\n",
      "epoch 36 | loss: 0.04668 | test_accuracy: 0.98001 | test_auc: 0.99836 |  0:03:24s\n",
      "epoch 37 | loss: 0.04583 | test_accuracy: 0.9788  | test_auc: 0.99833 |  0:03:27s\n",
      "epoch 38 | loss: 0.04573 | test_accuracy: 0.98019 | test_auc: 0.99831 |  0:03:30s\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 18 and best_test_auc = 0.99857\n",
      "Training fold 2/5...\n",
      "epoch 0  | loss: 0.19483 | test_accuracy: 0.72397 | test_auc: 0.96863 |  0:00:02s\n",
      "epoch 1  | loss: 0.06992 | test_accuracy: 0.72171 | test_auc: 0.97779 |  0:00:05s\n",
      "epoch 2  | loss: 0.06205 | test_accuracy: 0.94316 | test_auc: 0.9899  |  0:00:08s\n",
      "epoch 3  | loss: 0.0573  | test_accuracy: 0.95342 | test_auc: 0.99409 |  0:00:11s\n",
      "epoch 4  | loss: 0.05802 | test_accuracy: 0.96054 | test_auc: 0.99403 |  0:00:14s\n",
      "epoch 5  | loss: 0.05221 | test_accuracy: 0.95394 | test_auc: 0.9947  |  0:00:17s\n",
      "epoch 6  | loss: 0.05056 | test_accuracy: 0.97445 | test_auc: 0.99633 |  0:00:20s\n",
      "epoch 7  | loss: 0.04905 | test_accuracy: 0.97584 | test_auc: 0.99718 |  0:00:23s\n",
      "epoch 8  | loss: 0.05148 | test_accuracy: 0.97219 | test_auc: 0.99584 |  0:00:25s\n",
      "epoch 9  | loss: 0.05744 | test_accuracy: 0.97932 | test_auc: 0.99683 |  0:00:28s\n",
      "epoch 10 | loss: 0.05209 | test_accuracy: 0.97966 | test_auc: 0.99772 |  0:00:31s\n",
      "epoch 11 | loss: 0.04933 | test_accuracy: 0.97949 | test_auc: 0.99795 |  0:00:34s\n",
      "epoch 12 | loss: 0.04921 | test_accuracy: 0.98001 | test_auc: 0.99761 |  0:00:37s\n",
      "epoch 13 | loss: 0.05178 | test_accuracy: 0.97671 | test_auc: 0.99784 |  0:00:40s\n",
      "epoch 14 | loss: 0.05174 | test_accuracy: 0.98036 | test_auc: 0.99798 |  0:00:43s\n",
      "epoch 15 | loss: 0.04886 | test_accuracy: 0.9821  | test_auc: 0.9983  |  0:00:46s\n",
      "epoch 16 | loss: 0.04642 | test_accuracy: 0.98244 | test_auc: 0.99819 |  0:00:48s\n",
      "epoch 17 | loss: 0.04501 | test_accuracy: 0.98262 | test_auc: 0.99764 |  0:00:51s\n",
      "epoch 18 | loss: 0.04474 | test_accuracy: 0.98279 | test_auc: 0.99765 |  0:00:54s\n",
      "epoch 19 | loss: 0.04491 | test_accuracy: 0.9821  | test_auc: 0.99773 |  0:00:57s\n",
      "epoch 20 | loss: 0.04385 | test_accuracy: 0.98262 | test_auc: 0.99791 |  0:01:00s\n",
      "epoch 21 | loss: 0.04423 | test_accuracy: 0.98262 | test_auc: 0.99736 |  0:01:03s\n",
      "epoch 22 | loss: 0.04498 | test_accuracy: 0.98227 | test_auc: 0.99793 |  0:01:06s\n",
      "epoch 23 | loss: 0.04538 | test_accuracy: 0.98262 | test_auc: 0.99785 |  0:01:09s\n",
      "epoch 24 | loss: 0.04378 | test_accuracy: 0.98262 | test_auc: 0.99765 |  0:01:12s\n",
      "epoch 25 | loss: 0.04461 | test_accuracy: 0.98262 | test_auc: 0.99788 |  0:01:15s\n",
      "epoch 26 | loss: 0.04409 | test_accuracy: 0.98262 | test_auc: 0.99825 |  0:01:18s\n",
      "epoch 27 | loss: 0.04596 | test_accuracy: 0.98262 | test_auc: 0.99762 |  0:01:21s\n",
      "epoch 28 | loss: 0.04532 | test_accuracy: 0.9814  | test_auc: 0.99812 |  0:01:24s\n",
      "epoch 29 | loss: 0.04457 | test_accuracy: 0.9814  | test_auc: 0.9974  |  0:01:27s\n",
      "epoch 30 | loss: 0.04496 | test_accuracy: 0.98262 | test_auc: 0.99754 |  0:01:29s\n",
      "epoch 31 | loss: 0.04321 | test_accuracy: 0.98227 | test_auc: 0.99743 |  0:01:32s\n",
      "epoch 32 | loss: 0.04342 | test_accuracy: 0.98262 | test_auc: 0.99773 |  0:01:35s\n",
      "epoch 33 | loss: 0.04282 | test_accuracy: 0.98262 | test_auc: 0.99784 |  0:01:38s\n",
      "epoch 34 | loss: 0.04314 | test_accuracy: 0.98262 | test_auc: 0.99806 |  0:01:41s\n",
      "epoch 35 | loss: 0.04301 | test_accuracy: 0.98262 | test_auc: 0.99785 |  0:01:44s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_test_auc = 0.9983\n",
      "Training fold 3/5...\n",
      "epoch 0  | loss: 0.24395 | test_accuracy: 0.91292 | test_auc: 0.93035 |  0:00:02s\n",
      "epoch 1  | loss: 0.07585 | test_accuracy: 0.87433 | test_auc: 0.95509 |  0:00:05s\n",
      "epoch 2  | loss: 0.0634  | test_accuracy: 0.91344 | test_auc: 0.98073 |  0:00:08s\n",
      "epoch 3  | loss: 0.05917 | test_accuracy: 0.911   | test_auc: 0.97792 |  0:00:11s\n",
      "epoch 4  | loss: 0.05697 | test_accuracy: 0.91604 | test_auc: 0.98541 |  0:00:14s\n",
      "epoch 5  | loss: 0.05248 | test_accuracy: 0.95481 | test_auc: 0.98679 |  0:00:17s\n",
      "epoch 6  | loss: 0.05102 | test_accuracy: 0.96072 | test_auc: 0.98942 |  0:00:20s\n",
      "epoch 7  | loss: 0.04991 | test_accuracy: 0.9748  | test_auc: 0.99631 |  0:00:23s\n",
      "epoch 8  | loss: 0.04946 | test_accuracy: 0.97862 | test_auc: 0.9974  |  0:00:25s\n",
      "epoch 9  | loss: 0.04701 | test_accuracy: 0.98175 | test_auc: 0.99741 |  0:00:28s\n",
      "epoch 10 | loss: 0.04591 | test_accuracy: 0.98071 | test_auc: 0.99763 |  0:00:31s\n",
      "epoch 11 | loss: 0.04488 | test_accuracy: 0.9781  | test_auc: 0.9978  |  0:00:34s\n",
      "epoch 12 | loss: 0.04363 | test_accuracy: 0.98418 | test_auc: 0.99819 |  0:00:37s\n",
      "epoch 13 | loss: 0.04334 | test_accuracy: 0.9814  | test_auc: 0.99814 |  0:00:40s\n",
      "epoch 14 | loss: 0.04372 | test_accuracy: 0.9814  | test_auc: 0.99788 |  0:00:43s\n",
      "epoch 15 | loss: 0.04434 | test_accuracy: 0.9814  | test_auc: 0.9981  |  0:00:46s\n",
      "epoch 16 | loss: 0.04385 | test_accuracy: 0.98123 | test_auc: 0.99823 |  0:00:49s\n",
      "epoch 17 | loss: 0.04349 | test_accuracy: 0.98227 | test_auc: 0.99813 |  0:00:52s\n",
      "epoch 18 | loss: 0.04444 | test_accuracy: 0.98018 | test_auc: 0.99805 |  0:00:55s\n",
      "epoch 19 | loss: 0.04453 | test_accuracy: 0.9814  | test_auc: 0.99807 |  0:00:58s\n",
      "epoch 20 | loss: 0.04431 | test_accuracy: 0.98018 | test_auc: 0.99807 |  0:01:00s\n",
      "epoch 21 | loss: 0.04341 | test_accuracy: 0.98349 | test_auc: 0.99815 |  0:01:03s\n",
      "epoch 22 | loss: 0.04417 | test_accuracy: 0.98244 | test_auc: 0.99812 |  0:01:06s\n",
      "epoch 23 | loss: 0.04292 | test_accuracy: 0.98244 | test_auc: 0.99819 |  0:01:09s\n",
      "epoch 24 | loss: 0.04235 | test_accuracy: 0.98244 | test_auc: 0.9982  |  0:01:12s\n",
      "epoch 25 | loss: 0.04263 | test_accuracy: 0.98001 | test_auc: 0.99822 |  0:01:15s\n",
      "epoch 26 | loss: 0.0465  | test_accuracy: 0.98071 | test_auc: 0.99818 |  0:01:18s\n",
      "epoch 27 | loss: 0.04476 | test_accuracy: 0.98175 | test_auc: 0.99785 |  0:01:21s\n",
      "epoch 28 | loss: 0.04461 | test_accuracy: 0.98244 | test_auc: 0.99814 |  0:01:24s\n",
      "epoch 29 | loss: 0.0463  | test_accuracy: 0.98018 | test_auc: 0.99793 |  0:01:27s\n",
      "epoch 30 | loss: 0.04571 | test_accuracy: 0.98244 | test_auc: 0.99787 |  0:01:30s\n",
      "epoch 31 | loss: 0.0451  | test_accuracy: 0.98018 | test_auc: 0.99817 |  0:01:33s\n",
      "epoch 32 | loss: 0.04606 | test_accuracy: 0.98227 | test_auc: 0.99795 |  0:01:36s\n",
      "epoch 33 | loss: 0.04533 | test_accuracy: 0.98244 | test_auc: 0.99823 |  0:01:39s\n",
      "epoch 34 | loss: 0.04415 | test_accuracy: 0.98366 | test_auc: 0.99823 |  0:01:42s\n",
      "epoch 35 | loss: 0.04396 | test_accuracy: 0.98244 | test_auc: 0.99816 |  0:01:45s\n",
      "epoch 36 | loss: 0.04649 | test_accuracy: 0.98244 | test_auc: 0.99819 |  0:01:47s\n",
      "epoch 37 | loss: 0.04484 | test_accuracy: 0.98366 | test_auc: 0.99817 |  0:01:50s\n",
      "epoch 38 | loss: 0.04348 | test_accuracy: 0.98349 | test_auc: 0.99824 |  0:01:53s\n",
      "epoch 39 | loss: 0.04354 | test_accuracy: 0.98349 | test_auc: 0.99816 |  0:01:56s\n",
      "epoch 40 | loss: 0.0431  | test_accuracy: 0.98331 | test_auc: 0.99825 |  0:01:59s\n",
      "epoch 41 | loss: 0.04297 | test_accuracy: 0.98331 | test_auc: 0.99823 |  0:02:02s\n",
      "epoch 42 | loss: 0.04265 | test_accuracy: 0.98244 | test_auc: 0.99826 |  0:02:05s\n",
      "epoch 43 | loss: 0.04427 | test_accuracy: 0.98244 | test_auc: 0.99783 |  0:02:08s\n",
      "epoch 44 | loss: 0.04446 | test_accuracy: 0.9814  | test_auc: 0.99806 |  0:02:11s\n",
      "epoch 45 | loss: 0.0447  | test_accuracy: 0.98018 | test_auc: 0.99798 |  0:02:14s\n",
      "epoch 46 | loss: 0.04339 | test_accuracy: 0.98244 | test_auc: 0.99827 |  0:02:17s\n",
      "epoch 47 | loss: 0.04232 | test_accuracy: 0.98349 | test_auc: 0.99807 |  0:02:20s\n",
      "epoch 48 | loss: 0.0425  | test_accuracy: 0.98349 | test_auc: 0.99826 |  0:02:23s\n",
      "epoch 49 | loss: 0.04209 | test_accuracy: 0.98349 | test_auc: 0.99827 |  0:02:26s\n",
      "epoch 50 | loss: 0.04146 | test_accuracy: 0.98349 | test_auc: 0.99825 |  0:02:29s\n",
      "epoch 51 | loss: 0.04151 | test_accuracy: 0.98349 | test_auc: 0.99831 |  0:02:32s\n",
      "epoch 52 | loss: 0.04204 | test_accuracy: 0.98436 | test_auc: 0.99825 |  0:02:35s\n",
      "epoch 53 | loss: 0.04297 | test_accuracy: 0.98244 | test_auc: 0.99827 |  0:02:37s\n",
      "epoch 54 | loss: 0.04246 | test_accuracy: 0.98244 | test_auc: 0.99802 |  0:02:40s\n",
      "epoch 55 | loss: 0.04137 | test_accuracy: 0.98331 | test_auc: 0.99826 |  0:02:43s\n",
      "epoch 56 | loss: 0.04176 | test_accuracy: 0.9814  | test_auc: 0.99821 |  0:02:46s\n",
      "epoch 57 | loss: 0.04124 | test_accuracy: 0.9814  | test_auc: 0.99824 |  0:02:49s\n",
      "epoch 58 | loss: 0.04145 | test_accuracy: 0.98331 | test_auc: 0.99826 |  0:02:52s\n",
      "epoch 59 | loss: 0.04135 | test_accuracy: 0.98349 | test_auc: 0.9983  |  0:02:55s\n",
      "epoch 60 | loss: 0.0419  | test_accuracy: 0.98244 | test_auc: 0.99823 |  0:02:57s\n",
      "epoch 61 | loss: 0.04133 | test_accuracy: 0.98244 | test_auc: 0.99832 |  0:03:00s\n",
      "epoch 62 | loss: 0.04133 | test_accuracy: 0.98244 | test_auc: 0.99825 |  0:03:03s\n",
      "epoch 63 | loss: 0.04129 | test_accuracy: 0.98227 | test_auc: 0.99823 |  0:03:06s\n",
      "epoch 64 | loss: 0.04145 | test_accuracy: 0.98227 | test_auc: 0.99817 |  0:03:09s\n",
      "epoch 65 | loss: 0.04155 | test_accuracy: 0.98244 | test_auc: 0.99827 |  0:03:12s\n",
      "epoch 66 | loss: 0.04189 | test_accuracy: 0.98244 | test_auc: 0.99827 |  0:03:14s\n",
      "epoch 67 | loss: 0.04116 | test_accuracy: 0.98244 | test_auc: 0.9983  |  0:03:17s\n",
      "epoch 68 | loss: 0.04094 | test_accuracy: 0.98244 | test_auc: 0.99831 |  0:03:20s\n",
      "epoch 69 | loss: 0.04144 | test_accuracy: 0.98244 | test_auc: 0.99829 |  0:03:23s\n",
      "epoch 70 | loss: 0.04145 | test_accuracy: 0.98244 | test_auc: 0.99824 |  0:03:26s\n",
      "epoch 71 | loss: 0.04184 | test_accuracy: 0.98244 | test_auc: 0.99827 |  0:03:29s\n",
      "epoch 72 | loss: 0.04168 | test_accuracy: 0.98244 | test_auc: 0.99825 |  0:03:32s\n",
      "epoch 73 | loss: 0.04144 | test_accuracy: 0.98244 | test_auc: 0.99825 |  0:03:35s\n",
      "epoch 74 | loss: 0.0411  | test_accuracy: 0.98244 | test_auc: 0.99828 |  0:03:38s\n",
      "epoch 75 | loss: 0.04082 | test_accuracy: 0.98244 | test_auc: 0.99827 |  0:03:41s\n",
      "epoch 76 | loss: 0.04116 | test_accuracy: 0.98244 | test_auc: 0.99825 |  0:03:44s\n",
      "epoch 77 | loss: 0.04108 | test_accuracy: 0.98244 | test_auc: 0.99828 |  0:03:47s\n",
      "epoch 78 | loss: 0.04105 | test_accuracy: 0.98349 | test_auc: 0.99828 |  0:03:49s\n",
      "epoch 79 | loss: 0.04183 | test_accuracy: 0.98244 | test_auc: 0.9983  |  0:03:52s\n",
      "epoch 80 | loss: 0.04086 | test_accuracy: 0.98244 | test_auc: 0.99828 |  0:03:55s\n",
      "epoch 81 | loss: 0.04082 | test_accuracy: 0.98244 | test_auc: 0.99829 |  0:03:58s\n",
      "\n",
      "Early stopping occurred at epoch 81 with best_epoch = 61 and best_test_auc = 0.99832\n",
      "Training fold 4/5...\n",
      "epoch 0  | loss: 0.2339  | test_accuracy: 0.93725 | test_auc: 0.97439 |  0:00:02s\n",
      "epoch 1  | loss: 0.08114 | test_accuracy: 0.92665 | test_auc: 0.9876  |  0:00:05s\n",
      "epoch 2  | loss: 0.06755 | test_accuracy: 0.93273 | test_auc: 0.99195 |  0:00:08s\n",
      "epoch 3  | loss: 0.06165 | test_accuracy: 0.94264 | test_auc: 0.99389 |  0:00:11s\n",
      "epoch 4  | loss: 0.06134 | test_accuracy: 0.96697 | test_auc: 0.99542 |  0:00:14s\n",
      "epoch 5  | loss: 0.05775 | test_accuracy: 0.96367 | test_auc: 0.99545 |  0:00:17s\n",
      "epoch 6  | loss: 0.05494 | test_accuracy: 0.97149 | test_auc: 0.99557 |  0:00:20s\n",
      "epoch 7  | loss: 0.05583 | test_accuracy: 0.97792 | test_auc: 0.99631 |  0:00:23s\n",
      "epoch 8  | loss: 0.05475 | test_accuracy: 0.97341 | test_auc: 0.99707 |  0:00:26s\n",
      "epoch 9  | loss: 0.05426 | test_accuracy: 0.9814  | test_auc: 0.99771 |  0:00:29s\n",
      "epoch 10 | loss: 0.05243 | test_accuracy: 0.97879 | test_auc: 0.99776 |  0:00:32s\n",
      "epoch 11 | loss: 0.05388 | test_accuracy: 0.97949 | test_auc: 0.99752 |  0:00:35s\n",
      "epoch 12 | loss: 0.05259 | test_accuracy: 0.98123 | test_auc: 0.99758 |  0:00:38s\n",
      "epoch 13 | loss: 0.0532  | test_accuracy: 0.98071 | test_auc: 0.99789 |  0:00:41s\n",
      "epoch 14 | loss: 0.05035 | test_accuracy: 0.97966 | test_auc: 0.99765 |  0:00:44s\n",
      "epoch 15 | loss: 0.05232 | test_accuracy: 0.9814  | test_auc: 0.99811 |  0:00:47s\n",
      "epoch 16 | loss: 0.0511  | test_accuracy: 0.98279 | test_auc: 0.99807 |  0:00:50s\n",
      "epoch 17 | loss: 0.04936 | test_accuracy: 0.97984 | test_auc: 0.99794 |  0:00:53s\n",
      "epoch 18 | loss: 0.05433 | test_accuracy: 0.97932 | test_auc: 0.99802 |  0:00:56s\n",
      "epoch 19 | loss: 0.05166 | test_accuracy: 0.9821  | test_auc: 0.99797 |  0:00:59s\n",
      "epoch 20 | loss: 0.05249 | test_accuracy: 0.98157 | test_auc: 0.99813 |  0:01:02s\n",
      "epoch 21 | loss: 0.05042 | test_accuracy: 0.98192 | test_auc: 0.99818 |  0:01:04s\n",
      "epoch 22 | loss: 0.05042 | test_accuracy: 0.9821  | test_auc: 0.99789 |  0:01:07s\n",
      "epoch 23 | loss: 0.05031 | test_accuracy: 0.98279 | test_auc: 0.99823 |  0:01:10s\n",
      "epoch 24 | loss: 0.05055 | test_accuracy: 0.97932 | test_auc: 0.99798 |  0:01:13s\n",
      "epoch 25 | loss: 0.04842 | test_accuracy: 0.98157 | test_auc: 0.99807 |  0:01:16s\n",
      "epoch 26 | loss: 0.04845 | test_accuracy: 0.98105 | test_auc: 0.99805 |  0:01:19s\n",
      "epoch 27 | loss: 0.0474  | test_accuracy: 0.98297 | test_auc: 0.99832 |  0:01:22s\n",
      "epoch 28 | loss: 0.04694 | test_accuracy: 0.98175 | test_auc: 0.9982  |  0:01:25s\n",
      "epoch 29 | loss: 0.04606 | test_accuracy: 0.98279 | test_auc: 0.99842 |  0:01:28s\n",
      "epoch 30 | loss: 0.04529 | test_accuracy: 0.98175 | test_auc: 0.99832 |  0:01:31s\n",
      "epoch 31 | loss: 0.04649 | test_accuracy: 0.98192 | test_auc: 0.99839 |  0:01:34s\n",
      "epoch 32 | loss: 0.04601 | test_accuracy: 0.98279 | test_auc: 0.99833 |  0:01:37s\n",
      "epoch 33 | loss: 0.04773 | test_accuracy: 0.98314 | test_auc: 0.99828 |  0:01:40s\n",
      "epoch 34 | loss: 0.04713 | test_accuracy: 0.98349 | test_auc: 0.99832 |  0:01:43s\n",
      "epoch 35 | loss: 0.04583 | test_accuracy: 0.98279 | test_auc: 0.99841 |  0:01:45s\n",
      "epoch 36 | loss: 0.04577 | test_accuracy: 0.98123 | test_auc: 0.99811 |  0:01:48s\n",
      "epoch 37 | loss: 0.04625 | test_accuracy: 0.98175 | test_auc: 0.99825 |  0:01:51s\n",
      "epoch 38 | loss: 0.04654 | test_accuracy: 0.98175 | test_auc: 0.99822 |  0:01:54s\n",
      "epoch 39 | loss: 0.04635 | test_accuracy: 0.9821  | test_auc: 0.99819 |  0:01:57s\n",
      "epoch 40 | loss: 0.0464  | test_accuracy: 0.98262 | test_auc: 0.99837 |  0:02:00s\n",
      "epoch 41 | loss: 0.04557 | test_accuracy: 0.98175 | test_auc: 0.99841 |  0:02:03s\n",
      "epoch 42 | loss: 0.04464 | test_accuracy: 0.98279 | test_auc: 0.99845 |  0:02:06s\n",
      "epoch 43 | loss: 0.04358 | test_accuracy: 0.98279 | test_auc: 0.99847 |  0:02:09s\n",
      "epoch 44 | loss: 0.04351 | test_accuracy: 0.98383 | test_auc: 0.99846 |  0:02:12s\n",
      "epoch 45 | loss: 0.04357 | test_accuracy: 0.98262 | test_auc: 0.99834 |  0:02:15s\n",
      "epoch 46 | loss: 0.04468 | test_accuracy: 0.98279 | test_auc: 0.99846 |  0:02:18s\n",
      "epoch 47 | loss: 0.04358 | test_accuracy: 0.98262 | test_auc: 0.99851 |  0:02:21s\n",
      "epoch 48 | loss: 0.04292 | test_accuracy: 0.98279 | test_auc: 0.99848 |  0:02:24s\n",
      "epoch 49 | loss: 0.04387 | test_accuracy: 0.98244 | test_auc: 0.99827 |  0:02:26s\n",
      "epoch 50 | loss: 0.04638 | test_accuracy: 0.98279 | test_auc: 0.99829 |  0:02:29s\n",
      "epoch 51 | loss: 0.04585 | test_accuracy: 0.98279 | test_auc: 0.99829 |  0:02:32s\n",
      "epoch 52 | loss: 0.05089 | test_accuracy: 0.98071 | test_auc: 0.99758 |  0:02:35s\n",
      "epoch 53 | loss: 0.05555 | test_accuracy: 0.98105 | test_auc: 0.99356 |  0:02:38s\n",
      "epoch 54 | loss: 0.05745 | test_accuracy: 0.9814  | test_auc: 0.99821 |  0:02:41s\n",
      "epoch 55 | loss: 0.05883 | test_accuracy: 0.9814  | test_auc: 0.99773 |  0:02:44s\n",
      "epoch 56 | loss: 0.05263 | test_accuracy: 0.98175 | test_auc: 0.99805 |  0:02:47s\n",
      "epoch 57 | loss: 0.04939 | test_accuracy: 0.98175 | test_auc: 0.99788 |  0:02:50s\n",
      "epoch 58 | loss: 0.04842 | test_accuracy: 0.98262 | test_auc: 0.99822 |  0:02:53s\n",
      "epoch 59 | loss: 0.04714 | test_accuracy: 0.98192 | test_auc: 0.99839 |  0:02:55s\n",
      "epoch 60 | loss: 0.04682 | test_accuracy: 0.98349 | test_auc: 0.99824 |  0:02:58s\n",
      "epoch 61 | loss: 0.04793 | test_accuracy: 0.98297 | test_auc: 0.99838 |  0:03:01s\n",
      "epoch 62 | loss: 0.04624 | test_accuracy: 0.98297 | test_auc: 0.99814 |  0:03:04s\n",
      "epoch 63 | loss: 0.04566 | test_accuracy: 0.98262 | test_auc: 0.99842 |  0:03:07s\n",
      "epoch 64 | loss: 0.04657 | test_accuracy: 0.98366 | test_auc: 0.99845 |  0:03:10s\n",
      "epoch 65 | loss: 0.04494 | test_accuracy: 0.98262 | test_auc: 0.99822 |  0:03:13s\n",
      "epoch 66 | loss: 0.0449  | test_accuracy: 0.98366 | test_auc: 0.99845 |  0:03:15s\n",
      "epoch 67 | loss: 0.04469 | test_accuracy: 0.98297 | test_auc: 0.99832 |  0:03:18s\n",
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 47 and best_test_auc = 0.99851\n",
      "Training fold 5/5...\n",
      "epoch 0  | loss: 0.22228 | test_accuracy: 0.66    | test_auc: 0.8906  |  0:00:02s\n",
      "epoch 1  | loss: 0.08406 | test_accuracy: 0.8041  | test_auc: 0.68572 |  0:00:05s\n",
      "epoch 2  | loss: 0.07154 | test_accuracy: 0.8785  | test_auc: 0.97223 |  0:00:08s\n",
      "epoch 3  | loss: 0.06828 | test_accuracy: 0.9157  | test_auc: 0.98133 |  0:00:11s\n",
      "epoch 4  | loss: 0.05722 | test_accuracy: 0.91761 | test_auc: 0.99173 |  0:00:14s\n",
      "epoch 5  | loss: 0.05557 | test_accuracy: 0.91622 | test_auc: 0.99522 |  0:00:17s\n",
      "epoch 6  | loss: 0.05287 | test_accuracy: 0.97236 | test_auc: 0.99567 |  0:00:20s\n",
      "epoch 7  | loss: 0.05344 | test_accuracy: 0.97219 | test_auc: 0.99674 |  0:00:23s\n",
      "epoch 8  | loss: 0.05383 | test_accuracy: 0.98175 | test_auc: 0.99743 |  0:00:26s\n",
      "epoch 9  | loss: 0.05083 | test_accuracy: 0.98157 | test_auc: 0.99787 |  0:00:29s\n",
      "epoch 10 | loss: 0.05151 | test_accuracy: 0.98383 | test_auc: 0.99795 |  0:00:32s\n",
      "epoch 11 | loss: 0.04876 | test_accuracy: 0.98279 | test_auc: 0.99835 |  0:00:35s\n",
      "epoch 12 | loss: 0.04951 | test_accuracy: 0.98262 | test_auc: 0.99803 |  0:00:38s\n",
      "epoch 13 | loss: 0.04953 | test_accuracy: 0.98227 | test_auc: 0.99851 |  0:00:41s\n",
      "epoch 14 | loss: 0.04844 | test_accuracy: 0.98401 | test_auc: 0.99865 |  0:00:44s\n",
      "epoch 15 | loss: 0.04945 | test_accuracy: 0.98262 | test_auc: 0.99826 |  0:00:46s\n",
      "epoch 16 | loss: 0.04829 | test_accuracy: 0.98279 | test_auc: 0.99844 |  0:00:49s\n",
      "epoch 17 | loss: 0.04826 | test_accuracy: 0.98279 | test_auc: 0.99857 |  0:00:52s\n",
      "epoch 18 | loss: 0.0466  | test_accuracy: 0.98314 | test_auc: 0.99843 |  0:00:55s\n",
      "epoch 19 | loss: 0.04612 | test_accuracy: 0.98436 | test_auc: 0.99847 |  0:00:58s\n",
      "epoch 20 | loss: 0.0472  | test_accuracy: 0.98279 | test_auc: 0.99852 |  0:01:01s\n",
      "epoch 21 | loss: 0.04575 | test_accuracy: 0.98418 | test_auc: 0.99854 |  0:01:04s\n",
      "epoch 22 | loss: 0.0452  | test_accuracy: 0.98279 | test_auc: 0.99891 |  0:01:07s\n",
      "epoch 23 | loss: 0.04578 | test_accuracy: 0.98436 | test_auc: 0.99891 |  0:01:10s\n",
      "epoch 24 | loss: 0.04569 | test_accuracy: 0.98418 | test_auc: 0.99885 |  0:01:13s\n",
      "epoch 25 | loss: 0.04537 | test_accuracy: 0.98297 | test_auc: 0.99885 |  0:01:15s\n",
      "epoch 26 | loss: 0.04542 | test_accuracy: 0.98418 | test_auc: 0.99877 |  0:01:18s\n",
      "epoch 27 | loss: 0.04468 | test_accuracy: 0.98436 | test_auc: 0.99885 |  0:01:21s\n",
      "epoch 28 | loss: 0.04491 | test_accuracy: 0.98436 | test_auc: 0.99893 |  0:01:24s\n",
      "epoch 29 | loss: 0.04466 | test_accuracy: 0.98401 | test_auc: 0.99894 |  0:01:27s\n",
      "epoch 30 | loss: 0.04502 | test_accuracy: 0.98123 | test_auc: 0.99883 |  0:01:30s\n",
      "epoch 31 | loss: 0.04514 | test_accuracy: 0.98436 | test_auc: 0.99891 |  0:01:33s\n",
      "epoch 32 | loss: 0.04465 | test_accuracy: 0.98418 | test_auc: 0.99894 |  0:01:36s\n",
      "epoch 33 | loss: 0.04584 | test_accuracy: 0.98279 | test_auc: 0.99891 |  0:01:39s\n",
      "epoch 34 | loss: 0.04482 | test_accuracy: 0.98401 | test_auc: 0.99866 |  0:01:42s\n",
      "epoch 35 | loss: 0.044   | test_accuracy: 0.98436 | test_auc: 0.99887 |  0:01:45s\n",
      "epoch 36 | loss: 0.04399 | test_accuracy: 0.98279 | test_auc: 0.99897 |  0:01:47s\n",
      "epoch 37 | loss: 0.04391 | test_accuracy: 0.98436 | test_auc: 0.99896 |  0:01:50s\n",
      "epoch 38 | loss: 0.04351 | test_accuracy: 0.98436 | test_auc: 0.99896 |  0:01:53s\n",
      "epoch 39 | loss: 0.04393 | test_accuracy: 0.98401 | test_auc: 0.99864 |  0:01:56s\n",
      "epoch 40 | loss: 0.04382 | test_accuracy: 0.98401 | test_auc: 0.99894 |  0:01:59s\n",
      "epoch 41 | loss: 0.0446  | test_accuracy: 0.98401 | test_auc: 0.99889 |  0:02:02s\n",
      "epoch 42 | loss: 0.04455 | test_accuracy: 0.98436 | test_auc: 0.99891 |  0:02:05s\n",
      "epoch 43 | loss: 0.04416 | test_accuracy: 0.98436 | test_auc: 0.99892 |  0:02:08s\n",
      "epoch 44 | loss: 0.0442  | test_accuracy: 0.98436 | test_auc: 0.99896 |  0:02:11s\n",
      "epoch 45 | loss: 0.04398 | test_accuracy: 0.98436 | test_auc: 0.99897 |  0:02:14s\n",
      "epoch 46 | loss: 0.0443  | test_accuracy: 0.98436 | test_auc: 0.99891 |  0:02:17s\n",
      "epoch 47 | loss: 0.04385 | test_accuracy: 0.98436 | test_auc: 0.99887 |  0:02:20s\n",
      "epoch 48 | loss: 0.04413 | test_accuracy: 0.98401 | test_auc: 0.99893 |  0:02:23s\n",
      "epoch 49 | loss: 0.04476 | test_accuracy: 0.98436 | test_auc: 0.99894 |  0:02:26s\n",
      "epoch 50 | loss: 0.0445  | test_accuracy: 0.98436 | test_auc: 0.99896 |  0:02:29s\n",
      "epoch 51 | loss: 0.04455 | test_accuracy: 0.98436 | test_auc: 0.99897 |  0:02:32s\n",
      "epoch 52 | loss: 0.04464 | test_accuracy: 0.98436 | test_auc: 0.99893 |  0:02:35s\n",
      "epoch 53 | loss: 0.04448 | test_accuracy: 0.98279 | test_auc: 0.99895 |  0:02:37s\n",
      "epoch 54 | loss: 0.04415 | test_accuracy: 0.98436 | test_auc: 0.99896 |  0:02:40s\n",
      "epoch 55 | loss: 0.04368 | test_accuracy: 0.98436 | test_auc: 0.99895 |  0:02:43s\n",
      "epoch 56 | loss: 0.04394 | test_accuracy: 0.98436 | test_auc: 0.99894 |  0:02:46s\n",
      "epoch 57 | loss: 0.04406 | test_accuracy: 0.98436 | test_auc: 0.99892 |  0:02:49s\n",
      "epoch 58 | loss: 0.04415 | test_accuracy: 0.98436 | test_auc: 0.99895 |  0:02:52s\n",
      "epoch 59 | loss: 0.04435 | test_accuracy: 0.98436 | test_auc: 0.99893 |  0:02:55s\n",
      "epoch 60 | loss: 0.04413 | test_accuracy: 0.98436 | test_auc: 0.99897 |  0:02:58s\n",
      "epoch 61 | loss: 0.04363 | test_accuracy: 0.98262 | test_auc: 0.99892 |  0:03:01s\n",
      "epoch 62 | loss: 0.04432 | test_accuracy: 0.98436 | test_auc: 0.99894 |  0:03:04s\n",
      "epoch 63 | loss: 0.04664 | test_accuracy: 0.98436 | test_auc: 0.99887 |  0:03:07s\n",
      "epoch 64 | loss: 0.04471 | test_accuracy: 0.98418 | test_auc: 0.99856 |  0:03:09s\n",
      "epoch 65 | loss: 0.04474 | test_accuracy: 0.98418 | test_auc: 0.99889 |  0:03:12s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_test_auc = 0.99897\n",
      "\n",
      "Results for 4. Lasso:\n",
      "Average accuracy: 0.9829 ± 0.0008\n",
      "Average precision: 0.9834 ± 0.0041\n",
      "Average recall: 0.9683 ± 0.0049\n",
      "Average f1: 0.9758 ± 0.0011\n",
      "Average auc: 0.9796 ± 0.0015\n",
      "\n",
      "==================================================\n",
      "Processing 5. Random Forest Importance\n",
      "==================================================\n",
      "Selecting features using 5. Random Forest Importance...\n",
      "Top 10 features selected by 5. Random Forest Importance:\n",
      "1. Breathing Problem: 0.1560\n",
      "2. Sore throat: 0.2333\n",
      "3. Abroad travel: 0.1637\n",
      "4. Contact with COVID Patient: 0.0630\n",
      "5. Attended Large Gathering: 0.1179\n",
      "6. Family working in Public Exposed Places: 0.0940\n",
      "7. Fever: 0.0000\n",
      "8. Dry Cough: 0.0000\n",
      "9. Running Nose: 0.0000\n",
      "10. Asthma: 0.0000\n",
      "\n",
      "Training TabNet with features selected by 5. Random Forest Importance\n",
      "Training fold 1/5...\n",
      "epoch 0  | loss: 0.21439 | test_accuracy: 0.9131  | test_auc: 0.97981 |  0:00:02s\n",
      "epoch 1  | loss: 0.07887 | test_accuracy: 0.85662 | test_auc: 0.97214 |  0:00:05s\n",
      "epoch 2  | loss: 0.06272 | test_accuracy: 0.94526 | test_auc: 0.98813 |  0:00:08s\n",
      "epoch 3  | loss: 0.05851 | test_accuracy: 0.96767 | test_auc: 0.99371 |  0:00:11s\n",
      "epoch 4  | loss: 0.05477 | test_accuracy: 0.95933 | test_auc: 0.9933  |  0:00:14s\n",
      "epoch 5  | loss: 0.05364 | test_accuracy: 0.96767 | test_auc: 0.99488 |  0:00:17s\n",
      "epoch 6  | loss: 0.05179 | test_accuracy: 0.97167 | test_auc: 0.99639 |  0:00:20s\n",
      "epoch 7  | loss: 0.05259 | test_accuracy: 0.96767 | test_auc: 0.99728 |  0:00:22s\n",
      "epoch 8  | loss: 0.05064 | test_accuracy: 0.97445 | test_auc: 0.99797 |  0:00:25s\n",
      "epoch 9  | loss: 0.0483  | test_accuracy: 0.97358 | test_auc: 0.99765 |  0:00:28s\n",
      "epoch 10 | loss: 0.04699 | test_accuracy: 0.9814  | test_auc: 0.99814 |  0:00:31s\n",
      "epoch 11 | loss: 0.04486 | test_accuracy: 0.9821  | test_auc: 0.99844 |  0:00:34s\n",
      "epoch 12 | loss: 0.04448 | test_accuracy: 0.9821  | test_auc: 0.99845 |  0:00:37s\n",
      "epoch 13 | loss: 0.0437  | test_accuracy: 0.98175 | test_auc: 0.99845 |  0:00:40s\n",
      "epoch 14 | loss: 0.04359 | test_accuracy: 0.98175 | test_auc: 0.99832 |  0:00:43s\n",
      "epoch 15 | loss: 0.0449  | test_accuracy: 0.98175 | test_auc: 0.99843 |  0:00:46s\n",
      "epoch 16 | loss: 0.04351 | test_accuracy: 0.9821  | test_auc: 0.99826 |  0:00:49s\n",
      "epoch 17 | loss: 0.04243 | test_accuracy: 0.98106 | test_auc: 0.99833 |  0:00:52s\n",
      "epoch 18 | loss: 0.04293 | test_accuracy: 0.9821  | test_auc: 0.99842 |  0:00:55s\n",
      "epoch 19 | loss: 0.0424  | test_accuracy: 0.98175 | test_auc: 0.9984  |  0:00:58s\n",
      "epoch 20 | loss: 0.04338 | test_accuracy: 0.9821  | test_auc: 0.99829 |  0:01:00s\n",
      "epoch 21 | loss: 0.04416 | test_accuracy: 0.9821  | test_auc: 0.9981  |  0:01:03s\n",
      "epoch 22 | loss: 0.04314 | test_accuracy: 0.9821  | test_auc: 0.99832 |  0:01:06s\n",
      "epoch 23 | loss: 0.04589 | test_accuracy: 0.98088 | test_auc: 0.99793 |  0:01:09s\n",
      "epoch 24 | loss: 0.04692 | test_accuracy: 0.97862 | test_auc: 0.99827 |  0:01:12s\n",
      "epoch 25 | loss: 0.0436  | test_accuracy: 0.9821  | test_auc: 0.99821 |  0:01:15s\n",
      "epoch 26 | loss: 0.04275 | test_accuracy: 0.98193 | test_auc: 0.99835 |  0:01:18s\n",
      "epoch 27 | loss: 0.043   | test_accuracy: 0.9821  | test_auc: 0.9984  |  0:01:21s\n",
      "epoch 28 | loss: 0.04277 | test_accuracy: 0.9821  | test_auc: 0.99847 |  0:01:24s\n",
      "epoch 29 | loss: 0.04319 | test_accuracy: 0.9821  | test_auc: 0.99832 |  0:01:27s\n",
      "epoch 30 | loss: 0.04253 | test_accuracy: 0.9821  | test_auc: 0.99821 |  0:01:30s\n",
      "epoch 31 | loss: 0.04229 | test_accuracy: 0.9821  | test_auc: 0.99834 |  0:01:33s\n",
      "epoch 32 | loss: 0.04133 | test_accuracy: 0.9821  | test_auc: 0.99838 |  0:01:36s\n",
      "epoch 33 | loss: 0.04102 | test_accuracy: 0.9821  | test_auc: 0.99843 |  0:01:38s\n",
      "epoch 34 | loss: 0.04147 | test_accuracy: 0.9821  | test_auc: 0.99837 |  0:01:41s\n",
      "epoch 35 | loss: 0.04181 | test_accuracy: 0.9821  | test_auc: 0.99823 |  0:01:44s\n",
      "epoch 36 | loss: 0.04088 | test_accuracy: 0.9821  | test_auc: 0.99833 |  0:01:47s\n",
      "epoch 37 | loss: 0.04153 | test_accuracy: 0.9821  | test_auc: 0.99837 |  0:01:50s\n",
      "epoch 38 | loss: 0.04216 | test_accuracy: 0.9821  | test_auc: 0.99849 |  0:01:53s\n",
      "epoch 39 | loss: 0.04231 | test_accuracy: 0.9821  | test_auc: 0.99832 |  0:01:56s\n",
      "epoch 40 | loss: 0.04076 | test_accuracy: 0.9821  | test_auc: 0.99837 |  0:01:59s\n",
      "epoch 41 | loss: 0.04075 | test_accuracy: 0.9821  | test_auc: 0.99841 |  0:02:02s\n",
      "epoch 42 | loss: 0.04328 | test_accuracy: 0.98175 | test_auc: 0.99851 |  0:02:05s\n",
      "epoch 43 | loss: 0.04292 | test_accuracy: 0.9821  | test_auc: 0.99853 |  0:02:08s\n",
      "epoch 44 | loss: 0.04246 | test_accuracy: 0.98106 | test_auc: 0.99853 |  0:02:11s\n",
      "epoch 45 | loss: 0.04364 | test_accuracy: 0.98088 | test_auc: 0.99823 |  0:02:14s\n",
      "epoch 46 | loss: 0.04427 | test_accuracy: 0.98158 | test_auc: 0.99829 |  0:02:17s\n",
      "epoch 47 | loss: 0.04234 | test_accuracy: 0.98193 | test_auc: 0.99829 |  0:02:19s\n",
      "epoch 48 | loss: 0.04223 | test_accuracy: 0.98193 | test_auc: 0.99843 |  0:02:22s\n",
      "epoch 49 | loss: 0.04128 | test_accuracy: 0.98158 | test_auc: 0.99848 |  0:02:25s\n",
      "epoch 50 | loss: 0.04255 | test_accuracy: 0.97949 | test_auc: 0.99821 |  0:02:28s\n",
      "epoch 51 | loss: 0.04323 | test_accuracy: 0.98158 | test_auc: 0.99827 |  0:02:31s\n",
      "epoch 52 | loss: 0.04246 | test_accuracy: 0.98158 | test_auc: 0.99843 |  0:02:34s\n",
      "epoch 53 | loss: 0.0417  | test_accuracy: 0.98175 | test_auc: 0.99849 |  0:02:37s\n",
      "epoch 54 | loss: 0.04309 | test_accuracy: 0.98193 | test_auc: 0.9984  |  0:02:40s\n",
      "epoch 55 | loss: 0.04121 | test_accuracy: 0.9821  | test_auc: 0.99816 |  0:02:43s\n",
      "epoch 56 | loss: 0.04245 | test_accuracy: 0.9821  | test_auc: 0.99836 |  0:02:46s\n",
      "epoch 57 | loss: 0.04127 | test_accuracy: 0.9821  | test_auc: 0.99834 |  0:02:49s\n",
      "epoch 58 | loss: 0.04271 | test_accuracy: 0.98158 | test_auc: 0.9984  |  0:02:52s\n",
      "epoch 59 | loss: 0.04152 | test_accuracy: 0.98193 | test_auc: 0.9985  |  0:02:55s\n",
      "epoch 60 | loss: 0.04173 | test_accuracy: 0.98193 | test_auc: 0.99839 |  0:02:58s\n",
      "epoch 61 | loss: 0.04241 | test_accuracy: 0.98193 | test_auc: 0.99838 |  0:03:01s\n",
      "epoch 62 | loss: 0.04208 | test_accuracy: 0.98193 | test_auc: 0.99841 |  0:03:04s\n",
      "epoch 63 | loss: 0.04273 | test_accuracy: 0.9814  | test_auc: 0.99835 |  0:03:06s\n",
      "epoch 64 | loss: 0.04146 | test_accuracy: 0.98193 | test_auc: 0.99834 |  0:03:09s\n",
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 44 and best_test_auc = 0.99853\n",
      "Training fold 2/5...\n",
      "epoch 0  | loss: 0.19449 | test_accuracy: 0.89797 | test_auc: 0.97546 |  0:00:02s\n",
      "epoch 1  | loss: 0.08067 | test_accuracy: 0.91483 | test_auc: 0.98482 |  0:00:05s\n",
      "epoch 2  | loss: 0.07213 | test_accuracy: 0.92213 | test_auc: 0.98753 |  0:00:08s\n",
      "epoch 3  | loss: 0.06265 | test_accuracy: 0.96558 | test_auc: 0.99178 |  0:00:11s\n",
      "epoch 4  | loss: 0.05655 | test_accuracy: 0.96941 | test_auc: 0.99606 |  0:00:14s\n",
      "epoch 5  | loss: 0.05261 | test_accuracy: 0.97115 | test_auc: 0.99679 |  0:00:17s\n",
      "epoch 6  | loss: 0.04994 | test_accuracy: 0.97149 | test_auc: 0.99389 |  0:00:20s\n",
      "epoch 7  | loss: 0.04947 | test_accuracy: 0.97149 | test_auc: 0.99659 |  0:00:23s\n",
      "epoch 8  | loss: 0.04816 | test_accuracy: 0.9814  | test_auc: 0.99809 |  0:00:26s\n",
      "epoch 9  | loss: 0.0467  | test_accuracy: 0.98279 | test_auc: 0.9981  |  0:00:29s\n",
      "epoch 10 | loss: 0.04572 | test_accuracy: 0.97236 | test_auc: 0.99697 |  0:00:32s\n",
      "epoch 11 | loss: 0.04752 | test_accuracy: 0.98314 | test_auc: 0.99821 |  0:00:35s\n",
      "epoch 12 | loss: 0.04838 | test_accuracy: 0.98418 | test_auc: 0.99826 |  0:00:38s\n",
      "epoch 13 | loss: 0.04639 | test_accuracy: 0.98418 | test_auc: 0.99828 |  0:00:40s\n",
      "epoch 14 | loss: 0.04497 | test_accuracy: 0.98418 | test_auc: 0.99813 |  0:00:43s\n",
      "epoch 15 | loss: 0.04705 | test_accuracy: 0.9847  | test_auc: 0.99826 |  0:00:46s\n",
      "epoch 16 | loss: 0.04479 | test_accuracy: 0.98401 | test_auc: 0.99801 |  0:00:49s\n",
      "epoch 17 | loss: 0.04489 | test_accuracy: 0.9847  | test_auc: 0.99835 |  0:00:52s\n",
      "epoch 18 | loss: 0.04572 | test_accuracy: 0.98366 | test_auc: 0.99831 |  0:00:55s\n",
      "epoch 19 | loss: 0.04619 | test_accuracy: 0.98418 | test_auc: 0.9984  |  0:00:58s\n",
      "epoch 20 | loss: 0.04629 | test_accuracy: 0.98279 | test_auc: 0.99838 |  0:01:01s\n",
      "epoch 21 | loss: 0.0462  | test_accuracy: 0.98297 | test_auc: 0.99826 |  0:01:03s\n",
      "epoch 22 | loss: 0.04656 | test_accuracy: 0.98314 | test_auc: 0.99819 |  0:01:06s\n",
      "epoch 23 | loss: 0.04655 | test_accuracy: 0.98297 | test_auc: 0.99846 |  0:01:09s\n",
      "epoch 24 | loss: 0.04673 | test_accuracy: 0.98262 | test_auc: 0.9981  |  0:01:12s\n",
      "epoch 25 | loss: 0.04703 | test_accuracy: 0.98192 | test_auc: 0.99821 |  0:01:15s\n",
      "epoch 26 | loss: 0.05065 | test_accuracy: 0.98366 | test_auc: 0.99835 |  0:01:18s\n",
      "epoch 27 | loss: 0.04666 | test_accuracy: 0.98366 | test_auc: 0.99817 |  0:01:21s\n",
      "epoch 28 | loss: 0.04793 | test_accuracy: 0.98418 | test_auc: 0.99823 |  0:01:23s\n",
      "epoch 29 | loss: 0.04652 | test_accuracy: 0.98244 | test_auc: 0.99838 |  0:01:26s\n",
      "epoch 30 | loss: 0.04562 | test_accuracy: 0.98314 | test_auc: 0.9972  |  0:01:29s\n",
      "epoch 31 | loss: 0.04628 | test_accuracy: 0.98418 | test_auc: 0.99821 |  0:01:32s\n",
      "epoch 32 | loss: 0.04496 | test_accuracy: 0.9847  | test_auc: 0.99845 |  0:01:35s\n",
      "epoch 33 | loss: 0.04567 | test_accuracy: 0.98314 | test_auc: 0.99824 |  0:01:38s\n",
      "epoch 34 | loss: 0.04475 | test_accuracy: 0.98418 | test_auc: 0.99828 |  0:01:41s\n",
      "epoch 35 | loss: 0.04451 | test_accuracy: 0.98349 | test_auc: 0.99837 |  0:01:43s\n",
      "epoch 36 | loss: 0.04451 | test_accuracy: 0.9847  | test_auc: 0.99835 |  0:01:46s\n",
      "epoch 37 | loss: 0.04414 | test_accuracy: 0.98088 | test_auc: 0.99836 |  0:01:49s\n",
      "epoch 38 | loss: 0.04425 | test_accuracy: 0.98349 | test_auc: 0.99841 |  0:01:52s\n",
      "epoch 39 | loss: 0.04319 | test_accuracy: 0.9847  | test_auc: 0.99851 |  0:01:55s\n",
      "epoch 40 | loss: 0.04267 | test_accuracy: 0.9847  | test_auc: 0.99845 |  0:01:58s\n",
      "epoch 41 | loss: 0.04351 | test_accuracy: 0.98314 | test_auc: 0.99772 |  0:02:01s\n",
      "epoch 42 | loss: 0.0437  | test_accuracy: 0.98366 | test_auc: 0.99851 |  0:02:04s\n",
      "epoch 43 | loss: 0.04315 | test_accuracy: 0.9847  | test_auc: 0.99846 |  0:02:07s\n",
      "epoch 44 | loss: 0.04336 | test_accuracy: 0.9847  | test_auc: 0.99853 |  0:02:10s\n",
      "epoch 45 | loss: 0.04232 | test_accuracy: 0.98366 | test_auc: 0.99852 |  0:02:13s\n",
      "epoch 46 | loss: 0.0428  | test_accuracy: 0.98366 | test_auc: 0.99855 |  0:02:16s\n",
      "epoch 47 | loss: 0.0424  | test_accuracy: 0.9847  | test_auc: 0.99848 |  0:02:18s\n",
      "epoch 48 | loss: 0.04268 | test_accuracy: 0.98366 | test_auc: 0.99846 |  0:02:21s\n",
      "epoch 49 | loss: 0.04217 | test_accuracy: 0.9847  | test_auc: 0.99852 |  0:02:24s\n",
      "epoch 50 | loss: 0.04241 | test_accuracy: 0.9847  | test_auc: 0.99845 |  0:02:27s\n",
      "epoch 51 | loss: 0.04235 | test_accuracy: 0.9847  | test_auc: 0.99849 |  0:02:34s\n",
      "epoch 52 | loss: 0.04206 | test_accuracy: 0.98366 | test_auc: 0.99847 |  0:02:37s\n",
      "epoch 53 | loss: 0.04239 | test_accuracy: 0.9847  | test_auc: 0.99857 |  0:02:40s\n",
      "epoch 54 | loss: 0.04154 | test_accuracy: 0.9847  | test_auc: 0.99847 |  0:02:43s\n",
      "epoch 55 | loss: 0.04231 | test_accuracy: 0.98314 | test_auc: 0.99855 |  0:02:46s\n",
      "epoch 56 | loss: 0.04378 | test_accuracy: 0.9847  | test_auc: 0.9985  |  0:02:49s\n",
      "epoch 57 | loss: 0.04248 | test_accuracy: 0.9847  | test_auc: 0.99856 |  0:02:52s\n",
      "epoch 58 | loss: 0.05193 | test_accuracy: 0.98227 | test_auc: 0.99795 |  0:02:55s\n",
      "epoch 59 | loss: 0.05016 | test_accuracy: 0.98088 | test_auc: 0.99769 |  0:02:58s\n",
      "epoch 60 | loss: 0.05351 | test_accuracy: 0.97497 | test_auc: 0.99704 |  0:03:01s\n",
      "epoch 61 | loss: 0.05337 | test_accuracy: 0.98175 | test_auc: 0.99799 |  0:03:04s\n",
      "epoch 62 | loss: 0.05042 | test_accuracy: 0.98279 | test_auc: 0.99815 |  0:03:06s\n",
      "epoch 63 | loss: 0.04794 | test_accuracy: 0.98314 | test_auc: 0.99838 |  0:03:09s\n",
      "epoch 64 | loss: 0.04691 | test_accuracy: 0.98418 | test_auc: 0.99852 |  0:03:12s\n",
      "epoch 65 | loss: 0.0457  | test_accuracy: 0.98453 | test_auc: 0.99848 |  0:03:15s\n",
      "epoch 66 | loss: 0.04613 | test_accuracy: 0.98436 | test_auc: 0.99822 |  0:03:18s\n",
      "epoch 67 | loss: 0.04415 | test_accuracy: 0.98331 | test_auc: 0.99842 |  0:03:21s\n",
      "epoch 68 | loss: 0.04369 | test_accuracy: 0.98331 | test_auc: 0.9985  |  0:03:24s\n",
      "epoch 69 | loss: 0.0433  | test_accuracy: 0.9847  | test_auc: 0.99854 |  0:03:27s\n",
      "epoch 70 | loss: 0.04295 | test_accuracy: 0.98366 | test_auc: 0.99841 |  0:03:30s\n",
      "epoch 71 | loss: 0.04199 | test_accuracy: 0.98366 | test_auc: 0.99821 |  0:03:33s\n",
      "epoch 72 | loss: 0.04284 | test_accuracy: 0.9847  | test_auc: 0.99855 |  0:03:36s\n",
      "epoch 73 | loss: 0.04346 | test_accuracy: 0.9847  | test_auc: 0.99828 |  0:03:39s\n",
      "\n",
      "Early stopping occurred at epoch 73 with best_epoch = 53 and best_test_auc = 0.99857\n",
      "Training fold 3/5...\n",
      "epoch 0  | loss: 0.18214 | test_accuracy: 0.82513 | test_auc: 0.9261  |  0:00:02s\n",
      "epoch 1  | loss: 0.07368 | test_accuracy: 0.81592 | test_auc: 0.6602  |  0:00:05s\n",
      "epoch 2  | loss: 0.06204 | test_accuracy: 0.838   | test_auc: 0.7962  |  0:00:08s\n",
      "epoch 3  | loss: 0.05701 | test_accuracy: 0.88684 | test_auc: 0.93389 |  0:00:11s\n",
      "epoch 4  | loss: 0.05065 | test_accuracy: 0.90475 | test_auc: 0.95485 |  0:00:14s\n",
      "epoch 5  | loss: 0.0508  | test_accuracy: 0.91222 | test_auc: 0.96522 |  0:00:17s\n",
      "epoch 6  | loss: 0.04835 | test_accuracy: 0.91865 | test_auc: 0.98592 |  0:00:20s\n",
      "epoch 7  | loss: 0.04628 | test_accuracy: 0.92491 | test_auc: 0.98689 |  0:00:23s\n",
      "epoch 8  | loss: 0.04616 | test_accuracy: 0.92543 | test_auc: 0.98933 |  0:00:26s\n",
      "epoch 9  | loss: 0.04548 | test_accuracy: 0.93343 | test_auc: 0.99314 |  0:00:28s\n",
      "epoch 10 | loss: 0.0445  | test_accuracy: 0.97688 | test_auc: 0.99495 |  0:00:31s\n",
      "epoch 11 | loss: 0.0442  | test_accuracy: 0.98349 | test_auc: 0.99733 |  0:00:34s\n",
      "epoch 12 | loss: 0.04375 | test_accuracy: 0.98279 | test_auc: 0.99664 |  0:00:37s\n",
      "epoch 13 | loss: 0.04354 | test_accuracy: 0.98279 | test_auc: 0.99755 |  0:00:40s\n",
      "epoch 14 | loss: 0.04293 | test_accuracy: 0.97914 | test_auc: 0.99767 |  0:00:43s\n",
      "epoch 15 | loss: 0.04116 | test_accuracy: 0.98401 | test_auc: 0.99778 |  0:00:46s\n",
      "epoch 16 | loss: 0.04254 | test_accuracy: 0.98244 | test_auc: 0.99765 |  0:00:49s\n",
      "epoch 17 | loss: 0.04176 | test_accuracy: 0.98349 | test_auc: 0.99741 |  0:00:52s\n",
      "epoch 18 | loss: 0.04153 | test_accuracy: 0.98401 | test_auc: 0.99788 |  0:00:54s\n",
      "epoch 19 | loss: 0.043   | test_accuracy: 0.98401 | test_auc: 0.99773 |  0:00:57s\n",
      "epoch 20 | loss: 0.04302 | test_accuracy: 0.98401 | test_auc: 0.99781 |  0:01:00s\n",
      "epoch 21 | loss: 0.04184 | test_accuracy: 0.98401 | test_auc: 0.99783 |  0:01:03s\n",
      "epoch 22 | loss: 0.04194 | test_accuracy: 0.98401 | test_auc: 0.99792 |  0:01:06s\n",
      "epoch 23 | loss: 0.04165 | test_accuracy: 0.98401 | test_auc: 0.99795 |  0:01:09s\n",
      "epoch 24 | loss: 0.04091 | test_accuracy: 0.98331 | test_auc: 0.99777 |  0:01:12s\n",
      "epoch 25 | loss: 0.04164 | test_accuracy: 0.98297 | test_auc: 0.99795 |  0:01:15s\n",
      "epoch 26 | loss: 0.04113 | test_accuracy: 0.98401 | test_auc: 0.99793 |  0:01:18s\n",
      "epoch 27 | loss: 0.0436  | test_accuracy: 0.98401 | test_auc: 0.99778 |  0:01:21s\n",
      "epoch 28 | loss: 0.04214 | test_accuracy: 0.98279 | test_auc: 0.99772 |  0:01:24s\n",
      "epoch 29 | loss: 0.04161 | test_accuracy: 0.98349 | test_auc: 0.99779 |  0:01:27s\n",
      "epoch 30 | loss: 0.04242 | test_accuracy: 0.98349 | test_auc: 0.99779 |  0:01:29s\n",
      "epoch 31 | loss: 0.04205 | test_accuracy: 0.98401 | test_auc: 0.99789 |  0:01:32s\n",
      "epoch 32 | loss: 0.0432  | test_accuracy: 0.98366 | test_auc: 0.99788 |  0:01:35s\n",
      "epoch 33 | loss: 0.04133 | test_accuracy: 0.98401 | test_auc: 0.99784 |  0:01:38s\n",
      "epoch 34 | loss: 0.04089 | test_accuracy: 0.98401 | test_auc: 0.99789 |  0:01:41s\n",
      "epoch 35 | loss: 0.04111 | test_accuracy: 0.98401 | test_auc: 0.99795 |  0:01:44s\n",
      "epoch 36 | loss: 0.04025 | test_accuracy: 0.98401 | test_auc: 0.99791 |  0:01:47s\n",
      "epoch 37 | loss: 0.04064 | test_accuracy: 0.98401 | test_auc: 0.99795 |  0:01:50s\n",
      "epoch 38 | loss: 0.04081 | test_accuracy: 0.98401 | test_auc: 0.99791 |  0:01:52s\n",
      "epoch 39 | loss: 0.04079 | test_accuracy: 0.98401 | test_auc: 0.99796 |  0:01:55s\n",
      "epoch 40 | loss: 0.04124 | test_accuracy: 0.98349 | test_auc: 0.99792 |  0:01:58s\n",
      "epoch 41 | loss: 0.04089 | test_accuracy: 0.98349 | test_auc: 0.9979  |  0:02:01s\n",
      "epoch 42 | loss: 0.04125 | test_accuracy: 0.98314 | test_auc: 0.99766 |  0:02:04s\n",
      "epoch 43 | loss: 0.04081 | test_accuracy: 0.98401 | test_auc: 0.99794 |  0:02:07s\n",
      "epoch 44 | loss: 0.04129 | test_accuracy: 0.98366 | test_auc: 0.99798 |  0:02:10s\n",
      "epoch 45 | loss: 0.04496 | test_accuracy: 0.98088 | test_auc: 0.99763 |  0:02:13s\n",
      "epoch 46 | loss: 0.04444 | test_accuracy: 0.98349 | test_auc: 0.99797 |  0:02:16s\n",
      "epoch 47 | loss: 0.04212 | test_accuracy: 0.98349 | test_auc: 0.99789 |  0:02:19s\n",
      "epoch 48 | loss: 0.04279 | test_accuracy: 0.98401 | test_auc: 0.99787 |  0:02:22s\n",
      "epoch 49 | loss: 0.04136 | test_accuracy: 0.98401 | test_auc: 0.99796 |  0:02:25s\n",
      "epoch 50 | loss: 0.04095 | test_accuracy: 0.98401 | test_auc: 0.99792 |  0:02:28s\n",
      "epoch 51 | loss: 0.04018 | test_accuracy: 0.98401 | test_auc: 0.99792 |  0:02:30s\n",
      "epoch 52 | loss: 0.04043 | test_accuracy: 0.98401 | test_auc: 0.99797 |  0:02:33s\n",
      "epoch 53 | loss: 0.04028 | test_accuracy: 0.98349 | test_auc: 0.99794 |  0:02:36s\n",
      "epoch 54 | loss: 0.04004 | test_accuracy: 0.98401 | test_auc: 0.99793 |  0:02:39s\n",
      "epoch 55 | loss: 0.04061 | test_accuracy: 0.98401 | test_auc: 0.99798 |  0:02:42s\n",
      "epoch 56 | loss: 0.0404  | test_accuracy: 0.98401 | test_auc: 0.99799 |  0:02:45s\n",
      "epoch 57 | loss: 0.03978 | test_accuracy: 0.98401 | test_auc: 0.99803 |  0:02:48s\n",
      "epoch 58 | loss: 0.0409  | test_accuracy: 0.98349 | test_auc: 0.99794 |  0:02:51s\n",
      "epoch 59 | loss: 0.04337 | test_accuracy: 0.98401 | test_auc: 0.99783 |  0:02:54s\n",
      "epoch 60 | loss: 0.04138 | test_accuracy: 0.98401 | test_auc: 0.99793 |  0:02:57s\n",
      "epoch 61 | loss: 0.04293 | test_accuracy: 0.98401 | test_auc: 0.998   |  0:03:00s\n",
      "epoch 62 | loss: 0.04066 | test_accuracy: 0.98349 | test_auc: 0.99801 |  0:03:03s\n",
      "epoch 63 | loss: 0.04049 | test_accuracy: 0.98401 | test_auc: 0.99796 |  0:03:06s\n",
      "epoch 64 | loss: 0.04004 | test_accuracy: 0.98401 | test_auc: 0.99792 |  0:03:09s\n",
      "epoch 65 | loss: 0.04077 | test_accuracy: 0.98401 | test_auc: 0.99802 |  0:03:12s\n",
      "epoch 66 | loss: 0.04032 | test_accuracy: 0.98401 | test_auc: 0.99797 |  0:03:15s\n",
      "epoch 67 | loss: 0.03962 | test_accuracy: 0.98401 | test_auc: 0.99798 |  0:03:17s\n",
      "epoch 68 | loss: 0.03966 | test_accuracy: 0.98401 | test_auc: 0.99797 |  0:03:20s\n",
      "epoch 69 | loss: 0.03975 | test_accuracy: 0.98401 | test_auc: 0.99797 |  0:03:23s\n",
      "epoch 70 | loss: 0.03944 | test_accuracy: 0.98401 | test_auc: 0.99801 |  0:03:26s\n",
      "epoch 71 | loss: 0.04022 | test_accuracy: 0.98401 | test_auc: 0.99794 |  0:03:29s\n",
      "epoch 72 | loss: 0.03963 | test_accuracy: 0.98401 | test_auc: 0.99795 |  0:03:32s\n",
      "epoch 73 | loss: 0.04163 | test_accuracy: 0.98366 | test_auc: 0.9978  |  0:03:35s\n",
      "epoch 74 | loss: 0.04025 | test_accuracy: 0.98401 | test_auc: 0.99796 |  0:03:38s\n",
      "epoch 75 | loss: 0.04018 | test_accuracy: 0.98401 | test_auc: 0.99797 |  0:03:41s\n",
      "epoch 76 | loss: 0.03994 | test_accuracy: 0.98401 | test_auc: 0.99782 |  0:03:44s\n",
      "epoch 77 | loss: 0.0397  | test_accuracy: 0.98401 | test_auc: 0.99794 |  0:03:47s\n",
      "\n",
      "Early stopping occurred at epoch 77 with best_epoch = 57 and best_test_auc = 0.99803\n",
      "Training fold 4/5...\n",
      "epoch 0  | loss: 0.20338 | test_accuracy: 0.91969 | test_auc: 0.95296 |  0:00:02s\n",
      "epoch 1  | loss: 0.07498 | test_accuracy: 0.92508 | test_auc: 0.98583 |  0:00:05s\n",
      "epoch 2  | loss: 0.06127 | test_accuracy: 0.9442  | test_auc: 0.98578 |  0:00:08s\n",
      "epoch 3  | loss: 0.05715 | test_accuracy: 0.95915 | test_auc: 0.994   |  0:00:11s\n",
      "epoch 4  | loss: 0.05476 | test_accuracy: 0.96037 | test_auc: 0.99508 |  0:00:14s\n",
      "epoch 5  | loss: 0.05173 | test_accuracy: 0.95568 | test_auc: 0.99526 |  0:00:17s\n",
      "epoch 6  | loss: 0.05379 | test_accuracy: 0.96906 | test_auc: 0.9961  |  0:00:20s\n",
      "epoch 7  | loss: 0.05247 | test_accuracy: 0.97984 | test_auc: 0.99711 |  0:00:23s\n",
      "epoch 8  | loss: 0.05176 | test_accuracy: 0.98262 | test_auc: 0.99763 |  0:00:26s\n",
      "epoch 9  | loss: 0.04794 | test_accuracy: 0.98105 | test_auc: 0.99782 |  0:00:29s\n",
      "epoch 10 | loss: 0.04787 | test_accuracy: 0.98366 | test_auc: 0.998   |  0:00:32s\n",
      "epoch 11 | loss: 0.0478  | test_accuracy: 0.9847  | test_auc: 0.99741 |  0:00:35s\n",
      "epoch 12 | loss: 0.0469  | test_accuracy: 0.98505 | test_auc: 0.99838 |  0:00:38s\n",
      "epoch 13 | loss: 0.04563 | test_accuracy: 0.98523 | test_auc: 0.99812 |  0:00:41s\n",
      "epoch 14 | loss: 0.0449  | test_accuracy: 0.98575 | test_auc: 0.9985  |  0:00:44s\n",
      "epoch 15 | loss: 0.04629 | test_accuracy: 0.98575 | test_auc: 0.99851 |  0:00:47s\n",
      "epoch 16 | loss: 0.04488 | test_accuracy: 0.98575 | test_auc: 0.9982  |  0:00:50s\n",
      "epoch 17 | loss: 0.04476 | test_accuracy: 0.98575 | test_auc: 0.99838 |  0:00:53s\n",
      "epoch 18 | loss: 0.04554 | test_accuracy: 0.98314 | test_auc: 0.99849 |  0:00:55s\n",
      "epoch 19 | loss: 0.04625 | test_accuracy: 0.98505 | test_auc: 0.99837 |  0:00:58s\n",
      "epoch 20 | loss: 0.04811 | test_accuracy: 0.98575 | test_auc: 0.99815 |  0:01:01s\n",
      "epoch 21 | loss: 0.04528 | test_accuracy: 0.98575 | test_auc: 0.99851 |  0:01:04s\n",
      "epoch 22 | loss: 0.04456 | test_accuracy: 0.98105 | test_auc: 0.99773 |  0:01:07s\n",
      "epoch 23 | loss: 0.05502 | test_accuracy: 0.98331 | test_auc: 0.99773 |  0:01:10s\n",
      "epoch 24 | loss: 0.05064 | test_accuracy: 0.98523 | test_auc: 0.99799 |  0:01:13s\n",
      "epoch 25 | loss: 0.04757 | test_accuracy: 0.98575 | test_auc: 0.99848 |  0:01:16s\n",
      "epoch 26 | loss: 0.04531 | test_accuracy: 0.9854  | test_auc: 0.99855 |  0:01:18s\n",
      "epoch 27 | loss: 0.04446 | test_accuracy: 0.9854  | test_auc: 0.99856 |  0:01:21s\n",
      "epoch 28 | loss: 0.04342 | test_accuracy: 0.98575 | test_auc: 0.99858 |  0:01:24s\n",
      "epoch 29 | loss: 0.04326 | test_accuracy: 0.98488 | test_auc: 0.99854 |  0:01:27s\n",
      "epoch 30 | loss: 0.0439  | test_accuracy: 0.98575 | test_auc: 0.99858 |  0:01:30s\n",
      "epoch 31 | loss: 0.04292 | test_accuracy: 0.98575 | test_auc: 0.99861 |  0:01:33s\n",
      "epoch 32 | loss: 0.04236 | test_accuracy: 0.98575 | test_auc: 0.9986  |  0:01:36s\n",
      "epoch 33 | loss: 0.04296 | test_accuracy: 0.98575 | test_auc: 0.99857 |  0:01:39s\n",
      "epoch 34 | loss: 0.04307 | test_accuracy: 0.98575 | test_auc: 0.99858 |  0:01:42s\n",
      "epoch 35 | loss: 0.04298 | test_accuracy: 0.98575 | test_auc: 0.99857 |  0:01:44s\n",
      "epoch 36 | loss: 0.04242 | test_accuracy: 0.98575 | test_auc: 0.99859 |  0:01:47s\n",
      "epoch 37 | loss: 0.0428  | test_accuracy: 0.98575 | test_auc: 0.99859 |  0:01:50s\n",
      "epoch 38 | loss: 0.0419  | test_accuracy: 0.98575 | test_auc: 0.99857 |  0:01:53s\n",
      "epoch 39 | loss: 0.04221 | test_accuracy: 0.98575 | test_auc: 0.99859 |  0:01:56s\n",
      "epoch 40 | loss: 0.04245 | test_accuracy: 0.98575 | test_auc: 0.9986  |  0:01:59s\n",
      "epoch 41 | loss: 0.04258 | test_accuracy: 0.98575 | test_auc: 0.99858 |  0:02:02s\n",
      "epoch 42 | loss: 0.04253 | test_accuracy: 0.98575 | test_auc: 0.9986  |  0:02:05s\n",
      "epoch 43 | loss: 0.04261 | test_accuracy: 0.98575 | test_auc: 0.99856 |  0:02:08s\n",
      "epoch 44 | loss: 0.04227 | test_accuracy: 0.98575 | test_auc: 0.99859 |  0:02:11s\n",
      "epoch 45 | loss: 0.04322 | test_accuracy: 0.98575 | test_auc: 0.99839 |  0:02:13s\n",
      "epoch 46 | loss: 0.04339 | test_accuracy: 0.98575 | test_auc: 0.99858 |  0:02:16s\n",
      "epoch 47 | loss: 0.04207 | test_accuracy: 0.98575 | test_auc: 0.99861 |  0:02:19s\n",
      "epoch 48 | loss: 0.04329 | test_accuracy: 0.98575 | test_auc: 0.99856 |  0:02:22s\n",
      "epoch 49 | loss: 0.04252 | test_accuracy: 0.9854  | test_auc: 0.99857 |  0:02:25s\n",
      "epoch 50 | loss: 0.04245 | test_accuracy: 0.9854  | test_auc: 0.99861 |  0:02:28s\n",
      "epoch 51 | loss: 0.04176 | test_accuracy: 0.9854  | test_auc: 0.99857 |  0:02:31s\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 31 and best_test_auc = 0.99861\n",
      "Training fold 5/5...\n",
      "epoch 0  | loss: 0.20483 | test_accuracy: 0.88615 | test_auc: 0.93767 |  0:00:02s\n",
      "epoch 1  | loss: 0.08089 | test_accuracy: 0.93742 | test_auc: 0.96515 |  0:00:05s\n",
      "epoch 2  | loss: 0.06165 | test_accuracy: 0.9442  | test_auc: 0.98392 |  0:00:08s\n",
      "epoch 3  | loss: 0.05826 | test_accuracy: 0.95481 | test_auc: 0.99254 |  0:00:11s\n",
      "epoch 4  | loss: 0.05893 | test_accuracy: 0.95898 | test_auc: 0.99484 |  0:00:14s\n",
      "epoch 5  | loss: 0.05679 | test_accuracy: 0.95324 | test_auc: 0.99227 |  0:00:17s\n",
      "epoch 6  | loss: 0.05634 | test_accuracy: 0.93082 | test_auc: 0.99139 |  0:00:20s\n",
      "epoch 7  | loss: 0.0515  | test_accuracy: 0.97688 | test_auc: 0.99762 |  0:00:23s\n",
      "epoch 8  | loss: 0.0512  | test_accuracy: 0.97775 | test_auc: 0.99773 |  0:00:26s\n",
      "epoch 9  | loss: 0.05094 | test_accuracy: 0.97653 | test_auc: 0.99702 |  0:00:29s\n",
      "epoch 10 | loss: 0.04905 | test_accuracy: 0.98175 | test_auc: 0.99843 |  0:00:32s\n",
      "epoch 11 | loss: 0.04757 | test_accuracy: 0.98557 | test_auc: 0.99852 |  0:00:35s\n",
      "epoch 12 | loss: 0.04595 | test_accuracy: 0.98557 | test_auc: 0.99866 |  0:00:37s\n",
      "epoch 13 | loss: 0.0483  | test_accuracy: 0.98383 | test_auc: 0.99823 |  0:00:40s\n",
      "epoch 14 | loss: 0.05363 | test_accuracy: 0.98175 | test_auc: 0.99839 |  0:00:43s\n",
      "epoch 15 | loss: 0.04809 | test_accuracy: 0.98523 | test_auc: 0.9985  |  0:00:46s\n",
      "epoch 16 | loss: 0.0463  | test_accuracy: 0.98557 | test_auc: 0.9986  |  0:00:49s\n",
      "epoch 17 | loss: 0.04534 | test_accuracy: 0.98557 | test_auc: 0.99854 |  0:00:52s\n",
      "epoch 18 | loss: 0.04481 | test_accuracy: 0.98557 | test_auc: 0.998   |  0:00:55s\n",
      "epoch 19 | loss: 0.04646 | test_accuracy: 0.98575 | test_auc: 0.99859 |  0:00:58s\n",
      "epoch 20 | loss: 0.04628 | test_accuracy: 0.98557 | test_auc: 0.99868 |  0:01:01s\n",
      "epoch 21 | loss: 0.04488 | test_accuracy: 0.98557 | test_auc: 0.99855 |  0:01:04s\n",
      "epoch 22 | loss: 0.04475 | test_accuracy: 0.98557 | test_auc: 0.99872 |  0:01:07s\n",
      "epoch 23 | loss: 0.04449 | test_accuracy: 0.98557 | test_auc: 0.99865 |  0:01:10s\n",
      "epoch 24 | loss: 0.04489 | test_accuracy: 0.98557 | test_auc: 0.99867 |  0:01:13s\n",
      "epoch 25 | loss: 0.04451 | test_accuracy: 0.98157 | test_auc: 0.99871 |  0:01:16s\n",
      "epoch 26 | loss: 0.04453 | test_accuracy: 0.98557 | test_auc: 0.99869 |  0:01:19s\n",
      "epoch 27 | loss: 0.04436 | test_accuracy: 0.98557 | test_auc: 0.99858 |  0:01:21s\n",
      "epoch 28 | loss: 0.04421 | test_accuracy: 0.98557 | test_auc: 0.99869 |  0:01:24s\n",
      "epoch 29 | loss: 0.04461 | test_accuracy: 0.98557 | test_auc: 0.99863 |  0:01:27s\n",
      "epoch 30 | loss: 0.0446  | test_accuracy: 0.98557 | test_auc: 0.99865 |  0:01:30s\n",
      "epoch 31 | loss: 0.04407 | test_accuracy: 0.98557 | test_auc: 0.99871 |  0:01:33s\n",
      "epoch 32 | loss: 0.04399 | test_accuracy: 0.98557 | test_auc: 0.99868 |  0:01:36s\n",
      "epoch 33 | loss: 0.04466 | test_accuracy: 0.98557 | test_auc: 0.99874 |  0:01:39s\n",
      "epoch 34 | loss: 0.04471 | test_accuracy: 0.9854  | test_auc: 0.99869 |  0:01:42s\n",
      "epoch 35 | loss: 0.0452  | test_accuracy: 0.9854  | test_auc: 0.99868 |  0:01:45s\n",
      "epoch 36 | loss: 0.05961 | test_accuracy: 0.97341 | test_auc: 0.99778 |  0:01:48s\n",
      "epoch 37 | loss: 0.05668 | test_accuracy: 0.97845 | test_auc: 0.99811 |  0:01:51s\n",
      "epoch 38 | loss: 0.05478 | test_accuracy: 0.97688 | test_auc: 0.99806 |  0:01:54s\n",
      "epoch 39 | loss: 0.05418 | test_accuracy: 0.98071 | test_auc: 0.99843 |  0:01:57s\n",
      "epoch 40 | loss: 0.05225 | test_accuracy: 0.98157 | test_auc: 0.99846 |  0:02:00s\n",
      "epoch 41 | loss: 0.04954 | test_accuracy: 0.9847  | test_auc: 0.99858 |  0:02:03s\n",
      "epoch 42 | loss: 0.04758 | test_accuracy: 0.9847  | test_auc: 0.99848 |  0:02:06s\n",
      "epoch 43 | loss: 0.04686 | test_accuracy: 0.98488 | test_auc: 0.99864 |  0:02:09s\n",
      "epoch 44 | loss: 0.04668 | test_accuracy: 0.98418 | test_auc: 0.99855 |  0:02:12s\n",
      "epoch 45 | loss: 0.04894 | test_accuracy: 0.98383 | test_auc: 0.99857 |  0:02:15s\n",
      "epoch 46 | loss: 0.04724 | test_accuracy: 0.98505 | test_auc: 0.99866 |  0:02:18s\n",
      "epoch 47 | loss: 0.04563 | test_accuracy: 0.98575 | test_auc: 0.99858 |  0:02:20s\n",
      "epoch 48 | loss: 0.04526 | test_accuracy: 0.98349 | test_auc: 0.99866 |  0:02:23s\n",
      "epoch 49 | loss: 0.04466 | test_accuracy: 0.98575 | test_auc: 0.99873 |  0:02:26s\n",
      "epoch 50 | loss: 0.04552 | test_accuracy: 0.98523 | test_auc: 0.99873 |  0:02:29s\n",
      "epoch 51 | loss: 0.04434 | test_accuracy: 0.98575 | test_auc: 0.99873 |  0:02:32s\n",
      "epoch 52 | loss: 0.04434 | test_accuracy: 0.98349 | test_auc: 0.99877 |  0:02:35s\n",
      "epoch 53 | loss: 0.04407 | test_accuracy: 0.98575 | test_auc: 0.99873 |  0:02:38s\n",
      "epoch 54 | loss: 0.0434  | test_accuracy: 0.98575 | test_auc: 0.99872 |  0:02:41s\n",
      "epoch 55 | loss: 0.04367 | test_accuracy: 0.98575 | test_auc: 0.99869 |  0:02:44s\n",
      "epoch 56 | loss: 0.04312 | test_accuracy: 0.98575 | test_auc: 0.9987  |  0:02:47s\n",
      "epoch 57 | loss: 0.04414 | test_accuracy: 0.98575 | test_auc: 0.9987  |  0:02:50s\n",
      "epoch 58 | loss: 0.04337 | test_accuracy: 0.98575 | test_auc: 0.99866 |  0:02:53s\n",
      "epoch 59 | loss: 0.04365 | test_accuracy: 0.98575 | test_auc: 0.99865 |  0:02:56s\n",
      "epoch 60 | loss: 0.04353 | test_accuracy: 0.98575 | test_auc: 0.99871 |  0:02:59s\n",
      "epoch 61 | loss: 0.04565 | test_accuracy: 0.98505 | test_auc: 0.99839 |  0:03:02s\n",
      "epoch 62 | loss: 0.04691 | test_accuracy: 0.98575 | test_auc: 0.99852 |  0:03:05s\n",
      "epoch 63 | loss: 0.04553 | test_accuracy: 0.98523 | test_auc: 0.9987  |  0:03:07s\n",
      "epoch 64 | loss: 0.04458 | test_accuracy: 0.98523 | test_auc: 0.9987  |  0:03:10s\n",
      "epoch 65 | loss: 0.04513 | test_accuracy: 0.98523 | test_auc: 0.99867 |  0:03:13s\n",
      "epoch 66 | loss: 0.04491 | test_accuracy: 0.98523 | test_auc: 0.99865 |  0:03:16s\n",
      "epoch 67 | loss: 0.04602 | test_accuracy: 0.98488 | test_auc: 0.99859 |  0:03:19s\n",
      "epoch 68 | loss: 0.04551 | test_accuracy: 0.98523 | test_auc: 0.99869 |  0:03:22s\n",
      "epoch 69 | loss: 0.04548 | test_accuracy: 0.98436 | test_auc: 0.99867 |  0:03:24s\n",
      "epoch 70 | loss: 0.0469  | test_accuracy: 0.98488 | test_auc: 0.99861 |  0:03:27s\n",
      "epoch 71 | loss: 0.04572 | test_accuracy: 0.98523 | test_auc: 0.99867 |  0:03:30s\n",
      "epoch 72 | loss: 0.0456  | test_accuracy: 0.98436 | test_auc: 0.9985  |  0:03:33s\n",
      "\n",
      "Early stopping occurred at epoch 72 with best_epoch = 52 and best_test_auc = 0.99877\n",
      "\n",
      "Results for 5. Random Forest Importance:\n",
      "Average accuracy: 0.9838 ± 0.0016\n",
      "Average precision: 0.9914 ± 0.0030\n",
      "Average recall: 0.9629 ± 0.0045\n",
      "Average f1: 0.9769 ± 0.0026\n",
      "Average auc: 0.9791 ± 0.0022\n",
      "\n",
      "==================================================\n",
      "Processing 6. Boruta\n",
      "==================================================\n",
      "Selecting features using 6. Boruta...\n",
      "Top 10 features selected by 6. Boruta:\n",
      "1. Breathing Problem: 1.0000\n",
      "2. Sore throat: 1.0000\n",
      "3. Running Nose: 1.0000\n",
      "4. Asthma: 1.0000\n",
      "5. Chronic Lung Disease: 1.0000\n",
      "6. Headache: 1.0000\n",
      "7. Heart Disease: 1.0000\n",
      "8. Diabetes: 1.0000\n",
      "9. Hyper Tension: 1.0000\n",
      "10. Fatigue : 1.0000\n",
      "\n",
      "Training TabNet with features selected by 6. Boruta\n",
      "Training fold 1/5...\n",
      "epoch 0  | loss: 0.30237 | test_accuracy: 0.82951 | test_auc: 0.95311 |  0:00:02s\n",
      "epoch 1  | loss: 0.14688 | test_accuracy: 0.93761 | test_auc: 0.96882 |  0:00:05s\n",
      "epoch 2  | loss: 0.11818 | test_accuracy: 0.92979 | test_auc: 0.97048 |  0:00:08s\n",
      "epoch 3  | loss: 0.11039 | test_accuracy: 0.90233 | test_auc: 0.97785 |  0:00:11s\n",
      "epoch 4  | loss: 0.10219 | test_accuracy: 0.93518 | test_auc: 0.98551 |  0:00:14s\n",
      "epoch 5  | loss: 0.0841  | test_accuracy: 0.94873 | test_auc: 0.98622 |  0:00:17s\n",
      "epoch 6  | loss: 0.07763 | test_accuracy: 0.94769 | test_auc: 0.9888  |  0:00:20s\n",
      "epoch 7  | loss: 0.07723 | test_accuracy: 0.95255 | test_auc: 0.99143 |  0:00:23s\n",
      "epoch 8  | loss: 0.07021 | test_accuracy: 0.97793 | test_auc: 0.99649 |  0:00:26s\n",
      "epoch 9  | loss: 0.06245 | test_accuracy: 0.9788  | test_auc: 0.99698 |  0:00:29s\n",
      "epoch 10 | loss: 0.05635 | test_accuracy: 0.97237 | test_auc: 0.99717 |  0:00:32s\n",
      "epoch 11 | loss: 0.05687 | test_accuracy: 0.9854  | test_auc: 0.99824 |  0:00:35s\n",
      "epoch 12 | loss: 0.05645 | test_accuracy: 0.98436 | test_auc: 0.99817 |  0:00:38s\n",
      "epoch 13 | loss: 0.05323 | test_accuracy: 0.98471 | test_auc: 0.99814 |  0:00:41s\n",
      "epoch 14 | loss: 0.05299 | test_accuracy: 0.98366 | test_auc: 0.9984  |  0:00:44s\n",
      "epoch 15 | loss: 0.05702 | test_accuracy: 0.9854  | test_auc: 0.99871 |  0:00:47s\n",
      "epoch 16 | loss: 0.0614  | test_accuracy: 0.98366 | test_auc: 0.99793 |  0:00:50s\n",
      "epoch 17 | loss: 0.05714 | test_accuracy: 0.98766 | test_auc: 0.99795 |  0:00:53s\n",
      "epoch 18 | loss: 0.0524  | test_accuracy: 0.98731 | test_auc: 0.99813 |  0:00:56s\n",
      "epoch 19 | loss: 0.0506  | test_accuracy: 0.98749 | test_auc: 0.99841 |  0:00:58s\n",
      "epoch 20 | loss: 0.04983 | test_accuracy: 0.98523 | test_auc: 0.9983  |  0:01:01s\n",
      "epoch 21 | loss: 0.04856 | test_accuracy: 0.98783 | test_auc: 0.99699 |  0:01:04s\n",
      "epoch 22 | loss: 0.04883 | test_accuracy: 0.98697 | test_auc: 0.99877 |  0:01:07s\n",
      "epoch 23 | loss: 0.04884 | test_accuracy: 0.98644 | test_auc: 0.99875 |  0:01:10s\n",
      "epoch 24 | loss: 0.04766 | test_accuracy: 0.98697 | test_auc: 0.99844 |  0:01:13s\n",
      "epoch 25 | loss: 0.05075 | test_accuracy: 0.98679 | test_auc: 0.99875 |  0:01:16s\n",
      "epoch 26 | loss: 0.04734 | test_accuracy: 0.98662 | test_auc: 0.9983  |  0:01:19s\n",
      "epoch 27 | loss: 0.05014 | test_accuracy: 0.98697 | test_auc: 0.99875 |  0:01:22s\n",
      "epoch 28 | loss: 0.06953 | test_accuracy: 0.98662 | test_auc: 0.99648 |  0:01:25s\n",
      "epoch 29 | loss: 0.05991 | test_accuracy: 0.98332 | test_auc: 0.99827 |  0:01:28s\n",
      "epoch 30 | loss: 0.05689 | test_accuracy: 0.98349 | test_auc: 0.99774 |  0:01:30s\n",
      "epoch 31 | loss: 0.0593  | test_accuracy: 0.98193 | test_auc: 0.99802 |  0:01:33s\n",
      "epoch 32 | loss: 0.05703 | test_accuracy: 0.98332 | test_auc: 0.99836 |  0:01:36s\n",
      "epoch 33 | loss: 0.05256 | test_accuracy: 0.98436 | test_auc: 0.99876 |  0:01:39s\n",
      "epoch 34 | loss: 0.04921 | test_accuracy: 0.98453 | test_auc: 0.99847 |  0:01:42s\n",
      "epoch 35 | loss: 0.04841 | test_accuracy: 0.98749 | test_auc: 0.99844 |  0:01:45s\n",
      "epoch 36 | loss: 0.05034 | test_accuracy: 0.98749 | test_auc: 0.99871 |  0:01:48s\n",
      "epoch 37 | loss: 0.04846 | test_accuracy: 0.98644 | test_auc: 0.9985  |  0:01:51s\n",
      "epoch 38 | loss: 0.04961 | test_accuracy: 0.9861  | test_auc: 0.99876 |  0:01:54s\n",
      "epoch 39 | loss: 0.04863 | test_accuracy: 0.9861  | test_auc: 0.99867 |  0:01:57s\n",
      "epoch 40 | loss: 0.05367 | test_accuracy: 0.98627 | test_auc: 0.99815 |  0:02:00s\n",
      "epoch 41 | loss: 0.06543 | test_accuracy: 0.98088 | test_auc: 0.99811 |  0:02:03s\n",
      "epoch 42 | loss: 0.05469 | test_accuracy: 0.98575 | test_auc: 0.99853 |  0:02:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_test_auc = 0.99877\n",
      "Training fold 2/5...\n",
      "epoch 0  | loss: 0.30756 | test_accuracy: 0.66696 | test_auc: 0.90459 |  0:00:02s\n",
      "epoch 1  | loss: 0.1545  | test_accuracy: 0.68764 | test_auc: 0.92985 |  0:00:05s\n",
      "epoch 2  | loss: 0.12494 | test_accuracy: 0.69442 | test_auc: 0.9451  |  0:00:08s\n",
      "epoch 3  | loss: 0.10771 | test_accuracy: 0.94073 | test_auc: 0.95684 |  0:00:11s\n",
      "epoch 4  | loss: 0.1029  | test_accuracy: 0.89153 | test_auc: 0.95877 |  0:00:14s\n",
      "epoch 5  | loss: 0.09956 | test_accuracy: 0.95289 | test_auc: 0.98376 |  0:00:17s\n",
      "epoch 6  | loss: 0.09306 | test_accuracy: 0.95846 | test_auc: 0.98793 |  0:00:20s\n",
      "epoch 7  | loss: 0.08649 | test_accuracy: 0.96454 | test_auc: 0.9875  |  0:00:23s\n",
      "epoch 8  | loss: 0.07484 | test_accuracy: 0.96628 | test_auc: 0.99408 |  0:00:26s\n",
      "epoch 9  | loss: 0.07432 | test_accuracy: 0.96663 | test_auc: 0.99481 |  0:00:29s\n",
      "epoch 10 | loss: 0.06767 | test_accuracy: 0.97219 | test_auc: 0.99479 |  0:00:31s\n",
      "epoch 11 | loss: 0.06612 | test_accuracy: 0.97636 | test_auc: 0.99659 |  0:00:34s\n",
      "epoch 12 | loss: 0.06714 | test_accuracy: 0.96941 | test_auc: 0.99613 |  0:00:37s\n",
      "epoch 13 | loss: 0.06227 | test_accuracy: 0.97462 | test_auc: 0.99637 |  0:00:40s\n",
      "epoch 14 | loss: 0.06111 | test_accuracy: 0.97149 | test_auc: 0.99642 |  0:00:43s\n",
      "epoch 15 | loss: 0.06775 | test_accuracy: 0.97566 | test_auc: 0.99672 |  0:00:46s\n",
      "epoch 16 | loss: 0.06315 | test_accuracy: 0.97862 | test_auc: 0.99687 |  0:00:49s\n",
      "epoch 17 | loss: 0.05974 | test_accuracy: 0.97723 | test_auc: 0.99654 |  0:00:52s\n",
      "epoch 18 | loss: 0.0578  | test_accuracy: 0.98157 | test_auc: 0.99688 |  0:00:55s\n",
      "epoch 19 | loss: 0.05806 | test_accuracy: 0.97984 | test_auc: 0.99704 |  0:00:58s\n",
      "epoch 20 | loss: 0.05282 | test_accuracy: 0.97879 | test_auc: 0.99646 |  0:01:01s\n",
      "epoch 21 | loss: 0.04941 | test_accuracy: 0.98244 | test_auc: 0.99626 |  0:01:04s\n",
      "epoch 22 | loss: 0.04893 | test_accuracy: 0.98366 | test_auc: 0.99744 |  0:01:06s\n",
      "epoch 23 | loss: 0.05144 | test_accuracy: 0.9814  | test_auc: 0.99652 |  0:01:09s\n",
      "epoch 24 | loss: 0.04782 | test_accuracy: 0.98401 | test_auc: 0.99733 |  0:01:12s\n",
      "epoch 25 | loss: 0.04466 | test_accuracy: 0.98523 | test_auc: 0.99737 |  0:01:15s\n",
      "epoch 26 | loss: 0.05262 | test_accuracy: 0.98349 | test_auc: 0.99667 |  0:01:18s\n",
      "epoch 27 | loss: 0.04937 | test_accuracy: 0.98418 | test_auc: 0.99739 |  0:01:21s\n",
      "epoch 28 | loss: 0.04554 | test_accuracy: 0.9854  | test_auc: 0.99762 |  0:01:24s\n",
      "epoch 29 | loss: 0.04351 | test_accuracy: 0.98453 | test_auc: 0.99728 |  0:01:27s\n",
      "epoch 30 | loss: 0.04345 | test_accuracy: 0.98557 | test_auc: 0.99734 |  0:01:29s\n",
      "epoch 31 | loss: 0.04574 | test_accuracy: 0.98523 | test_auc: 0.99731 |  0:01:32s\n",
      "epoch 32 | loss: 0.04358 | test_accuracy: 0.98523 | test_auc: 0.99765 |  0:01:35s\n",
      "epoch 33 | loss: 0.04574 | test_accuracy: 0.98036 | test_auc: 0.99613 |  0:01:38s\n",
      "epoch 34 | loss: 0.05361 | test_accuracy: 0.98053 | test_auc: 0.99728 |  0:01:41s\n",
      "epoch 35 | loss: 0.05377 | test_accuracy: 0.98453 | test_auc: 0.99733 |  0:01:44s\n",
      "epoch 36 | loss: 0.04884 | test_accuracy: 0.97984 | test_auc: 0.99729 |  0:01:47s\n",
      "epoch 37 | loss: 0.05121 | test_accuracy: 0.98401 | test_auc: 0.9972  |  0:01:50s\n",
      "epoch 38 | loss: 0.05043 | test_accuracy: 0.98331 | test_auc: 0.99708 |  0:01:52s\n",
      "epoch 39 | loss: 0.04455 | test_accuracy: 0.98592 | test_auc: 0.9974  |  0:01:55s\n",
      "epoch 40 | loss: 0.04074 | test_accuracy: 0.98349 | test_auc: 0.9975  |  0:01:58s\n",
      "epoch 41 | loss: 0.04291 | test_accuracy: 0.98609 | test_auc: 0.9976  |  0:02:01s\n",
      "epoch 42 | loss: 0.03972 | test_accuracy: 0.98557 | test_auc: 0.99674 |  0:02:04s\n",
      "epoch 43 | loss: 0.04124 | test_accuracy: 0.98557 | test_auc: 0.99746 |  0:02:07s\n",
      "epoch 44 | loss: 0.03959 | test_accuracy: 0.98644 | test_auc: 0.99681 |  0:02:10s\n",
      "epoch 45 | loss: 0.03979 | test_accuracy: 0.98523 | test_auc: 0.99724 |  0:02:13s\n",
      "epoch 46 | loss: 0.05534 | test_accuracy: 0.97932 | test_auc: 0.99601 |  0:02:16s\n",
      "epoch 47 | loss: 0.047   | test_accuracy: 0.98436 | test_auc: 0.997   |  0:02:19s\n",
      "epoch 48 | loss: 0.04281 | test_accuracy: 0.98575 | test_auc: 0.99671 |  0:02:22s\n",
      "epoch 49 | loss: 0.04137 | test_accuracy: 0.98592 | test_auc: 0.99769 |  0:02:25s\n",
      "epoch 50 | loss: 0.04047 | test_accuracy: 0.98505 | test_auc: 0.99742 |  0:02:28s\n",
      "epoch 51 | loss: 0.0493  | test_accuracy: 0.98383 | test_auc: 0.99737 |  0:02:31s\n",
      "epoch 52 | loss: 0.05095 | test_accuracy: 0.98297 | test_auc: 0.99739 |  0:02:34s\n",
      "epoch 53 | loss: 0.04312 | test_accuracy: 0.98575 | test_auc: 0.99703 |  0:02:37s\n",
      "epoch 54 | loss: 0.04219 | test_accuracy: 0.98592 | test_auc: 0.99735 |  0:02:40s\n",
      "epoch 55 | loss: 0.04258 | test_accuracy: 0.98349 | test_auc: 0.9969  |  0:02:43s\n",
      "epoch 56 | loss: 0.04274 | test_accuracy: 0.98436 | test_auc: 0.99719 |  0:02:46s\n",
      "epoch 57 | loss: 0.04857 | test_accuracy: 0.98331 | test_auc: 0.99712 |  0:02:49s\n",
      "epoch 58 | loss: 0.04384 | test_accuracy: 0.98592 | test_auc: 0.99736 |  0:02:51s\n",
      "epoch 59 | loss: 0.04029 | test_accuracy: 0.98557 | test_auc: 0.99766 |  0:02:54s\n",
      "epoch 60 | loss: 0.0401  | test_accuracy: 0.9854  | test_auc: 0.9979  |  0:02:57s\n",
      "epoch 61 | loss: 0.04001 | test_accuracy: 0.98679 | test_auc: 0.998   |  0:03:00s\n",
      "epoch 62 | loss: 0.03931 | test_accuracy: 0.98627 | test_auc: 0.99784 |  0:03:03s\n",
      "epoch 63 | loss: 0.03843 | test_accuracy: 0.98488 | test_auc: 0.99793 |  0:03:06s\n",
      "epoch 64 | loss: 0.03838 | test_accuracy: 0.98662 | test_auc: 0.99794 |  0:03:09s\n",
      "epoch 65 | loss: 0.03874 | test_accuracy: 0.98609 | test_auc: 0.99793 |  0:03:12s\n",
      "epoch 66 | loss: 0.04105 | test_accuracy: 0.98557 | test_auc: 0.99748 |  0:03:15s\n",
      "epoch 67 | loss: 0.04212 | test_accuracy: 0.98627 | test_auc: 0.99749 |  0:03:18s\n",
      "epoch 68 | loss: 0.03956 | test_accuracy: 0.98436 | test_auc: 0.99752 |  0:03:21s\n",
      "epoch 69 | loss: 0.04498 | test_accuracy: 0.98366 | test_auc: 0.99722 |  0:03:24s\n",
      "epoch 70 | loss: 0.0433  | test_accuracy: 0.98644 | test_auc: 0.99651 |  0:03:27s\n",
      "epoch 71 | loss: 0.03891 | test_accuracy: 0.98575 | test_auc: 0.99806 |  0:03:30s\n",
      "epoch 72 | loss: 0.0399  | test_accuracy: 0.98627 | test_auc: 0.99744 |  0:03:32s\n",
      "epoch 73 | loss: 0.04019 | test_accuracy: 0.98575 | test_auc: 0.99773 |  0:03:35s\n",
      "epoch 74 | loss: 0.04279 | test_accuracy: 0.98523 | test_auc: 0.99698 |  0:03:38s\n",
      "epoch 75 | loss: 0.04083 | test_accuracy: 0.98523 | test_auc: 0.99755 |  0:03:41s\n",
      "epoch 76 | loss: 0.04214 | test_accuracy: 0.98488 | test_auc: 0.99783 |  0:03:44s\n",
      "epoch 77 | loss: 0.04071 | test_accuracy: 0.98662 | test_auc: 0.99736 |  0:03:47s\n",
      "epoch 78 | loss: 0.03863 | test_accuracy: 0.98644 | test_auc: 0.99781 |  0:03:50s\n",
      "epoch 79 | loss: 0.03626 | test_accuracy: 0.98662 | test_auc: 0.99742 |  0:03:53s\n",
      "epoch 80 | loss: 0.0373  | test_accuracy: 0.98644 | test_auc: 0.99759 |  0:03:56s\n",
      "epoch 81 | loss: 0.03738 | test_accuracy: 0.98644 | test_auc: 0.99749 |  0:03:59s\n",
      "epoch 82 | loss: 0.03884 | test_accuracy: 0.98627 | test_auc: 0.99768 |  0:04:02s\n",
      "epoch 83 | loss: 0.04078 | test_accuracy: 0.98609 | test_auc: 0.99784 |  0:04:05s\n",
      "epoch 84 | loss: 0.03723 | test_accuracy: 0.98609 | test_auc: 0.99759 |  0:04:08s\n",
      "epoch 85 | loss: 0.03796 | test_accuracy: 0.98662 | test_auc: 0.99788 |  0:04:10s\n",
      "epoch 86 | loss: 0.03658 | test_accuracy: 0.98627 | test_auc: 0.99794 |  0:04:13s\n",
      "epoch 87 | loss: 0.03726 | test_accuracy: 0.9854  | test_auc: 0.99784 |  0:04:16s\n",
      "epoch 88 | loss: 0.03613 | test_accuracy: 0.98696 | test_auc: 0.99759 |  0:04:19s\n",
      "epoch 89 | loss: 0.03639 | test_accuracy: 0.98575 | test_auc: 0.99792 |  0:04:22s\n",
      "epoch 90 | loss: 0.03886 | test_accuracy: 0.98679 | test_auc: 0.99768 |  0:04:25s\n",
      "epoch 91 | loss: 0.04299 | test_accuracy: 0.98488 | test_auc: 0.99759 |  0:04:28s\n",
      "\n",
      "Early stopping occurred at epoch 91 with best_epoch = 71 and best_test_auc = 0.99806\n",
      "Training fold 3/5...\n",
      "epoch 0  | loss: 0.29385 | test_accuracy: 0.575   | test_auc: 0.84767 |  0:00:02s\n",
      "epoch 1  | loss: 0.15648 | test_accuracy: 0.81262 | test_auc: 0.96417 |  0:00:05s\n",
      "epoch 2  | loss: 0.12442 | test_accuracy: 0.81766 | test_auc: 0.97289 |  0:00:08s\n",
      "epoch 3  | loss: 0.10601 | test_accuracy: 0.89553 | test_auc: 0.9833  |  0:00:11s\n",
      "epoch 4  | loss: 0.09793 | test_accuracy: 0.90127 | test_auc: 0.98732 |  0:00:14s\n",
      "epoch 5  | loss: 0.09843 | test_accuracy: 0.93812 | test_auc: 0.98871 |  0:00:17s\n",
      "epoch 6  | loss: 0.0895  | test_accuracy: 0.94038 | test_auc: 0.98988 |  0:00:20s\n",
      "epoch 7  | loss: 0.09169 | test_accuracy: 0.95324 | test_auc: 0.99151 |  0:00:23s\n",
      "epoch 8  | loss: 0.10284 | test_accuracy: 0.95915 | test_auc: 0.99177 |  0:00:26s\n",
      "epoch 9  | loss: 0.09037 | test_accuracy: 0.96802 | test_auc: 0.99422 |  0:00:29s\n",
      "epoch 10 | loss: 0.08095 | test_accuracy: 0.96697 | test_auc: 0.99423 |  0:00:31s\n",
      "epoch 11 | loss: 0.07711 | test_accuracy: 0.97062 | test_auc: 0.99475 |  0:00:34s\n",
      "epoch 12 | loss: 0.07456 | test_accuracy: 0.97201 | test_auc: 0.99556 |  0:00:37s\n",
      "epoch 13 | loss: 0.07125 | test_accuracy: 0.97184 | test_auc: 0.99641 |  0:00:40s\n",
      "epoch 14 | loss: 0.07046 | test_accuracy: 0.9741  | test_auc: 0.99638 |  0:00:43s\n",
      "epoch 15 | loss: 0.075   | test_accuracy: 0.97393 | test_auc: 0.99636 |  0:00:46s\n",
      "epoch 16 | loss: 0.06749 | test_accuracy: 0.97723 | test_auc: 0.99682 |  0:00:49s\n",
      "epoch 17 | loss: 0.06855 | test_accuracy: 0.97827 | test_auc: 0.9963  |  0:00:52s\n",
      "epoch 18 | loss: 0.06298 | test_accuracy: 0.97845 | test_auc: 0.99683 |  0:00:55s\n",
      "epoch 19 | loss: 0.06216 | test_accuracy: 0.97584 | test_auc: 0.99674 |  0:00:57s\n",
      "epoch 20 | loss: 0.06406 | test_accuracy: 0.98331 | test_auc: 0.99685 |  0:01:04s\n",
      "epoch 21 | loss: 0.05668 | test_accuracy: 0.98244 | test_auc: 0.99606 |  0:01:07s\n",
      "epoch 22 | loss: 0.0521  | test_accuracy: 0.98453 | test_auc: 0.9976  |  0:01:10s\n",
      "epoch 23 | loss: 0.06212 | test_accuracy: 0.98123 | test_auc: 0.9956  |  0:01:13s\n",
      "epoch 24 | loss: 0.06154 | test_accuracy: 0.98123 | test_auc: 0.99603 |  0:01:16s\n",
      "epoch 25 | loss: 0.05364 | test_accuracy: 0.98297 | test_auc: 0.99725 |  0:01:19s\n",
      "epoch 26 | loss: 0.0495  | test_accuracy: 0.98366 | test_auc: 0.99767 |  0:01:21s\n",
      "epoch 27 | loss: 0.04668 | test_accuracy: 0.98401 | test_auc: 0.99724 |  0:01:24s\n",
      "epoch 28 | loss: 0.04505 | test_accuracy: 0.98436 | test_auc: 0.99751 |  0:01:27s\n",
      "epoch 29 | loss: 0.04441 | test_accuracy: 0.98227 | test_auc: 0.99786 |  0:01:30s\n",
      "epoch 30 | loss: 0.04593 | test_accuracy: 0.98244 | test_auc: 0.99789 |  0:01:33s\n",
      "epoch 31 | loss: 0.04463 | test_accuracy: 0.98297 | test_auc: 0.99755 |  0:01:36s\n",
      "epoch 32 | loss: 0.05162 | test_accuracy: 0.98262 | test_auc: 0.99755 |  0:01:39s\n",
      "epoch 33 | loss: 0.05387 | test_accuracy: 0.98244 | test_auc: 0.99755 |  0:01:42s\n",
      "epoch 34 | loss: 0.04639 | test_accuracy: 0.98227 | test_auc: 0.99708 |  0:01:45s\n",
      "epoch 35 | loss: 0.04472 | test_accuracy: 0.98297 | test_auc: 0.9978  |  0:01:48s\n",
      "epoch 36 | loss: 0.04383 | test_accuracy: 0.98418 | test_auc: 0.99641 |  0:01:51s\n",
      "epoch 37 | loss: 0.04455 | test_accuracy: 0.98488 | test_auc: 0.99731 |  0:01:54s\n",
      "epoch 38 | loss: 0.04155 | test_accuracy: 0.98523 | test_auc: 0.99755 |  0:01:56s\n",
      "epoch 39 | loss: 0.0407  | test_accuracy: 0.98523 | test_auc: 0.9981  |  0:01:59s\n",
      "epoch 40 | loss: 0.04397 | test_accuracy: 0.98366 | test_auc: 0.99787 |  0:02:02s\n",
      "epoch 41 | loss: 0.0457  | test_accuracy: 0.9847  | test_auc: 0.99811 |  0:02:05s\n",
      "epoch 42 | loss: 0.04168 | test_accuracy: 0.98366 | test_auc: 0.99798 |  0:02:08s\n",
      "epoch 43 | loss: 0.04265 | test_accuracy: 0.98627 | test_auc: 0.99756 |  0:02:11s\n",
      "epoch 44 | loss: 0.04518 | test_accuracy: 0.98418 | test_auc: 0.99791 |  0:02:14s\n",
      "epoch 45 | loss: 0.04543 | test_accuracy: 0.9847  | test_auc: 0.99795 |  0:02:17s\n",
      "epoch 46 | loss: 0.04139 | test_accuracy: 0.98557 | test_auc: 0.99819 |  0:02:20s\n",
      "epoch 47 | loss: 0.04007 | test_accuracy: 0.98436 | test_auc: 0.99839 |  0:02:23s\n",
      "epoch 48 | loss: 0.03867 | test_accuracy: 0.98523 | test_auc: 0.99827 |  0:02:26s\n",
      "epoch 49 | loss: 0.03857 | test_accuracy: 0.98627 | test_auc: 0.99839 |  0:02:29s\n",
      "epoch 50 | loss: 0.03855 | test_accuracy: 0.98627 | test_auc: 0.99849 |  0:02:32s\n",
      "epoch 51 | loss: 0.0387  | test_accuracy: 0.98488 | test_auc: 0.99806 |  0:02:35s\n",
      "epoch 52 | loss: 0.04148 | test_accuracy: 0.98609 | test_auc: 0.99848 |  0:02:37s\n",
      "epoch 53 | loss: 0.03837 | test_accuracy: 0.98488 | test_auc: 0.99841 |  0:02:40s\n",
      "epoch 54 | loss: 0.03699 | test_accuracy: 0.98592 | test_auc: 0.99828 |  0:02:43s\n",
      "epoch 55 | loss: 0.03804 | test_accuracy: 0.98575 | test_auc: 0.99807 |  0:02:46s\n",
      "epoch 56 | loss: 0.03999 | test_accuracy: 0.98609 | test_auc: 0.99805 |  0:02:49s\n",
      "epoch 57 | loss: 0.0405  | test_accuracy: 0.98609 | test_auc: 0.99752 |  0:02:52s\n",
      "epoch 58 | loss: 0.04192 | test_accuracy: 0.98662 | test_auc: 0.99809 |  0:02:55s\n",
      "epoch 59 | loss: 0.03971 | test_accuracy: 0.98453 | test_auc: 0.99791 |  0:02:58s\n",
      "epoch 60 | loss: 0.03944 | test_accuracy: 0.98505 | test_auc: 0.9982  |  0:03:01s\n",
      "epoch 61 | loss: 0.03935 | test_accuracy: 0.98679 | test_auc: 0.99782 |  0:03:04s\n",
      "epoch 62 | loss: 0.03825 | test_accuracy: 0.98523 | test_auc: 0.99841 |  0:03:07s\n",
      "epoch 63 | loss: 0.03852 | test_accuracy: 0.98592 | test_auc: 0.99845 |  0:03:10s\n",
      "epoch 64 | loss: 0.03876 | test_accuracy: 0.98575 | test_auc: 0.99842 |  0:03:13s\n",
      "epoch 65 | loss: 0.0389  | test_accuracy: 0.98644 | test_auc: 0.99854 |  0:03:16s\n",
      "epoch 66 | loss: 0.03807 | test_accuracy: 0.9854  | test_auc: 0.99808 |  0:03:19s\n",
      "epoch 67 | loss: 0.03676 | test_accuracy: 0.9847  | test_auc: 0.99836 |  0:03:22s\n",
      "epoch 68 | loss: 0.03732 | test_accuracy: 0.98644 | test_auc: 0.99821 |  0:03:24s\n",
      "epoch 69 | loss: 0.03761 | test_accuracy: 0.98488 | test_auc: 0.99841 |  0:03:28s\n",
      "epoch 70 | loss: 0.0384  | test_accuracy: 0.9847  | test_auc: 0.99856 |  0:03:30s\n",
      "epoch 71 | loss: 0.03825 | test_accuracy: 0.98644 | test_auc: 0.99853 |  0:03:33s\n",
      "epoch 72 | loss: 0.03717 | test_accuracy: 0.98696 | test_auc: 0.99853 |  0:03:36s\n",
      "epoch 73 | loss: 0.04138 | test_accuracy: 0.98575 | test_auc: 0.99835 |  0:03:39s\n",
      "epoch 74 | loss: 0.04092 | test_accuracy: 0.98801 | test_auc: 0.99838 |  0:03:42s\n",
      "epoch 75 | loss: 0.03729 | test_accuracy: 0.98557 | test_auc: 0.99828 |  0:03:45s\n",
      "epoch 76 | loss: 0.04029 | test_accuracy: 0.98592 | test_auc: 0.99845 |  0:03:48s\n",
      "epoch 77 | loss: 0.03767 | test_accuracy: 0.98696 | test_auc: 0.99842 |  0:03:51s\n",
      "epoch 78 | loss: 0.03584 | test_accuracy: 0.98644 | test_auc: 0.99859 |  0:03:54s\n",
      "epoch 79 | loss: 0.03718 | test_accuracy: 0.98505 | test_auc: 0.99797 |  0:03:57s\n",
      "epoch 80 | loss: 0.03777 | test_accuracy: 0.98575 | test_auc: 0.99646 |  0:04:00s\n",
      "epoch 81 | loss: 0.04021 | test_accuracy: 0.98679 | test_auc: 0.99847 |  0:04:03s\n",
      "epoch 82 | loss: 0.04488 | test_accuracy: 0.98575 | test_auc: 0.9977  |  0:04:05s\n",
      "epoch 83 | loss: 0.04121 | test_accuracy: 0.98609 | test_auc: 0.99834 |  0:04:08s\n",
      "epoch 84 | loss: 0.03731 | test_accuracy: 0.98714 | test_auc: 0.99862 |  0:04:11s\n",
      "epoch 85 | loss: 0.03678 | test_accuracy: 0.98731 | test_auc: 0.99842 |  0:04:14s\n",
      "epoch 86 | loss: 0.03614 | test_accuracy: 0.98575 | test_auc: 0.99848 |  0:04:17s\n",
      "epoch 87 | loss: 0.03564 | test_accuracy: 0.98592 | test_auc: 0.9986  |  0:04:20s\n",
      "epoch 88 | loss: 0.03644 | test_accuracy: 0.98731 | test_auc: 0.99842 |  0:04:23s\n",
      "epoch 89 | loss: 0.03491 | test_accuracy: 0.98731 | test_auc: 0.99857 |  0:04:26s\n",
      "epoch 90 | loss: 0.03499 | test_accuracy: 0.98731 | test_auc: 0.9986  |  0:04:29s\n",
      "epoch 91 | loss: 0.03584 | test_accuracy: 0.98696 | test_auc: 0.99855 |  0:04:32s\n",
      "epoch 92 | loss: 0.03847 | test_accuracy: 0.98662 | test_auc: 0.99848 |  0:04:35s\n",
      "epoch 93 | loss: 0.03827 | test_accuracy: 0.98575 | test_auc: 0.99842 |  0:04:37s\n",
      "epoch 94 | loss: 0.03738 | test_accuracy: 0.98523 | test_auc: 0.99856 |  0:04:40s\n",
      "epoch 95 | loss: 0.03719 | test_accuracy: 0.98714 | test_auc: 0.99863 |  0:04:43s\n",
      "epoch 96 | loss: 0.0374  | test_accuracy: 0.98696 | test_auc: 0.99853 |  0:04:46s\n",
      "epoch 97 | loss: 0.03562 | test_accuracy: 0.98714 | test_auc: 0.99853 |  0:04:49s\n",
      "epoch 98 | loss: 0.03584 | test_accuracy: 0.98575 | test_auc: 0.99837 |  0:04:52s\n",
      "epoch 99 | loss: 0.03548 | test_accuracy: 0.98714 | test_auc: 0.99862 |  0:04:55s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 95 and best_test_auc = 0.99863\n",
      "Training fold 4/5...\n",
      "epoch 0  | loss: 0.2952  | test_accuracy: 0.87172 | test_auc: 0.96561 |  0:00:02s\n",
      "epoch 1  | loss: 0.13345 | test_accuracy: 0.90527 | test_auc: 0.95299 |  0:00:05s\n",
      "epoch 2  | loss: 0.11057 | test_accuracy: 0.87328 | test_auc: 0.95407 |  0:00:08s\n",
      "epoch 3  | loss: 0.09652 | test_accuracy: 0.87971 | test_auc: 0.96988 |  0:00:11s\n",
      "epoch 4  | loss: 0.09701 | test_accuracy: 0.9263  | test_auc: 0.97967 |  0:00:14s\n",
      "epoch 5  | loss: 0.09463 | test_accuracy: 0.94733 | test_auc: 0.98623 |  0:00:17s\n",
      "epoch 6  | loss: 0.08148 | test_accuracy: 0.94994 | test_auc: 0.98853 |  0:00:19s\n",
      "epoch 7  | loss: 0.07271 | test_accuracy: 0.94612 | test_auc: 0.98853 |  0:00:22s\n",
      "epoch 8  | loss: 0.07254 | test_accuracy: 0.96089 | test_auc: 0.9909  |  0:00:25s\n",
      "epoch 9  | loss: 0.06862 | test_accuracy: 0.96384 | test_auc: 0.99528 |  0:00:28s\n",
      "epoch 10 | loss: 0.06698 | test_accuracy: 0.97584 | test_auc: 0.99572 |  0:00:31s\n",
      "epoch 11 | loss: 0.06751 | test_accuracy: 0.98001 | test_auc: 0.99584 |  0:00:34s\n",
      "epoch 12 | loss: 0.0811  | test_accuracy: 0.97445 | test_auc: 0.99611 |  0:00:36s\n",
      "epoch 13 | loss: 0.08164 | test_accuracy: 0.97462 | test_auc: 0.99658 |  0:00:39s\n",
      "epoch 14 | loss: 0.07531 | test_accuracy: 0.9741  | test_auc: 0.9966  |  0:00:42s\n",
      "epoch 15 | loss: 0.07266 | test_accuracy: 0.9748  | test_auc: 0.9967  |  0:00:45s\n",
      "epoch 16 | loss: 0.07106 | test_accuracy: 0.96975 | test_auc: 0.99632 |  0:00:48s\n",
      "epoch 17 | loss: 0.06845 | test_accuracy: 0.97497 | test_auc: 0.99699 |  0:00:51s\n",
      "epoch 18 | loss: 0.05927 | test_accuracy: 0.98071 | test_auc: 0.99728 |  0:00:54s\n",
      "epoch 19 | loss: 0.05259 | test_accuracy: 0.98175 | test_auc: 0.99726 |  0:00:57s\n",
      "epoch 20 | loss: 0.05234 | test_accuracy: 0.97775 | test_auc: 0.99722 |  0:01:00s\n",
      "epoch 21 | loss: 0.0535  | test_accuracy: 0.98175 | test_auc: 0.99715 |  0:01:02s\n",
      "epoch 22 | loss: 0.05288 | test_accuracy: 0.98053 | test_auc: 0.99721 |  0:01:05s\n",
      "epoch 23 | loss: 0.05152 | test_accuracy: 0.98088 | test_auc: 0.99747 |  0:01:08s\n",
      "epoch 24 | loss: 0.05913 | test_accuracy: 0.98001 | test_auc: 0.99651 |  0:01:11s\n",
      "epoch 25 | loss: 0.0678  | test_accuracy: 0.98157 | test_auc: 0.99678 |  0:01:14s\n",
      "epoch 26 | loss: 0.05753 | test_accuracy: 0.98314 | test_auc: 0.9971  |  0:01:17s\n",
      "epoch 27 | loss: 0.05303 | test_accuracy: 0.98088 | test_auc: 0.9966  |  0:01:20s\n",
      "epoch 28 | loss: 0.05187 | test_accuracy: 0.9821  | test_auc: 0.9971  |  0:01:23s\n",
      "epoch 29 | loss: 0.04676 | test_accuracy: 0.98331 | test_auc: 0.99742 |  0:01:26s\n",
      "epoch 30 | loss: 0.05283 | test_accuracy: 0.98105 | test_auc: 0.9972  |  0:01:29s\n",
      "epoch 31 | loss: 0.0554  | test_accuracy: 0.98314 | test_auc: 0.99722 |  0:01:32s\n",
      "epoch 32 | loss: 0.04916 | test_accuracy: 0.98331 | test_auc: 0.9974  |  0:01:35s\n",
      "epoch 33 | loss: 0.0456  | test_accuracy: 0.98505 | test_auc: 0.99751 |  0:01:38s\n",
      "epoch 34 | loss: 0.04705 | test_accuracy: 0.98557 | test_auc: 0.9976  |  0:01:40s\n",
      "epoch 35 | loss: 0.04613 | test_accuracy: 0.98453 | test_auc: 0.99763 |  0:01:43s\n",
      "epoch 36 | loss: 0.06412 | test_accuracy: 0.97758 | test_auc: 0.99608 |  0:01:46s\n",
      "epoch 37 | loss: 0.05785 | test_accuracy: 0.97966 | test_auc: 0.99692 |  0:01:49s\n",
      "epoch 38 | loss: 0.04913 | test_accuracy: 0.98383 | test_auc: 0.99752 |  0:01:52s\n",
      "epoch 39 | loss: 0.05325 | test_accuracy: 0.98001 | test_auc: 0.99705 |  0:01:55s\n",
      "epoch 40 | loss: 0.05248 | test_accuracy: 0.9847  | test_auc: 0.99743 |  0:01:58s\n",
      "epoch 41 | loss: 0.04911 | test_accuracy: 0.98349 | test_auc: 0.99748 |  0:02:01s\n",
      "epoch 42 | loss: 0.04506 | test_accuracy: 0.9847  | test_auc: 0.99745 |  0:02:04s\n",
      "epoch 43 | loss: 0.04328 | test_accuracy: 0.9847  | test_auc: 0.99776 |  0:02:07s\n",
      "epoch 44 | loss: 0.04956 | test_accuracy: 0.98349 | test_auc: 0.99749 |  0:02:09s\n",
      "epoch 45 | loss: 0.05817 | test_accuracy: 0.98175 | test_auc: 0.99652 |  0:02:12s\n",
      "epoch 46 | loss: 0.06189 | test_accuracy: 0.97984 | test_auc: 0.99689 |  0:02:15s\n",
      "epoch 47 | loss: 0.05841 | test_accuracy: 0.98105 | test_auc: 0.99685 |  0:02:18s\n",
      "epoch 48 | loss: 0.05702 | test_accuracy: 0.98227 | test_auc: 0.99603 |  0:02:21s\n",
      "epoch 49 | loss: 0.06899 | test_accuracy: 0.97845 | test_auc: 0.9963  |  0:02:24s\n",
      "epoch 50 | loss: 0.05642 | test_accuracy: 0.98314 | test_auc: 0.99637 |  0:02:27s\n",
      "epoch 51 | loss: 0.05063 | test_accuracy: 0.98436 | test_auc: 0.99714 |  0:02:29s\n",
      "epoch 52 | loss: 0.05001 | test_accuracy: 0.98488 | test_auc: 0.99739 |  0:02:32s\n",
      "epoch 53 | loss: 0.05125 | test_accuracy: 0.98505 | test_auc: 0.99729 |  0:02:35s\n",
      "epoch 54 | loss: 0.04871 | test_accuracy: 0.97723 | test_auc: 0.99667 |  0:02:38s\n",
      "epoch 55 | loss: 0.05491 | test_accuracy: 0.97897 | test_auc: 0.99711 |  0:02:41s\n",
      "epoch 56 | loss: 0.06175 | test_accuracy: 0.98227 | test_auc: 0.99673 |  0:02:44s\n",
      "epoch 57 | loss: 0.05502 | test_accuracy: 0.98314 | test_auc: 0.99693 |  0:02:47s\n",
      "epoch 58 | loss: 0.0563  | test_accuracy: 0.98331 | test_auc: 0.99651 |  0:02:49s\n",
      "epoch 59 | loss: 0.05364 | test_accuracy: 0.98036 | test_auc: 0.99568 |  0:02:52s\n",
      "epoch 60 | loss: 0.06074 | test_accuracy: 0.98175 | test_auc: 0.99589 |  0:02:55s\n",
      "epoch 61 | loss: 0.05931 | test_accuracy: 0.97827 | test_auc: 0.99581 |  0:02:58s\n",
      "epoch 62 | loss: 0.07103 | test_accuracy: 0.97532 | test_auc: 0.99545 |  0:03:01s\n",
      "epoch 63 | loss: 0.06445 | test_accuracy: 0.98157 | test_auc: 0.99618 |  0:03:04s\n",
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 43 and best_test_auc = 0.99776\n",
      "Training fold 5/5...\n",
      "epoch 0  | loss: 0.30572 | test_accuracy: 0.87346 | test_auc: 0.97132 |  0:00:02s\n",
      "epoch 1  | loss: 0.16478 | test_accuracy: 0.87937 | test_auc: 0.97511 |  0:00:05s\n",
      "epoch 2  | loss: 0.14078 | test_accuracy: 0.89449 | test_auc: 0.9766  |  0:00:08s\n",
      "epoch 3  | loss: 0.11956 | test_accuracy: 0.89623 | test_auc: 0.9813  |  0:00:11s\n",
      "epoch 4  | loss: 0.09827 | test_accuracy: 0.94368 | test_auc: 0.98309 |  0:00:14s\n",
      "epoch 5  | loss: 0.08897 | test_accuracy: 0.94525 | test_auc: 0.98774 |  0:00:17s\n",
      "epoch 6  | loss: 0.09471 | test_accuracy: 0.95394 | test_auc: 0.99121 |  0:00:19s\n",
      "epoch 7  | loss: 0.08014 | test_accuracy: 0.95846 | test_auc: 0.99203 |  0:00:22s\n",
      "epoch 8  | loss: 0.08468 | test_accuracy: 0.96072 | test_auc: 0.98812 |  0:00:25s\n",
      "epoch 9  | loss: 0.07905 | test_accuracy: 0.96524 | test_auc: 0.99396 |  0:00:28s\n",
      "epoch 10 | loss: 0.07811 | test_accuracy: 0.97132 | test_auc: 0.99431 |  0:00:31s\n",
      "epoch 11 | loss: 0.07204 | test_accuracy: 0.9708  | test_auc: 0.99564 |  0:00:34s\n",
      "epoch 12 | loss: 0.0842  | test_accuracy: 0.96871 | test_auc: 0.99458 |  0:00:36s\n",
      "epoch 13 | loss: 0.08769 | test_accuracy: 0.96906 | test_auc: 0.99558 |  0:00:39s\n",
      "epoch 14 | loss: 0.08515 | test_accuracy: 0.97062 | test_auc: 0.99511 |  0:00:42s\n",
      "epoch 15 | loss: 0.0729  | test_accuracy: 0.97775 | test_auc: 0.99707 |  0:00:45s\n",
      "epoch 16 | loss: 0.06917 | test_accuracy: 0.97758 | test_auc: 0.99538 |  0:00:48s\n",
      "epoch 17 | loss: 0.06655 | test_accuracy: 0.97932 | test_auc: 0.99705 |  0:00:51s\n",
      "epoch 18 | loss: 0.06335 | test_accuracy: 0.9781  | test_auc: 0.99728 |  0:00:54s\n",
      "epoch 19 | loss: 0.05976 | test_accuracy: 0.97914 | test_auc: 0.99788 |  0:00:57s\n",
      "epoch 20 | loss: 0.05512 | test_accuracy: 0.98297 | test_auc: 0.998   |  0:00:59s\n",
      "epoch 21 | loss: 0.05216 | test_accuracy: 0.98297 | test_auc: 0.99852 |  0:01:02s\n",
      "epoch 22 | loss: 0.05129 | test_accuracy: 0.98505 | test_auc: 0.99806 |  0:01:05s\n",
      "epoch 23 | loss: 0.06678 | test_accuracy: 0.97427 | test_auc: 0.99654 |  0:01:08s\n",
      "epoch 24 | loss: 0.06738 | test_accuracy: 0.98105 | test_auc: 0.99736 |  0:01:11s\n",
      "epoch 25 | loss: 0.05899 | test_accuracy: 0.98105 | test_auc: 0.99805 |  0:01:14s\n",
      "epoch 26 | loss: 0.06052 | test_accuracy: 0.98418 | test_auc: 0.9984  |  0:01:17s\n",
      "epoch 27 | loss: 0.0571  | test_accuracy: 0.98123 | test_auc: 0.99765 |  0:01:19s\n",
      "epoch 28 | loss: 0.05225 | test_accuracy: 0.98644 | test_auc: 0.99808 |  0:01:22s\n",
      "epoch 29 | loss: 0.04937 | test_accuracy: 0.98401 | test_auc: 0.9978  |  0:01:25s\n",
      "epoch 30 | loss: 0.049   | test_accuracy: 0.9847  | test_auc: 0.99795 |  0:01:28s\n",
      "epoch 31 | loss: 0.04686 | test_accuracy: 0.98575 | test_auc: 0.9981  |  0:01:31s\n",
      "epoch 32 | loss: 0.04514 | test_accuracy: 0.98731 | test_auc: 0.99811 |  0:01:34s\n",
      "epoch 33 | loss: 0.04292 | test_accuracy: 0.98662 | test_auc: 0.99826 |  0:01:36s\n",
      "epoch 34 | loss: 0.04233 | test_accuracy: 0.98592 | test_auc: 0.99838 |  0:01:39s\n",
      "epoch 35 | loss: 0.04155 | test_accuracy: 0.98783 | test_auc: 0.9983  |  0:01:42s\n",
      "epoch 36 | loss: 0.04288 | test_accuracy: 0.98644 | test_auc: 0.99849 |  0:01:45s\n",
      "epoch 37 | loss: 0.04187 | test_accuracy: 0.98609 | test_auc: 0.99853 |  0:01:48s\n",
      "epoch 38 | loss: 0.042   | test_accuracy: 0.98627 | test_auc: 0.99821 |  0:01:51s\n",
      "epoch 39 | loss: 0.04233 | test_accuracy: 0.98627 | test_auc: 0.99858 |  0:01:54s\n",
      "epoch 40 | loss: 0.0471  | test_accuracy: 0.98644 | test_auc: 0.99838 |  0:01:57s\n",
      "epoch 41 | loss: 0.04629 | test_accuracy: 0.98662 | test_auc: 0.99811 |  0:01:59s\n",
      "epoch 42 | loss: 0.04325 | test_accuracy: 0.98679 | test_auc: 0.99875 |  0:02:02s\n",
      "epoch 43 | loss: 0.04423 | test_accuracy: 0.98748 | test_auc: 0.99826 |  0:02:05s\n",
      "epoch 44 | loss: 0.04328 | test_accuracy: 0.98627 | test_auc: 0.99848 |  0:02:08s\n",
      "epoch 45 | loss: 0.04091 | test_accuracy: 0.98783 | test_auc: 0.99842 |  0:02:11s\n",
      "epoch 46 | loss: 0.04016 | test_accuracy: 0.98644 | test_auc: 0.99849 |  0:02:14s\n",
      "epoch 47 | loss: 0.03966 | test_accuracy: 0.98818 | test_auc: 0.9986  |  0:02:17s\n",
      "epoch 48 | loss: 0.03923 | test_accuracy: 0.98766 | test_auc: 0.99861 |  0:02:20s\n",
      "epoch 49 | loss: 0.0391  | test_accuracy: 0.98696 | test_auc: 0.99847 |  0:02:23s\n",
      "epoch 50 | loss: 0.04073 | test_accuracy: 0.98818 | test_auc: 0.99865 |  0:02:25s\n",
      "epoch 51 | loss: 0.04133 | test_accuracy: 0.98297 | test_auc: 0.99795 |  0:02:28s\n",
      "epoch 52 | loss: 0.04448 | test_accuracy: 0.98783 | test_auc: 0.99782 |  0:02:31s\n",
      "epoch 53 | loss: 0.04514 | test_accuracy: 0.98575 | test_auc: 0.99819 |  0:02:34s\n",
      "epoch 54 | loss: 0.04598 | test_accuracy: 0.98609 | test_auc: 0.99825 |  0:02:37s\n",
      "epoch 55 | loss: 0.04311 | test_accuracy: 0.98679 | test_auc: 0.99828 |  0:02:40s\n",
      "epoch 56 | loss: 0.04198 | test_accuracy: 0.98123 | test_auc: 0.99819 |  0:02:43s\n",
      "epoch 57 | loss: 0.04346 | test_accuracy: 0.98801 | test_auc: 0.99854 |  0:02:45s\n",
      "epoch 58 | loss: 0.04041 | test_accuracy: 0.98818 | test_auc: 0.99849 |  0:02:48s\n",
      "epoch 59 | loss: 0.03917 | test_accuracy: 0.98818 | test_auc: 0.99853 |  0:02:51s\n",
      "epoch 60 | loss: 0.0397  | test_accuracy: 0.98644 | test_auc: 0.99848 |  0:02:54s\n",
      "epoch 61 | loss: 0.03946 | test_accuracy: 0.98766 | test_auc: 0.99865 |  0:02:57s\n",
      "epoch 62 | loss: 0.03868 | test_accuracy: 0.98766 | test_auc: 0.99854 |  0:03:00s\n",
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 42 and best_test_auc = 0.99875\n",
      "\n",
      "Results for 6. Boruta:\n",
      "Average accuracy: 0.9863 ± 0.0009\n",
      "Average precision: 0.9902 ± 0.0034\n",
      "Average recall: 0.9711 ± 0.0027\n",
      "Average f1: 0.9806 ± 0.0010\n",
      "Average auc: 0.9829 ± 0.0009\n",
      "\n",
      "==================================================\n",
      "Processing 7. Correlation-based\n",
      "==================================================\n",
      "Selecting features using 7. Correlation-based...\n",
      "Top 10 features selected by 7. Correlation-based:\n",
      "1. Breathing Problem: 0.7502\n",
      "2. Fever: nan\n",
      "3. Dry Cough: nan\n",
      "4. Sore throat: 0.8549\n",
      "5. Abroad travel: 0.7081\n",
      "6. Attended Large Gathering: 0.6758\n",
      "7. Family working in Public Exposed Places: 0.6449\n",
      "8. Contact with COVID Patient: 0.6027\n",
      "9. Diabetes: 0.4719\n",
      "10. Heart Disease: 0.4197\n",
      "\n",
      "Training TabNet with features selected by 7. Correlation-based\n",
      "Training fold 1/5...\n",
      "epoch 0  | loss: 0.20158 | test_accuracy: 0.94821 | test_auc: 0.98783 |  0:00:02s\n",
      "epoch 1  | loss: 0.07981 | test_accuracy: 0.84272 | test_auc: 0.99092 |  0:00:05s\n",
      "epoch 2  | loss: 0.06843 | test_accuracy: 0.91571 | test_auc: 0.98442 |  0:00:08s\n",
      "epoch 3  | loss: 0.06732 | test_accuracy: 0.95881 | test_auc: 0.99542 |  0:00:11s\n",
      "epoch 4  | loss: 0.06872 | test_accuracy: 0.95829 | test_auc: 0.9962  |  0:00:14s\n",
      "epoch 5  | loss: 0.06256 | test_accuracy: 0.96263 | test_auc: 0.99616 |  0:00:16s\n",
      "epoch 6  | loss: 0.05828 | test_accuracy: 0.96194 | test_auc: 0.99628 |  0:00:19s\n",
      "epoch 7  | loss: 0.05592 | test_accuracy: 0.96403 | test_auc: 0.99734 |  0:00:22s\n",
      "epoch 8  | loss: 0.05626 | test_accuracy: 0.96733 | test_auc: 0.99715 |  0:00:25s\n",
      "epoch 9  | loss: 0.05414 | test_accuracy: 0.97619 | test_auc: 0.99741 |  0:00:28s\n",
      "epoch 10 | loss: 0.05232 | test_accuracy: 0.97584 | test_auc: 0.9975  |  0:00:31s\n",
      "epoch 11 | loss: 0.05353 | test_accuracy: 0.97619 | test_auc: 0.99784 |  0:00:33s\n",
      "epoch 12 | loss: 0.05181 | test_accuracy: 0.97619 | test_auc: 0.99774 |  0:00:36s\n",
      "epoch 13 | loss: 0.05005 | test_accuracy: 0.97341 | test_auc: 0.99762 |  0:00:39s\n",
      "epoch 14 | loss: 0.04953 | test_accuracy: 0.9788  | test_auc: 0.99791 |  0:00:42s\n",
      "epoch 15 | loss: 0.04957 | test_accuracy: 0.97619 | test_auc: 0.99785 |  0:00:45s\n",
      "epoch 16 | loss: 0.05054 | test_accuracy: 0.97845 | test_auc: 0.99784 |  0:00:48s\n",
      "epoch 17 | loss: 0.04971 | test_accuracy: 0.97619 | test_auc: 0.99792 |  0:00:50s\n",
      "epoch 18 | loss: 0.04907 | test_accuracy: 0.97619 | test_auc: 0.99779 |  0:00:53s\n",
      "epoch 19 | loss: 0.04928 | test_accuracy: 0.97567 | test_auc: 0.99775 |  0:00:56s\n",
      "epoch 20 | loss: 0.05375 | test_accuracy: 0.97445 | test_auc: 0.99762 |  0:00:59s\n",
      "epoch 21 | loss: 0.05142 | test_accuracy: 0.97619 | test_auc: 0.99804 |  0:01:02s\n",
      "epoch 22 | loss: 0.05069 | test_accuracy: 0.97619 | test_auc: 0.99772 |  0:01:05s\n",
      "epoch 23 | loss: 0.05131 | test_accuracy: 0.9755  | test_auc: 0.99767 |  0:01:08s\n",
      "epoch 24 | loss: 0.05184 | test_accuracy: 0.9781  | test_auc: 0.99781 |  0:01:11s\n",
      "epoch 25 | loss: 0.0493  | test_accuracy: 0.9788  | test_auc: 0.9979  |  0:01:14s\n",
      "epoch 26 | loss: 0.04954 | test_accuracy: 0.97619 | test_auc: 0.99791 |  0:01:17s\n",
      "epoch 27 | loss: 0.04896 | test_accuracy: 0.97358 | test_auc: 0.99791 |  0:01:19s\n",
      "epoch 28 | loss: 0.05052 | test_accuracy: 0.97828 | test_auc: 0.99777 |  0:01:22s\n",
      "epoch 29 | loss: 0.05183 | test_accuracy: 0.97828 | test_auc: 0.99774 |  0:01:25s\n",
      "epoch 30 | loss: 0.0496  | test_accuracy: 0.9788  | test_auc: 0.99771 |  0:01:28s\n",
      "epoch 31 | loss: 0.04985 | test_accuracy: 0.9788  | test_auc: 0.99786 |  0:01:31s\n",
      "epoch 32 | loss: 0.04816 | test_accuracy: 0.9788  | test_auc: 0.99791 |  0:01:34s\n",
      "epoch 33 | loss: 0.04838 | test_accuracy: 0.97602 | test_auc: 0.99795 |  0:01:36s\n",
      "epoch 34 | loss: 0.04804 | test_accuracy: 0.97949 | test_auc: 0.99798 |  0:01:39s\n",
      "epoch 35 | loss: 0.05009 | test_accuracy: 0.97619 | test_auc: 0.99776 |  0:01:42s\n",
      "epoch 36 | loss: 0.04744 | test_accuracy: 0.97532 | test_auc: 0.99786 |  0:01:45s\n",
      "epoch 37 | loss: 0.04653 | test_accuracy: 0.97949 | test_auc: 0.99817 |  0:01:48s\n",
      "epoch 38 | loss: 0.04652 | test_accuracy: 0.97532 | test_auc: 0.99803 |  0:01:50s\n",
      "epoch 39 | loss: 0.05118 | test_accuracy: 0.97254 | test_auc: 0.99763 |  0:01:53s\n",
      "epoch 40 | loss: 0.04933 | test_accuracy: 0.97984 | test_auc: 0.99806 |  0:01:56s\n",
      "epoch 41 | loss: 0.05018 | test_accuracy: 0.97949 | test_auc: 0.99796 |  0:01:59s\n",
      "epoch 42 | loss: 0.04949 | test_accuracy: 0.97689 | test_auc: 0.99793 |  0:02:02s\n",
      "epoch 43 | loss: 0.04878 | test_accuracy: 0.97671 | test_auc: 0.99819 |  0:02:04s\n",
      "epoch 44 | loss: 0.04747 | test_accuracy: 0.97949 | test_auc: 0.99813 |  0:02:07s\n",
      "epoch 45 | loss: 0.0474  | test_accuracy: 0.97914 | test_auc: 0.99813 |  0:02:10s\n",
      "epoch 46 | loss: 0.04732 | test_accuracy: 0.97949 | test_auc: 0.9982  |  0:02:13s\n",
      "epoch 47 | loss: 0.04637 | test_accuracy: 0.97619 | test_auc: 0.99814 |  0:02:15s\n",
      "epoch 48 | loss: 0.0466  | test_accuracy: 0.97949 | test_auc: 0.9982  |  0:02:18s\n",
      "epoch 49 | loss: 0.04626 | test_accuracy: 0.97949 | test_auc: 0.99821 |  0:02:21s\n",
      "epoch 50 | loss: 0.04561 | test_accuracy: 0.97949 | test_auc: 0.99823 |  0:02:24s\n",
      "epoch 51 | loss: 0.04643 | test_accuracy: 0.97723 | test_auc: 0.99818 |  0:02:27s\n",
      "epoch 52 | loss: 0.04576 | test_accuracy: 0.97949 | test_auc: 0.99818 |  0:02:30s\n",
      "epoch 53 | loss: 0.04563 | test_accuracy: 0.97949 | test_auc: 0.99821 |  0:02:33s\n",
      "epoch 54 | loss: 0.04696 | test_accuracy: 0.98001 | test_auc: 0.99818 |  0:02:35s\n",
      "epoch 55 | loss: 0.04626 | test_accuracy: 0.97654 | test_auc: 0.99802 |  0:02:38s\n",
      "epoch 56 | loss: 0.04814 | test_accuracy: 0.98001 | test_auc: 0.99776 |  0:02:41s\n",
      "epoch 57 | loss: 0.04956 | test_accuracy: 0.9788  | test_auc: 0.99795 |  0:02:44s\n",
      "epoch 58 | loss: 0.04776 | test_accuracy: 0.9788  | test_auc: 0.99797 |  0:02:47s\n",
      "epoch 59 | loss: 0.0467  | test_accuracy: 0.9788  | test_auc: 0.99802 |  0:02:50s\n",
      "epoch 60 | loss: 0.04564 | test_accuracy: 0.97949 | test_auc: 0.998   |  0:02:53s\n",
      "epoch 61 | loss: 0.04583 | test_accuracy: 0.97932 | test_auc: 0.99804 |  0:02:55s\n",
      "epoch 62 | loss: 0.04626 | test_accuracy: 0.9814  | test_auc: 0.99823 |  0:02:58s\n",
      "epoch 63 | loss: 0.04669 | test_accuracy: 0.97949 | test_auc: 0.99829 |  0:03:01s\n",
      "epoch 64 | loss: 0.04626 | test_accuracy: 0.98088 | test_auc: 0.99839 |  0:03:04s\n",
      "epoch 65 | loss: 0.04687 | test_accuracy: 0.9741  | test_auc: 0.99807 |  0:03:07s\n",
      "epoch 66 | loss: 0.05451 | test_accuracy: 0.97115 | test_auc: 0.99751 |  0:03:10s\n",
      "epoch 67 | loss: 0.05802 | test_accuracy: 0.97654 | test_auc: 0.99777 |  0:03:13s\n",
      "epoch 68 | loss: 0.05058 | test_accuracy: 0.9781  | test_auc: 0.99802 |  0:03:16s\n",
      "epoch 69 | loss: 0.04993 | test_accuracy: 0.97741 | test_auc: 0.99792 |  0:03:25s\n",
      "epoch 70 | loss: 0.05035 | test_accuracy: 0.97741 | test_auc: 0.99799 |  0:03:38s\n",
      "epoch 71 | loss: 0.04932 | test_accuracy: 0.97741 | test_auc: 0.99795 |  0:03:50s\n",
      "epoch 72 | loss: 0.04856 | test_accuracy: 0.97741 | test_auc: 0.99804 |  0:03:59s\n",
      "epoch 73 | loss: 0.04764 | test_accuracy: 0.97741 | test_auc: 0.99804 |  0:04:10s\n",
      "epoch 74 | loss: 0.04873 | test_accuracy: 0.97741 | test_auc: 0.99794 |  0:04:23s\n",
      "epoch 75 | loss: 0.04987 | test_accuracy: 0.97914 | test_auc: 0.99804 |  0:04:34s\n",
      "epoch 76 | loss: 0.04985 | test_accuracy: 0.97619 | test_auc: 0.99771 |  0:04:47s\n",
      "epoch 77 | loss: 0.05424 | test_accuracy: 0.97324 | test_auc: 0.99756 |  0:05:01s\n",
      "epoch 78 | loss: 0.05508 | test_accuracy: 0.97706 | test_auc: 0.99794 |  0:05:12s\n",
      "epoch 79 | loss: 0.05458 | test_accuracy: 0.97706 | test_auc: 0.99793 |  0:05:26s\n",
      "epoch 80 | loss: 0.05286 | test_accuracy: 0.97723 | test_auc: 0.99807 |  0:05:41s\n",
      "epoch 81 | loss: 0.04954 | test_accuracy: 0.9781  | test_auc: 0.99801 |  0:05:54s\n",
      "epoch 82 | loss: 0.04868 | test_accuracy: 0.9788  | test_auc: 0.998   |  0:06:07s\n",
      "epoch 83 | loss: 0.04903 | test_accuracy: 0.98019 | test_auc: 0.99803 |  0:06:17s\n",
      "epoch 84 | loss: 0.04765 | test_accuracy: 0.97949 | test_auc: 0.99804 |  0:06:31s\n",
      "\n",
      "Early stopping occurred at epoch 84 with best_epoch = 64 and best_test_auc = 0.99839\n",
      "Training fold 2/5...\n",
      "epoch 0  | loss: 0.18421 | test_accuracy: 0.94785 | test_auc: 0.98712 |  0:00:12s\n",
      "epoch 1  | loss: 0.07945 | test_accuracy: 0.94681 | test_auc: 0.99053 |  0:00:23s\n",
      "epoch 2  | loss: 0.06537 | test_accuracy: 0.94055 | test_auc: 0.99085 |  0:00:33s\n",
      "epoch 3  | loss: 0.06172 | test_accuracy: 0.95446 | test_auc: 0.99079 |  0:00:46s\n",
      "epoch 4  | loss: 0.0646  | test_accuracy: 0.94959 | test_auc: 0.9922  |  0:00:57s\n",
      "epoch 5  | loss: 0.06251 | test_accuracy: 0.95446 | test_auc: 0.99414 |  0:01:09s\n",
      "epoch 6  | loss: 0.05628 | test_accuracy: 0.96628 | test_auc: 0.99533 |  0:01:21s\n",
      "epoch 7  | loss: 0.05386 | test_accuracy: 0.96836 | test_auc: 0.99624 |  0:01:35s\n",
      "epoch 8  | loss: 0.05288 | test_accuracy: 0.97045 | test_auc: 0.99619 |  0:01:48s\n",
      "epoch 9  | loss: 0.05305 | test_accuracy: 0.96506 | test_auc: 0.99721 |  0:01:57s\n",
      "epoch 10 | loss: 0.04949 | test_accuracy: 0.97149 | test_auc: 0.99713 |  0:02:10s\n",
      "epoch 11 | loss: 0.04856 | test_accuracy: 0.97393 | test_auc: 0.99732 |  0:02:22s\n",
      "epoch 12 | loss: 0.04834 | test_accuracy: 0.97775 | test_auc: 0.99701 |  0:02:37s\n",
      "epoch 13 | loss: 0.04864 | test_accuracy: 0.97966 | test_auc: 0.99734 |  0:02:50s\n",
      "epoch 14 | loss: 0.04773 | test_accuracy: 0.98036 | test_auc: 0.99769 |  0:03:02s\n",
      "epoch 15 | loss: 0.05053 | test_accuracy: 0.98018 | test_auc: 0.99796 |  0:03:14s\n",
      "epoch 16 | loss: 0.05026 | test_accuracy: 0.97879 | test_auc: 0.99784 |  0:03:27s\n",
      "epoch 17 | loss: 0.0523  | test_accuracy: 0.97914 | test_auc: 0.99774 |  0:03:41s\n",
      "epoch 18 | loss: 0.05015 | test_accuracy: 0.97775 | test_auc: 0.998   |  0:03:57s\n",
      "epoch 19 | loss: 0.04898 | test_accuracy: 0.97862 | test_auc: 0.99782 |  0:04:08s\n",
      "epoch 20 | loss: 0.04963 | test_accuracy: 0.97966 | test_auc: 0.99803 |  0:04:21s\n",
      "epoch 21 | loss: 0.04686 | test_accuracy: 0.98105 | test_auc: 0.99798 |  0:04:33s\n",
      "epoch 22 | loss: 0.04689 | test_accuracy: 0.98018 | test_auc: 0.99809 |  0:04:47s\n",
      "epoch 23 | loss: 0.04756 | test_accuracy: 0.98001 | test_auc: 0.99792 |  0:05:02s\n",
      "epoch 24 | loss: 0.04818 | test_accuracy: 0.98018 | test_auc: 0.99803 |  0:05:13s\n",
      "epoch 25 | loss: 0.04726 | test_accuracy: 0.97949 | test_auc: 0.99806 |  0:05:24s\n",
      "epoch 26 | loss: 0.04636 | test_accuracy: 0.98018 | test_auc: 0.99812 |  0:05:36s\n",
      "epoch 27 | loss: 0.04652 | test_accuracy: 0.97966 | test_auc: 0.99817 |  0:05:46s\n",
      "epoch 28 | loss: 0.04633 | test_accuracy: 0.98018 | test_auc: 0.9981  |  0:06:00s\n",
      "epoch 29 | loss: 0.04682 | test_accuracy: 0.98105 | test_auc: 0.9981  |  0:06:13s\n",
      "epoch 30 | loss: 0.04683 | test_accuracy: 0.98053 | test_auc: 0.99799 |  0:06:25s\n",
      "epoch 31 | loss: 0.04663 | test_accuracy: 0.98036 | test_auc: 0.99827 |  0:06:38s\n",
      "epoch 32 | loss: 0.04608 | test_accuracy: 0.98157 | test_auc: 0.9982  |  0:06:53s\n",
      "epoch 33 | loss: 0.04578 | test_accuracy: 0.98088 | test_auc: 0.99803 |  0:07:06s\n",
      "epoch 34 | loss: 0.0463  | test_accuracy: 0.98279 | test_auc: 0.99817 |  0:07:20s\n",
      "epoch 35 | loss: 0.04861 | test_accuracy: 0.97723 | test_auc: 0.99795 |  0:07:31s\n",
      "epoch 36 | loss: 0.05059 | test_accuracy: 0.97514 | test_auc: 0.9977  |  0:07:44s\n",
      "epoch 37 | loss: 0.05382 | test_accuracy: 0.97653 | test_auc: 0.99787 |  0:07:59s\n",
      "epoch 38 | loss: 0.05018 | test_accuracy: 0.97845 | test_auc: 0.99805 |  0:08:14s\n",
      "epoch 39 | loss: 0.04826 | test_accuracy: 0.9781  | test_auc: 0.9981  |  0:08:25s\n",
      "epoch 40 | loss: 0.04864 | test_accuracy: 0.97845 | test_auc: 0.99786 |  0:08:33s\n",
      "epoch 41 | loss: 0.04721 | test_accuracy: 0.97949 | test_auc: 0.99805 |  0:08:44s\n",
      "epoch 42 | loss: 0.04785 | test_accuracy: 0.98001 | test_auc: 0.99809 |  0:08:59s\n",
      "epoch 43 | loss: 0.04804 | test_accuracy: 0.97862 | test_auc: 0.99809 |  0:09:10s\n",
      "epoch 44 | loss: 0.04749 | test_accuracy: 0.97653 | test_auc: 0.99782 |  0:09:22s\n",
      "epoch 45 | loss: 0.04835 | test_accuracy: 0.97932 | test_auc: 0.99806 |  0:09:32s\n",
      "epoch 46 | loss: 0.04745 | test_accuracy: 0.97932 | test_auc: 0.99803 |  0:09:42s\n",
      "epoch 47 | loss: 0.04758 | test_accuracy: 0.97897 | test_auc: 0.99801 |  0:09:55s\n",
      "epoch 48 | loss: 0.04692 | test_accuracy: 0.97949 | test_auc: 0.99806 |  0:10:10s\n",
      "epoch 49 | loss: 0.04649 | test_accuracy: 0.97792 | test_auc: 0.99804 |  0:10:25s\n",
      "epoch 50 | loss: 0.04711 | test_accuracy: 0.97966 | test_auc: 0.99791 |  0:10:38s\n",
      "epoch 51 | loss: 0.04726 | test_accuracy: 0.97932 | test_auc: 0.99806 |  0:10:52s\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 31 and best_test_auc = 0.99827\n",
      "Training fold 3/5...\n",
      "epoch 0  | loss: 0.19093 | test_accuracy: 0.87554 | test_auc: 0.92506 |  0:00:14s\n",
      "epoch 1  | loss: 0.0773  | test_accuracy: 0.89571 | test_auc: 0.9621  |  0:00:30s\n",
      "epoch 2  | loss: 0.0634  | test_accuracy: 0.89658 | test_auc: 0.98008 |  0:00:44s\n",
      "epoch 3  | loss: 0.05658 | test_accuracy: 0.90544 | test_auc: 0.98847 |  0:00:56s\n",
      "epoch 4  | loss: 0.05257 | test_accuracy: 0.96193 | test_auc: 0.99348 |  0:01:08s\n",
      "epoch 5  | loss: 0.05335 | test_accuracy: 0.92161 | test_auc: 0.99145 |  0:01:19s\n",
      "epoch 6  | loss: 0.05387 | test_accuracy: 0.93134 | test_auc: 0.99502 |  0:01:28s\n",
      "epoch 7  | loss: 0.05024 | test_accuracy: 0.97358 | test_auc: 0.99726 |  0:01:41s\n",
      "epoch 8  | loss: 0.05136 | test_accuracy: 0.97393 | test_auc: 0.99715 |  0:01:53s\n",
      "epoch 9  | loss: 0.04918 | test_accuracy: 0.9701  | test_auc: 0.9973  |  0:02:03s\n",
      "epoch 10 | loss: 0.04916 | test_accuracy: 0.97758 | test_auc: 0.99768 |  0:02:17s\n",
      "epoch 11 | loss: 0.04879 | test_accuracy: 0.97497 | test_auc: 0.99762 |  0:02:27s\n",
      "epoch 12 | loss: 0.04835 | test_accuracy: 0.9741  | test_auc: 0.99765 |  0:02:38s\n",
      "epoch 13 | loss: 0.04776 | test_accuracy: 0.97219 | test_auc: 0.99745 |  0:02:49s\n",
      "epoch 14 | loss: 0.04815 | test_accuracy: 0.97532 | test_auc: 0.99763 |  0:03:01s\n",
      "epoch 15 | loss: 0.04831 | test_accuracy: 0.97341 | test_auc: 0.9976  |  0:03:15s\n",
      "epoch 16 | loss: 0.05011 | test_accuracy: 0.97323 | test_auc: 0.99752 |  0:03:27s\n",
      "epoch 17 | loss: 0.05084 | test_accuracy: 0.97427 | test_auc: 0.99767 |  0:03:40s\n",
      "epoch 18 | loss: 0.04968 | test_accuracy: 0.97184 | test_auc: 0.99748 |  0:03:56s\n",
      "epoch 19 | loss: 0.04836 | test_accuracy: 0.97601 | test_auc: 0.99767 |  0:04:09s\n",
      "epoch 20 | loss: 0.04781 | test_accuracy: 0.97723 | test_auc: 0.99762 |  0:04:26s\n",
      "epoch 21 | loss: 0.04693 | test_accuracy: 0.97236 | test_auc: 0.99765 |  0:04:40s\n",
      "epoch 22 | loss: 0.04622 | test_accuracy: 0.97288 | test_auc: 0.9972  |  0:04:57s\n",
      "epoch 23 | loss: 0.04949 | test_accuracy: 0.97201 | test_auc: 0.99769 |  0:05:11s\n",
      "epoch 24 | loss: 0.04735 | test_accuracy: 0.97236 | test_auc: 0.99753 |  0:05:23s\n",
      "epoch 25 | loss: 0.04727 | test_accuracy: 0.97219 | test_auc: 0.99746 |  0:05:38s\n",
      "epoch 26 | loss: 0.04854 | test_accuracy: 0.9741  | test_auc: 0.9976  |  0:05:50s\n",
      "epoch 27 | loss: 0.04692 | test_accuracy: 0.97619 | test_auc: 0.99771 |  0:06:05s\n",
      "epoch 28 | loss: 0.04673 | test_accuracy: 0.97306 | test_auc: 0.99771 |  0:06:18s\n",
      "epoch 29 | loss: 0.04743 | test_accuracy: 0.97306 | test_auc: 0.99764 |  0:06:28s\n",
      "epoch 30 | loss: 0.04773 | test_accuracy: 0.97323 | test_auc: 0.9976  |  0:06:40s\n",
      "epoch 31 | loss: 0.04819 | test_accuracy: 0.97514 | test_auc: 0.99756 |  0:06:53s\n",
      "epoch 32 | loss: 0.04678 | test_accuracy: 0.97201 | test_auc: 0.99762 |  0:07:05s\n",
      "epoch 33 | loss: 0.04647 | test_accuracy: 0.97514 | test_auc: 0.99749 |  0:07:21s\n",
      "epoch 34 | loss: 0.0497  | test_accuracy: 0.97462 | test_auc: 0.99682 |  0:07:33s\n",
      "epoch 35 | loss: 0.04989 | test_accuracy: 0.9781  | test_auc: 0.99742 |  0:07:42s\n",
      "epoch 36 | loss: 0.04979 | test_accuracy: 0.97288 | test_auc: 0.99719 |  0:07:53s\n",
      "epoch 37 | loss: 0.04985 | test_accuracy: 0.97028 | test_auc: 0.99737 |  0:08:10s\n",
      "epoch 38 | loss: 0.05165 | test_accuracy: 0.97445 | test_auc: 0.99757 |  0:08:25s\n",
      "epoch 39 | loss: 0.05062 | test_accuracy: 0.97201 | test_auc: 0.99748 |  0:08:37s\n",
      "epoch 40 | loss: 0.05116 | test_accuracy: 0.96975 | test_auc: 0.99743 |  0:08:58s\n",
      "epoch 41 | loss: 0.0507  | test_accuracy: 0.9701  | test_auc: 0.99743 |  0:09:13s\n",
      "epoch 42 | loss: 0.04869 | test_accuracy: 0.97688 | test_auc: 0.99761 |  0:09:26s\n",
      "epoch 43 | loss: 0.04833 | test_accuracy: 0.97462 | test_auc: 0.99747 |  0:09:38s\n",
      "epoch 44 | loss: 0.04795 | test_accuracy: 0.97636 | test_auc: 0.99761 |  0:09:51s\n",
      "epoch 45 | loss: 0.0468  | test_accuracy: 0.97341 | test_auc: 0.99737 |  0:10:05s\n",
      "epoch 46 | loss: 0.04664 | test_accuracy: 0.97236 | test_auc: 0.99748 |  0:10:16s\n",
      "epoch 47 | loss: 0.0464  | test_accuracy: 0.97619 | test_auc: 0.99766 |  0:10:29s\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 27 and best_test_auc = 0.99771\n",
      "Training fold 4/5...\n",
      "epoch 0  | loss: 0.18794 | test_accuracy: 0.9409  | test_auc: 0.98926 |  0:00:14s\n",
      "epoch 1  | loss: 0.08543 | test_accuracy: 0.9409  | test_auc: 0.98574 |  0:00:26s\n",
      "epoch 2  | loss: 0.07251 | test_accuracy: 0.94872 | test_auc: 0.995   |  0:00:39s\n",
      "epoch 3  | loss: 0.06954 | test_accuracy: 0.94942 | test_auc: 0.99441 |  0:00:54s\n",
      "epoch 4  | loss: 0.06576 | test_accuracy: 0.95967 | test_auc: 0.99486 |  0:01:11s\n",
      "epoch 5  | loss: 0.06695 | test_accuracy: 0.96871 | test_auc: 0.99536 |  0:01:23s\n",
      "epoch 6  | loss: 0.06432 | test_accuracy: 0.95272 | test_auc: 0.99416 |  0:01:36s\n",
      "epoch 7  | loss: 0.06304 | test_accuracy: 0.95707 | test_auc: 0.99579 |  0:01:50s\n",
      "epoch 8  | loss: 0.06124 | test_accuracy: 0.97462 | test_auc: 0.99665 |  0:02:05s\n",
      "epoch 9  | loss: 0.06065 | test_accuracy: 0.9741  | test_auc: 0.9969  |  0:02:20s\n",
      "epoch 10 | loss: 0.05717 | test_accuracy: 0.97445 | test_auc: 0.99724 |  0:02:34s\n",
      "epoch 11 | loss: 0.05595 | test_accuracy: 0.9741  | test_auc: 0.99758 |  0:02:47s\n",
      "epoch 12 | loss: 0.05613 | test_accuracy: 0.97445 | test_auc: 0.99745 |  0:02:59s\n",
      "epoch 13 | loss: 0.05305 | test_accuracy: 0.97497 | test_auc: 0.99774 |  0:03:12s\n",
      "epoch 14 | loss: 0.05104 | test_accuracy: 0.97393 | test_auc: 0.99757 |  0:03:21s\n",
      "epoch 15 | loss: 0.05316 | test_accuracy: 0.97706 | test_auc: 0.99791 |  0:03:32s\n",
      "epoch 16 | loss: 0.05451 | test_accuracy: 0.97271 | test_auc: 0.99785 |  0:03:44s\n",
      "epoch 17 | loss: 0.05265 | test_accuracy: 0.97549 | test_auc: 0.99794 |  0:03:55s\n",
      "epoch 18 | loss: 0.0505  | test_accuracy: 0.97775 | test_auc: 0.99801 |  0:04:06s\n",
      "epoch 19 | loss: 0.05031 | test_accuracy: 0.97566 | test_auc: 0.99799 |  0:04:18s\n",
      "epoch 20 | loss: 0.05032 | test_accuracy: 0.97271 | test_auc: 0.9979  |  0:04:30s\n",
      "epoch 21 | loss: 0.05057 | test_accuracy: 0.97949 | test_auc: 0.99801 |  0:04:41s\n",
      "epoch 22 | loss: 0.04861 | test_accuracy: 0.98192 | test_auc: 0.99803 |  0:04:55s\n",
      "epoch 23 | loss: 0.05056 | test_accuracy: 0.97775 | test_auc: 0.99795 |  0:05:08s\n",
      "epoch 24 | loss: 0.0526  | test_accuracy: 0.97897 | test_auc: 0.99806 |  0:05:24s\n",
      "epoch 25 | loss: 0.04861 | test_accuracy: 0.97845 | test_auc: 0.99812 |  0:05:38s\n",
      "epoch 26 | loss: 0.04783 | test_accuracy: 0.97932 | test_auc: 0.9981  |  0:05:53s\n",
      "epoch 27 | loss: 0.04614 | test_accuracy: 0.97862 | test_auc: 0.99816 |  0:06:08s\n",
      "epoch 28 | loss: 0.04784 | test_accuracy: 0.97845 | test_auc: 0.99811 |  0:06:22s\n",
      "epoch 29 | loss: 0.04784 | test_accuracy: 0.98036 | test_auc: 0.99816 |  0:06:37s\n",
      "epoch 30 | loss: 0.04657 | test_accuracy: 0.98053 | test_auc: 0.99819 |  0:06:49s\n",
      "epoch 31 | loss: 0.04796 | test_accuracy: 0.97949 | test_auc: 0.998   |  0:07:01s\n",
      "epoch 32 | loss: 0.04667 | test_accuracy: 0.98053 | test_auc: 0.99812 |  0:07:11s\n",
      "epoch 33 | loss: 0.04772 | test_accuracy: 0.97827 | test_auc: 0.99802 |  0:07:23s\n",
      "epoch 34 | loss: 0.04849 | test_accuracy: 0.97879 | test_auc: 0.99811 |  0:07:38s\n",
      "epoch 35 | loss: 0.04756 | test_accuracy: 0.97879 | test_auc: 0.99811 |  0:07:51s\n",
      "epoch 36 | loss: 0.04754 | test_accuracy: 0.97879 | test_auc: 0.99813 |  0:08:04s\n",
      "epoch 37 | loss: 0.04695 | test_accuracy: 0.97879 | test_auc: 0.99816 |  0:08:18s\n",
      "epoch 38 | loss: 0.04575 | test_accuracy: 0.97949 | test_auc: 0.99808 |  0:08:30s\n",
      "epoch 39 | loss: 0.04642 | test_accuracy: 0.97845 | test_auc: 0.99816 |  0:08:44s\n",
      "epoch 40 | loss: 0.05518 | test_accuracy: 0.97236 | test_auc: 0.99806 |  0:08:57s\n",
      "epoch 41 | loss: 0.05214 | test_accuracy: 0.97879 | test_auc: 0.99817 |  0:09:12s\n",
      "epoch 42 | loss: 0.0473  | test_accuracy: 0.97845 | test_auc: 0.99809 |  0:09:26s\n",
      "epoch 43 | loss: 0.04708 | test_accuracy: 0.97845 | test_auc: 0.99815 |  0:09:39s\n",
      "epoch 44 | loss: 0.04691 | test_accuracy: 0.97984 | test_auc: 0.99803 |  0:09:53s\n",
      "epoch 45 | loss: 0.0466  | test_accuracy: 0.97879 | test_auc: 0.99809 |  0:10:03s\n",
      "epoch 46 | loss: 0.04682 | test_accuracy: 0.97862 | test_auc: 0.9981  |  0:10:18s\n",
      "epoch 47 | loss: 0.04704 | test_accuracy: 0.97984 | test_auc: 0.99817 |  0:10:32s\n",
      "epoch 48 | loss: 0.046   | test_accuracy: 0.98105 | test_auc: 0.99817 |  0:10:47s\n",
      "epoch 49 | loss: 0.04656 | test_accuracy: 0.97949 | test_auc: 0.99812 |  0:10:58s\n",
      "epoch 50 | loss: 0.04561 | test_accuracy: 0.97879 | test_auc: 0.99815 |  0:11:09s\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 30 and best_test_auc = 0.99819\n",
      "Training fold 5/5...\n",
      "epoch 0  | loss: 0.22044 | test_accuracy: 0.92613 | test_auc: 0.97743 |  0:00:12s\n",
      "epoch 1  | loss: 0.08494 | test_accuracy: 0.89849 | test_auc: 0.95517 |  0:00:24s\n",
      "epoch 2  | loss: 0.06837 | test_accuracy: 0.91431 | test_auc: 0.97375 |  0:00:36s\n",
      "epoch 3  | loss: 0.06418 | test_accuracy: 0.91778 | test_auc: 0.98685 |  0:00:50s\n",
      "epoch 4  | loss: 0.06006 | test_accuracy: 0.95481 | test_auc: 0.99016 |  0:01:02s\n",
      "epoch 5  | loss: 0.05685 | test_accuracy: 0.96193 | test_auc: 0.9898  |  0:01:15s\n",
      "epoch 6  | loss: 0.0559  | test_accuracy: 0.97914 | test_auc: 0.99204 |  0:01:29s\n",
      "epoch 7  | loss: 0.05601 | test_accuracy: 0.96993 | test_auc: 0.99429 |  0:01:43s\n",
      "epoch 8  | loss: 0.05446 | test_accuracy: 0.98262 | test_auc: 0.99375 |  0:01:58s\n",
      "epoch 9  | loss: 0.05362 | test_accuracy: 0.98227 | test_auc: 0.99376 |  0:02:08s\n",
      "epoch 10 | loss: 0.05311 | test_accuracy: 0.98192 | test_auc: 0.99256 |  0:02:22s\n",
      "epoch 11 | loss: 0.05257 | test_accuracy: 0.98297 | test_auc: 0.99778 |  0:02:36s\n",
      "epoch 12 | loss: 0.05172 | test_accuracy: 0.98401 | test_auc: 0.99796 |  0:02:50s\n",
      "epoch 13 | loss: 0.0534  | test_accuracy: 0.98331 | test_auc: 0.99823 |  0:03:07s\n",
      "epoch 14 | loss: 0.05444 | test_accuracy: 0.98349 | test_auc: 0.99859 |  0:03:19s\n",
      "epoch 15 | loss: 0.05131 | test_accuracy: 0.98331 | test_auc: 0.99855 |  0:03:32s\n",
      "epoch 16 | loss: 0.05026 | test_accuracy: 0.98349 | test_auc: 0.99849 |  0:03:45s\n",
      "epoch 17 | loss: 0.04991 | test_accuracy: 0.98418 | test_auc: 0.99858 |  0:03:59s\n",
      "epoch 18 | loss: 0.04908 | test_accuracy: 0.9847  | test_auc: 0.99877 |  0:04:12s\n",
      "epoch 19 | loss: 0.04754 | test_accuracy: 0.9847  | test_auc: 0.9987  |  0:04:23s\n",
      "epoch 20 | loss: 0.04999 | test_accuracy: 0.98488 | test_auc: 0.99873 |  0:04:36s\n",
      "epoch 21 | loss: 0.04918 | test_accuracy: 0.9854  | test_auc: 0.99864 |  0:04:46s\n",
      "epoch 22 | loss: 0.04741 | test_accuracy: 0.98488 | test_auc: 0.99866 |  0:04:59s\n",
      "epoch 23 | loss: 0.04737 | test_accuracy: 0.98505 | test_auc: 0.99873 |  0:05:13s\n",
      "epoch 24 | loss: 0.04673 | test_accuracy: 0.98523 | test_auc: 0.99876 |  0:05:26s\n",
      "epoch 25 | loss: 0.04716 | test_accuracy: 0.98523 | test_auc: 0.99868 |  0:05:40s\n",
      "epoch 26 | loss: 0.04715 | test_accuracy: 0.98488 | test_auc: 0.99878 |  0:05:55s\n",
      "epoch 27 | loss: 0.04826 | test_accuracy: 0.98453 | test_auc: 0.99864 |  0:06:09s\n",
      "epoch 28 | loss: 0.04828 | test_accuracy: 0.98383 | test_auc: 0.99873 |  0:06:23s\n",
      "epoch 29 | loss: 0.04885 | test_accuracy: 0.98488 | test_auc: 0.99878 |  0:06:33s\n",
      "epoch 30 | loss: 0.04738 | test_accuracy: 0.98488 | test_auc: 0.99802 |  0:06:48s\n",
      "epoch 31 | loss: 0.04704 | test_accuracy: 0.98453 | test_auc: 0.9981  |  0:07:03s\n",
      "epoch 32 | loss: 0.0466  | test_accuracy: 0.98505 | test_auc: 0.99877 |  0:07:19s\n",
      "epoch 33 | loss: 0.04797 | test_accuracy: 0.98436 | test_auc: 0.99827 |  0:07:33s\n",
      "epoch 34 | loss: 0.05101 | test_accuracy: 0.9847  | test_auc: 0.99799 |  0:07:44s\n",
      "epoch 35 | loss: 0.04911 | test_accuracy: 0.98488 | test_auc: 0.99865 |  0:07:59s\n",
      "epoch 36 | loss: 0.0479  | test_accuracy: 0.9847  | test_auc: 0.99862 |  0:08:13s\n",
      "epoch 37 | loss: 0.04697 | test_accuracy: 0.9854  | test_auc: 0.99874 |  0:08:28s\n",
      "epoch 38 | loss: 0.0462  | test_accuracy: 0.9854  | test_auc: 0.99875 |  0:08:41s\n",
      "epoch 39 | loss: 0.04619 | test_accuracy: 0.9854  | test_auc: 0.99881 |  0:08:54s\n",
      "epoch 40 | loss: 0.04596 | test_accuracy: 0.9854  | test_auc: 0.99879 |  0:09:08s\n",
      "epoch 41 | loss: 0.04621 | test_accuracy: 0.9854  | test_auc: 0.99876 |  0:09:22s\n",
      "epoch 42 | loss: 0.04622 | test_accuracy: 0.98523 | test_auc: 0.99874 |  0:09:35s\n",
      "epoch 43 | loss: 0.04637 | test_accuracy: 0.9854  | test_auc: 0.99872 |  0:09:48s\n",
      "epoch 44 | loss: 0.04599 | test_accuracy: 0.9854  | test_auc: 0.99879 |  0:10:01s\n",
      "epoch 45 | loss: 0.04612 | test_accuracy: 0.98488 | test_auc: 0.99883 |  0:10:14s\n",
      "epoch 46 | loss: 0.04588 | test_accuracy: 0.98505 | test_auc: 0.99875 |  0:10:30s\n",
      "epoch 47 | loss: 0.04589 | test_accuracy: 0.9854  | test_auc: 0.99877 |  0:10:45s\n",
      "epoch 48 | loss: 0.05016 | test_accuracy: 0.98331 | test_auc: 0.99862 |  0:10:57s\n",
      "epoch 49 | loss: 0.05027 | test_accuracy: 0.9847  | test_auc: 0.99864 |  0:11:10s\n",
      "epoch 50 | loss: 0.05163 | test_accuracy: 0.98331 | test_auc: 0.99868 |  0:11:25s\n",
      "epoch 51 | loss: 0.04982 | test_accuracy: 0.98436 | test_auc: 0.99856 |  0:11:38s\n",
      "epoch 52 | loss: 0.04691 | test_accuracy: 0.98523 | test_auc: 0.99873 |  0:11:50s\n",
      "epoch 53 | loss: 0.04692 | test_accuracy: 0.9854  | test_auc: 0.99873 |  0:12:01s\n",
      "epoch 54 | loss: 0.04625 | test_accuracy: 0.98523 | test_auc: 0.99879 |  0:12:15s\n",
      "epoch 55 | loss: 0.04642 | test_accuracy: 0.98505 | test_auc: 0.9987  |  0:12:28s\n",
      "epoch 56 | loss: 0.04588 | test_accuracy: 0.98401 | test_auc: 0.99876 |  0:12:41s\n",
      "epoch 57 | loss: 0.04578 | test_accuracy: 0.9854  | test_auc: 0.99879 |  0:12:55s\n",
      "epoch 58 | loss: 0.04573 | test_accuracy: 0.98488 | test_auc: 0.99877 |  0:13:07s\n",
      "epoch 59 | loss: 0.04521 | test_accuracy: 0.98505 | test_auc: 0.99879 |  0:13:21s\n",
      "epoch 60 | loss: 0.04571 | test_accuracy: 0.98488 | test_auc: 0.99879 |  0:13:36s\n",
      "epoch 61 | loss: 0.04626 | test_accuracy: 0.98418 | test_auc: 0.99874 |  0:13:51s\n",
      "epoch 62 | loss: 0.04644 | test_accuracy: 0.98401 | test_auc: 0.99874 |  0:14:06s\n",
      "epoch 63 | loss: 0.04728 | test_accuracy: 0.98383 | test_auc: 0.99875 |  0:14:18s\n",
      "epoch 64 | loss: 0.04621 | test_accuracy: 0.9854  | test_auc: 0.99877 |  0:14:34s\n",
      "epoch 65 | loss: 0.04544 | test_accuracy: 0.98453 | test_auc: 0.99883 |  0:14:49s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_test_auc = 0.99883\n",
      "\n",
      "Results for 7. Correlation-based:\n",
      "Average accuracy: 0.9806 ± 0.0028\n",
      "Average precision: 0.9795 ± 0.0045\n",
      "Average recall: 0.9656 ± 0.0075\n",
      "Average f1: 0.9725 ± 0.0041\n",
      "Average auc: 0.9772 ± 0.0037\n",
      "\n",
      "==================================================\n",
      "Processing 8. Sequential Forward Selection\n",
      "==================================================\n",
      "Selecting features using 8. Sequential Forward Selection...\n",
      "Top 10 features selected by 8. Sequential Forward Selection:\n",
      "1. Fever: 1.0000\n",
      "2. Dry Cough: 1.0000\n",
      "3. Sore throat: 1.0000\n",
      "4. Running Nose: 1.0000\n",
      "5. Asthma: 1.0000\n",
      "6. Chronic Lung Disease: 1.0000\n",
      "7. Abroad travel: 1.0000\n",
      "8. Attended Large Gathering: 1.0000\n",
      "9. Wearing Masks: 1.0000\n",
      "10. Sanitization from Market: 1.0000\n",
      "\n",
      "Training TabNet with features selected by 8. Sequential Forward Selection\n",
      "Training fold 1/5...\n",
      "epoch 0  | loss: 0.2736  | test_accuracy: 0.63365 | test_auc: 0.91614 |  0:00:02s\n",
      "epoch 1  | loss: 0.11639 | test_accuracy: 0.38356 | test_auc: 0.95738 |  0:00:06s\n",
      "epoch 2  | loss: 0.10722 | test_accuracy: 0.54675 | test_auc: 0.95971 |  0:00:09s\n",
      "epoch 3  | loss: 0.09994 | test_accuracy: 0.66875 | test_auc: 0.96593 |  0:00:12s\n",
      "epoch 4  | loss: 0.09552 | test_accuracy: 0.66371 | test_auc: 0.96962 |  0:00:15s\n",
      "epoch 5  | loss: 0.09525 | test_accuracy: 0.94856 | test_auc: 0.97002 |  0:00:17s\n",
      "epoch 6  | loss: 0.09508 | test_accuracy: 0.95273 | test_auc: 0.97741 |  0:00:20s\n",
      "epoch 7  | loss: 0.0936  | test_accuracy: 0.95273 | test_auc: 0.98245 |  0:00:23s\n",
      "epoch 8  | loss: 0.09313 | test_accuracy: 0.95342 | test_auc: 0.98919 |  0:00:26s\n",
      "epoch 9  | loss: 0.09477 | test_accuracy: 0.95395 | test_auc: 0.98444 |  0:00:29s\n",
      "epoch 10 | loss: 0.09541 | test_accuracy: 0.95395 | test_auc: 0.98889 |  0:00:32s\n",
      "epoch 11 | loss: 0.09543 | test_accuracy: 0.95499 | test_auc: 0.9909  |  0:00:35s\n",
      "epoch 12 | loss: 0.09439 | test_accuracy: 0.95551 | test_auc: 0.99028 |  0:00:38s\n",
      "epoch 13 | loss: 0.09356 | test_accuracy: 0.95499 | test_auc: 0.991   |  0:00:41s\n",
      "epoch 14 | loss: 0.09316 | test_accuracy: 0.95742 | test_auc: 0.99154 |  0:00:43s\n",
      "epoch 15 | loss: 0.09392 | test_accuracy: 0.95499 | test_auc: 0.99118 |  0:00:46s\n",
      "epoch 16 | loss: 0.09337 | test_accuracy: 0.95499 | test_auc: 0.99129 |  0:00:49s\n",
      "epoch 17 | loss: 0.09452 | test_accuracy: 0.95551 | test_auc: 0.99063 |  0:00:52s\n",
      "epoch 18 | loss: 0.10034 | test_accuracy: 0.95342 | test_auc: 0.99046 |  0:00:55s\n",
      "epoch 19 | loss: 0.09956 | test_accuracy: 0.95395 | test_auc: 0.9907  |  0:00:58s\n",
      "epoch 20 | loss: 0.09822 | test_accuracy: 0.95342 | test_auc: 0.99078 |  0:01:01s\n",
      "epoch 21 | loss: 0.09576 | test_accuracy: 0.95499 | test_auc: 0.9892  |  0:01:04s\n",
      "epoch 22 | loss: 0.09363 | test_accuracy: 0.95499 | test_auc: 0.99131 |  0:01:06s\n",
      "epoch 23 | loss: 0.0924  | test_accuracy: 0.95499 | test_auc: 0.98934 |  0:01:09s\n",
      "epoch 24 | loss: 0.09197 | test_accuracy: 0.95499 | test_auc: 0.99174 |  0:01:12s\n",
      "epoch 25 | loss: 0.09204 | test_accuracy: 0.9562  | test_auc: 0.99104 |  0:01:15s\n",
      "epoch 26 | loss: 0.09217 | test_accuracy: 0.95499 | test_auc: 0.9914  |  0:01:18s\n",
      "epoch 27 | loss: 0.09172 | test_accuracy: 0.95499 | test_auc: 0.99151 |  0:01:21s\n",
      "epoch 28 | loss: 0.09295 | test_accuracy: 0.95551 | test_auc: 0.99157 |  0:01:24s\n",
      "epoch 29 | loss: 0.09248 | test_accuracy: 0.95499 | test_auc: 0.99141 |  0:01:27s\n",
      "epoch 30 | loss: 0.09272 | test_accuracy: 0.95499 | test_auc: 0.99119 |  0:01:30s\n",
      "epoch 31 | loss: 0.09223 | test_accuracy: 0.9562  | test_auc: 0.99152 |  0:01:33s\n",
      "epoch 32 | loss: 0.09184 | test_accuracy: 0.95673 | test_auc: 0.9918  |  0:01:36s\n",
      "epoch 33 | loss: 0.09212 | test_accuracy: 0.95673 | test_auc: 0.99157 |  0:01:39s\n",
      "epoch 34 | loss: 0.09174 | test_accuracy: 0.95673 | test_auc: 0.99143 |  0:01:41s\n",
      "epoch 35 | loss: 0.09222 | test_accuracy: 0.95673 | test_auc: 0.9913  |  0:01:44s\n",
      "epoch 36 | loss: 0.09175 | test_accuracy: 0.9562  | test_auc: 0.99154 |  0:01:47s\n",
      "epoch 37 | loss: 0.09229 | test_accuracy: 0.9562  | test_auc: 0.98992 |  0:01:50s\n",
      "epoch 38 | loss: 0.09297 | test_accuracy: 0.95499 | test_auc: 0.98947 |  0:01:53s\n",
      "epoch 39 | loss: 0.09469 | test_accuracy: 0.95499 | test_auc: 0.99111 |  0:01:56s\n",
      "epoch 40 | loss: 0.09254 | test_accuracy: 0.95499 | test_auc: 0.99097 |  0:01:59s\n",
      "epoch 41 | loss: 0.09223 | test_accuracy: 0.95499 | test_auc: 0.9916  |  0:02:02s\n",
      "epoch 42 | loss: 0.09182 | test_accuracy: 0.95499 | test_auc: 0.99145 |  0:02:05s\n",
      "epoch 43 | loss: 0.0909  | test_accuracy: 0.95551 | test_auc: 0.99157 |  0:02:07s\n",
      "epoch 44 | loss: 0.092   | test_accuracy: 0.95499 | test_auc: 0.99141 |  0:02:10s\n",
      "epoch 45 | loss: 0.09154 | test_accuracy: 0.95499 | test_auc: 0.99163 |  0:02:13s\n",
      "epoch 46 | loss: 0.09178 | test_accuracy: 0.95499 | test_auc: 0.99104 |  0:02:16s\n",
      "epoch 47 | loss: 0.09177 | test_accuracy: 0.95499 | test_auc: 0.99167 |  0:02:19s\n",
      "epoch 48 | loss: 0.09144 | test_accuracy: 0.95499 | test_auc: 0.99165 |  0:02:22s\n",
      "epoch 49 | loss: 0.09157 | test_accuracy: 0.9562  | test_auc: 0.99162 |  0:02:25s\n",
      "epoch 50 | loss: 0.09167 | test_accuracy: 0.95499 | test_auc: 0.99153 |  0:02:28s\n",
      "epoch 51 | loss: 0.09187 | test_accuracy: 0.95499 | test_auc: 0.9915  |  0:02:31s\n",
      "epoch 52 | loss: 0.0918  | test_accuracy: 0.95499 | test_auc: 0.99158 |  0:02:34s\n",
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 32 and best_test_auc = 0.9918\n",
      "Training fold 2/5...\n",
      "epoch 0  | loss: 0.27165 | test_accuracy: 0.93777 | test_auc: 0.97304 |  0:00:02s\n",
      "epoch 1  | loss: 0.12424 | test_accuracy: 0.55832 | test_auc: 0.90126 |  0:00:05s\n",
      "epoch 2  | loss: 0.10526 | test_accuracy: 0.93881 | test_auc: 0.95461 |  0:00:08s\n",
      "epoch 3  | loss: 0.10111 | test_accuracy: 0.63689 | test_auc: 0.96631 |  0:00:11s\n",
      "epoch 4  | loss: 0.09928 | test_accuracy: 0.94924 | test_auc: 0.97807 |  0:00:15s\n",
      "epoch 5  | loss: 0.09628 | test_accuracy: 0.94994 | test_auc: 0.98029 |  0:00:17s\n",
      "epoch 6  | loss: 0.09516 | test_accuracy: 0.95741 | test_auc: 0.98396 |  0:00:21s\n",
      "epoch 7  | loss: 0.09437 | test_accuracy: 0.95672 | test_auc: 0.97345 |  0:00:24s\n",
      "epoch 8  | loss: 0.09379 | test_accuracy: 0.95376 | test_auc: 0.98444 |  0:00:27s\n",
      "epoch 9  | loss: 0.09448 | test_accuracy: 0.95585 | test_auc: 0.98655 |  0:00:30s\n",
      "epoch 10 | loss: 0.09433 | test_accuracy: 0.95237 | test_auc: 0.98875 |  0:00:33s\n",
      "epoch 11 | loss: 0.09555 | test_accuracy: 0.95967 | test_auc: 0.99058 |  0:00:36s\n",
      "epoch 12 | loss: 0.09908 | test_accuracy: 0.9562  | test_auc: 0.99026 |  0:00:39s\n",
      "epoch 13 | loss: 0.10057 | test_accuracy: 0.95515 | test_auc: 0.99069 |  0:00:42s\n",
      "epoch 14 | loss: 0.09629 | test_accuracy: 0.9562  | test_auc: 0.99113 |  0:00:45s\n",
      "epoch 15 | loss: 0.09476 | test_accuracy: 0.95707 | test_auc: 0.99158 |  0:00:48s\n",
      "epoch 16 | loss: 0.09478 | test_accuracy: 0.95707 | test_auc: 0.99178 |  0:00:51s\n",
      "epoch 17 | loss: 0.09352 | test_accuracy: 0.95637 | test_auc: 0.99158 |  0:00:55s\n",
      "epoch 18 | loss: 0.09375 | test_accuracy: 0.95707 | test_auc: 0.99167 |  0:00:58s\n",
      "epoch 19 | loss: 0.09414 | test_accuracy: 0.95707 | test_auc: 0.99187 |  0:01:01s\n",
      "epoch 20 | loss: 0.09364 | test_accuracy: 0.95637 | test_auc: 0.99173 |  0:01:04s\n",
      "epoch 21 | loss: 0.09292 | test_accuracy: 0.95463 | test_auc: 0.99175 |  0:01:07s\n",
      "epoch 22 | loss: 0.09297 | test_accuracy: 0.95637 | test_auc: 0.99152 |  0:01:10s\n",
      "epoch 23 | loss: 0.09279 | test_accuracy: 0.95707 | test_auc: 0.99173 |  0:01:13s\n",
      "epoch 24 | loss: 0.09283 | test_accuracy: 0.95463 | test_auc: 0.99103 |  0:01:16s\n",
      "epoch 25 | loss: 0.09269 | test_accuracy: 0.95446 | test_auc: 0.9918  |  0:01:19s\n",
      "epoch 26 | loss: 0.09285 | test_accuracy: 0.95707 | test_auc: 0.99185 |  0:01:22s\n",
      "epoch 27 | loss: 0.09296 | test_accuracy: 0.95707 | test_auc: 0.99188 |  0:01:25s\n",
      "epoch 28 | loss: 0.09348 | test_accuracy: 0.95707 | test_auc: 0.99185 |  0:01:28s\n",
      "epoch 29 | loss: 0.09307 | test_accuracy: 0.95463 | test_auc: 0.99186 |  0:01:31s\n",
      "epoch 30 | loss: 0.09312 | test_accuracy: 0.95463 | test_auc: 0.99127 |  0:01:34s\n",
      "epoch 31 | loss: 0.09316 | test_accuracy: 0.95463 | test_auc: 0.99159 |  0:01:37s\n",
      "epoch 32 | loss: 0.09294 | test_accuracy: 0.95724 | test_auc: 0.99199 |  0:01:39s\n",
      "epoch 33 | loss: 0.09261 | test_accuracy: 0.95707 | test_auc: 0.99181 |  0:01:42s\n",
      "epoch 34 | loss: 0.09305 | test_accuracy: 0.95707 | test_auc: 0.99183 |  0:01:45s\n",
      "epoch 35 | loss: 0.09263 | test_accuracy: 0.95463 | test_auc: 0.9915  |  0:01:48s\n",
      "epoch 36 | loss: 0.0928  | test_accuracy: 0.95689 | test_auc: 0.992   |  0:01:51s\n",
      "epoch 37 | loss: 0.09271 | test_accuracy: 0.95689 | test_auc: 0.99187 |  0:01:54s\n",
      "epoch 38 | loss: 0.09269 | test_accuracy: 0.95707 | test_auc: 0.9919  |  0:01:57s\n",
      "epoch 39 | loss: 0.09261 | test_accuracy: 0.95463 | test_auc: 0.99183 |  0:02:00s\n",
      "epoch 40 | loss: 0.09349 | test_accuracy: 0.95707 | test_auc: 0.99185 |  0:02:03s\n",
      "epoch 41 | loss: 0.09328 | test_accuracy: 0.95707 | test_auc: 0.99172 |  0:02:06s\n",
      "epoch 42 | loss: 0.09208 | test_accuracy: 0.95707 | test_auc: 0.99185 |  0:02:09s\n",
      "epoch 43 | loss: 0.09306 | test_accuracy: 0.95707 | test_auc: 0.99153 |  0:02:12s\n",
      "epoch 44 | loss: 0.09259 | test_accuracy: 0.95637 | test_auc: 0.99191 |  0:02:15s\n",
      "epoch 45 | loss: 0.09252 | test_accuracy: 0.95463 | test_auc: 0.99168 |  0:02:18s\n",
      "epoch 46 | loss: 0.09219 | test_accuracy: 0.95707 | test_auc: 0.99203 |  0:02:21s\n",
      "epoch 47 | loss: 0.09242 | test_accuracy: 0.95446 | test_auc: 0.99208 |  0:02:24s\n",
      "epoch 48 | loss: 0.09279 | test_accuracy: 0.95707 | test_auc: 0.99199 |  0:02:27s\n",
      "epoch 49 | loss: 0.09236 | test_accuracy: 0.95707 | test_auc: 0.99194 |  0:02:30s\n",
      "epoch 50 | loss: 0.09266 | test_accuracy: 0.95689 | test_auc: 0.99212 |  0:02:33s\n",
      "epoch 51 | loss: 0.09211 | test_accuracy: 0.95689 | test_auc: 0.99197 |  0:02:36s\n",
      "epoch 52 | loss: 0.09206 | test_accuracy: 0.95463 | test_auc: 0.99198 |  0:02:38s\n",
      "epoch 53 | loss: 0.09195 | test_accuracy: 0.95463 | test_auc: 0.99197 |  0:02:41s\n",
      "epoch 54 | loss: 0.0929  | test_accuracy: 0.95463 | test_auc: 0.99199 |  0:02:44s\n",
      "epoch 55 | loss: 0.09256 | test_accuracy: 0.95481 | test_auc: 0.99213 |  0:02:48s\n",
      "epoch 56 | loss: 0.09241 | test_accuracy: 0.95707 | test_auc: 0.99202 |  0:02:51s\n",
      "epoch 57 | loss: 0.09289 | test_accuracy: 0.95463 | test_auc: 0.99194 |  0:02:54s\n",
      "epoch 58 | loss: 0.09216 | test_accuracy: 0.95707 | test_auc: 0.9919  |  0:02:57s\n",
      "epoch 59 | loss: 0.09283 | test_accuracy: 0.95707 | test_auc: 0.99216 |  0:02:59s\n",
      "epoch 60 | loss: 0.09238 | test_accuracy: 0.95463 | test_auc: 0.99207 |  0:03:03s\n",
      "epoch 61 | loss: 0.09336 | test_accuracy: 0.95463 | test_auc: 0.992   |  0:03:06s\n",
      "epoch 62 | loss: 0.09231 | test_accuracy: 0.95689 | test_auc: 0.99214 |  0:03:08s\n",
      "epoch 63 | loss: 0.0922  | test_accuracy: 0.95689 | test_auc: 0.9916  |  0:03:12s\n",
      "epoch 64 | loss: 0.09208 | test_accuracy: 0.95689 | test_auc: 0.99217 |  0:03:14s\n",
      "epoch 65 | loss: 0.09229 | test_accuracy: 0.95446 | test_auc: 0.99194 |  0:03:17s\n",
      "epoch 66 | loss: 0.09244 | test_accuracy: 0.95707 | test_auc: 0.99215 |  0:03:21s\n",
      "epoch 67 | loss: 0.09335 | test_accuracy: 0.95707 | test_auc: 0.99207 |  0:03:24s\n",
      "epoch 68 | loss: 0.09404 | test_accuracy: 0.95707 | test_auc: 0.99056 |  0:03:26s\n",
      "epoch 69 | loss: 0.09254 | test_accuracy: 0.95463 | test_auc: 0.99208 |  0:03:29s\n",
      "epoch 70 | loss: 0.09213 | test_accuracy: 0.95724 | test_auc: 0.99163 |  0:03:32s\n",
      "epoch 71 | loss: 0.09293 | test_accuracy: 0.95707 | test_auc: 0.99202 |  0:03:35s\n",
      "epoch 72 | loss: 0.09618 | test_accuracy: 0.95689 | test_auc: 0.99153 |  0:03:38s\n",
      "epoch 73 | loss: 0.09457 | test_accuracy: 0.95707 | test_auc: 0.99198 |  0:03:41s\n",
      "epoch 74 | loss: 0.09316 | test_accuracy: 0.95707 | test_auc: 0.99167 |  0:03:44s\n",
      "epoch 75 | loss: 0.09332 | test_accuracy: 0.9595  | test_auc: 0.99182 |  0:03:47s\n",
      "epoch 76 | loss: 0.09351 | test_accuracy: 0.95689 | test_auc: 0.99185 |  0:03:50s\n",
      "epoch 77 | loss: 0.09242 | test_accuracy: 0.95463 | test_auc: 0.99171 |  0:03:53s\n",
      "epoch 78 | loss: 0.09308 | test_accuracy: 0.95707 | test_auc: 0.99168 |  0:03:56s\n",
      "epoch 79 | loss: 0.09284 | test_accuracy: 0.95707 | test_auc: 0.99208 |  0:03:59s\n",
      "epoch 80 | loss: 0.09323 | test_accuracy: 0.95707 | test_auc: 0.99168 |  0:04:02s\n",
      "epoch 81 | loss: 0.09231 | test_accuracy: 0.95707 | test_auc: 0.99213 |  0:04:05s\n",
      "epoch 82 | loss: 0.09295 | test_accuracy: 0.95707 | test_auc: 0.99218 |  0:04:08s\n",
      "epoch 83 | loss: 0.09227 | test_accuracy: 0.95724 | test_auc: 0.99184 |  0:04:11s\n",
      "epoch 84 | loss: 0.09309 | test_accuracy: 0.95707 | test_auc: 0.99211 |  0:04:13s\n",
      "epoch 85 | loss: 0.09236 | test_accuracy: 0.95707 | test_auc: 0.9922  |  0:04:16s\n",
      "epoch 86 | loss: 0.0921  | test_accuracy: 0.95602 | test_auc: 0.99145 |  0:04:19s\n",
      "epoch 87 | loss: 0.09343 | test_accuracy: 0.95463 | test_auc: 0.99134 |  0:04:22s\n",
      "epoch 88 | loss: 0.09369 | test_accuracy: 0.95707 | test_auc: 0.99102 |  0:04:25s\n",
      "epoch 89 | loss: 0.09278 | test_accuracy: 0.95707 | test_auc: 0.99113 |  0:04:28s\n",
      "epoch 90 | loss: 0.09291 | test_accuracy: 0.95707 | test_auc: 0.99141 |  0:04:31s\n",
      "epoch 91 | loss: 0.09256 | test_accuracy: 0.95707 | test_auc: 0.99158 |  0:04:34s\n",
      "epoch 92 | loss: 0.09343 | test_accuracy: 0.95689 | test_auc: 0.99187 |  0:04:37s\n",
      "epoch 93 | loss: 0.0931  | test_accuracy: 0.95707 | test_auc: 0.99221 |  0:04:40s\n",
      "epoch 94 | loss: 0.09301 | test_accuracy: 0.95707 | test_auc: 0.99121 |  0:04:43s\n",
      "epoch 95 | loss: 0.09288 | test_accuracy: 0.95689 | test_auc: 0.99202 |  0:04:46s\n",
      "epoch 96 | loss: 0.0926  | test_accuracy: 0.95463 | test_auc: 0.99212 |  0:04:49s\n",
      "epoch 97 | loss: 0.09263 | test_accuracy: 0.95463 | test_auc: 0.99116 |  0:04:52s\n",
      "epoch 98 | loss: 0.09203 | test_accuracy: 0.95463 | test_auc: 0.99203 |  0:04:54s\n",
      "epoch 99 | loss: 0.09244 | test_accuracy: 0.95689 | test_auc: 0.9921  |  0:04:57s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 93 and best_test_auc = 0.99221\n",
      "Training fold 3/5...\n",
      "epoch 0  | loss: 0.28613 | test_accuracy: 0.77108 | test_auc: 0.85454 |  0:00:02s\n",
      "epoch 1  | loss: 0.11035 | test_accuracy: 0.35581 | test_auc: 0.93105 |  0:00:05s\n",
      "epoch 2  | loss: 0.10115 | test_accuracy: 0.71128 | test_auc: 0.97337 |  0:00:08s\n",
      "epoch 3  | loss: 0.09973 | test_accuracy: 0.73492 | test_auc: 0.96984 |  0:00:11s\n",
      "epoch 4  | loss: 0.09997 | test_accuracy: 0.83974 | test_auc: 0.95821 |  0:00:14s\n",
      "epoch 5  | loss: 0.09786 | test_accuracy: 0.86355 | test_auc: 0.97357 |  0:00:17s\n",
      "epoch 6  | loss: 0.09488 | test_accuracy: 0.9482  | test_auc: 0.98658 |  0:00:20s\n",
      "epoch 7  | loss: 0.09398 | test_accuracy: 0.94629 | test_auc: 0.98722 |  0:00:23s\n",
      "epoch 8  | loss: 0.09436 | test_accuracy: 0.95098 | test_auc: 0.98762 |  0:00:25s\n",
      "epoch 9  | loss: 0.09249 | test_accuracy: 0.95203 | test_auc: 0.98757 |  0:00:28s\n",
      "epoch 10 | loss: 0.09424 | test_accuracy: 0.95898 | test_auc: 0.98916 |  0:00:32s\n",
      "epoch 11 | loss: 0.09296 | test_accuracy: 0.95898 | test_auc: 0.9903  |  0:00:35s\n",
      "epoch 12 | loss: 0.09241 | test_accuracy: 0.95724 | test_auc: 0.99016 |  0:00:38s\n",
      "epoch 13 | loss: 0.09153 | test_accuracy: 0.96072 | test_auc: 0.98992 |  0:00:41s\n",
      "epoch 14 | loss: 0.09255 | test_accuracy: 0.95915 | test_auc: 0.99005 |  0:00:44s\n",
      "epoch 15 | loss: 0.09206 | test_accuracy: 0.95985 | test_auc: 0.99007 |  0:00:47s\n",
      "epoch 16 | loss: 0.09313 | test_accuracy: 0.95707 | test_auc: 0.98909 |  0:00:50s\n",
      "epoch 17 | loss: 0.09207 | test_accuracy: 0.95602 | test_auc: 0.98996 |  0:00:53s\n",
      "epoch 18 | loss: 0.09127 | test_accuracy: 0.96176 | test_auc: 0.99024 |  0:00:56s\n",
      "epoch 19 | loss: 0.09149 | test_accuracy: 0.96072 | test_auc: 0.99031 |  0:00:59s\n",
      "epoch 20 | loss: 0.09056 | test_accuracy: 0.96176 | test_auc: 0.99027 |  0:01:02s\n",
      "epoch 21 | loss: 0.09098 | test_accuracy: 0.96089 | test_auc: 0.99047 |  0:01:04s\n",
      "epoch 22 | loss: 0.0912  | test_accuracy: 0.95898 | test_auc: 0.99021 |  0:01:07s\n",
      "epoch 23 | loss: 0.0906  | test_accuracy: 0.96072 | test_auc: 0.99024 |  0:01:10s\n",
      "epoch 24 | loss: 0.09067 | test_accuracy: 0.96072 | test_auc: 0.99029 |  0:01:13s\n",
      "epoch 25 | loss: 0.09074 | test_accuracy: 0.96089 | test_auc: 0.99048 |  0:01:16s\n",
      "epoch 26 | loss: 0.09069 | test_accuracy: 0.96089 | test_auc: 0.9903  |  0:01:19s\n",
      "epoch 27 | loss: 0.09045 | test_accuracy: 0.96089 | test_auc: 0.98959 |  0:01:22s\n",
      "epoch 28 | loss: 0.09045 | test_accuracy: 0.96089 | test_auc: 0.99046 |  0:01:25s\n",
      "epoch 29 | loss: 0.0907  | test_accuracy: 0.95898 | test_auc: 0.99015 |  0:01:28s\n",
      "epoch 30 | loss: 0.09076 | test_accuracy: 0.96089 | test_auc: 0.99054 |  0:01:31s\n",
      "epoch 31 | loss: 0.09071 | test_accuracy: 0.96072 | test_auc: 0.99027 |  0:01:34s\n",
      "epoch 32 | loss: 0.09061 | test_accuracy: 0.96089 | test_auc: 0.99045 |  0:01:37s\n",
      "epoch 33 | loss: 0.08987 | test_accuracy: 0.96072 | test_auc: 0.99033 |  0:01:40s\n",
      "epoch 34 | loss: 0.09019 | test_accuracy: 0.96072 | test_auc: 0.99024 |  0:01:43s\n",
      "epoch 35 | loss: 0.09006 | test_accuracy: 0.96089 | test_auc: 0.99042 |  0:01:46s\n",
      "epoch 36 | loss: 0.08951 | test_accuracy: 0.96089 | test_auc: 0.99041 |  0:01:49s\n",
      "epoch 37 | loss: 0.09026 | test_accuracy: 0.9588  | test_auc: 0.99002 |  0:01:52s\n",
      "epoch 38 | loss: 0.08989 | test_accuracy: 0.96072 | test_auc: 0.99037 |  0:01:54s\n",
      "epoch 39 | loss: 0.09018 | test_accuracy: 0.96072 | test_auc: 0.99029 |  0:01:57s\n",
      "epoch 40 | loss: 0.08981 | test_accuracy: 0.96072 | test_auc: 0.99029 |  0:02:00s\n",
      "epoch 41 | loss: 0.0898  | test_accuracy: 0.96089 | test_auc: 0.9904  |  0:02:03s\n",
      "epoch 42 | loss: 0.0897  | test_accuracy: 0.9588  | test_auc: 0.99014 |  0:02:06s\n",
      "epoch 43 | loss: 0.09063 | test_accuracy: 0.96072 | test_auc: 0.99028 |  0:02:09s\n",
      "epoch 44 | loss: 0.09067 | test_accuracy: 0.96176 | test_auc: 0.99063 |  0:02:12s\n",
      "epoch 45 | loss: 0.0899  | test_accuracy: 0.96089 | test_auc: 0.99029 |  0:02:15s\n",
      "epoch 46 | loss: 0.09033 | test_accuracy: 0.96176 | test_auc: 0.99035 |  0:02:18s\n",
      "epoch 47 | loss: 0.08969 | test_accuracy: 0.96089 | test_auc: 0.99042 |  0:02:21s\n",
      "epoch 48 | loss: 0.08966 | test_accuracy: 0.9588  | test_auc: 0.99011 |  0:02:24s\n",
      "epoch 49 | loss: 0.08983 | test_accuracy: 0.96072 | test_auc: 0.99068 |  0:02:27s\n",
      "epoch 50 | loss: 0.09004 | test_accuracy: 0.96072 | test_auc: 0.99028 |  0:02:29s\n",
      "epoch 51 | loss: 0.0899  | test_accuracy: 0.96072 | test_auc: 0.99065 |  0:02:32s\n",
      "epoch 52 | loss: 0.09014 | test_accuracy: 0.96072 | test_auc: 0.99045 |  0:02:35s\n",
      "epoch 53 | loss: 0.08975 | test_accuracy: 0.96089 | test_auc: 0.99011 |  0:02:38s\n",
      "epoch 54 | loss: 0.08986 | test_accuracy: 0.96089 | test_auc: 0.99039 |  0:02:41s\n",
      "epoch 55 | loss: 0.08927 | test_accuracy: 0.96072 | test_auc: 0.99041 |  0:02:44s\n",
      "epoch 56 | loss: 0.08994 | test_accuracy: 0.96089 | test_auc: 0.99061 |  0:02:47s\n",
      "epoch 57 | loss: 0.09089 | test_accuracy: 0.96089 | test_auc: 0.99025 |  0:02:50s\n",
      "epoch 58 | loss: 0.09311 | test_accuracy: 0.96089 | test_auc: 0.99036 |  0:02:53s\n",
      "epoch 59 | loss: 0.09223 | test_accuracy: 0.95967 | test_auc: 0.98916 |  0:02:56s\n",
      "epoch 60 | loss: 0.09182 | test_accuracy: 0.96089 | test_auc: 0.98935 |  0:02:59s\n",
      "epoch 61 | loss: 0.09242 | test_accuracy: 0.95898 | test_auc: 0.98992 |  0:03:02s\n",
      "epoch 62 | loss: 0.09134 | test_accuracy: 0.96089 | test_auc: 0.99028 |  0:03:05s\n",
      "epoch 63 | loss: 0.09095 | test_accuracy: 0.9588  | test_auc: 0.99012 |  0:03:07s\n",
      "epoch 64 | loss: 0.09396 | test_accuracy: 0.9588  | test_auc: 0.99013 |  0:03:10s\n",
      "epoch 65 | loss: 0.0935  | test_accuracy: 0.96072 | test_auc: 0.99029 |  0:03:13s\n",
      "epoch 66 | loss: 0.09312 | test_accuracy: 0.9588  | test_auc: 0.99018 |  0:03:16s\n",
      "epoch 67 | loss: 0.09315 | test_accuracy: 0.9562  | test_auc: 0.98953 |  0:03:19s\n",
      "epoch 68 | loss: 0.09771 | test_accuracy: 0.95376 | test_auc: 0.98902 |  0:03:22s\n",
      "epoch 69 | loss: 0.10052 | test_accuracy: 0.95602 | test_auc: 0.98927 |  0:03:25s\n",
      "\n",
      "Early stopping occurred at epoch 69 with best_epoch = 49 and best_test_auc = 0.99068\n",
      "Training fold 4/5...\n",
      "epoch 0  | loss: 0.26956 | test_accuracy: 0.8001  | test_auc: 0.88616 |  0:00:02s\n",
      "epoch 1  | loss: 0.13194 | test_accuracy: 0.82305 | test_auc: 0.9692  |  0:00:05s\n",
      "epoch 2  | loss: 0.11893 | test_accuracy: 0.82062 | test_auc: 0.97639 |  0:00:08s\n",
      "epoch 3  | loss: 0.11259 | test_accuracy: 0.83921 | test_auc: 0.97566 |  0:00:11s\n",
      "epoch 4  | loss: 0.104   | test_accuracy: 0.87676 | test_auc: 0.97923 |  0:00:14s\n",
      "epoch 5  | loss: 0.10029 | test_accuracy: 0.95324 | test_auc: 0.98984 |  0:00:17s\n",
      "epoch 6  | loss: 0.09713 | test_accuracy: 0.90648 | test_auc: 0.98196 |  0:00:20s\n",
      "epoch 7  | loss: 0.09646 | test_accuracy: 0.95637 | test_auc: 0.98623 |  0:00:23s\n",
      "epoch 8  | loss: 0.09462 | test_accuracy: 0.96019 | test_auc: 0.98704 |  0:00:26s\n",
      "epoch 9  | loss: 0.09533 | test_accuracy: 0.95654 | test_auc: 0.98973 |  0:00:29s\n",
      "epoch 10 | loss: 0.09546 | test_accuracy: 0.96019 | test_auc: 0.98946 |  0:00:32s\n",
      "epoch 11 | loss: 0.09435 | test_accuracy: 0.95654 | test_auc: 0.99115 |  0:00:34s\n",
      "epoch 12 | loss: 0.09535 | test_accuracy: 0.96019 | test_auc: 0.99096 |  0:00:37s\n",
      "epoch 13 | loss: 0.09436 | test_accuracy: 0.96019 | test_auc: 0.9913  |  0:00:40s\n",
      "epoch 14 | loss: 0.09338 | test_accuracy: 0.95654 | test_auc: 0.99104 |  0:00:43s\n",
      "epoch 15 | loss: 0.09447 | test_accuracy: 0.96019 | test_auc: 0.99125 |  0:00:46s\n",
      "epoch 16 | loss: 0.09576 | test_accuracy: 0.95498 | test_auc: 0.99124 |  0:00:49s\n",
      "epoch 17 | loss: 0.09648 | test_accuracy: 0.96019 | test_auc: 0.99133 |  0:00:51s\n",
      "epoch 18 | loss: 0.09575 | test_accuracy: 0.96019 | test_auc: 0.99136 |  0:00:54s\n",
      "epoch 19 | loss: 0.09489 | test_accuracy: 0.96019 | test_auc: 0.99148 |  0:00:57s\n",
      "epoch 20 | loss: 0.09826 | test_accuracy: 0.95637 | test_auc: 0.99065 |  0:01:00s\n",
      "epoch 21 | loss: 0.09666 | test_accuracy: 0.95654 | test_auc: 0.99128 |  0:01:03s\n",
      "epoch 22 | loss: 0.09328 | test_accuracy: 0.96019 | test_auc: 0.99134 |  0:01:06s\n",
      "epoch 23 | loss: 0.09424 | test_accuracy: 0.96019 | test_auc: 0.99098 |  0:01:09s\n",
      "epoch 24 | loss: 0.0941  | test_accuracy: 0.96019 | test_auc: 0.99153 |  0:01:12s\n",
      "epoch 25 | loss: 0.09396 | test_accuracy: 0.95654 | test_auc: 0.9915  |  0:01:14s\n",
      "epoch 26 | loss: 0.0936  | test_accuracy: 0.95654 | test_auc: 0.99159 |  0:01:17s\n",
      "epoch 27 | loss: 0.09285 | test_accuracy: 0.96019 | test_auc: 0.99158 |  0:01:20s\n",
      "epoch 28 | loss: 0.09312 | test_accuracy: 0.95654 | test_auc: 0.99148 |  0:01:23s\n",
      "epoch 29 | loss: 0.09364 | test_accuracy: 0.96019 | test_auc: 0.9916  |  0:01:26s\n",
      "epoch 30 | loss: 0.09273 | test_accuracy: 0.95654 | test_auc: 0.99143 |  0:01:29s\n",
      "epoch 31 | loss: 0.09315 | test_accuracy: 0.96019 | test_auc: 0.9915  |  0:01:36s\n",
      "epoch 32 | loss: 0.09282 | test_accuracy: 0.96019 | test_auc: 0.99165 |  0:01:39s\n",
      "epoch 33 | loss: 0.0931  | test_accuracy: 0.95654 | test_auc: 0.99156 |  0:01:42s\n",
      "epoch 34 | loss: 0.09283 | test_accuracy: 0.96019 | test_auc: 0.9917  |  0:01:45s\n",
      "epoch 35 | loss: 0.09245 | test_accuracy: 0.95654 | test_auc: 0.99158 |  0:01:48s\n",
      "epoch 36 | loss: 0.09264 | test_accuracy: 0.95654 | test_auc: 0.99154 |  0:01:51s\n",
      "epoch 37 | loss: 0.09326 | test_accuracy: 0.96019 | test_auc: 0.99133 |  0:01:54s\n",
      "epoch 38 | loss: 0.09378 | test_accuracy: 0.96019 | test_auc: 0.99163 |  0:01:57s\n",
      "epoch 39 | loss: 0.09293 | test_accuracy: 0.95498 | test_auc: 0.99144 |  0:02:00s\n",
      "epoch 40 | loss: 0.09399 | test_accuracy: 0.95654 | test_auc: 0.99153 |  0:02:03s\n",
      "epoch 41 | loss: 0.09384 | test_accuracy: 0.96019 | test_auc: 0.99135 |  0:02:06s\n",
      "epoch 42 | loss: 0.09322 | test_accuracy: 0.96019 | test_auc: 0.99156 |  0:02:09s\n",
      "epoch 43 | loss: 0.09284 | test_accuracy: 0.95654 | test_auc: 0.99157 |  0:02:12s\n",
      "epoch 44 | loss: 0.09303 | test_accuracy: 0.95654 | test_auc: 0.99164 |  0:02:15s\n",
      "epoch 45 | loss: 0.09254 | test_accuracy: 0.95654 | test_auc: 0.99149 |  0:02:18s\n",
      "epoch 46 | loss: 0.09271 | test_accuracy: 0.96019 | test_auc: 0.99141 |  0:02:20s\n",
      "epoch 47 | loss: 0.09231 | test_accuracy: 0.96019 | test_auc: 0.99165 |  0:02:23s\n",
      "epoch 48 | loss: 0.09249 | test_accuracy: 0.96019 | test_auc: 0.99167 |  0:02:26s\n",
      "epoch 49 | loss: 0.09228 | test_accuracy: 0.96019 | test_auc: 0.99167 |  0:02:29s\n",
      "epoch 50 | loss: 0.09199 | test_accuracy: 0.95654 | test_auc: 0.99146 |  0:02:32s\n",
      "epoch 51 | loss: 0.09251 | test_accuracy: 0.95654 | test_auc: 0.99168 |  0:02:35s\n",
      "epoch 52 | loss: 0.09245 | test_accuracy: 0.95654 | test_auc: 0.99167 |  0:02:38s\n",
      "epoch 53 | loss: 0.09251 | test_accuracy: 0.95654 | test_auc: 0.99161 |  0:02:41s\n",
      "epoch 54 | loss: 0.09321 | test_accuracy: 0.95689 | test_auc: 0.99178 |  0:02:44s\n",
      "epoch 55 | loss: 0.09256 | test_accuracy: 0.95846 | test_auc: 0.99168 |  0:02:47s\n",
      "epoch 56 | loss: 0.09245 | test_accuracy: 0.96019 | test_auc: 0.99168 |  0:02:50s\n",
      "epoch 57 | loss: 0.09226 | test_accuracy: 0.95846 | test_auc: 0.99166 |  0:02:53s\n",
      "epoch 58 | loss: 0.09316 | test_accuracy: 0.95846 | test_auc: 0.99169 |  0:02:56s\n",
      "epoch 59 | loss: 0.09265 | test_accuracy: 0.96019 | test_auc: 0.99012 |  0:02:59s\n",
      "epoch 60 | loss: 0.09434 | test_accuracy: 0.96019 | test_auc: 0.99107 |  0:03:01s\n",
      "epoch 61 | loss: 0.09377 | test_accuracy: 0.96019 | test_auc: 0.99149 |  0:03:04s\n",
      "epoch 62 | loss: 0.09373 | test_accuracy: 0.95846 | test_auc: 0.99137 |  0:03:07s\n",
      "epoch 63 | loss: 0.09353 | test_accuracy: 0.96019 | test_auc: 0.99148 |  0:03:10s\n",
      "epoch 64 | loss: 0.09369 | test_accuracy: 0.95846 | test_auc: 0.99153 |  0:03:13s\n",
      "epoch 65 | loss: 0.09307 | test_accuracy: 0.95846 | test_auc: 0.99129 |  0:03:16s\n",
      "epoch 66 | loss: 0.09365 | test_accuracy: 0.95846 | test_auc: 0.99156 |  0:03:19s\n",
      "epoch 67 | loss: 0.09319 | test_accuracy: 0.95689 | test_auc: 0.99143 |  0:03:22s\n",
      "epoch 68 | loss: 0.09333 | test_accuracy: 0.96019 | test_auc: 0.99163 |  0:03:25s\n",
      "epoch 69 | loss: 0.09287 | test_accuracy: 0.95846 | test_auc: 0.99153 |  0:03:28s\n",
      "epoch 70 | loss: 0.09288 | test_accuracy: 0.95846 | test_auc: 0.99168 |  0:03:31s\n",
      "epoch 71 | loss: 0.09243 | test_accuracy: 0.96019 | test_auc: 0.99154 |  0:03:34s\n",
      "epoch 72 | loss: 0.09331 | test_accuracy: 0.95846 | test_auc: 0.99154 |  0:03:37s\n",
      "epoch 73 | loss: 0.09357 | test_accuracy: 0.96019 | test_auc: 0.99144 |  0:03:40s\n",
      "epoch 74 | loss: 0.09302 | test_accuracy: 0.96211 | test_auc: 0.99184 |  0:03:43s\n",
      "epoch 75 | loss: 0.0927  | test_accuracy: 0.95846 | test_auc: 0.99174 |  0:03:45s\n",
      "epoch 76 | loss: 0.09305 | test_accuracy: 0.96211 | test_auc: 0.99162 |  0:03:48s\n",
      "epoch 77 | loss: 0.09259 | test_accuracy: 0.95846 | test_auc: 0.99183 |  0:03:51s\n",
      "epoch 78 | loss: 0.09377 | test_accuracy: 0.96141 | test_auc: 0.9915  |  0:03:54s\n",
      "epoch 79 | loss: 0.09543 | test_accuracy: 0.95759 | test_auc: 0.99103 |  0:03:57s\n",
      "epoch 80 | loss: 0.09678 | test_accuracy: 0.96141 | test_auc: 0.99161 |  0:04:00s\n",
      "epoch 81 | loss: 0.09574 | test_accuracy: 0.96141 | test_auc: 0.99164 |  0:04:03s\n",
      "epoch 82 | loss: 0.09384 | test_accuracy: 0.96124 | test_auc: 0.99144 |  0:04:06s\n",
      "epoch 83 | loss: 0.09319 | test_accuracy: 0.96211 | test_auc: 0.99155 |  0:04:09s\n",
      "epoch 84 | loss: 0.09624 | test_accuracy: 0.95828 | test_auc: 0.99119 |  0:04:11s\n",
      "epoch 85 | loss: 0.09433 | test_accuracy: 0.96002 | test_auc: 0.99129 |  0:04:14s\n",
      "epoch 86 | loss: 0.09467 | test_accuracy: 0.96211 | test_auc: 0.9915  |  0:04:17s\n",
      "epoch 87 | loss: 0.09306 | test_accuracy: 0.96211 | test_auc: 0.98439 |  0:04:20s\n",
      "epoch 88 | loss: 0.0987  | test_accuracy: 0.96211 | test_auc: 0.98737 |  0:04:23s\n",
      "epoch 89 | loss: 0.09554 | test_accuracy: 0.96211 | test_auc: 0.98896 |  0:04:26s\n",
      "epoch 90 | loss: 0.09421 | test_accuracy: 0.96193 | test_auc: 0.99047 |  0:04:29s\n",
      "epoch 91 | loss: 0.09393 | test_accuracy: 0.96054 | test_auc: 0.99085 |  0:04:32s\n",
      "epoch 92 | loss: 0.09411 | test_accuracy: 0.9588  | test_auc: 0.98952 |  0:04:35s\n",
      "epoch 93 | loss: 0.09448 | test_accuracy: 0.96037 | test_auc: 0.99082 |  0:04:37s\n",
      "epoch 94 | loss: 0.09432 | test_accuracy: 0.96211 | test_auc: 0.99083 |  0:04:40s\n",
      "\n",
      "Early stopping occurred at epoch 94 with best_epoch = 74 and best_test_auc = 0.99184\n",
      "Training fold 5/5...\n",
      "epoch 0  | loss: 0.30117 | test_accuracy: 0.46984 | test_auc: 0.72147 |  0:00:02s\n",
      "epoch 1  | loss: 0.12321 | test_accuracy: 0.3539  | test_auc: 0.97769 |  0:00:05s\n",
      "epoch 2  | loss: 0.10777 | test_accuracy: 0.57622 | test_auc: 0.97777 |  0:00:08s\n",
      "epoch 3  | loss: 0.10258 | test_accuracy: 0.6169  | test_auc: 0.96759 |  0:00:11s\n",
      "epoch 4  | loss: 0.10082 | test_accuracy: 0.91483 | test_auc: 0.97134 |  0:00:14s\n",
      "epoch 5  | loss: 0.10298 | test_accuracy: 0.9489  | test_auc: 0.98326 |  0:00:17s\n",
      "epoch 6  | loss: 0.09881 | test_accuracy: 0.94107 | test_auc: 0.98355 |  0:00:20s\n",
      "epoch 7  | loss: 0.09566 | test_accuracy: 0.9555  | test_auc: 0.98989 |  0:00:23s\n",
      "epoch 8  | loss: 0.09652 | test_accuracy: 0.96245 | test_auc: 0.99136 |  0:00:26s\n",
      "epoch 9  | loss: 0.09581 | test_accuracy: 0.96524 | test_auc: 0.99264 |  0:00:29s\n",
      "epoch 10 | loss: 0.09502 | test_accuracy: 0.96558 | test_auc: 0.99284 |  0:00:31s\n",
      "epoch 11 | loss: 0.09534 | test_accuracy: 0.96558 | test_auc: 0.99311 |  0:00:34s\n",
      "epoch 12 | loss: 0.09618 | test_accuracy: 0.96106 | test_auc: 0.99321 |  0:00:37s\n",
      "epoch 13 | loss: 0.09484 | test_accuracy: 0.96211 | test_auc: 0.99314 |  0:00:40s\n",
      "epoch 14 | loss: 0.09517 | test_accuracy: 0.96211 | test_auc: 0.99325 |  0:00:43s\n",
      "epoch 15 | loss: 0.09516 | test_accuracy: 0.96419 | test_auc: 0.99338 |  0:00:46s\n",
      "epoch 16 | loss: 0.09525 | test_accuracy: 0.96558 | test_auc: 0.99338 |  0:00:49s\n",
      "epoch 17 | loss: 0.0949  | test_accuracy: 0.96558 | test_auc: 0.99344 |  0:00:52s\n",
      "epoch 18 | loss: 0.09498 | test_accuracy: 0.96593 | test_auc: 0.99326 |  0:00:55s\n",
      "epoch 19 | loss: 0.09428 | test_accuracy: 0.96593 | test_auc: 0.99352 |  0:00:58s\n",
      "epoch 20 | loss: 0.09513 | test_accuracy: 0.96072 | test_auc: 0.99352 |  0:01:01s\n",
      "epoch 21 | loss: 0.09533 | test_accuracy: 0.96245 | test_auc: 0.99336 |  0:01:03s\n",
      "epoch 22 | loss: 0.09503 | test_accuracy: 0.96072 | test_auc: 0.99317 |  0:01:06s\n",
      "epoch 23 | loss: 0.09457 | test_accuracy: 0.96245 | test_auc: 0.99339 |  0:01:09s\n",
      "epoch 24 | loss: 0.09437 | test_accuracy: 0.96245 | test_auc: 0.99351 |  0:01:12s\n",
      "epoch 25 | loss: 0.09424 | test_accuracy: 0.96245 | test_auc: 0.99341 |  0:01:15s\n",
      "epoch 26 | loss: 0.09515 | test_accuracy: 0.96245 | test_auc: 0.99364 |  0:01:18s\n",
      "epoch 27 | loss: 0.0944  | test_accuracy: 0.96211 | test_auc: 0.99352 |  0:01:21s\n",
      "epoch 28 | loss: 0.09405 | test_accuracy: 0.96558 | test_auc: 0.99366 |  0:01:24s\n",
      "epoch 29 | loss: 0.09407 | test_accuracy: 0.96558 | test_auc: 0.99363 |  0:01:27s\n",
      "epoch 30 | loss: 0.09408 | test_accuracy: 0.96558 | test_auc: 0.99364 |  0:01:30s\n",
      "epoch 31 | loss: 0.09445 | test_accuracy: 0.96419 | test_auc: 0.99334 |  0:01:33s\n",
      "epoch 32 | loss: 0.09391 | test_accuracy: 0.96558 | test_auc: 0.99356 |  0:01:36s\n",
      "epoch 33 | loss: 0.09421 | test_accuracy: 0.96558 | test_auc: 0.99339 |  0:01:39s\n",
      "epoch 34 | loss: 0.09338 | test_accuracy: 0.96593 | test_auc: 0.99353 |  0:01:42s\n",
      "epoch 35 | loss: 0.09505 | test_accuracy: 0.96419 | test_auc: 0.99339 |  0:01:44s\n",
      "epoch 36 | loss: 0.09443 | test_accuracy: 0.96558 | test_auc: 0.9934  |  0:01:47s\n",
      "epoch 37 | loss: 0.09601 | test_accuracy: 0.96558 | test_auc: 0.99347 |  0:01:50s\n",
      "epoch 38 | loss: 0.09512 | test_accuracy: 0.96593 | test_auc: 0.99358 |  0:01:53s\n",
      "epoch 39 | loss: 0.09435 | test_accuracy: 0.96593 | test_auc: 0.99345 |  0:01:56s\n",
      "epoch 40 | loss: 0.09364 | test_accuracy: 0.96558 | test_auc: 0.99352 |  0:01:59s\n",
      "epoch 41 | loss: 0.09321 | test_accuracy: 0.96558 | test_auc: 0.99352 |  0:02:02s\n",
      "epoch 42 | loss: 0.09416 | test_accuracy: 0.96593 | test_auc: 0.99335 |  0:02:05s\n",
      "epoch 43 | loss: 0.09352 | test_accuracy: 0.96558 | test_auc: 0.99359 |  0:02:08s\n",
      "epoch 44 | loss: 0.09423 | test_accuracy: 0.96593 | test_auc: 0.99356 |  0:02:11s\n",
      "epoch 45 | loss: 0.09325 | test_accuracy: 0.96558 | test_auc: 0.99331 |  0:02:14s\n",
      "epoch 46 | loss: 0.09459 | test_accuracy: 0.96558 | test_auc: 0.99363 |  0:02:17s\n",
      "epoch 47 | loss: 0.09777 | test_accuracy: 0.96106 | test_auc: 0.99328 |  0:02:20s\n",
      "epoch 48 | loss: 0.10076 | test_accuracy: 0.96245 | test_auc: 0.99327 |  0:02:29s\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_test_auc = 0.99366\n",
      "\n",
      "Results for 8. Sequential Forward Selection:\n",
      "Average accuracy: 0.9604 ± 0.0033\n",
      "Average precision: 0.9620 ± 0.0098\n",
      "Average recall: 0.9257 ± 0.0071\n",
      "Average f1: 0.9434 ± 0.0046\n",
      "Average auc: 0.9527 ± 0.0034\n",
      "\n",
      "==================================================\n",
      "Processing 9. XGBoost Importance\n",
      "==================================================\n",
      "Selecting features using 9. XGBoost Importance...\n",
      "Top 10 features selected by 9. XGBoost Importance:\n",
      "1. Sore throat: 0.5873\n",
      "2. Abroad travel: 0.2135\n",
      "3. Attended Large Gathering: 0.0666\n",
      "4. Breathing Problem: 0.0000\n",
      "5. Fever: 0.0000\n",
      "6. Dry Cough: 0.0000\n",
      "7. Running Nose: 0.0000\n",
      "8. Asthma: 0.0000\n",
      "9. Chronic Lung Disease: 0.0000\n",
      "10. Headache: 0.0000\n",
      "\n",
      "Training TabNet with features selected by 9. XGBoost Importance\n",
      "Training fold 1/5...\n",
      "epoch 0  | loss: 0.21433 | test_accuracy: 0.53233 | test_auc: 0.93251 |  0:00:12s\n",
      "epoch 1  | loss: 0.10173 | test_accuracy: 0.87852 | test_auc: 0.9614  |  0:00:24s\n",
      "epoch 2  | loss: 0.0754  | test_accuracy: 0.87052 | test_auc: 0.96162 |  0:00:39s\n",
      "epoch 3  | loss: 0.06436 | test_accuracy: 0.90737 | test_auc: 0.96516 |  0:00:53s\n",
      "epoch 4  | loss: 0.05944 | test_accuracy: 0.91502 | test_auc: 0.98938 |  0:01:08s\n",
      "epoch 5  | loss: 0.05468 | test_accuracy: 0.92892 | test_auc: 0.98968 |  0:01:21s\n",
      "epoch 6  | loss: 0.05104 | test_accuracy: 0.95412 | test_auc: 0.99381 |  0:01:36s\n",
      "epoch 7  | loss: 0.05361 | test_accuracy: 0.97515 | test_auc: 0.99654 |  0:01:50s\n",
      "epoch 8  | loss: 0.05229 | test_accuracy: 0.97324 | test_auc: 0.99646 |  0:02:05s\n",
      "epoch 9  | loss: 0.05207 | test_accuracy: 0.97602 | test_auc: 0.99758 |  0:02:20s\n",
      "epoch 10 | loss: 0.05023 | test_accuracy: 0.98158 | test_auc: 0.99801 |  0:02:32s\n",
      "epoch 11 | loss: 0.04892 | test_accuracy: 0.9821  | test_auc: 0.99808 |  0:02:46s\n",
      "epoch 12 | loss: 0.04864 | test_accuracy: 0.98001 | test_auc: 0.99781 |  0:03:00s\n",
      "epoch 13 | loss: 0.05074 | test_accuracy: 0.97845 | test_auc: 0.99804 |  0:03:15s\n",
      "epoch 14 | loss: 0.04942 | test_accuracy: 0.98193 | test_auc: 0.99833 |  0:03:28s\n",
      "epoch 15 | loss: 0.04894 | test_accuracy: 0.98106 | test_auc: 0.99835 |  0:03:37s\n",
      "epoch 16 | loss: 0.04703 | test_accuracy: 0.98245 | test_auc: 0.9985  |  0:03:50s\n",
      "epoch 17 | loss: 0.04673 | test_accuracy: 0.98384 | test_auc: 0.99845 |  0:04:03s\n",
      "epoch 18 | loss: 0.04702 | test_accuracy: 0.98366 | test_auc: 0.99847 |  0:04:16s\n",
      "epoch 19 | loss: 0.04701 | test_accuracy: 0.98366 | test_auc: 0.99854 |  0:04:31s\n",
      "epoch 20 | loss: 0.04773 | test_accuracy: 0.98123 | test_auc: 0.99834 |  0:04:43s\n",
      "epoch 21 | loss: 0.04641 | test_accuracy: 0.98245 | test_auc: 0.99844 |  0:04:59s\n",
      "epoch 22 | loss: 0.04498 | test_accuracy: 0.98175 | test_auc: 0.99839 |  0:05:16s\n",
      "epoch 23 | loss: 0.04491 | test_accuracy: 0.98401 | test_auc: 0.99841 |  0:05:31s\n",
      "epoch 24 | loss: 0.04526 | test_accuracy: 0.98123 | test_auc: 0.99847 |  0:05:44s\n",
      "epoch 25 | loss: 0.04442 | test_accuracy: 0.98401 | test_auc: 0.99848 |  0:05:56s\n",
      "epoch 26 | loss: 0.04457 | test_accuracy: 0.98297 | test_auc: 0.99859 |  0:06:11s\n",
      "epoch 27 | loss: 0.04453 | test_accuracy: 0.98193 | test_auc: 0.99845 |  0:06:27s\n",
      "epoch 28 | loss: 0.04405 | test_accuracy: 0.98245 | test_auc: 0.99828 |  0:06:39s\n",
      "epoch 29 | loss: 0.04493 | test_accuracy: 0.98245 | test_auc: 0.99836 |  0:06:50s\n",
      "epoch 30 | loss: 0.04587 | test_accuracy: 0.98106 | test_auc: 0.99835 |  0:07:02s\n",
      "epoch 31 | loss: 0.04584 | test_accuracy: 0.98314 | test_auc: 0.99852 |  0:07:17s\n",
      "epoch 32 | loss: 0.04781 | test_accuracy: 0.98158 | test_auc: 0.99794 |  0:07:30s\n",
      "epoch 33 | loss: 0.05963 | test_accuracy: 0.97393 | test_auc: 0.9976  |  0:07:41s\n",
      "epoch 34 | loss: 0.0562  | test_accuracy: 0.9814  | test_auc: 0.99809 |  0:07:53s\n",
      "epoch 35 | loss: 0.05044 | test_accuracy: 0.98054 | test_auc: 0.99838 |  0:08:03s\n",
      "epoch 36 | loss: 0.04995 | test_accuracy: 0.98193 | test_auc: 0.99804 |  0:08:15s\n",
      "epoch 37 | loss: 0.04892 | test_accuracy: 0.98193 | test_auc: 0.99797 |  0:08:29s\n",
      "epoch 38 | loss: 0.04731 | test_accuracy: 0.98193 | test_auc: 0.99786 |  0:08:43s\n",
      "epoch 39 | loss: 0.04618 | test_accuracy: 0.98193 | test_auc: 0.99805 |  0:08:57s\n",
      "epoch 40 | loss: 0.04494 | test_accuracy: 0.9814  | test_auc: 0.99813 |  0:09:08s\n",
      "epoch 41 | loss: 0.04495 | test_accuracy: 0.98193 | test_auc: 0.99822 |  0:09:20s\n",
      "epoch 42 | loss: 0.04356 | test_accuracy: 0.98279 | test_auc: 0.9985  |  0:09:34s\n",
      "epoch 43 | loss: 0.04303 | test_accuracy: 0.98193 | test_auc: 0.99855 |  0:09:49s\n",
      "epoch 44 | loss: 0.04401 | test_accuracy: 0.98297 | test_auc: 0.99862 |  0:10:03s\n",
      "epoch 45 | loss: 0.04364 | test_accuracy: 0.98314 | test_auc: 0.9986  |  0:10:13s\n",
      "epoch 46 | loss: 0.04463 | test_accuracy: 0.98332 | test_auc: 0.99844 |  0:10:29s\n",
      "epoch 47 | loss: 0.04403 | test_accuracy: 0.9821  | test_auc: 0.99844 |  0:10:40s\n",
      "epoch 48 | loss: 0.04369 | test_accuracy: 0.98332 | test_auc: 0.99842 |  0:10:53s\n",
      "epoch 49 | loss: 0.0438  | test_accuracy: 0.98314 | test_auc: 0.99852 |  0:11:08s\n",
      "epoch 50 | loss: 0.04438 | test_accuracy: 0.98123 | test_auc: 0.99841 |  0:11:16s\n",
      "epoch 51 | loss: 0.0456  | test_accuracy: 0.98314 | test_auc: 0.99842 |  0:11:28s\n",
      "epoch 52 | loss: 0.04508 | test_accuracy: 0.98332 | test_auc: 0.99851 |  0:11:41s\n",
      "epoch 53 | loss: 0.04349 | test_accuracy: 0.98332 | test_auc: 0.99847 |  0:11:53s\n",
      "epoch 54 | loss: 0.04349 | test_accuracy: 0.98262 | test_auc: 0.99847 |  0:12:08s\n",
      "epoch 55 | loss: 0.04269 | test_accuracy: 0.98314 | test_auc: 0.99844 |  0:12:20s\n",
      "epoch 56 | loss: 0.04258 | test_accuracy: 0.98314 | test_auc: 0.99849 |  0:12:35s\n",
      "epoch 57 | loss: 0.04264 | test_accuracy: 0.98279 | test_auc: 0.99841 |  0:12:51s\n",
      "epoch 58 | loss: 0.04224 | test_accuracy: 0.98332 | test_auc: 0.99841 |  0:13:06s\n",
      "epoch 59 | loss: 0.04268 | test_accuracy: 0.98279 | test_auc: 0.9984  |  0:13:20s\n",
      "epoch 60 | loss: 0.04256 | test_accuracy: 0.98314 | test_auc: 0.99857 |  0:13:33s\n",
      "epoch 61 | loss: 0.04223 | test_accuracy: 0.98332 | test_auc: 0.99859 |  0:13:48s\n",
      "epoch 62 | loss: 0.04243 | test_accuracy: 0.98314 | test_auc: 0.99858 |  0:14:04s\n",
      "epoch 63 | loss: 0.04234 | test_accuracy: 0.98332 | test_auc: 0.99854 |  0:14:17s\n",
      "epoch 64 | loss: 0.04239 | test_accuracy: 0.98332 | test_auc: 0.99848 |  0:14:30s\n",
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 44 and best_test_auc = 0.99862\n",
      "Training fold 2/5...\n",
      "epoch 0  | loss: 0.18023 | test_accuracy: 0.80706 | test_auc: 0.86406 |  0:00:13s\n",
      "epoch 1  | loss: 0.07672 | test_accuracy: 0.8307  | test_auc: 0.94244 |  0:00:26s\n",
      "epoch 2  | loss: 0.0674  | test_accuracy: 0.86564 | test_auc: 0.96652 |  0:00:39s\n",
      "epoch 3  | loss: 0.06579 | test_accuracy: 0.93742 | test_auc: 0.97171 |  0:00:54s\n",
      "epoch 4  | loss: 0.06912 | test_accuracy: 0.96419 | test_auc: 0.98709 |  0:01:05s\n",
      "epoch 5  | loss: 0.05899 | test_accuracy: 0.90614 | test_auc: 0.98676 |  0:01:17s\n",
      "epoch 6  | loss: 0.05539 | test_accuracy: 0.96002 | test_auc: 0.98885 |  0:01:31s\n",
      "epoch 7  | loss: 0.05324 | test_accuracy: 0.91674 | test_auc: 0.99244 |  0:01:44s\n",
      "epoch 8  | loss: 0.05136 | test_accuracy: 0.97966 | test_auc: 0.99447 |  0:01:57s\n",
      "epoch 9  | loss: 0.05316 | test_accuracy: 0.97219 | test_auc: 0.98955 |  0:02:10s\n",
      "epoch 10 | loss: 0.05173 | test_accuracy: 0.9821  | test_auc: 0.99655 |  0:02:23s\n",
      "epoch 11 | loss: 0.04956 | test_accuracy: 0.9814  | test_auc: 0.99758 |  0:02:36s\n",
      "epoch 12 | loss: 0.05005 | test_accuracy: 0.98383 | test_auc: 0.99737 |  0:02:48s\n",
      "epoch 13 | loss: 0.05011 | test_accuracy: 0.9854  | test_auc: 0.99818 |  0:02:59s\n",
      "epoch 14 | loss: 0.04914 | test_accuracy: 0.98557 | test_auc: 0.99789 |  0:03:09s\n",
      "epoch 15 | loss: 0.04869 | test_accuracy: 0.98383 | test_auc: 0.99783 |  0:03:19s\n",
      "epoch 16 | loss: 0.04989 | test_accuracy: 0.98366 | test_auc: 0.99845 |  0:03:33s\n",
      "epoch 17 | loss: 0.04802 | test_accuracy: 0.98453 | test_auc: 0.99829 |  0:03:48s\n",
      "epoch 18 | loss: 0.04823 | test_accuracy: 0.9847  | test_auc: 0.99824 |  0:04:04s\n",
      "epoch 19 | loss: 0.05222 | test_accuracy: 0.98418 | test_auc: 0.99806 |  0:04:18s\n",
      "epoch 20 | loss: 0.05167 | test_accuracy: 0.98331 | test_auc: 0.99845 |  0:04:30s\n",
      "epoch 21 | loss: 0.0493  | test_accuracy: 0.98383 | test_auc: 0.99801 |  0:04:39s\n",
      "epoch 22 | loss: 0.04781 | test_accuracy: 0.98453 | test_auc: 0.99793 |  0:04:52s\n",
      "epoch 23 | loss: 0.04559 | test_accuracy: 0.9854  | test_auc: 0.99814 |  0:05:01s\n",
      "epoch 24 | loss: 0.04433 | test_accuracy: 0.98383 | test_auc: 0.99825 |  0:05:10s\n",
      "epoch 25 | loss: 0.04498 | test_accuracy: 0.98331 | test_auc: 0.99833 |  0:05:20s\n",
      "epoch 26 | loss: 0.04495 | test_accuracy: 0.98383 | test_auc: 0.99844 |  0:05:29s\n",
      "epoch 27 | loss: 0.04846 | test_accuracy: 0.98331 | test_auc: 0.99827 |  0:05:43s\n",
      "epoch 28 | loss: 0.0456  | test_accuracy: 0.98331 | test_auc: 0.99853 |  0:05:56s\n",
      "epoch 29 | loss: 0.04507 | test_accuracy: 0.98418 | test_auc: 0.99807 |  0:06:09s\n",
      "epoch 30 | loss: 0.04511 | test_accuracy: 0.98401 | test_auc: 0.99817 |  0:06:23s\n",
      "epoch 31 | loss: 0.04412 | test_accuracy: 0.98453 | test_auc: 0.9982  |  0:06:34s\n",
      "epoch 32 | loss: 0.04731 | test_accuracy: 0.98314 | test_auc: 0.99836 |  0:06:47s\n",
      "epoch 33 | loss: 0.04482 | test_accuracy: 0.98436 | test_auc: 0.99845 |  0:07:01s\n",
      "epoch 34 | loss: 0.04505 | test_accuracy: 0.98453 | test_auc: 0.99848 |  0:07:17s\n",
      "epoch 35 | loss: 0.04447 | test_accuracy: 0.98366 | test_auc: 0.9982  |  0:07:30s\n",
      "epoch 36 | loss: 0.04348 | test_accuracy: 0.98523 | test_auc: 0.99856 |  0:07:42s\n",
      "epoch 37 | loss: 0.04283 | test_accuracy: 0.98523 | test_auc: 0.99851 |  0:07:57s\n",
      "epoch 38 | loss: 0.04573 | test_accuracy: 0.98453 | test_auc: 0.99808 |  0:08:08s\n",
      "epoch 39 | loss: 0.04502 | test_accuracy: 0.98505 | test_auc: 0.99828 |  0:08:20s\n",
      "epoch 40 | loss: 0.04481 | test_accuracy: 0.98557 | test_auc: 0.99804 |  0:08:33s\n",
      "epoch 41 | loss: 0.04409 | test_accuracy: 0.98557 | test_auc: 0.99803 |  0:08:44s\n",
      "epoch 42 | loss: 0.0433  | test_accuracy: 0.98488 | test_auc: 0.99804 |  0:08:58s\n",
      "epoch 43 | loss: 0.04339 | test_accuracy: 0.98401 | test_auc: 0.99815 |  0:09:11s\n",
      "epoch 44 | loss: 0.04288 | test_accuracy: 0.98523 | test_auc: 0.99821 |  0:09:26s\n",
      "epoch 45 | loss: 0.04296 | test_accuracy: 0.98401 | test_auc: 0.99819 |  0:09:38s\n",
      "epoch 46 | loss: 0.04264 | test_accuracy: 0.9847  | test_auc: 0.9982  |  0:09:48s\n",
      "epoch 47 | loss: 0.04304 | test_accuracy: 0.98523 | test_auc: 0.99816 |  0:09:59s\n",
      "epoch 48 | loss: 0.04266 | test_accuracy: 0.98523 | test_auc: 0.99821 |  0:10:12s\n",
      "epoch 49 | loss: 0.04245 | test_accuracy: 0.98557 | test_auc: 0.99819 |  0:10:27s\n",
      "epoch 50 | loss: 0.04287 | test_accuracy: 0.98488 | test_auc: 0.9982  |  0:10:40s\n",
      "epoch 51 | loss: 0.04248 | test_accuracy: 0.98401 | test_auc: 0.99824 |  0:10:52s\n",
      "epoch 52 | loss: 0.04278 | test_accuracy: 0.98557 | test_auc: 0.99823 |  0:11:00s\n",
      "epoch 53 | loss: 0.04245 | test_accuracy: 0.98505 | test_auc: 0.99824 |  0:11:07s\n",
      "epoch 54 | loss: 0.04438 | test_accuracy: 0.98314 | test_auc: 0.99788 |  0:11:14s\n",
      "epoch 55 | loss: 0.05177 | test_accuracy: 0.98262 | test_auc: 0.99799 |  0:11:28s\n",
      "epoch 56 | loss: 0.05046 | test_accuracy: 0.98244 | test_auc: 0.99827 |  0:11:43s\n",
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 36 and best_test_auc = 0.99856\n",
      "Training fold 3/5...\n",
      "epoch 0  | loss: 0.19012 | test_accuracy: 0.92352 | test_auc: 0.95202 |  0:00:13s\n",
      "epoch 1  | loss: 0.07514 | test_accuracy: 0.87606 | test_auc: 0.92551 |  0:00:23s\n",
      "epoch 2  | loss: 0.06253 | test_accuracy: 0.91431 | test_auc: 0.95452 |  0:00:33s\n",
      "epoch 3  | loss: 0.05681 | test_accuracy: 0.94559 | test_auc: 0.95849 |  0:00:42s\n",
      "epoch 4  | loss: 0.05825 | test_accuracy: 0.92387 | test_auc: 0.96556 |  0:00:54s\n",
      "epoch 5  | loss: 0.05324 | test_accuracy: 0.95446 | test_auc: 0.95604 |  0:01:09s\n",
      "epoch 6  | loss: 0.05116 | test_accuracy: 0.9555  | test_auc: 0.97333 |  0:01:20s\n",
      "epoch 7  | loss: 0.05061 | test_accuracy: 0.96854 | test_auc: 0.98397 |  0:01:32s\n",
      "epoch 8  | loss: 0.05266 | test_accuracy: 0.97671 | test_auc: 0.99633 |  0:01:44s\n",
      "epoch 9  | loss: 0.04985 | test_accuracy: 0.97845 | test_auc: 0.99676 |  0:01:57s\n",
      "epoch 10 | loss: 0.05038 | test_accuracy: 0.97932 | test_auc: 0.99705 |  0:02:11s\n",
      "epoch 11 | loss: 0.048   | test_accuracy: 0.98036 | test_auc: 0.99669 |  0:02:24s\n",
      "epoch 12 | loss: 0.04826 | test_accuracy: 0.98036 | test_auc: 0.99739 |  0:02:37s\n",
      "epoch 13 | loss: 0.04774 | test_accuracy: 0.97706 | test_auc: 0.99688 |  0:02:53s\n",
      "epoch 14 | loss: 0.04661 | test_accuracy: 0.97862 | test_auc: 0.99703 |  0:03:07s\n",
      "epoch 15 | loss: 0.04543 | test_accuracy: 0.98036 | test_auc: 0.99687 |  0:03:21s\n",
      "epoch 16 | loss: 0.04426 | test_accuracy: 0.98071 | test_auc: 0.99755 |  0:03:33s\n",
      "epoch 17 | loss: 0.04431 | test_accuracy: 0.98018 | test_auc: 0.99774 |  0:03:45s\n",
      "epoch 18 | loss: 0.0454  | test_accuracy: 0.97914 | test_auc: 0.99771 |  0:04:00s\n",
      "epoch 19 | loss: 0.04497 | test_accuracy: 0.98036 | test_auc: 0.99773 |  0:04:12s\n",
      "epoch 20 | loss: 0.04511 | test_accuracy: 0.97827 | test_auc: 0.9977  |  0:04:23s\n",
      "epoch 21 | loss: 0.0444  | test_accuracy: 0.98001 | test_auc: 0.99705 |  0:04:36s\n",
      "epoch 22 | loss: 0.04309 | test_accuracy: 0.97897 | test_auc: 0.99785 |  0:04:47s\n",
      "epoch 23 | loss: 0.04283 | test_accuracy: 0.98071 | test_auc: 0.99772 |  0:05:00s\n",
      "epoch 24 | loss: 0.04242 | test_accuracy: 0.98088 | test_auc: 0.99787 |  0:05:10s\n",
      "epoch 25 | loss: 0.04239 | test_accuracy: 0.97914 | test_auc: 0.99777 |  0:05:22s\n",
      "epoch 26 | loss: 0.04373 | test_accuracy: 0.97984 | test_auc: 0.9975  |  0:05:35s\n",
      "epoch 27 | loss: 0.04299 | test_accuracy: 0.98088 | test_auc: 0.99751 |  0:05:47s\n",
      "epoch 28 | loss: 0.04218 | test_accuracy: 0.9814  | test_auc: 0.99789 |  0:05:56s\n",
      "epoch 29 | loss: 0.04223 | test_accuracy: 0.98053 | test_auc: 0.99769 |  0:06:09s\n",
      "epoch 30 | loss: 0.04635 | test_accuracy: 0.98001 | test_auc: 0.99763 |  0:06:24s\n",
      "epoch 31 | loss: 0.04424 | test_accuracy: 0.97862 | test_auc: 0.99774 |  0:06:40s\n",
      "epoch 32 | loss: 0.04288 | test_accuracy: 0.98001 | test_auc: 0.99781 |  0:06:52s\n",
      "epoch 33 | loss: 0.04345 | test_accuracy: 0.97845 | test_auc: 0.99782 |  0:07:07s\n",
      "epoch 34 | loss: 0.04268 | test_accuracy: 0.97827 | test_auc: 0.99767 |  0:07:22s\n",
      "epoch 35 | loss: 0.0417  | test_accuracy: 0.98105 | test_auc: 0.99799 |  0:07:37s\n",
      "epoch 36 | loss: 0.04243 | test_accuracy: 0.97897 | test_auc: 0.99777 |  0:07:53s\n",
      "epoch 37 | loss: 0.04213 | test_accuracy: 0.97966 | test_auc: 0.99785 |  0:08:03s\n",
      "epoch 38 | loss: 0.04136 | test_accuracy: 0.97914 | test_auc: 0.99792 |  0:08:14s\n",
      "epoch 39 | loss: 0.04082 | test_accuracy: 0.97949 | test_auc: 0.99761 |  0:08:27s\n",
      "epoch 40 | loss: 0.0415  | test_accuracy: 0.97897 | test_auc: 0.998   |  0:08:42s\n",
      "epoch 41 | loss: 0.04151 | test_accuracy: 0.9814  | test_auc: 0.99797 |  0:08:56s\n",
      "epoch 42 | loss: 0.0412  | test_accuracy: 0.97897 | test_auc: 0.9978  |  0:09:11s\n",
      "epoch 43 | loss: 0.04082 | test_accuracy: 0.97879 | test_auc: 0.99785 |  0:09:22s\n",
      "epoch 44 | loss: 0.04101 | test_accuracy: 0.98071 | test_auc: 0.99809 |  0:09:35s\n",
      "epoch 45 | loss: 0.04086 | test_accuracy: 0.97897 | test_auc: 0.99804 |  0:09:47s\n",
      "epoch 46 | loss: 0.04165 | test_accuracy: 0.98088 | test_auc: 0.99788 |  0:09:58s\n",
      "epoch 47 | loss: 0.04206 | test_accuracy: 0.97775 | test_auc: 0.99778 |  0:10:11s\n",
      "epoch 48 | loss: 0.0426  | test_accuracy: 0.97949 | test_auc: 0.99805 |  0:10:27s\n",
      "epoch 49 | loss: 0.04152 | test_accuracy: 0.97984 | test_auc: 0.99787 |  0:10:42s\n",
      "epoch 50 | loss: 0.04185 | test_accuracy: 0.97862 | test_auc: 0.99802 |  0:10:58s\n",
      "epoch 51 | loss: 0.04302 | test_accuracy: 0.97949 | test_auc: 0.9973  |  0:11:12s\n",
      "epoch 52 | loss: 0.04283 | test_accuracy: 0.98036 | test_auc: 0.99766 |  0:11:25s\n",
      "epoch 53 | loss: 0.04144 | test_accuracy: 0.9781  | test_auc: 0.99786 |  0:11:40s\n",
      "epoch 54 | loss: 0.04169 | test_accuracy: 0.97758 | test_auc: 0.99787 |  0:11:54s\n",
      "epoch 55 | loss: 0.0411  | test_accuracy: 0.98018 | test_auc: 0.99805 |  0:12:09s\n",
      "epoch 56 | loss: 0.04184 | test_accuracy: 0.98071 | test_auc: 0.99808 |  0:12:23s\n",
      "epoch 57 | loss: 0.04261 | test_accuracy: 0.98053 | test_auc: 0.99792 |  0:12:35s\n",
      "epoch 58 | loss: 0.04171 | test_accuracy: 0.97984 | test_auc: 0.99758 |  0:12:46s\n",
      "epoch 59 | loss: 0.04208 | test_accuracy: 0.98053 | test_auc: 0.99775 |  0:13:00s\n",
      "epoch 60 | loss: 0.04209 | test_accuracy: 0.97879 | test_auc: 0.9978  |  0:13:08s\n",
      "epoch 61 | loss: 0.04095 | test_accuracy: 0.98053 | test_auc: 0.99791 |  0:13:21s\n",
      "epoch 62 | loss: 0.04029 | test_accuracy: 0.98036 | test_auc: 0.99776 |  0:13:31s\n",
      "epoch 63 | loss: 0.0404  | test_accuracy: 0.98157 | test_auc: 0.99728 |  0:13:43s\n",
      "epoch 64 | loss: 0.04107 | test_accuracy: 0.98036 | test_auc: 0.99808 |  0:13:57s\n",
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 44 and best_test_auc = 0.99809\n",
      "Training fold 4/5...\n",
      "epoch 0  | loss: 0.22064 | test_accuracy: 0.88284 | test_auc: 0.96667 |  0:00:14s\n",
      "epoch 1  | loss: 0.08333 | test_accuracy: 0.83939 | test_auc: 0.94897 |  0:00:30s\n",
      "epoch 2  | loss: 0.07173 | test_accuracy: 0.75074 | test_auc: 0.97772 |  0:00:42s\n",
      "epoch 3  | loss: 0.06726 | test_accuracy: 0.95307 | test_auc: 0.985   |  0:00:57s\n",
      "epoch 4  | loss: 0.06343 | test_accuracy: 0.97375 | test_auc: 0.98827 |  0:01:12s\n",
      "epoch 5  | loss: 0.05794 | test_accuracy: 0.97323 | test_auc: 0.99152 |  0:01:26s\n",
      "epoch 6  | loss: 0.05787 | test_accuracy: 0.96524 | test_auc: 0.9932  |  0:01:39s\n",
      "epoch 7  | loss: 0.05622 | test_accuracy: 0.9748  | test_auc: 0.99634 |  0:01:53s\n",
      "epoch 8  | loss: 0.05778 | test_accuracy: 0.97792 | test_auc: 0.99459 |  0:02:07s\n",
      "epoch 9  | loss: 0.0518  | test_accuracy: 0.98018 | test_auc: 0.99796 |  0:02:17s\n",
      "epoch 10 | loss: 0.05271 | test_accuracy: 0.9781  | test_auc: 0.99765 |  0:02:30s\n",
      "epoch 11 | loss: 0.04935 | test_accuracy: 0.98001 | test_auc: 0.99797 |  0:02:41s\n",
      "epoch 12 | loss: 0.04894 | test_accuracy: 0.97949 | test_auc: 0.99791 |  0:02:49s\n",
      "epoch 13 | loss: 0.04914 | test_accuracy: 0.98105 | test_auc: 0.99813 |  0:03:04s\n",
      "epoch 14 | loss: 0.04647 | test_accuracy: 0.98088 | test_auc: 0.99814 |  0:03:16s\n",
      "epoch 15 | loss: 0.04926 | test_accuracy: 0.98157 | test_auc: 0.99814 |  0:03:28s\n",
      "epoch 16 | loss: 0.04919 | test_accuracy: 0.98175 | test_auc: 0.99811 |  0:03:39s\n",
      "epoch 17 | loss: 0.05013 | test_accuracy: 0.98157 | test_auc: 0.99783 |  0:03:49s\n",
      "epoch 18 | loss: 0.0462  | test_accuracy: 0.98157 | test_auc: 0.99813 |  0:04:01s\n",
      "epoch 19 | loss: 0.04581 | test_accuracy: 0.98157 | test_auc: 0.9982  |  0:04:16s\n",
      "epoch 20 | loss: 0.04531 | test_accuracy: 0.98105 | test_auc: 0.99827 |  0:04:31s\n",
      "epoch 21 | loss: 0.04583 | test_accuracy: 0.9821  | test_auc: 0.99824 |  0:04:45s\n",
      "epoch 22 | loss: 0.04902 | test_accuracy: 0.98175 | test_auc: 0.99648 |  0:04:56s\n",
      "epoch 23 | loss: 0.04817 | test_accuracy: 0.98123 | test_auc: 0.9977  |  0:05:11s\n",
      "epoch 24 | loss: 0.05075 | test_accuracy: 0.9821  | test_auc: 0.99787 |  0:05:24s\n",
      "epoch 25 | loss: 0.04843 | test_accuracy: 0.98157 | test_auc: 0.99807 |  0:05:40s\n",
      "epoch 26 | loss: 0.04613 | test_accuracy: 0.9821  | test_auc: 0.99802 |  0:05:56s\n",
      "epoch 27 | loss: 0.04561 | test_accuracy: 0.98175 | test_auc: 0.99801 |  0:06:08s\n",
      "epoch 28 | loss: 0.04527 | test_accuracy: 0.98227 | test_auc: 0.99827 |  0:06:20s\n",
      "epoch 29 | loss: 0.045   | test_accuracy: 0.98227 | test_auc: 0.99827 |  0:06:34s\n",
      "epoch 30 | loss: 0.04374 | test_accuracy: 0.98105 | test_auc: 0.99827 |  0:06:47s\n",
      "epoch 31 | loss: 0.04401 | test_accuracy: 0.9821  | test_auc: 0.99824 |  0:06:59s\n",
      "epoch 32 | loss: 0.04346 | test_accuracy: 0.98175 | test_auc: 0.99825 |  0:07:09s\n",
      "epoch 33 | loss: 0.04278 | test_accuracy: 0.98227 | test_auc: 0.99826 |  0:07:23s\n",
      "epoch 34 | loss: 0.04252 | test_accuracy: 0.98227 | test_auc: 0.99826 |  0:07:36s\n",
      "epoch 35 | loss: 0.0424  | test_accuracy: 0.98157 | test_auc: 0.99827 |  0:07:51s\n",
      "epoch 36 | loss: 0.04252 | test_accuracy: 0.97984 | test_auc: 0.99825 |  0:08:02s\n",
      "epoch 37 | loss: 0.04272 | test_accuracy: 0.98175 | test_auc: 0.99823 |  0:08:14s\n",
      "epoch 38 | loss: 0.04353 | test_accuracy: 0.98227 | test_auc: 0.99823 |  0:08:29s\n",
      "epoch 39 | loss: 0.04577 | test_accuracy: 0.98175 | test_auc: 0.99819 |  0:08:44s\n",
      "epoch 40 | loss: 0.04527 | test_accuracy: 0.98105 | test_auc: 0.99823 |  0:08:56s\n",
      "epoch 41 | loss: 0.0446  | test_accuracy: 0.98262 | test_auc: 0.99831 |  0:09:12s\n",
      "epoch 42 | loss: 0.04354 | test_accuracy: 0.98227 | test_auc: 0.99834 |  0:09:23s\n",
      "epoch 43 | loss: 0.04292 | test_accuracy: 0.9814  | test_auc: 0.99806 |  0:09:38s\n",
      "epoch 44 | loss: 0.04339 | test_accuracy: 0.98227 | test_auc: 0.9981  |  0:09:53s\n",
      "epoch 45 | loss: 0.04232 | test_accuracy: 0.98175 | test_auc: 0.99817 |  0:10:08s\n",
      "epoch 46 | loss: 0.04364 | test_accuracy: 0.98175 | test_auc: 0.99815 |  0:10:20s\n",
      "epoch 47 | loss: 0.04408 | test_accuracy: 0.98262 | test_auc: 0.9982  |  0:10:32s\n",
      "epoch 48 | loss: 0.04387 | test_accuracy: 0.98192 | test_auc: 0.99804 |  0:10:45s\n",
      "epoch 49 | loss: 0.05036 | test_accuracy: 0.98123 | test_auc: 0.99823 |  0:11:00s\n",
      "epoch 50 | loss: 0.05359 | test_accuracy: 0.98088 | test_auc: 0.99779 |  0:11:13s\n",
      "epoch 51 | loss: 0.04895 | test_accuracy: 0.98157 | test_auc: 0.99811 |  0:11:26s\n",
      "epoch 52 | loss: 0.04699 | test_accuracy: 0.97879 | test_auc: 0.998   |  0:11:38s\n",
      "epoch 53 | loss: 0.04769 | test_accuracy: 0.98262 | test_auc: 0.99801 |  0:11:51s\n",
      "epoch 54 | loss: 0.04598 | test_accuracy: 0.97914 | test_auc: 0.99775 |  0:12:04s\n",
      "epoch 55 | loss: 0.04629 | test_accuracy: 0.9821  | test_auc: 0.99782 |  0:12:20s\n",
      "epoch 56 | loss: 0.04434 | test_accuracy: 0.98279 | test_auc: 0.99811 |  0:12:34s\n",
      "epoch 57 | loss: 0.04474 | test_accuracy: 0.98279 | test_auc: 0.99803 |  0:12:49s\n",
      "epoch 58 | loss: 0.04297 | test_accuracy: 0.98192 | test_auc: 0.99822 |  0:13:04s\n",
      "epoch 59 | loss: 0.04445 | test_accuracy: 0.9814  | test_auc: 0.99793 |  0:13:19s\n",
      "epoch 60 | loss: 0.04363 | test_accuracy: 0.98227 | test_auc: 0.99829 |  0:13:34s\n",
      "epoch 61 | loss: 0.04266 | test_accuracy: 0.98175 | test_auc: 0.99826 |  0:13:46s\n",
      "epoch 62 | loss: 0.04247 | test_accuracy: 0.98227 | test_auc: 0.99831 |  0:14:00s\n",
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 42 and best_test_auc = 0.99834\n",
      "Training fold 5/5...\n",
      "epoch 0  | loss: 0.19567 | test_accuracy: 0.88128 | test_auc: 0.93216 |  0:00:10s\n",
      "epoch 1  | loss: 0.07683 | test_accuracy: 0.89953 | test_auc: 0.92827 |  0:00:22s\n",
      "epoch 2  | loss: 0.06286 | test_accuracy: 0.94281 | test_auc: 0.95558 |  0:00:36s\n",
      "epoch 3  | loss: 0.05901 | test_accuracy: 0.95185 | test_auc: 0.98158 |  0:00:45s\n",
      "epoch 4  | loss: 0.05602 | test_accuracy: 0.97115 | test_auc: 0.98866 |  0:01:00s\n",
      "epoch 5  | loss: 0.05317 | test_accuracy: 0.97201 | test_auc: 0.99066 |  0:01:11s\n",
      "epoch 6  | loss: 0.05206 | test_accuracy: 0.97149 | test_auc: 0.99332 |  0:01:21s\n",
      "epoch 7  | loss: 0.04938 | test_accuracy: 0.97236 | test_auc: 0.99664 |  0:01:33s\n",
      "epoch 8  | loss: 0.04879 | test_accuracy: 0.9748  | test_auc: 0.99674 |  0:01:45s\n",
      "epoch 9  | loss: 0.04861 | test_accuracy: 0.9748  | test_auc: 0.99665 |  0:01:56s\n",
      "epoch 10 | loss: 0.05079 | test_accuracy: 0.97914 | test_auc: 0.99594 |  0:02:10s\n",
      "epoch 11 | loss: 0.05017 | test_accuracy: 0.98036 | test_auc: 0.99779 |  0:02:24s\n",
      "epoch 12 | loss: 0.05042 | test_accuracy: 0.9741  | test_auc: 0.99788 |  0:02:40s\n",
      "epoch 13 | loss: 0.05036 | test_accuracy: 0.97932 | test_auc: 0.99781 |  0:02:54s\n",
      "epoch 14 | loss: 0.05292 | test_accuracy: 0.98331 | test_auc: 0.99793 |  0:03:09s\n",
      "epoch 15 | loss: 0.04913 | test_accuracy: 0.98331 | test_auc: 0.99805 |  0:03:24s\n",
      "epoch 16 | loss: 0.04957 | test_accuracy: 0.98227 | test_auc: 0.99816 |  0:03:38s\n",
      "epoch 17 | loss: 0.04854 | test_accuracy: 0.98244 | test_auc: 0.99787 |  0:03:52s\n",
      "epoch 18 | loss: 0.05058 | test_accuracy: 0.9821  | test_auc: 0.99816 |  0:04:04s\n",
      "epoch 19 | loss: 0.05043 | test_accuracy: 0.98314 | test_auc: 0.99849 |  0:04:15s\n",
      "epoch 20 | loss: 0.04802 | test_accuracy: 0.98383 | test_auc: 0.99824 |  0:04:30s\n",
      "epoch 21 | loss: 0.04558 | test_accuracy: 0.98366 | test_auc: 0.99862 |  0:04:52s\n",
      "epoch 22 | loss: 0.04632 | test_accuracy: 0.98314 | test_auc: 0.99855 |  0:05:05s\n",
      "epoch 23 | loss: 0.04494 | test_accuracy: 0.98383 | test_auc: 0.99852 |  0:05:15s\n",
      "epoch 24 | loss: 0.0454  | test_accuracy: 0.98244 | test_auc: 0.99844 |  0:05:28s\n",
      "epoch 25 | loss: 0.04571 | test_accuracy: 0.98279 | test_auc: 0.99862 |  0:05:40s\n",
      "epoch 26 | loss: 0.04561 | test_accuracy: 0.98314 | test_auc: 0.99862 |  0:05:52s\n",
      "epoch 27 | loss: 0.04585 | test_accuracy: 0.98244 | test_auc: 0.99845 |  0:06:04s\n",
      "epoch 28 | loss: 0.04654 | test_accuracy: 0.98383 | test_auc: 0.99864 |  0:06:18s\n",
      "epoch 29 | loss: 0.04638 | test_accuracy: 0.98366 | test_auc: 0.99833 |  0:06:35s\n",
      "epoch 30 | loss: 0.04566 | test_accuracy: 0.98366 | test_auc: 0.99857 |  0:06:50s\n",
      "epoch 31 | loss: 0.04439 | test_accuracy: 0.98297 | test_auc: 0.9986  |  0:07:05s\n",
      "epoch 32 | loss: 0.04544 | test_accuracy: 0.98192 | test_auc: 0.99835 |  0:07:17s\n",
      "epoch 33 | loss: 0.04594 | test_accuracy: 0.98383 | test_auc: 0.99861 |  0:07:32s\n",
      "epoch 34 | loss: 0.04564 | test_accuracy: 0.98366 | test_auc: 0.99853 |  0:07:46s\n",
      "epoch 35 | loss: 0.04518 | test_accuracy: 0.98383 | test_auc: 0.9987  |  0:08:00s\n",
      "epoch 36 | loss: 0.04426 | test_accuracy: 0.98383 | test_auc: 0.99865 |  0:08:13s\n",
      "epoch 37 | loss: 0.04439 | test_accuracy: 0.98366 | test_auc: 0.99853 |  0:08:25s\n",
      "epoch 38 | loss: 0.04448 | test_accuracy: 0.98366 | test_auc: 0.9985  |  0:08:35s\n",
      "epoch 39 | loss: 0.04506 | test_accuracy: 0.98297 | test_auc: 0.9986  |  0:08:48s\n",
      "epoch 40 | loss: 0.0445  | test_accuracy: 0.98314 | test_auc: 0.99869 |  0:08:59s\n",
      "epoch 41 | loss: 0.04364 | test_accuracy: 0.98331 | test_auc: 0.99847 |  0:09:10s\n",
      "epoch 42 | loss: 0.04463 | test_accuracy: 0.98383 | test_auc: 0.99856 |  0:09:23s\n",
      "epoch 43 | loss: 0.0435  | test_accuracy: 0.98401 | test_auc: 0.99857 |  0:09:33s\n",
      "epoch 44 | loss: 0.04361 | test_accuracy: 0.98331 | test_auc: 0.99846 |  0:09:44s\n",
      "epoch 45 | loss: 0.04367 | test_accuracy: 0.98314 | test_auc: 0.99864 |  0:09:56s\n",
      "epoch 46 | loss: 0.04655 | test_accuracy: 0.98436 | test_auc: 0.99826 |  0:10:11s\n",
      "epoch 47 | loss: 0.0463  | test_accuracy: 0.98349 | test_auc: 0.99859 |  0:10:25s\n",
      "epoch 48 | loss: 0.04518 | test_accuracy: 0.98418 | test_auc: 0.99852 |  0:10:37s\n",
      "epoch 49 | loss: 0.04397 | test_accuracy: 0.98244 | test_auc: 0.99857 |  0:10:52s\n",
      "epoch 50 | loss: 0.04328 | test_accuracy: 0.98262 | test_auc: 0.99865 |  0:11:08s\n",
      "epoch 51 | loss: 0.0468  | test_accuracy: 0.98279 | test_auc: 0.99856 |  0:11:23s\n",
      "epoch 52 | loss: 0.04636 | test_accuracy: 0.98331 | test_auc: 0.99862 |  0:11:37s\n",
      "epoch 53 | loss: 0.04513 | test_accuracy: 0.98331 | test_auc: 0.99871 |  0:11:47s\n",
      "epoch 54 | loss: 0.04329 | test_accuracy: 0.98401 | test_auc: 0.99859 |  0:12:02s\n",
      "epoch 55 | loss: 0.04274 | test_accuracy: 0.98331 | test_auc: 0.99864 |  0:12:13s\n",
      "epoch 56 | loss: 0.0453  | test_accuracy: 0.98001 | test_auc: 0.99846 |  0:12:25s\n",
      "epoch 57 | loss: 0.04795 | test_accuracy: 0.98331 | test_auc: 0.99847 |  0:12:38s\n",
      "epoch 58 | loss: 0.04831 | test_accuracy: 0.98401 | test_auc: 0.99835 |  0:12:48s\n",
      "epoch 59 | loss: 0.04767 | test_accuracy: 0.9821  | test_auc: 0.99841 |  0:13:01s\n",
      "epoch 60 | loss: 0.05079 | test_accuracy: 0.98123 | test_auc: 0.99821 |  0:13:14s\n",
      "epoch 61 | loss: 0.04718 | test_accuracy: 0.98366 | test_auc: 0.99824 |  0:13:27s\n",
      "epoch 62 | loss: 0.04577 | test_accuracy: 0.98297 | test_auc: 0.99853 |  0:13:39s\n",
      "epoch 63 | loss: 0.04811 | test_accuracy: 0.98123 | test_auc: 0.99827 |  0:13:52s\n",
      "epoch 64 | loss: 0.0475  | test_accuracy: 0.98366 | test_auc: 0.99817 |  0:14:06s\n",
      "epoch 65 | loss: 0.04601 | test_accuracy: 0.98366 | test_auc: 0.99823 |  0:14:19s\n",
      "epoch 66 | loss: 0.04513 | test_accuracy: 0.98244 | test_auc: 0.99828 |  0:14:33s\n",
      "epoch 67 | loss: 0.04738 | test_accuracy: 0.98262 | test_auc: 0.99836 |  0:14:47s\n",
      "epoch 68 | loss: 0.04502 | test_accuracy: 0.98366 | test_auc: 0.99845 |  0:14:59s\n",
      "epoch 69 | loss: 0.04488 | test_accuracy: 0.98366 | test_auc: 0.99849 |  0:15:12s\n",
      "epoch 70 | loss: 0.04485 | test_accuracy: 0.98401 | test_auc: 0.99836 |  0:15:25s\n",
      "epoch 71 | loss: 0.04688 | test_accuracy: 0.98401 | test_auc: 0.99839 |  0:15:41s\n",
      "epoch 72 | loss: 0.04459 | test_accuracy: 0.98349 | test_auc: 0.9984  |  0:15:55s\n",
      "epoch 73 | loss: 0.04527 | test_accuracy: 0.98331 | test_auc: 0.99844 |  0:16:06s\n",
      "\n",
      "Early stopping occurred at epoch 73 with best_epoch = 53 and best_test_auc = 0.99871\n",
      "\n",
      "Results for 9. XGBoost Importance:\n",
      "Average accuracy: 0.9829 ± 0.0015\n",
      "Average precision: 0.9917 ± 0.0043\n",
      "Average recall: 0.9600 ± 0.0054\n",
      "Average f1: 0.9756 ± 0.0024\n",
      "Average auc: 0.9778 ± 0.0022\n",
      "\n",
      "==================================================\n",
      "Processing 10. LightGBM Importance\n",
      "==================================================\n",
      "Selecting features using 10. LightGBM Importance...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10252, number of negative: 18514\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32\n",
      "[LightGBM] [Info] Number of data points in the train set: 28766, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.356393 -> initscore=-0.591054\n",
      "[LightGBM] [Info] Start training from score -0.591054\n",
      "Top 10 features selected by 10. LightGBM Importance:\n",
      "1. Breathing Problem: 266.0000\n",
      "2. Sore throat: 212.0000\n",
      "3. Asthma: 220.0000\n",
      "4. Chronic Lung Disease: 240.0000\n",
      "5. Heart Disease: 207.0000\n",
      "6. Hyper Tension: 207.0000\n",
      "7. Abroad travel: 169.0000\n",
      "8. Contact with COVID Patient: 216.0000\n",
      "9. Attended Large Gathering: 183.0000\n",
      "10. Family working in Public Exposed Places: 199.0000\n",
      "\n",
      "Training TabNet with features selected by 10. LightGBM Importance\n",
      "Training fold 1/5...\n",
      "epoch 0  | loss: 0.23776 | test_accuracy: 0.62009 | test_auc: 0.97616 |  0:00:13s\n",
      "epoch 1  | loss: 0.07354 | test_accuracy: 0.8601  | test_auc: 0.98385 |  0:00:26s\n",
      "epoch 2  | loss: 0.06089 | test_accuracy: 0.88391 | test_auc: 0.99162 |  0:00:41s\n",
      "epoch 3  | loss: 0.05346 | test_accuracy: 0.9204  | test_auc: 0.99429 |  0:00:54s\n",
      "epoch 4  | loss: 0.04989 | test_accuracy: 0.93187 | test_auc: 0.99375 |  0:01:04s\n",
      "epoch 5  | loss: 0.04456 | test_accuracy: 0.94352 | test_auc: 0.99632 |  0:01:18s\n",
      "epoch 6  | loss: 0.04001 | test_accuracy: 0.94439 | test_auc: 0.99691 |  0:01:32s\n",
      "epoch 7  | loss: 0.03539 | test_accuracy: 0.98418 | test_auc: 0.99804 |  0:01:45s\n",
      "epoch 8  | loss: 0.03617 | test_accuracy: 0.98106 | test_auc: 0.99801 |  0:01:58s\n",
      "epoch 9  | loss: 0.0344  | test_accuracy: 0.98627 | test_auc: 0.99861 |  0:02:09s\n",
      "epoch 10 | loss: 0.03675 | test_accuracy: 0.98436 | test_auc: 0.99871 |  0:02:25s\n",
      "epoch 11 | loss: 0.03523 | test_accuracy: 0.99096 | test_auc: 0.99923 |  0:02:40s\n",
      "epoch 12 | loss: 0.03097 | test_accuracy: 0.99253 | test_auc: 0.99914 |  0:02:56s\n",
      "epoch 13 | loss: 0.02956 | test_accuracy: 0.9934  | test_auc: 0.9992  |  0:03:11s\n",
      "epoch 14 | loss: 0.03041 | test_accuracy: 0.99392 | test_auc: 0.99899 |  0:03:24s\n",
      "epoch 15 | loss: 0.02947 | test_accuracy: 0.99374 | test_auc: 0.99937 |  0:03:41s\n",
      "epoch 16 | loss: 0.02861 | test_accuracy: 0.99426 | test_auc: 0.99923 |  0:03:55s\n",
      "epoch 17 | loss: 0.02842 | test_accuracy: 0.99444 | test_auc: 0.99916 |  0:04:07s\n",
      "epoch 18 | loss: 0.02604 | test_accuracy: 0.99426 | test_auc: 0.99923 |  0:04:17s\n",
      "epoch 19 | loss: 0.02723 | test_accuracy: 0.99287 | test_auc: 0.99917 |  0:04:29s\n",
      "epoch 20 | loss: 0.02753 | test_accuracy: 0.99392 | test_auc: 0.99921 |  0:04:42s\n",
      "epoch 21 | loss: 0.02863 | test_accuracy: 0.99166 | test_auc: 0.99916 |  0:04:55s\n",
      "epoch 22 | loss: 0.02889 | test_accuracy: 0.98801 | test_auc: 0.99912 |  0:05:09s\n",
      "epoch 23 | loss: 0.02864 | test_accuracy: 0.99409 | test_auc: 0.99922 |  0:05:21s\n",
      "epoch 24 | loss: 0.02939 | test_accuracy: 0.99374 | test_auc: 0.99919 |  0:05:33s\n",
      "epoch 25 | loss: 0.02755 | test_accuracy: 0.99374 | test_auc: 0.9993  |  0:05:46s\n",
      "epoch 26 | loss: 0.02664 | test_accuracy: 0.99426 | test_auc: 0.99917 |  0:06:00s\n",
      "epoch 27 | loss: 0.02624 | test_accuracy: 0.99374 | test_auc: 0.99933 |  0:06:19s\n",
      "epoch 28 | loss: 0.02499 | test_accuracy: 0.99322 | test_auc: 0.9993  |  0:06:33s\n",
      "epoch 29 | loss: 0.02585 | test_accuracy: 0.99409 | test_auc: 0.99928 |  0:06:48s\n",
      "epoch 30 | loss: 0.02613 | test_accuracy: 0.99409 | test_auc: 0.99935 |  0:07:03s\n",
      "epoch 31 | loss: 0.02619 | test_accuracy: 0.99305 | test_auc: 0.99931 |  0:07:19s\n",
      "epoch 32 | loss: 0.02563 | test_accuracy: 0.99409 | test_auc: 0.99936 |  0:07:35s\n",
      "epoch 33 | loss: 0.02469 | test_accuracy: 0.99409 | test_auc: 0.9993  |  0:07:50s\n",
      "epoch 34 | loss: 0.0255  | test_accuracy: 0.99426 | test_auc: 0.99942 |  0:08:03s\n",
      "epoch 35 | loss: 0.02576 | test_accuracy: 0.99409 | test_auc: 0.99934 |  0:08:15s\n",
      "epoch 36 | loss: 0.02459 | test_accuracy: 0.99409 | test_auc: 0.99943 |  0:08:28s\n",
      "epoch 37 | loss: 0.02495 | test_accuracy: 0.99426 | test_auc: 0.99936 |  0:08:40s\n",
      "epoch 38 | loss: 0.0254  | test_accuracy: 0.99409 | test_auc: 0.99925 |  0:08:51s\n",
      "epoch 39 | loss: 0.0248  | test_accuracy: 0.99374 | test_auc: 0.99926 |  0:09:04s\n",
      "epoch 40 | loss: 0.02449 | test_accuracy: 0.99374 | test_auc: 0.99942 |  0:09:17s\n",
      "epoch 41 | loss: 0.02395 | test_accuracy: 0.99374 | test_auc: 0.99946 |  0:09:28s\n",
      "epoch 42 | loss: 0.0232  | test_accuracy: 0.99322 | test_auc: 0.99953 |  0:09:43s\n",
      "epoch 43 | loss: 0.02412 | test_accuracy: 0.99374 | test_auc: 0.99953 |  0:09:51s\n",
      "epoch 44 | loss: 0.02375 | test_accuracy: 0.99374 | test_auc: 0.99954 |  0:10:05s\n",
      "epoch 45 | loss: 0.02404 | test_accuracy: 0.99426 | test_auc: 0.99947 |  0:10:21s\n",
      "epoch 46 | loss: 0.02421 | test_accuracy: 0.99392 | test_auc: 0.99951 |  0:10:35s\n",
      "epoch 47 | loss: 0.02533 | test_accuracy: 0.99374 | test_auc: 0.99932 |  0:10:50s\n",
      "epoch 48 | loss: 0.02567 | test_accuracy: 0.99374 | test_auc: 0.99947 |  0:11:01s\n",
      "epoch 49 | loss: 0.02557 | test_accuracy: 0.99409 | test_auc: 0.99952 |  0:11:16s\n",
      "epoch 50 | loss: 0.02559 | test_accuracy: 0.99218 | test_auc: 0.9995  |  0:11:29s\n",
      "epoch 51 | loss: 0.02733 | test_accuracy: 0.99357 | test_auc: 0.99946 |  0:11:44s\n",
      "epoch 52 | loss: 0.02659 | test_accuracy: 0.99409 | test_auc: 0.99944 |  0:11:58s\n",
      "epoch 53 | loss: 0.02605 | test_accuracy: 0.99114 | test_auc: 0.99907 |  0:12:11s\n",
      "epoch 54 | loss: 0.02619 | test_accuracy: 0.99305 | test_auc: 0.9994  |  0:12:23s\n",
      "epoch 55 | loss: 0.02437 | test_accuracy: 0.99357 | test_auc: 0.99945 |  0:12:35s\n",
      "epoch 56 | loss: 0.02547 | test_accuracy: 0.99374 | test_auc: 0.99952 |  0:12:50s\n",
      "epoch 57 | loss: 0.02485 | test_accuracy: 0.99322 | test_auc: 0.99949 |  0:13:03s\n",
      "epoch 58 | loss: 0.02548 | test_accuracy: 0.99392 | test_auc: 0.99953 |  0:13:14s\n",
      "epoch 59 | loss: 0.02457 | test_accuracy: 0.99357 | test_auc: 0.99949 |  0:13:27s\n",
      "epoch 60 | loss: 0.0247  | test_accuracy: 0.99409 | test_auc: 0.99942 |  0:13:41s\n",
      "epoch 61 | loss: 0.02425 | test_accuracy: 0.99409 | test_auc: 0.99954 |  0:13:53s\n",
      "epoch 62 | loss: 0.02392 | test_accuracy: 0.99426 | test_auc: 0.99955 |  0:14:06s\n",
      "epoch 63 | loss: 0.02365 | test_accuracy: 0.99444 | test_auc: 0.99954 |  0:14:18s\n",
      "epoch 64 | loss: 0.0228  | test_accuracy: 0.99409 | test_auc: 0.99954 |  0:14:34s\n",
      "epoch 65 | loss: 0.02372 | test_accuracy: 0.99409 | test_auc: 0.99951 |  0:14:50s\n",
      "epoch 66 | loss: 0.02441 | test_accuracy: 0.99374 | test_auc: 0.99949 |  0:15:06s\n",
      "epoch 67 | loss: 0.02399 | test_accuracy: 0.99444 | test_auc: 0.99941 |  0:15:18s\n",
      "epoch 68 | loss: 0.02469 | test_accuracy: 0.99374 | test_auc: 0.99944 |  0:15:33s\n",
      "epoch 69 | loss: 0.0236  | test_accuracy: 0.99426 | test_auc: 0.99952 |  0:15:50s\n",
      "epoch 70 | loss: 0.02346 | test_accuracy: 0.99322 | test_auc: 0.99936 |  0:16:01s\n",
      "epoch 71 | loss: 0.02755 | test_accuracy: 0.99305 | test_auc: 0.99941 |  0:16:13s\n",
      "epoch 72 | loss: 0.02544 | test_accuracy: 0.99392 | test_auc: 0.99942 |  0:16:25s\n",
      "epoch 73 | loss: 0.02603 | test_accuracy: 0.99392 | test_auc: 0.99938 |  0:16:38s\n",
      "epoch 74 | loss: 0.02516 | test_accuracy: 0.99374 | test_auc: 0.99939 |  0:16:51s\n",
      "epoch 75 | loss: 0.02748 | test_accuracy: 0.99235 | test_auc: 0.99914 |  0:17:05s\n",
      "epoch 76 | loss: 0.03009 | test_accuracy: 0.99253 | test_auc: 0.99916 |  0:17:18s\n",
      "epoch 77 | loss: 0.03146 | test_accuracy: 0.99409 | test_auc: 0.99933 |  0:17:29s\n",
      "epoch 78 | loss: 0.02646 | test_accuracy: 0.9934  | test_auc: 0.99939 |  0:17:41s\n",
      "epoch 79 | loss: 0.02527 | test_accuracy: 0.99253 | test_auc: 0.99925 |  0:17:54s\n",
      "epoch 80 | loss: 0.02509 | test_accuracy: 0.99409 | test_auc: 0.99922 |  0:18:09s\n",
      "epoch 81 | loss: 0.0243  | test_accuracy: 0.99409 | test_auc: 0.99942 |  0:18:25s\n",
      "epoch 82 | loss: 0.02454 | test_accuracy: 0.99392 | test_auc: 0.99945 |  0:18:36s\n",
      "\n",
      "Early stopping occurred at epoch 82 with best_epoch = 62 and best_test_auc = 0.99955\n",
      "Training fold 2/5...\n",
      "epoch 0  | loss: 0.25574 | test_accuracy: 0.69442 | test_auc: 0.98524 |  0:00:16s\n",
      "epoch 1  | loss: 0.07677 | test_accuracy: 0.90857 | test_auc: 0.99108 |  0:00:27s\n",
      "epoch 2  | loss: 0.05792 | test_accuracy: 0.91952 | test_auc: 0.99429 |  0:00:40s\n",
      "epoch 3  | loss: 0.05243 | test_accuracy: 0.9628  | test_auc: 0.99589 |  0:00:55s\n",
      "epoch 4  | loss: 0.04981 | test_accuracy: 0.98036 | test_auc: 0.9961  |  0:01:07s\n",
      "epoch 5  | loss: 0.04459 | test_accuracy: 0.9489  | test_auc: 0.99632 |  0:01:21s\n",
      "epoch 6  | loss: 0.04206 | test_accuracy: 0.98662 | test_auc: 0.99739 |  0:01:34s\n",
      "epoch 7  | loss: 0.04051 | test_accuracy: 0.95116 | test_auc: 0.99721 |  0:01:46s\n",
      "epoch 8  | loss: 0.04301 | test_accuracy: 0.98592 | test_auc: 0.99846 |  0:01:58s\n",
      "epoch 9  | loss: 0.04299 | test_accuracy: 0.98835 | test_auc: 0.99844 |  0:02:08s\n",
      "epoch 10 | loss: 0.03686 | test_accuracy: 0.98557 | test_auc: 0.99789 |  0:02:20s\n",
      "epoch 11 | loss: 0.03939 | test_accuracy: 0.98696 | test_auc: 0.99834 |  0:02:32s\n",
      "epoch 12 | loss: 0.03714 | test_accuracy: 0.98853 | test_auc: 0.99845 |  0:02:46s\n",
      "epoch 13 | loss: 0.04188 | test_accuracy: 0.98801 | test_auc: 0.99853 |  0:02:59s\n",
      "epoch 14 | loss: 0.03817 | test_accuracy: 0.98644 | test_auc: 0.99822 |  0:03:11s\n",
      "epoch 15 | loss: 0.04432 | test_accuracy: 0.98401 | test_auc: 0.99798 |  0:03:25s\n",
      "epoch 16 | loss: 0.04141 | test_accuracy: 0.98992 | test_auc: 0.99864 |  0:03:40s\n",
      "epoch 17 | loss: 0.03656 | test_accuracy: 0.99009 | test_auc: 0.99877 |  0:03:54s\n",
      "epoch 18 | loss: 0.03514 | test_accuracy: 0.99044 | test_auc: 0.99898 |  0:04:09s\n",
      "epoch 19 | loss: 0.03414 | test_accuracy: 0.98974 | test_auc: 0.99868 |  0:04:22s\n",
      "epoch 20 | loss: 0.03713 | test_accuracy: 0.98957 | test_auc: 0.99851 |  0:04:39s\n",
      "epoch 21 | loss: 0.03406 | test_accuracy: 0.99114 | test_auc: 0.99855 |  0:04:54s\n",
      "epoch 22 | loss: 0.03495 | test_accuracy: 0.99061 | test_auc: 0.99849 |  0:05:11s\n",
      "epoch 23 | loss: 0.03452 | test_accuracy: 0.98992 | test_auc: 0.99869 |  0:05:24s\n",
      "epoch 24 | loss: 0.03668 | test_accuracy: 0.99096 | test_auc: 0.99847 |  0:05:38s\n",
      "epoch 25 | loss: 0.03367 | test_accuracy: 0.99183 | test_auc: 0.99901 |  0:05:52s\n",
      "epoch 26 | loss: 0.03522 | test_accuracy: 0.99044 | test_auc: 0.99848 |  0:06:05s\n",
      "epoch 27 | loss: 0.03255 | test_accuracy: 0.99253 | test_auc: 0.99881 |  0:06:16s\n",
      "epoch 28 | loss: 0.02945 | test_accuracy: 0.992   | test_auc: 0.99875 |  0:06:29s\n",
      "epoch 29 | loss: 0.02802 | test_accuracy: 0.99235 | test_auc: 0.99903 |  0:06:42s\n",
      "epoch 30 | loss: 0.02858 | test_accuracy: 0.992   | test_auc: 0.99873 |  0:06:56s\n",
      "epoch 31 | loss: 0.0289  | test_accuracy: 0.99131 | test_auc: 0.99887 |  0:07:11s\n",
      "epoch 32 | loss: 0.03901 | test_accuracy: 0.98853 | test_auc: 0.99791 |  0:07:24s\n",
      "epoch 33 | loss: 0.04783 | test_accuracy: 0.98592 | test_auc: 0.99791 |  0:07:37s\n",
      "epoch 34 | loss: 0.04165 | test_accuracy: 0.9894  | test_auc: 0.99868 |  0:07:53s\n",
      "epoch 35 | loss: 0.03569 | test_accuracy: 0.992   | test_auc: 0.99892 |  0:08:08s\n",
      "epoch 36 | loss: 0.0355  | test_accuracy: 0.99131 | test_auc: 0.99878 |  0:08:23s\n",
      "epoch 37 | loss: 0.0339  | test_accuracy: 0.99079 | test_auc: 0.9983  |  0:08:38s\n",
      "epoch 38 | loss: 0.0322  | test_accuracy: 0.99148 | test_auc: 0.99911 |  0:08:52s\n",
      "epoch 39 | loss: 0.02956 | test_accuracy: 0.99166 | test_auc: 0.99913 |  0:09:07s\n",
      "epoch 40 | loss: 0.03214 | test_accuracy: 0.99253 | test_auc: 0.99889 |  0:09:19s\n",
      "epoch 41 | loss: 0.03047 | test_accuracy: 0.9927  | test_auc: 0.99903 |  0:09:33s\n",
      "epoch 42 | loss: 0.02786 | test_accuracy: 0.99235 | test_auc: 0.99904 |  0:09:46s\n",
      "epoch 43 | loss: 0.02831 | test_accuracy: 0.99183 | test_auc: 0.999   |  0:09:57s\n",
      "epoch 44 | loss: 0.02799 | test_accuracy: 0.99322 | test_auc: 0.9991  |  0:10:12s\n",
      "epoch 45 | loss: 0.02584 | test_accuracy: 0.99287 | test_auc: 0.99898 |  0:10:25s\n",
      "epoch 46 | loss: 0.02573 | test_accuracy: 0.99305 | test_auc: 0.99907 |  0:10:33s\n",
      "epoch 47 | loss: 0.02373 | test_accuracy: 0.99305 | test_auc: 0.99914 |  0:10:45s\n",
      "epoch 48 | loss: 0.02469 | test_accuracy: 0.99374 | test_auc: 0.99907 |  0:10:55s\n",
      "epoch 49 | loss: 0.02478 | test_accuracy: 0.99305 | test_auc: 0.9991  |  0:11:08s\n",
      "epoch 50 | loss: 0.02566 | test_accuracy: 0.99357 | test_auc: 0.99911 |  0:11:23s\n",
      "epoch 51 | loss: 0.02402 | test_accuracy: 0.99374 | test_auc: 0.99908 |  0:11:40s\n",
      "epoch 52 | loss: 0.02377 | test_accuracy: 0.99374 | test_auc: 0.99908 |  0:11:56s\n",
      "epoch 53 | loss: 0.02359 | test_accuracy: 0.99374 | test_auc: 0.99913 |  0:12:10s\n",
      "epoch 54 | loss: 0.02332 | test_accuracy: 0.99374 | test_auc: 0.99918 |  0:12:26s\n",
      "epoch 55 | loss: 0.02338 | test_accuracy: 0.99374 | test_auc: 0.99921 |  0:12:40s\n",
      "epoch 56 | loss: 0.02482 | test_accuracy: 0.99409 | test_auc: 0.99918 |  0:12:56s\n",
      "epoch 57 | loss: 0.02382 | test_accuracy: 0.99305 | test_auc: 0.99917 |  0:13:11s\n",
      "epoch 58 | loss: 0.02445 | test_accuracy: 0.99374 | test_auc: 0.99912 |  0:13:24s\n",
      "epoch 59 | loss: 0.02626 | test_accuracy: 0.99305 | test_auc: 0.99916 |  0:13:36s\n",
      "epoch 60 | loss: 0.02585 | test_accuracy: 0.99287 | test_auc: 0.99902 |  0:13:48s\n",
      "epoch 61 | loss: 0.02427 | test_accuracy: 0.99287 | test_auc: 0.99905 |  0:14:02s\n",
      "epoch 62 | loss: 0.02547 | test_accuracy: 0.99183 | test_auc: 0.99904 |  0:14:13s\n",
      "epoch 63 | loss: 0.02667 | test_accuracy: 0.9927  | test_auc: 0.9991  |  0:14:26s\n",
      "epoch 64 | loss: 0.02501 | test_accuracy: 0.99287 | test_auc: 0.99913 |  0:14:38s\n",
      "epoch 65 | loss: 0.02508 | test_accuracy: 0.99339 | test_auc: 0.99914 |  0:14:49s\n",
      "epoch 66 | loss: 0.02434 | test_accuracy: 0.99287 | test_auc: 0.99905 |  0:15:02s\n",
      "epoch 67 | loss: 0.02376 | test_accuracy: 0.99287 | test_auc: 0.99906 |  0:15:16s\n",
      "epoch 68 | loss: 0.02426 | test_accuracy: 0.99339 | test_auc: 0.99919 |  0:15:29s\n",
      "epoch 69 | loss: 0.02418 | test_accuracy: 0.9927  | test_auc: 0.99918 |  0:15:45s\n",
      "epoch 70 | loss: 0.02443 | test_accuracy: 0.99339 | test_auc: 0.99915 |  0:16:01s\n",
      "epoch 71 | loss: 0.02348 | test_accuracy: 0.99339 | test_auc: 0.99921 |  0:16:15s\n",
      "epoch 72 | loss: 0.02374 | test_accuracy: 0.99339 | test_auc: 0.99921 |  0:16:25s\n",
      "epoch 73 | loss: 0.02325 | test_accuracy: 0.99339 | test_auc: 0.99904 |  0:16:39s\n",
      "epoch 74 | loss: 0.0237  | test_accuracy: 0.99339 | test_auc: 0.99919 |  0:16:56s\n",
      "epoch 75 | loss: 0.02364 | test_accuracy: 0.99339 | test_auc: 0.99921 |  0:17:13s\n",
      "epoch 76 | loss: 0.02328 | test_accuracy: 0.99339 | test_auc: 0.99915 |  0:17:25s\n",
      "epoch 77 | loss: 0.02303 | test_accuracy: 0.99339 | test_auc: 0.99912 |  0:17:36s\n",
      "epoch 78 | loss: 0.02346 | test_accuracy: 0.99339 | test_auc: 0.99913 |  0:17:51s\n",
      "epoch 79 | loss: 0.02428 | test_accuracy: 0.99339 | test_auc: 0.99908 |  0:18:06s\n",
      "epoch 80 | loss: 0.02342 | test_accuracy: 0.99339 | test_auc: 0.99916 |  0:18:19s\n",
      "epoch 81 | loss: 0.02396 | test_accuracy: 0.99339 | test_auc: 0.99909 |  0:18:33s\n",
      "epoch 82 | loss: 0.02541 | test_accuracy: 0.99253 | test_auc: 0.99902 |  0:18:44s\n",
      "epoch 83 | loss: 0.02815 | test_accuracy: 0.99166 | test_auc: 0.99907 |  0:18:56s\n",
      "epoch 84 | loss: 0.02524 | test_accuracy: 0.99235 | test_auc: 0.99903 |  0:19:08s\n",
      "epoch 85 | loss: 0.02524 | test_accuracy: 0.99339 | test_auc: 0.99909 |  0:19:22s\n",
      "epoch 86 | loss: 0.02475 | test_accuracy: 0.99339 | test_auc: 0.99908 |  0:19:38s\n",
      "epoch 87 | loss: 0.02512 | test_accuracy: 0.99253 | test_auc: 0.99887 |  0:19:50s\n",
      "epoch 88 | loss: 0.02483 | test_accuracy: 0.99339 | test_auc: 0.99915 |  0:20:06s\n",
      "epoch 89 | loss: 0.02381 | test_accuracy: 0.99374 | test_auc: 0.99912 |  0:20:21s\n",
      "epoch 90 | loss: 0.02383 | test_accuracy: 0.99305 | test_auc: 0.9991  |  0:20:34s\n",
      "epoch 91 | loss: 0.02341 | test_accuracy: 0.99374 | test_auc: 0.99922 |  0:20:49s\n",
      "epoch 92 | loss: 0.02283 | test_accuracy: 0.99374 | test_auc: 0.9992  |  0:21:02s\n",
      "epoch 93 | loss: 0.02302 | test_accuracy: 0.99374 | test_auc: 0.99914 |  0:21:18s\n",
      "epoch 94 | loss: 0.02268 | test_accuracy: 0.99374 | test_auc: 0.9989  |  0:21:28s\n",
      "epoch 95 | loss: 0.02351 | test_accuracy: 0.99374 | test_auc: 0.99876 |  0:21:41s\n",
      "epoch 96 | loss: 0.02382 | test_accuracy: 0.99374 | test_auc: 0.99885 |  0:21:53s\n",
      "epoch 97 | loss: 0.02322 | test_accuracy: 0.99374 | test_auc: 0.9989  |  0:22:06s\n",
      "epoch 98 | loss: 0.02369 | test_accuracy: 0.99339 | test_auc: 0.99891 |  0:22:19s\n",
      "epoch 99 | loss: 0.02392 | test_accuracy: 0.99374 | test_auc: 0.9988  |  0:22:31s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 91 and best_test_auc = 0.99922\n",
      "Training fold 3/5...\n",
      "epoch 0  | loss: 0.22874 | test_accuracy: 0.84669 | test_auc: 0.99002 |  0:00:12s\n",
      "epoch 1  | loss: 0.06491 | test_accuracy: 0.58787 | test_auc: 0.9946  |  0:00:24s\n",
      "epoch 2  | loss: 0.04713 | test_accuracy: 0.91952 | test_auc: 0.99552 |  0:00:35s\n",
      "epoch 3  | loss: 0.0429  | test_accuracy: 0.91205 | test_auc: 0.99625 |  0:00:53s\n",
      "epoch 4  | loss: 0.03956 | test_accuracy: 0.92387 | test_auc: 0.99529 |  0:01:08s\n",
      "epoch 5  | loss: 0.03338 | test_accuracy: 0.92891 | test_auc: 0.99637 |  0:01:24s\n",
      "epoch 6  | loss: 0.03277 | test_accuracy: 0.94577 | test_auc: 0.99625 |  0:01:37s\n",
      "epoch 7  | loss: 0.03308 | test_accuracy: 0.94055 | test_auc: 0.99703 |  0:01:52s\n",
      "epoch 8  | loss: 0.03236 | test_accuracy: 0.98748 | test_auc: 0.99799 |  0:02:08s\n",
      "epoch 9  | loss: 0.03226 | test_accuracy: 0.98418 | test_auc: 0.99687 |  0:02:24s\n",
      "epoch 10 | loss: 0.03219 | test_accuracy: 0.98627 | test_auc: 0.99801 |  0:02:38s\n",
      "epoch 11 | loss: 0.02987 | test_accuracy: 0.98835 | test_auc: 0.99807 |  0:02:51s\n",
      "epoch 12 | loss: 0.02796 | test_accuracy: 0.98922 | test_auc: 0.99804 |  0:03:02s\n",
      "epoch 13 | loss: 0.0295  | test_accuracy: 0.98748 | test_auc: 0.99817 |  0:03:12s\n",
      "epoch 14 | loss: 0.02957 | test_accuracy: 0.9887  | test_auc: 0.99849 |  0:03:25s\n",
      "epoch 15 | loss: 0.02918 | test_accuracy: 0.98957 | test_auc: 0.99853 |  0:03:38s\n",
      "epoch 16 | loss: 0.02795 | test_accuracy: 0.98905 | test_auc: 0.99829 |  0:03:48s\n",
      "epoch 17 | loss: 0.03046 | test_accuracy: 0.98922 | test_auc: 0.99811 |  0:04:01s\n",
      "epoch 18 | loss: 0.02793 | test_accuracy: 0.9887  | test_auc: 0.99845 |  0:04:14s\n",
      "epoch 19 | loss: 0.02571 | test_accuracy: 0.98905 | test_auc: 0.99849 |  0:04:29s\n",
      "epoch 20 | loss: 0.02684 | test_accuracy: 0.98888 | test_auc: 0.99857 |  0:04:44s\n",
      "epoch 21 | loss: 0.02469 | test_accuracy: 0.99027 | test_auc: 0.9986  |  0:04:58s\n",
      "epoch 22 | loss: 0.02432 | test_accuracy: 0.99061 | test_auc: 0.99854 |  0:05:13s\n",
      "epoch 23 | loss: 0.025   | test_accuracy: 0.98974 | test_auc: 0.99865 |  0:05:28s\n",
      "epoch 24 | loss: 0.02438 | test_accuracy: 0.98905 | test_auc: 0.99847 |  0:05:41s\n",
      "epoch 25 | loss: 0.02467 | test_accuracy: 0.98922 | test_auc: 0.99839 |  0:05:56s\n",
      "epoch 26 | loss: 0.02519 | test_accuracy: 0.99061 | test_auc: 0.99858 |  0:06:12s\n",
      "epoch 27 | loss: 0.02447 | test_accuracy: 0.99061 | test_auc: 0.99845 |  0:06:27s\n",
      "epoch 28 | loss: 0.02357 | test_accuracy: 0.99079 | test_auc: 0.99876 |  0:06:43s\n",
      "epoch 29 | loss: 0.02381 | test_accuracy: 0.99044 | test_auc: 0.99836 |  0:06:56s\n",
      "epoch 30 | loss: 0.0231  | test_accuracy: 0.99148 | test_auc: 0.99871 |  0:07:09s\n",
      "epoch 31 | loss: 0.02302 | test_accuracy: 0.99096 | test_auc: 0.99863 |  0:07:22s\n",
      "epoch 32 | loss: 0.02366 | test_accuracy: 0.99131 | test_auc: 0.99866 |  0:07:36s\n",
      "epoch 33 | loss: 0.0237  | test_accuracy: 0.99079 | test_auc: 0.99875 |  0:07:48s\n",
      "epoch 34 | loss: 0.02401 | test_accuracy: 0.99061 | test_auc: 0.99865 |  0:08:01s\n",
      "epoch 35 | loss: 0.02522 | test_accuracy: 0.99027 | test_auc: 0.99828 |  0:08:12s\n",
      "epoch 36 | loss: 0.02553 | test_accuracy: 0.99027 | test_auc: 0.99875 |  0:08:25s\n",
      "epoch 37 | loss: 0.02898 | test_accuracy: 0.98888 | test_auc: 0.99839 |  0:08:40s\n",
      "epoch 38 | loss: 0.02742 | test_accuracy: 0.98974 | test_auc: 0.99859 |  0:08:56s\n",
      "epoch 39 | loss: 0.02751 | test_accuracy: 0.99061 | test_auc: 0.99844 |  0:09:10s\n",
      "epoch 40 | loss: 0.0271  | test_accuracy: 0.98853 | test_auc: 0.99845 |  0:09:26s\n",
      "epoch 41 | loss: 0.02661 | test_accuracy: 0.99027 | test_auc: 0.99841 |  0:09:42s\n",
      "epoch 42 | loss: 0.02631 | test_accuracy: 0.99079 | test_auc: 0.99856 |  0:09:57s\n",
      "epoch 43 | loss: 0.02389 | test_accuracy: 0.98922 | test_auc: 0.99845 |  0:10:13s\n",
      "epoch 44 | loss: 0.02421 | test_accuracy: 0.99027 | test_auc: 0.99836 |  0:10:24s\n",
      "epoch 45 | loss: 0.02379 | test_accuracy: 0.99079 | test_auc: 0.9986  |  0:10:40s\n",
      "epoch 46 | loss: 0.02438 | test_accuracy: 0.98801 | test_auc: 0.9986  |  0:10:54s\n",
      "epoch 47 | loss: 0.02518 | test_accuracy: 0.99027 | test_auc: 0.99822 |  0:11:05s\n",
      "epoch 48 | loss: 0.0249  | test_accuracy: 0.99027 | test_auc: 0.99874 |  0:11:20s\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_test_auc = 0.99876\n",
      "Training fold 4/5...\n",
      "epoch 0  | loss: 0.23051 | test_accuracy: 0.90249 | test_auc: 0.98698 |  0:00:10s\n",
      "epoch 1  | loss: 0.06141 | test_accuracy: 0.85729 | test_auc: 0.9913  |  0:00:23s\n",
      "epoch 2  | loss: 0.04716 | test_accuracy: 0.88441 | test_auc: 0.9966  |  0:00:35s\n",
      "epoch 3  | loss: 0.0459  | test_accuracy: 0.92839 | test_auc: 0.99599 |  0:00:49s\n",
      "epoch 4  | loss: 0.03772 | test_accuracy: 0.97984 | test_auc: 0.99672 |  0:01:04s\n",
      "epoch 5  | loss: 0.03936 | test_accuracy: 0.97653 | test_auc: 0.99775 |  0:01:14s\n",
      "epoch 6  | loss: 0.03758 | test_accuracy: 0.98401 | test_auc: 0.9984  |  0:01:29s\n",
      "epoch 7  | loss: 0.03742 | test_accuracy: 0.98297 | test_auc: 0.99845 |  0:01:42s\n",
      "epoch 8  | loss: 0.03667 | test_accuracy: 0.9821  | test_auc: 0.9985  |  0:01:57s\n",
      "epoch 9  | loss: 0.0363  | test_accuracy: 0.98523 | test_auc: 0.9988  |  0:02:12s\n",
      "epoch 10 | loss: 0.03598 | test_accuracy: 0.98922 | test_auc: 0.99884 |  0:02:26s\n",
      "epoch 11 | loss: 0.03562 | test_accuracy: 0.99044 | test_auc: 0.99897 |  0:02:43s\n",
      "epoch 12 | loss: 0.03324 | test_accuracy: 0.99114 | test_auc: 0.99911 |  0:03:00s\n",
      "epoch 13 | loss: 0.03237 | test_accuracy: 0.98992 | test_auc: 0.99887 |  0:03:14s\n",
      "epoch 14 | loss: 0.03505 | test_accuracy: 0.98818 | test_auc: 0.99903 |  0:03:25s\n",
      "epoch 15 | loss: 0.03558 | test_accuracy: 0.98783 | test_auc: 0.99915 |  0:03:38s\n",
      "epoch 16 | loss: 0.0355  | test_accuracy: 0.98888 | test_auc: 0.99887 |  0:03:51s\n",
      "epoch 17 | loss: 0.0359  | test_accuracy: 0.99044 | test_auc: 0.99885 |  0:04:01s\n",
      "epoch 18 | loss: 0.03128 | test_accuracy: 0.99061 | test_auc: 0.99919 |  0:04:15s\n",
      "epoch 19 | loss: 0.03196 | test_accuracy: 0.99061 | test_auc: 0.99914 |  0:04:26s\n",
      "epoch 20 | loss: 0.03161 | test_accuracy: 0.99061 | test_auc: 0.99903 |  0:04:39s\n",
      "epoch 21 | loss: 0.03246 | test_accuracy: 0.99061 | test_auc: 0.99917 |  0:04:53s\n",
      "epoch 22 | loss: 0.02964 | test_accuracy: 0.99027 | test_auc: 0.99893 |  0:05:07s\n",
      "epoch 23 | loss: 0.0306  | test_accuracy: 0.99027 | test_auc: 0.99921 |  0:05:21s\n",
      "epoch 24 | loss: 0.03346 | test_accuracy: 0.99061 | test_auc: 0.99912 |  0:05:33s\n",
      "epoch 25 | loss: 0.03011 | test_accuracy: 0.99079 | test_auc: 0.99919 |  0:05:44s\n",
      "epoch 26 | loss: 0.03804 | test_accuracy: 0.98401 | test_auc: 0.99839 |  0:05:48s\n",
      "epoch 27 | loss: 0.0414  | test_accuracy: 0.98575 | test_auc: 0.99859 |  0:05:51s\n",
      "epoch 28 | loss: 0.03936 | test_accuracy: 0.98783 | test_auc: 0.99876 |  0:05:54s\n",
      "epoch 29 | loss: 0.03589 | test_accuracy: 0.99061 | test_auc: 0.99901 |  0:05:58s\n",
      "epoch 30 | loss: 0.03178 | test_accuracy: 0.98957 | test_auc: 0.99902 |  0:06:02s\n",
      "epoch 31 | loss: 0.03072 | test_accuracy: 0.98974 | test_auc: 0.99909 |  0:06:05s\n",
      "epoch 32 | loss: 0.02968 | test_accuracy: 0.99009 | test_auc: 0.99879 |  0:06:08s\n",
      "epoch 33 | loss: 0.02948 | test_accuracy: 0.99253 | test_auc: 0.999   |  0:06:11s\n",
      "epoch 34 | loss: 0.02878 | test_accuracy: 0.99218 | test_auc: 0.99906 |  0:06:14s\n",
      "epoch 35 | loss: 0.02961 | test_accuracy: 0.99079 | test_auc: 0.99895 |  0:06:17s\n",
      "epoch 36 | loss: 0.02781 | test_accuracy: 0.99322 | test_auc: 0.9991  |  0:06:20s\n",
      "epoch 37 | loss: 0.02658 | test_accuracy: 0.99322 | test_auc: 0.99886 |  0:06:23s\n",
      "epoch 38 | loss: 0.02711 | test_accuracy: 0.99305 | test_auc: 0.99905 |  0:06:26s\n",
      "epoch 39 | loss: 0.02671 | test_accuracy: 0.99287 | test_auc: 0.99905 |  0:06:29s\n",
      "epoch 40 | loss: 0.02798 | test_accuracy: 0.99235 | test_auc: 0.99893 |  0:06:33s\n",
      "epoch 41 | loss: 0.02993 | test_accuracy: 0.99218 | test_auc: 0.99913 |  0:06:36s\n",
      "epoch 42 | loss: 0.02771 | test_accuracy: 0.99339 | test_auc: 0.99915 |  0:06:40s\n",
      "epoch 43 | loss: 0.02688 | test_accuracy: 0.99339 | test_auc: 0.99914 |  0:06:43s\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_test_auc = 0.99921\n",
      "Training fold 5/5...\n",
      "epoch 0  | loss: 0.24683 | test_accuracy: 0.86876 | test_auc: 0.9614  |  0:00:03s\n",
      "epoch 1  | loss: 0.08602 | test_accuracy: 0.88754 | test_auc: 0.98958 |  0:00:07s\n",
      "epoch 2  | loss: 0.06002 | test_accuracy: 0.89501 | test_auc: 0.99017 |  0:00:10s\n",
      "epoch 3  | loss: 0.0523  | test_accuracy: 0.97236 | test_auc: 0.99809 |  0:00:13s\n",
      "epoch 4  | loss: 0.05286 | test_accuracy: 0.97375 | test_auc: 0.99819 |  0:00:16s\n",
      "epoch 5  | loss: 0.04398 | test_accuracy: 0.97897 | test_auc: 0.99853 |  0:00:19s\n",
      "epoch 6  | loss: 0.04059 | test_accuracy: 0.9847  | test_auc: 0.99807 |  0:00:22s\n",
      "epoch 7  | loss: 0.038   | test_accuracy: 0.9847  | test_auc: 0.99883 |  0:00:25s\n",
      "epoch 8  | loss: 0.03895 | test_accuracy: 0.98922 | test_auc: 0.99914 |  0:00:28s\n",
      "epoch 9  | loss: 0.03635 | test_accuracy: 0.99114 | test_auc: 0.99921 |  0:00:31s\n",
      "epoch 10 | loss: 0.03499 | test_accuracy: 0.98922 | test_auc: 0.99922 |  0:00:34s\n",
      "epoch 11 | loss: 0.03314 | test_accuracy: 0.99183 | test_auc: 0.99915 |  0:00:37s\n",
      "epoch 12 | loss: 0.03134 | test_accuracy: 0.99183 | test_auc: 0.99897 |  0:00:40s\n",
      "epoch 13 | loss: 0.03292 | test_accuracy: 0.99131 | test_auc: 0.99919 |  0:00:43s\n",
      "epoch 14 | loss: 0.0303  | test_accuracy: 0.99009 | test_auc: 0.99873 |  0:00:46s\n",
      "epoch 15 | loss: 0.03422 | test_accuracy: 0.99027 | test_auc: 0.9991  |  0:00:49s\n",
      "epoch 16 | loss: 0.03282 | test_accuracy: 0.992   | test_auc: 0.9993  |  0:00:52s\n",
      "epoch 17 | loss: 0.03188 | test_accuracy: 0.99166 | test_auc: 0.9993  |  0:00:56s\n",
      "epoch 18 | loss: 0.03286 | test_accuracy: 0.99218 | test_auc: 0.99924 |  0:00:59s\n",
      "epoch 19 | loss: 0.0299  | test_accuracy: 0.99148 | test_auc: 0.99933 |  0:01:02s\n",
      "epoch 20 | loss: 0.02926 | test_accuracy: 0.99218 | test_auc: 0.99943 |  0:01:05s\n",
      "epoch 21 | loss: 0.03139 | test_accuracy: 0.99148 | test_auc: 0.99941 |  0:01:08s\n",
      "epoch 22 | loss: 0.03021 | test_accuracy: 0.99183 | test_auc: 0.99938 |  0:01:11s\n",
      "epoch 23 | loss: 0.0291  | test_accuracy: 0.99166 | test_auc: 0.99936 |  0:01:14s\n",
      "epoch 24 | loss: 0.02776 | test_accuracy: 0.99218 | test_auc: 0.9994  |  0:01:17s\n",
      "epoch 25 | loss: 0.02829 | test_accuracy: 0.99218 | test_auc: 0.99945 |  0:01:21s\n",
      "epoch 26 | loss: 0.02801 | test_accuracy: 0.99218 | test_auc: 0.99946 |  0:01:24s\n",
      "epoch 27 | loss: 0.02771 | test_accuracy: 0.99218 | test_auc: 0.99933 |  0:01:27s\n",
      "epoch 28 | loss: 0.02755 | test_accuracy: 0.99218 | test_auc: 0.99941 |  0:01:30s\n",
      "epoch 29 | loss: 0.0285  | test_accuracy: 0.99183 | test_auc: 0.99943 |  0:01:33s\n",
      "epoch 30 | loss: 0.02729 | test_accuracy: 0.99218 | test_auc: 0.99943 |  0:01:36s\n",
      "epoch 31 | loss: 0.02751 | test_accuracy: 0.99235 | test_auc: 0.99947 |  0:01:39s\n",
      "epoch 32 | loss: 0.02701 | test_accuracy: 0.99096 | test_auc: 0.99945 |  0:01:42s\n",
      "epoch 33 | loss: 0.0267  | test_accuracy: 0.99218 | test_auc: 0.99948 |  0:01:45s\n",
      "epoch 34 | loss: 0.02782 | test_accuracy: 0.99131 | test_auc: 0.99946 |  0:01:48s\n",
      "epoch 35 | loss: 0.02701 | test_accuracy: 0.99218 | test_auc: 0.99947 |  0:01:52s\n",
      "epoch 36 | loss: 0.02717 | test_accuracy: 0.99218 | test_auc: 0.99944 |  0:01:55s\n",
      "epoch 37 | loss: 0.02648 | test_accuracy: 0.99235 | test_auc: 0.99946 |  0:01:58s\n",
      "epoch 38 | loss: 0.02615 | test_accuracy: 0.99218 | test_auc: 0.99946 |  0:02:01s\n",
      "epoch 39 | loss: 0.02661 | test_accuracy: 0.99218 | test_auc: 0.99943 |  0:02:05s\n",
      "epoch 40 | loss: 0.02701 | test_accuracy: 0.992   | test_auc: 0.99947 |  0:02:08s\n",
      "epoch 41 | loss: 0.02647 | test_accuracy: 0.992   | test_auc: 0.99946 |  0:02:11s\n",
      "epoch 42 | loss: 0.02604 | test_accuracy: 0.99183 | test_auc: 0.99945 |  0:02:14s\n",
      "epoch 43 | loss: 0.02604 | test_accuracy: 0.992   | test_auc: 0.99942 |  0:02:17s\n",
      "epoch 44 | loss: 0.02602 | test_accuracy: 0.99218 | test_auc: 0.99931 |  0:02:20s\n",
      "epoch 45 | loss: 0.02564 | test_accuracy: 0.992   | test_auc: 0.99936 |  0:02:23s\n",
      "epoch 46 | loss: 0.02669 | test_accuracy: 0.992   | test_auc: 0.99945 |  0:02:26s\n",
      "epoch 47 | loss: 0.02609 | test_accuracy: 0.99235 | test_auc: 0.99947 |  0:02:29s\n",
      "epoch 48 | loss: 0.02575 | test_accuracy: 0.99218 | test_auc: 0.99941 |  0:02:32s\n",
      "epoch 49 | loss: 0.02655 | test_accuracy: 0.99218 | test_auc: 0.99947 |  0:02:36s\n",
      "epoch 50 | loss: 0.02591 | test_accuracy: 0.99218 | test_auc: 0.99948 |  0:02:39s\n",
      "epoch 51 | loss: 0.02509 | test_accuracy: 0.992   | test_auc: 0.99949 |  0:02:42s\n",
      "epoch 52 | loss: 0.0253  | test_accuracy: 0.99218 | test_auc: 0.99949 |  0:02:45s\n",
      "epoch 53 | loss: 0.02723 | test_accuracy: 0.992   | test_auc: 0.99941 |  0:02:55s\n",
      "epoch 54 | loss: 0.02633 | test_accuracy: 0.98835 | test_auc: 0.99943 |  0:02:59s\n",
      "epoch 55 | loss: 0.02706 | test_accuracy: 0.992   | test_auc: 0.99934 |  0:03:02s\n",
      "epoch 56 | loss: 0.02665 | test_accuracy: 0.99235 | test_auc: 0.99948 |  0:03:04s\n",
      "epoch 57 | loss: 0.02585 | test_accuracy: 0.99183 | test_auc: 0.99933 |  0:03:07s\n",
      "epoch 58 | loss: 0.02794 | test_accuracy: 0.99079 | test_auc: 0.99927 |  0:03:11s\n",
      "epoch 59 | loss: 0.02786 | test_accuracy: 0.99183 | test_auc: 0.99935 |  0:03:13s\n",
      "epoch 60 | loss: 0.02641 | test_accuracy: 0.992   | test_auc: 0.9994  |  0:03:16s\n",
      "epoch 61 | loss: 0.02595 | test_accuracy: 0.992   | test_auc: 0.99938 |  0:03:19s\n",
      "epoch 62 | loss: 0.02605 | test_accuracy: 0.99218 | test_auc: 0.99934 |  0:03:22s\n",
      "epoch 63 | loss: 0.02705 | test_accuracy: 0.992   | test_auc: 0.99946 |  0:03:25s\n",
      "epoch 64 | loss: 0.02555 | test_accuracy: 0.992   | test_auc: 0.99947 |  0:03:29s\n",
      "epoch 65 | loss: 0.02486 | test_accuracy: 0.992   | test_auc: 0.99924 |  0:03:32s\n",
      "epoch 66 | loss: 0.02491 | test_accuracy: 0.992   | test_auc: 0.99947 |  0:03:35s\n",
      "epoch 67 | loss: 0.0259  | test_accuracy: 0.992   | test_auc: 0.99951 |  0:03:38s\n",
      "epoch 68 | loss: 0.02479 | test_accuracy: 0.992   | test_auc: 0.99944 |  0:03:41s\n",
      "epoch 69 | loss: 0.02763 | test_accuracy: 0.99148 | test_auc: 0.99942 |  0:03:44s\n",
      "epoch 70 | loss: 0.02687 | test_accuracy: 0.99114 | test_auc: 0.99945 |  0:03:47s\n",
      "epoch 71 | loss: 0.02529 | test_accuracy: 0.99061 | test_auc: 0.99943 |  0:03:50s\n",
      "epoch 72 | loss: 0.02566 | test_accuracy: 0.99253 | test_auc: 0.99944 |  0:03:53s\n",
      "epoch 73 | loss: 0.02512 | test_accuracy: 0.99148 | test_auc: 0.99936 |  0:03:56s\n",
      "epoch 74 | loss: 0.02592 | test_accuracy: 0.98974 | test_auc: 0.99934 |  0:04:00s\n",
      "epoch 75 | loss: 0.02717 | test_accuracy: 0.99131 | test_auc: 0.99937 |  0:04:02s\n",
      "epoch 76 | loss: 0.0322  | test_accuracy: 0.99114 | test_auc: 0.99925 |  0:04:05s\n",
      "epoch 77 | loss: 0.02954 | test_accuracy: 0.99235 | test_auc: 0.99938 |  0:04:08s\n",
      "epoch 78 | loss: 0.02983 | test_accuracy: 0.9927  | test_auc: 0.99939 |  0:04:12s\n",
      "epoch 79 | loss: 0.02673 | test_accuracy: 0.9927  | test_auc: 0.99935 |  0:04:15s\n",
      "epoch 80 | loss: 0.02517 | test_accuracy: 0.99235 | test_auc: 0.99938 |  0:04:18s\n",
      "epoch 81 | loss: 0.02545 | test_accuracy: 0.99218 | test_auc: 0.99936 |  0:04:21s\n",
      "epoch 82 | loss: 0.02526 | test_accuracy: 0.99235 | test_auc: 0.99946 |  0:04:24s\n",
      "epoch 83 | loss: 0.02662 | test_accuracy: 0.9927  | test_auc: 0.99946 |  0:04:27s\n",
      "epoch 84 | loss: 0.02504 | test_accuracy: 0.99253 | test_auc: 0.99946 |  0:04:30s\n",
      "epoch 85 | loss: 0.02372 | test_accuracy: 0.9927  | test_auc: 0.99949 |  0:04:33s\n",
      "epoch 86 | loss: 0.02276 | test_accuracy: 0.9927  | test_auc: 0.9995  |  0:04:36s\n",
      "epoch 87 | loss: 0.02303 | test_accuracy: 0.9927  | test_auc: 0.9994  |  0:04:39s\n",
      "\n",
      "Early stopping occurred at epoch 87 with best_epoch = 67 and best_test_auc = 0.99951\n",
      "\n",
      "Results for 10. LightGBM Importance:\n",
      "Average accuracy: 0.9922 ± 0.0016\n",
      "Average precision: 0.9967 ± 0.0031\n",
      "Average recall: 0.9815 ± 0.0035\n",
      "Average f1: 0.9890 ± 0.0022\n",
      "Average auc: 0.9898 ± 0.0019\n",
      "Comparison chart saved as 'feature_selection_comparison_TabNet.png'\n",
      "Heatmap saved as 'feature_selection_heatmap_TabNet.png'\n",
      "\n",
      "==================================================\n",
      "FINAL SUMMARY\n",
      "==================================================\n",
      "\n",
      "Techniques ranked by accuracy:\n",
      "1. 10. LightGBM Importance: 0.9922\n",
      "2. 1. Chi-Square: 0.9886\n",
      "3. 2. Mutual Information: 0.9886\n",
      "4. 6. Boruta: 0.9863\n",
      "5. 5. Random Forest Importance: 0.9838\n",
      "6. 9. XGBoost Importance: 0.9829\n",
      "7. 4. Lasso: 0.9829\n",
      "8. 3. Recursive Feature Elimination: 0.9813\n",
      "9. 7. Correlation-based: 0.9806\n",
      "10. 8. Sequential Forward Selection: 0.9604\n",
      "\n",
      "Best performing technique: 10. LightGBM Importance\n",
      "Top 10 features selected by 10. LightGBM Importance:\n",
      "1. Breathing Problem\n",
      "2. Sore throat\n",
      "3. Asthma\n",
      "4. Chronic Lung Disease\n",
      "5. Heart Disease\n",
      "6. Hyper Tension\n",
      "7. Abroad travel\n",
      "8. Contact with COVID Patient\n",
      "9. Attended Large Gathering\n",
      "10. Family working in Public Exposed Places\n"
     ]
    }
   ],
   "source": [
    "# Dependencies installation (run these commands in your terminal)\n",
    "# pip install pandas numpy scikit-learn tensorflow keras matplotlib seaborn xgboost lightgbm boruta\n",
    "# pip install imbalanced-learn statsmodels scipy pytorch-tabnet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import warnings\n",
    "import torch  # Importing PyTorch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "def load_data(file_path):\n",
    "    print(\"Loading dataset...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=['COVID-19'])\n",
    "    y = df['COVID-19']\n",
    "    print(f\"Dataset loaded: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "    print(f\"Class distribution: {dict(y.value_counts())}\")\n",
    "    return X, y\n",
    "\n",
    "# Define all feature selection techniques\n",
    "def get_feature_selectors(X, y, n_features=10):\n",
    "    print(\"Initializing feature selection techniques...\")\n",
    "    feature_selectors = {\n",
    "        \"1. Chi-Square\": SelectKBest(chi2, k=n_features),\n",
    "        \"2. Mutual Information\": SelectKBest(mutual_info_classif, k=n_features),\n",
    "        \"3. Recursive Feature Elimination\": RFE(\n",
    "            estimator=LogisticRegression(solver='liblinear', max_iter=1000, random_state=42),\n",
    "            n_features_to_select=n_features\n",
    "        ),\n",
    "        \"4. Lasso\": SelectFromModel(\n",
    "            Lasso(alpha=0.01, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"5. Random Forest Importance\": SelectFromModel(\n",
    "            RandomForestClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"6. Boruta\": BorutaPy(\n",
    "            RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            n_estimators='auto', verbose=0, random_state=42\n",
    "        ),\n",
    "        \"7. Correlation-based\": None,  # Custom implementation\n",
    "        \"8. Sequential Forward Selection\": SequentialFeatureSelector(\n",
    "            RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "            n_features_to_select=n_features,\n",
    "            direction='forward'\n",
    "        ),\n",
    "        \"9. XGBoost Importance\": SelectFromModel(\n",
    "            XGBClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"10. LightGBM Importance\": SelectFromModel(\n",
    "            LGBMClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        )\n",
    "    }\n",
    "    return feature_selectors\n",
    "\n",
    "# Function to select top features using each technique\n",
    "def select_features(X, y, technique_name, selector, n_features=10):\n",
    "    print(f\"Selecting features using {technique_name}...\")\n",
    "    feature_names = X.columns.tolist()\n",
    "    \n",
    "    # Handle special case for Correlation-based selection\n",
    "    if technique_name == \"7. Correlation-based\":\n",
    "        # Calculate correlation of each feature with target\n",
    "        correlations = []\n",
    "        for col in X.columns:\n",
    "            corr = np.abs(X[col].corr(y))\n",
    "            correlations.append((col, corr))\n",
    "        \n",
    "        # Sort by correlation and select top n_features\n",
    "        correlations.sort(key=lambda x: x[1], reverse=True)\n",
    "        selected_features = [item[0] for item in correlations[:n_features]]\n",
    "        feature_importances = [item[1] for item in correlations[:n_features]]\n",
    "        \n",
    "    # Handle special case for Boruta\n",
    "    elif technique_name == \"6. Boruta\":\n",
    "        # Boruta requires array input\n",
    "        X_array = X.values\n",
    "        selector.fit(X_array, y)\n",
    "        \n",
    "        # Get the selected features\n",
    "        selected_mask = selector.support_\n",
    "        ranking = selector.ranking_\n",
    "        \n",
    "        # Sort by ranking and select top features\n",
    "        feature_ranking = [(feature, rank) for feature, rank, mask in \n",
    "                          zip(feature_names, ranking, selected_mask) if mask]\n",
    "        feature_ranking.sort(key=lambda x: x[1])\n",
    "        \n",
    "        # If Boruta selected fewer than n_features, add more by ranking\n",
    "        if len(feature_ranking) < n_features:\n",
    "            additional = [(f, r) for f, r, m in \n",
    "                         zip(feature_names, ranking, selected_mask) if not m]\n",
    "            additional.sort(key=lambda x: x[1])\n",
    "            feature_ranking.extend(additional[:n_features-len(feature_ranking)])\n",
    "        \n",
    "        feature_ranking = feature_ranking[:n_features]\n",
    "        selected_features = [item[0] for item in feature_ranking]\n",
    "        feature_importances = [1.0/item[1] for item in feature_ranking]  # Invert ranking for visualization\n",
    "    \n",
    "    else:\n",
    "        # Standard scikit-learn selectors\n",
    "        try:\n",
    "            selector.fit(X, y)\n",
    "            \n",
    "            # Different selector types have different ways to get selected features\n",
    "            if hasattr(selector, 'get_support'):\n",
    "                selected_mask = selector.get_support()\n",
    "                selected_features = [f for f, selected in zip(feature_names, selected_mask) if selected]\n",
    "                \n",
    "                # Get feature importances if available\n",
    "                if hasattr(selector, 'estimator_') and hasattr(selector.estimator_, 'feature_importances_'):\n",
    "                    feature_importances = selector.estimator_.feature_importances_[selected_mask]\n",
    "                elif hasattr(selector, 'scores_'):\n",
    "                    feature_importances = selector.scores_[selected_mask]\n",
    "                else:\n",
    "                    feature_importances = np.ones(len(selected_features))\n",
    "                    \n",
    "            elif hasattr(selector, 'coef_'):\n",
    "                # For models with coefficients like Lasso\n",
    "                coefs = np.abs(selector.coef_)\n",
    "                indices = np.argsort(coefs)[::-1][:n_features]\n",
    "                selected_features = [feature_names[i] for i in indices]\n",
    "                feature_importances = [coefs[i] for i in indices]\n",
    "                \n",
    "            else:\n",
    "                # Get features from the model itself\n",
    "                try:\n",
    "                    importances = getattr(selector, 'feature_importances_', \n",
    "                                         getattr(selector, 'coef_', None))\n",
    "                    if importances is None:\n",
    "                        importances = np.ones(len(feature_names))\n",
    "                    \n",
    "                    # For 2D coefficients (like in multiclass), take the mean\n",
    "                    if importances.ndim > 1:\n",
    "                        importances = np.mean(np.abs(importances), axis=0)\n",
    "                    \n",
    "                    # Select top features\n",
    "                    indices = np.argsort(np.abs(importances))[::-1][:n_features]\n",
    "                    selected_features = [feature_names[i] for i in indices]\n",
    "                    feature_importances = [np.abs(importances)[i] for i in indices]\n",
    "                    \n",
    "                except:\n",
    "                    # Fallback for other selectors\n",
    "                    indices = getattr(selector, 'support_', np.arange(min(n_features, len(feature_names))))\n",
    "                    if len(indices) > n_features:\n",
    "                        indices = indices[:n_features]\n",
    "                    selected_features = [feature_names[i] for i in indices]\n",
    "                    feature_importances = np.ones(len(selected_features))\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error with {technique_name}: {str(e)}\")\n",
    "            # Default to the first n_features if there's an error\n",
    "            selected_features = feature_names[:n_features]\n",
    "            feature_importances = np.ones(n_features)\n",
    "    \n",
    "    # Ensure exactly n_features are selected (truncate or pad if necessary)\n",
    "    if len(selected_features) > n_features:\n",
    "        selected_features = selected_features[:n_features]\n",
    "        feature_importances = feature_importances[:n_features]\n",
    "    elif len(selected_features) < n_features:\n",
    "        # Add remaining features based on variance\n",
    "        remaining = [f for f in feature_names if f not in selected_features]\n",
    "        selected_features.extend(remaining[:n_features-len(selected_features)])\n",
    "        feature_importances = list(feature_importances) + [0] * (n_features - len(feature_importances))\n",
    "    \n",
    "    # Print selected features\n",
    "    print(f\"Top {len(selected_features)} features selected by {technique_name}:\")\n",
    "    for i, (feature, importance) in enumerate(zip(selected_features, feature_importances)):\n",
    "        print(f\"{i+1}. {feature}: {importance:.4f}\")\n",
    "    \n",
    "    return selected_features, feature_importances\n",
    "\n",
    "# Build the TabNet model for a specific set of features\n",
    "def build_tabnet_model():\n",
    "    model = TabNetClassifier(\n",
    "        n_d=8, \n",
    "        n_a=8, \n",
    "        n_steps=3, \n",
    "        gamma=1.3, \n",
    "        n_independent=2, \n",
    "        n_shared=2, \n",
    "        lambda_sparse=1e-5,\n",
    "        optimizer_fn=torch.optim.Adam,  # Corrected to use the actual optimizer function\n",
    "        optimizer_params=dict(lr=2e-2),\n",
    "        mask_type='sparsemax',  # Can be 'sparsemax' or 'entmax'\n",
    "        scheduler_params={\"step_size\": 100, \"gamma\": 0.9},\n",
    "        scheduler_fn=torch.optim.lr_scheduler.StepLR  # Use a callable for the scheduler\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Train and evaluate model with k-fold cross validation\n",
    "def train_and_evaluate(X, y, selected_features, technique_name, k=5):\n",
    "    print(f\"\\nTraining TabNet with features selected by {technique_name}\")\n",
    "    \n",
    "    # Prepare data for TabNet\n",
    "    X_selected = X[selected_features].values\n",
    "    y_values = y.values\n",
    "    \n",
    "    # K-Fold validation\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    metrics = {\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': [],\n",
    "        'auc': []\n",
    "    }\n",
    "    \n",
    "    # Train and evaluate for each fold\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X_selected)):\n",
    "        print(f\"Training fold {fold+1}/{k}...\")\n",
    "        \n",
    "        X_train, X_test = X_selected[train_idx], X_selected[test_idx]\n",
    "        y_train, y_test = y_values[train_idx], y_values[test_idx]\n",
    "        \n",
    "        # Build and train model\n",
    "        model = build_tabnet_model()\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_test, y_test)],\n",
    "            eval_name=['test'],\n",
    "            eval_metric=['accuracy', 'auc'],\n",
    "            max_epochs=100,\n",
    "            patience=20,\n",
    "            batch_size=1024,\n",
    "            virtual_batch_size=128,\n",
    "            num_workers=0,\n",
    "            drop_last=False\n",
    "        )\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics['accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "        metrics['precision'].append(precision_score(y_test, y_pred))\n",
    "        metrics['recall'].append(recall_score(y_test, y_pred))\n",
    "        metrics['f1'].append(f1_score(y_test, y_pred))\n",
    "        metrics['auc'].append(roc_auc_score(y_test, y_pred))\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {metric: np.mean(values) for metric, values in metrics.items()}\n",
    "    std_metrics = {metric: np.std(values) for metric, values in metrics.items()}\n",
    "    \n",
    "    print(f\"\\nResults for {technique_name}:\")\n",
    "    for metric, value in avg_metrics.items():\n",
    "        print(f\"Average {metric}: {value:.4f} ± {std_metrics[metric]:.4f}\")\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "# Plot comparison bar chart\n",
    "def plot_comparison(all_results):\n",
    "    metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
    "    \n",
    "    # Sort techniques by accuracy\n",
    "    sorted_techniques = sorted(\n",
    "        all_results.keys(),\n",
    "        key=lambda x: all_results[x]['accuracy'],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Set width of bars\n",
    "    bar_width = 0.15\n",
    "    index = np.arange(len(sorted_techniques))\n",
    "    \n",
    "    # Colors for different metrics\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    \n",
    "    # Plot bars for each metric\n",
    "    for i, metric in enumerate(metrics_to_plot):\n",
    "        values = [all_results[technique][metric] for technique in sorted_techniques]\n",
    "        plt.bar(\n",
    "            index + i * bar_width, \n",
    "            values, \n",
    "            bar_width, \n",
    "            label=metric.capitalize(),\n",
    "            color=colors[i]\n",
    "        )\n",
    "    \n",
    "    # Add labels and legend\n",
    "    plt.xlabel('Feature Selection Technique', fontsize=12)\n",
    "    plt.ylabel('Score', fontsize=12)\n",
    "    plt.title('Comparison of Feature Selection Techniques', fontsize=14)\n",
    "    plt.xticks(\n",
    "        index + bar_width * 2, \n",
    "        [t.split('. ')[1] if '. ' in t else t for t in sorted_techniques],\n",
    "        rotation=45,\n",
    "        ha='right'\n",
    "    )\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=5)\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig('feature_selection_comparison_TabNet.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Comparison chart saved as 'feature_selection_comparison_TabNet.png'\")\n",
    "    plt.close()\n",
    "\n",
    "# Plot feature heatmap\n",
    "def plot_feature_heatmap(all_features, X):\n",
    "    # Create a matrix of features vs techniques\n",
    "    techniques = list(all_features.keys())\n",
    "    all_unique_features = list(set(feature for features in all_features.values() for feature in features))\n",
    "    \n",
    "    # Create a matrix with 1 if feature is selected by technique, 0 otherwise\n",
    "    matrix = np.zeros((len(techniques), len(all_unique_features)))\n",
    "    \n",
    "    for i, technique in enumerate(techniques):\n",
    "        for j, feature in enumerate(all_unique_features):\n",
    "            if feature in all_features[technique]:\n",
    "                matrix[i, j] = 1\n",
    "    \n",
    "    # Sort features by frequency of selection\n",
    "    feature_counts = matrix.sum(axis=0)\n",
    "    sorted_indices = np.argsort(feature_counts)[::-1]\n",
    "    sorted_features = [all_unique_features[i] for i in sorted_indices]\n",
    "    sorted_matrix = matrix[:, sorted_indices]\n",
    "    \n",
    "    # Create heatmap\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    sns.heatmap(\n",
    "        sorted_matrix,\n",
    "        cmap='Blues',\n",
    "        xticklabels=sorted_features,\n",
    "        yticklabels=[t.split('. ')[1] if '. ' in t else t for t in techniques],\n",
    "        cbar_kws={'label': 'Selected'}\n",
    "    )\n",
    "    plt.title('Feature Selection by Different Techniques', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig('feature_selection_heatmap_TabNet.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Heatmap saved as 'feature_selection_heatmap_TabNet.png'\")\n",
    "    plt.close()\n",
    "\n",
    "# Main function to run the whole process\n",
    "def main():\n",
    "    # Load data\n",
    "    file_path = \"Downloads/preprocessed_merged500_covid_data.csv\"  # Update with your path\n",
    "    X, y = load_data(file_path)\n",
    "    \n",
    "    # Get feature selectors\n",
    "    feature_selectors = get_feature_selectors(X, y)\n",
    "    \n",
    "    # Store results\n",
    "    all_results = {}\n",
    "    all_selected_features = {}\n",
    "    \n",
    "    # For each technique, select features and train model\n",
    "    for technique_name, selector in feature_selectors.items():\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Processing {technique_name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Select features\n",
    "        selected_features, _ = select_features(X, y, technique_name, selector)\n",
    "        all_selected_features[technique_name] = selected_features\n",
    "        \n",
    "        # Train and evaluate\n",
    "        results = train_and_evaluate(X, y, selected_features, technique_name)\n",
    "        all_results[technique_name] = results\n",
    "    \n",
    "    # Plot comparison\n",
    "    plot_comparison(all_results)\n",
    "    \n",
    "    # Plot feature heatmap\n",
    "    plot_feature_heatmap(all_selected_features, X)\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Sort techniques by accuracy\n",
    "    sorted_techniques = sorted(\n",
    "        all_results.keys(),\n",
    "        key=lambda x: all_results[x]['accuracy'],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTechniques ranked by accuracy:\")\n",
    "    for i, technique in enumerate(sorted_techniques):\n",
    "        print(f\"{i+1}. {technique}: {all_results[technique]['accuracy']:.4f}\")\n",
    "    \n",
    "    best_technique = sorted_techniques[0]\n",
    "    print(f\"\\nBest performing technique: {best_technique}\")\n",
    "    print(f\"Top 10 features selected by {best_technique}:\")\n",
    "    for i, feature in enumerate(all_selected_features[best_technique]):\n",
    "        print(f\"{i+1}. {feature}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cddb18e-8b3f-43f2-b836-61fcc5a49373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
