{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "737b7d25-cf29-4aa0-88f1-de787bd94bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded: 37028 samples, 20 features\n",
      "Class distribution: {1.0: 18514, 0.0: 18514}\n",
      "Initializing feature selection techniques...\n",
      "\n",
      "==================================================\n",
      "Processing 1. Chi-Square\n",
      "==================================================\n",
      "Selecting features using 1. Chi-Square...\n",
      "Top 10 features selected by 1. Chi-Square:\n",
      "1. Breathing Problem: 10858.4695\n",
      "2. Sore throat: 13901.1472\n",
      "3. Running Nose: 1792.9213\n",
      "4. Headache: 1768.0620\n",
      "5. Heart Disease: 4165.6170\n",
      "6. Diabetes: 2915.7714\n",
      "7. Hyper Tension: 3682.1903\n",
      "8. Gastrointestinal : 2622.2793\n",
      "9. Attended Large Gathering: 9772.2954\n",
      "10. Family working in Public Exposed Places: 8644.4843\n",
      "\n",
      "Training CNN with features selected by 1. Chi-Square\n",
      "Training fold 1/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "\n",
      "Results for 1. Chi-Square:\n",
      "Average accuracy: 0.9561 ± 0.0093\n",
      "Average precision: 0.9794 ± 0.0060\n",
      "Average recall: 0.9319 ± 0.0142\n",
      "Average f1: 0.9550 ± 0.0097\n",
      "Average auc: 0.9955 ± 0.0014\n",
      "\n",
      "==================================================\n",
      "Processing 2. Mutual Information\n",
      "==================================================\n",
      "Selecting features using 2. Mutual Information...\n",
      "Top 10 features selected by 2. Mutual Information:\n",
      "1. Breathing Problem: 0.3312\n",
      "2. Sore throat: 0.4519\n",
      "3. Running Nose: 0.0807\n",
      "4. Headache: 0.0639\n",
      "5. Heart Disease: 0.0943\n",
      "6. Diabetes: 0.1220\n",
      "7. Hyper Tension: 0.0835\n",
      "8. Gastrointestinal : 0.0827\n",
      "9. Attended Large Gathering: 0.2473\n",
      "10. Family working in Public Exposed Places: 0.2331\n",
      "\n",
      "Training CNN with features selected by 2. Mutual Information\n",
      "Training fold 1/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "Results for 2. Mutual Information:\n",
      "Average accuracy: 0.9612 ± 0.0077\n",
      "Average precision: 0.9805 ± 0.0089\n",
      "Average recall: 0.9411 ± 0.0104\n",
      "Average f1: 0.9603 ± 0.0079\n",
      "Average auc: 0.9958 ± 0.0015\n",
      "\n",
      "==================================================\n",
      "Processing 3. Recursive Feature Elimination\n",
      "==================================================\n",
      "Selecting features using 3. Recursive Feature Elimination...\n",
      "Top 10 features selected by 3. Recursive Feature Elimination:\n",
      "1. Breathing Problem: 1.0000\n",
      "2. Fever: 1.0000\n",
      "3. Dry Cough: 1.0000\n",
      "4. Sore throat: 1.0000\n",
      "5. Running Nose: 1.0000\n",
      "6. Headache: 1.0000\n",
      "7. Hyper Tension: 1.0000\n",
      "8. Fatigue : 1.0000\n",
      "9. Attended Large Gathering: 1.0000\n",
      "10. Family working in Public Exposed Places: 1.0000\n",
      "\n",
      "Training CNN with features selected by 3. Recursive Feature Elimination\n",
      "Training fold 1/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "Results for 3. Recursive Feature Elimination:\n",
      "Average accuracy: 0.9552 ± 0.0066\n",
      "Average precision: 0.9767 ± 0.0023\n",
      "Average recall: 0.9327 ± 0.0139\n",
      "Average f1: 0.9541 ± 0.0071\n",
      "Average auc: 0.9938 ± 0.0009\n",
      "\n",
      "==================================================\n",
      "Processing 4. Lasso\n",
      "==================================================\n",
      "Selecting features using 4. Lasso...\n",
      "Top 10 features selected by 4. Lasso:\n",
      "1. Breathing Problem: 1.0000\n",
      "2. Sore throat: 1.0000\n",
      "3. Hyper Tension: 1.0000\n",
      "4. Attended Large Gathering: 1.0000\n",
      "5. Family working in Public Exposed Places: 1.0000\n",
      "6. Fever: 0.0000\n",
      "7. Dry Cough: 0.0000\n",
      "8. Running Nose: 0.0000\n",
      "9. Asthma: 0.0000\n",
      "10. Chronic Lung Disease: 0.0000\n",
      "\n",
      "Training CNN with features selected by 4. Lasso\n",
      "Training fold 1/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "Results for 4. Lasso:\n",
      "Average accuracy: 0.9464 ± 0.0083\n",
      "Average precision: 0.9675 ± 0.0117\n",
      "Average recall: 0.9241 ± 0.0259\n",
      "Average f1: 0.9449 ± 0.0100\n",
      "Average auc: 0.9924 ± 0.0013\n",
      "\n",
      "==================================================\n",
      "Processing 5. Random Forest Importance\n",
      "==================================================\n",
      "Selecting features using 5. Random Forest Importance...\n",
      "Top 10 features selected by 5. Random Forest Importance:\n",
      "1. Breathing Problem: 0.1800\n",
      "2. Sore throat: 0.3007\n",
      "3. Attended Large Gathering: 0.1447\n",
      "4. Family working in Public Exposed Places: 0.1215\n",
      "5. Fever: 0.0000\n",
      "6. Dry Cough: 0.0000\n",
      "7. Running Nose: 0.0000\n",
      "8. Asthma: 0.0000\n",
      "9. Chronic Lung Disease: 0.0000\n",
      "10. Headache: 0.0000\n",
      "\n",
      "Training CNN with features selected by 5. Random Forest Importance\n",
      "Training fold 1/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "Results for 5. Random Forest Importance:\n",
      "Average accuracy: 0.9525 ± 0.0067\n",
      "Average precision: 0.9686 ± 0.0054\n",
      "Average recall: 0.9352 ± 0.0096\n",
      "Average f1: 0.9516 ± 0.0069\n",
      "Average auc: 0.9926 ± 0.0016\n",
      "\n",
      "==================================================\n",
      "Processing 6. Boruta\n",
      "==================================================\n",
      "Selecting features using 6. Boruta...\n",
      "Top 10 features selected by 6. Boruta:\n",
      "1. Breathing Problem: 1.0000\n",
      "2. Sore throat: 1.0000\n",
      "3. Running Nose: 1.0000\n",
      "4. Chronic Lung Disease: 1.0000\n",
      "5. Headache: 1.0000\n",
      "6. Heart Disease: 1.0000\n",
      "7. Diabetes: 1.0000\n",
      "8. Hyper Tension: 1.0000\n",
      "9. Gastrointestinal : 1.0000\n",
      "10. Attended Large Gathering: 1.0000\n",
      "\n",
      "Training CNN with features selected by 6. Boruta\n",
      "Training fold 1/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "Results for 6. Boruta:\n",
      "Average accuracy: 0.9635 ± 0.0084\n",
      "Average precision: 0.9770 ± 0.0115\n",
      "Average recall: 0.9495 ± 0.0086\n",
      "Average f1: 0.9630 ± 0.0086\n",
      "Average auc: 0.9950 ± 0.0017\n",
      "\n",
      "==================================================\n",
      "Processing 7. Correlation-based\n",
      "==================================================\n",
      "Selecting features using 7. Correlation-based...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6832\\2188346920.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_selected_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbest_technique\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"- {feature}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6832\\2188346920.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"=\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Processing {technique_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"=\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[0mselected_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtechnique_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m         \u001b[0mall_selected_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtechnique_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselected_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselected_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtechnique_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6832\\2188346920.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(X, y, technique_name, selector, n_features)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;31m# Handle special case for Correlation-based selection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtechnique_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"7. Correlation-based\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mcorrelations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             corr = np.abs(pd.crosstab(X[col], y, normalize='columns').iloc[1, 1] - \n\u001b[0m\u001b[0;32m     85\u001b[0m                           pd.crosstab(X[col], y, normalize='columns').iloc[1, 0])\n\u001b[0;32m     86\u001b[0m             \u001b[0mcorrelations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1146\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1147\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   3999\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mCaller\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mresponsible\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchecking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4000\u001b[0m         \"\"\"\n\u001b[0;32m   4001\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4002\u001b[0m             \u001b[0mseries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4003\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4005\u001b[0m         \u001b[0mseries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4006\u001b[0m         \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_selection import (\n",
    "    VarianceThreshold, chi2, f_classif, mutual_info_classif, \n",
    "    SelectKBest, RFE, SelectFromModel, SequentialFeatureSelector\n",
    ")\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from boruta import BorutaPy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Conv1D, MaxPooling1D, Dropout, Flatten, Dense, BatchNormalization\n",
    ")\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "def load_data(file_path):\n",
    "    print(\"Loading dataset...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=['COVID-19'])\n",
    "    y = df['COVID-19']\n",
    "    print(f\"Dataset loaded: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "    print(f\"Class distribution: {dict(y.value_counts())}\")\n",
    "    return X, y\n",
    "\n",
    "# Define all feature selection techniques\n",
    "def get_feature_selectors(X, y, n_features=10):\n",
    "    print(\"Initializing feature selection techniques...\")\n",
    "    feature_selectors = {\n",
    "        \"1. Chi-Square\": SelectKBest(chi2, k=n_features),\n",
    "        \"2. Mutual Information\": SelectKBest(mutual_info_classif, k=n_features),\n",
    "        \"3. Recursive Feature Elimination\": RFE(\n",
    "            estimator=LogisticRegression(solver='liblinear', max_iter=1000, random_state=42),\n",
    "            n_features_to_select=n_features\n",
    "        ),\n",
    "        \"4. Lasso\": SelectFromModel(\n",
    "            Lasso(alpha=0.01, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"5. Random Forest Importance\": SelectFromModel(\n",
    "            RandomForestClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"6. Boruta\": BorutaPy(\n",
    "            RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            n_estimators='auto', verbose=0, random_state=42\n",
    "        ),\n",
    "        \"7. Correlation-based\": None,  # Custom implementation\n",
    "        \"8. Sequential Forward Selection\": SequentialFeatureSelector(\n",
    "            RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "            n_features_to_select=n_features,\n",
    "            direction='forward'\n",
    "        ),\n",
    "        \"9. XGBoost Importance\": SelectFromModel(\n",
    "            XGBClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"10. LightGBM Importance\": SelectFromModel(\n",
    "            LGBMClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        )\n",
    "    }\n",
    "    return feature_selectors\n",
    "\n",
    "# Function to select top features using each technique\n",
    "def select_features(X, y, technique_name, selector, n_features=10):\n",
    "    print(f\"Selecting features using {technique_name}...\")\n",
    "    feature_names = X.columns.tolist()\n",
    "    \n",
    "    # Handle special case for Correlation-based selection\n",
    "    if technique_name == \"7. Correlation-based\":\n",
    "        correlations = []\n",
    "        for col in X.columns:\n",
    "            corr = np.abs(pd.crosstab(X[col], y, normalize='columns').iloc[1, 1] - \n",
    "                          pd.crosstab(X[col], y, normalize='columns').iloc[1, 0])\n",
    "            correlations.append((col, corr))\n",
    "        \n",
    "        correlations.sort(key=lambda x: x[1], reverse=True)\n",
    "        selected_features = [item[0] for item in correlations[:n_features]]\n",
    "        feature_importances = [item[1] for item in correlations[:n_features]]\n",
    "        \n",
    "    elif technique_name == \"6. Boruta\":\n",
    "        X_array = X.values\n",
    "        selector.fit(X_array, y)\n",
    "        selected_mask = selector.support_\n",
    "        ranking = selector.ranking_\n",
    "        \n",
    "        feature_ranking = [(feature, rank) for feature, rank, mask in \n",
    "                          zip(feature_names, ranking, selected_mask) if mask]\n",
    "        feature_ranking.sort(key=lambda x: x[1])\n",
    "        \n",
    "        if len(feature_ranking) < n_features:\n",
    "            additional = [(f, r) for f, r, m in \n",
    "                         zip(feature_names, ranking, selected_mask) if not m]\n",
    "            additional.sort(key=lambda x: x[1])\n",
    "            feature_ranking.extend(additional[:n_features-len(feature_ranking)])\n",
    "        \n",
    "        feature_ranking = feature_ranking[:n_features]\n",
    "        selected_features = [item[0] for item in feature_ranking]\n",
    "        feature_importances = [1.0/item[1] for item in feature_ranking]\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            selector.fit(X, y)\n",
    "            selected_mask = selector.get_support()\n",
    "            selected_features = [f for f, selected in zip(feature_names, selected_mask) if selected]\n",
    "            \n",
    "            if hasattr(selector, 'estimator_') and hasattr(selector.estimator_, 'feature_importances_'):\n",
    "                feature_importances = selector.estimator_.feature_importances_[selected_mask]\n",
    "            elif hasattr(selector, 'scores_'):\n",
    "                feature_importances = selector.scores_[selected_mask]\n",
    "            else:\n",
    "                feature_importances = np.ones(len(selected_features))\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error with {technique_name}: {str(e)}\")\n",
    "            selected_features = feature_names[:n_features]\n",
    "            feature_importances = np.ones(n_features)\n",
    "    \n",
    "    if len(selected_features) > n_features:\n",
    "        selected_features = selected_features[:n_features]\n",
    "        feature_importances = feature_importances[:n_features]\n",
    "    elif len(selected_features) < n_features:\n",
    "        remaining = [f for f in feature_names if f not in selected_features]\n",
    "        selected_features.extend(remaining[:n_features-len(selected_features)])\n",
    "        feature_importances = list(feature_importances) + [0] * (n_features - len(feature_importances))\n",
    "    \n",
    "    print(f\"Top {len(selected_features)} features selected by {technique_name}:\")\n",
    "    for i, (feature, importance) in enumerate(zip(selected_features, feature_importances)):\n",
    "        print(f\"{i+1}. {feature}: {importance:.4f}\")\n",
    "    \n",
    "    return selected_features, feature_importances\n",
    "\n",
    "# Build the CNN model for a specific set of features\n",
    "def build_cnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu', padding='same', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2, padding='same'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2, padding='same'),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(32, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train and evaluate model with k-fold cross validation\n",
    "def train_and_evaluate(X, y, selected_features, technique_name, k=5):\n",
    "    print(f\"\\nTraining CNN with features selected by {technique_name}\")\n",
    "    \n",
    "    X_selected = X[selected_features].values\n",
    "    X_selected = X_selected.reshape(X_selected.shape[0], X_selected.shape[1], 1)\n",
    "    y_values = y.values\n",
    "    \n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    metrics = {\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': [],\n",
    "        'auc': []\n",
    "    }\n",
    "    \n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X_selected)):\n",
    "        print(f\"Training fold {fold+1}/{k}...\")\n",
    "        \n",
    "        X_train, X_test = X_selected[train_idx], X_selected[test_idx]\n",
    "        y_train, y_test = y_values[train_idx], y_values[test_idx]\n",
    "        \n",
    "        model = build_cnn_model((X_selected.shape[1], 1))\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            verbose=0,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[early_stop]\n",
    "        )\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "        \n",
    "        metrics['accuracy'].append(accuracy_score(y_test, y_pred_classes))\n",
    "        metrics['precision'].append(precision_score(y_test, y_pred_classes))\n",
    "        metrics['recall'].append(recall_score(y_test, y_pred_classes))\n",
    "        metrics['f1'].append(f1_score(y_test, y_pred_classes))\n",
    "        try:\n",
    "            metrics['auc'].append(roc_auc_score(y_test, y_pred))\n",
    "        except:\n",
    "            metrics['auc'].append(0.5)\n",
    "    \n",
    "    avg_metrics = {metric: np.mean(values) for metric, values in metrics.items()}\n",
    "    std_metrics = {metric: np.std(values) for metric, values in metrics.items()}\n",
    "    \n",
    "    print(f\"\\nResults for {technique_name}:\")\n",
    "    for metric, value in avg_metrics.items():\n",
    "        print(f\"Average {metric}: {value:.4f} ± {std_metrics[metric]:.4f}\")\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "# Plot comparison bar chart\n",
    "def plot_comparison(all_results):\n",
    "    metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
    "    \n",
    "    sorted_techniques = sorted(\n",
    "        all_results.keys(),\n",
    "        key=lambda x: all_results[x]['accuracy'],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    bar_width = 0.15\n",
    "    index = np.arange(len(sorted_techniques))\n",
    "    \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    \n",
    "    for i, metric in enumerate(metrics_to_plot):\n",
    "        values = [all_results[technique][metric] for technique in sorted_techniques]\n",
    "        plt.bar(\n",
    "            index + i * bar_width, \n",
    "            values, \n",
    "            bar_width, \n",
    "            label=metric.capitalize(),\n",
    "            color=colors[i]\n",
    "        )\n",
    "    \n",
    "    plt.xlabel('Feature Selection Technique', fontsize=12)\n",
    "    plt.ylabel('Score', fontsize=12)\n",
    "    plt.title('Comparison of Feature Selection Techniques', fontsize=14)\n",
    "    plt.xticks(\n",
    "        index + bar_width * 2, \n",
    "        [t.split('. ')[1] if '. ' in t else t for t in sorted_techniques],\n",
    "        rotation=45,\n",
    "        ha='right'\n",
    "    )\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=5)\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('feature_selection_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Comparison chart saved as 'feature_selection_comparison.png'\")\n",
    "    plt.close()\n",
    "\n",
    "# Main function to run the whole process\n",
    "def main():\n",
    "    file_path = \"OneDrive/Desktop/Research_Capstone_Project/preprocessed_covid500_final.csv\"  # Update with your path\n",
    "    X, y = load_data(file_path)\n",
    "    \n",
    "    feature_selectors = get_feature_selectors(X, y)\n",
    "    \n",
    "    all_results = {}\n",
    "    all_selected_features = {}\n",
    "    \n",
    "    for technique_name, selector in feature_selectors.items():\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Processing {technique_name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        selected_features, _ = select_features(X, y, technique_name, selector)\n",
    "        all_selected_features[technique_name] = selected_features\n",
    "        \n",
    "        results = train_and_evaluate(X, y, selected_features, technique_name)\n",
    "        all_results[technique_name] = results\n",
    "    \n",
    "    plot_comparison(all_results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    sorted_techniques = sorted(\n",
    "        all_results.keys(),\n",
    "        key=lambda x: all_results[x]['accuracy'],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTechniques ranked by accuracy:\")\n",
    "    for i, technique in enumerate(sorted_techniques):\n",
    "        print(f\"{i+1}. {technique}: {all_results[technique]['accuracy']:.4f}\")\n",
    "    \n",
    "    best_technique = sorted_techniques[0]\n",
    "    print(f\"\\nBest performing technique: {best_technique}\")\n",
    "    print(f\"Top features selected by {best_technique}:\")\n",
    "    for feature in all_selected_features[best_technique]:\n",
    "        print(f\"- {feature}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a18edf64-29c3-40c4-b335-ef3573ba8048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded: 37028 samples, 20 features\n",
      "Class distribution: {1.0: 18514, 0.0: 18514}\n",
      "Initializing feature selection techniques...\n",
      "\n",
      "==================================================\n",
      "Processing 7. Correlation-based\n",
      "==================================================\n",
      "Selecting features using 7. Correlation-based...\n",
      "Top 10 features selected by 7. Correlation-based:\n",
      "1. Sore throat: 0.8626\n",
      "2. Breathing Problem: 0.7603\n",
      "3. Attended Large Gathering: 0.6464\n",
      "4. Family working in Public Exposed Places: 0.6421\n",
      "5. Diabetes: 0.4481\n",
      "6. Heart Disease: 0.3999\n",
      "7. Gastrointestinal : 0.3950\n",
      "8. Hyper Tension: 0.3846\n",
      "9. Running Nose: 0.3583\n",
      "10. Headache: 0.3389\n",
      "\n",
      "Training CNN with features selected by 7. Correlation-based\n",
      "Training fold 1/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "\n",
      "Results for 7. Correlation-based:\n",
      "Average accuracy: 0.9562 ± 0.0109\n",
      "Average precision: 0.9801 ± 0.0099\n",
      "Average recall: 0.9313 ± 0.0196\n",
      "Average f1: 0.9550 ± 0.0115\n",
      "Average auc: 0.9951 ± 0.0017\n",
      "\n",
      "==================================================\n",
      "Processing 8. Sequential Forward Selection\n",
      "==================================================\n",
      "Selecting features using 8. Sequential Forward Selection...\n",
      "Top 10 features selected by 8. Sequential Forward Selection:\n",
      "1. Breathing Problem: 1.0000\n",
      "2. Sore throat: 1.0000\n",
      "3. Running Nose: 1.0000\n",
      "4. Chronic Lung Disease: 1.0000\n",
      "5. Headache: 1.0000\n",
      "6. Heart Disease: 1.0000\n",
      "7. Diabetes: 1.0000\n",
      "8. Gastrointestinal : 1.0000\n",
      "9. Attended Large Gathering: 1.0000\n",
      "10. Family working in Public Exposed Places: 1.0000\n",
      "\n",
      "Training CNN with features selected by 8. Sequential Forward Selection\n",
      "Training fold 1/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\n",
      "Results for 8. Sequential Forward Selection:\n",
      "Average accuracy: 0.9624 ± 0.0067\n",
      "Average precision: 0.9827 ± 0.0046\n",
      "Average recall: 0.9414 ± 0.0104\n",
      "Average f1: 0.9616 ± 0.0070\n",
      "Average auc: 0.9953 ± 0.0017\n",
      "\n",
      "==================================================\n",
      "Processing 9. XGBoost Importance\n",
      "==================================================\n",
      "Selecting features using 9. XGBoost Importance...\n",
      "Top 10 features selected by 9. XGBoost Importance:\n",
      "1. Sore throat: 0.7893\n",
      "2. Attended Large Gathering: 0.0601\n",
      "3. Breathing Problem: 0.0000\n",
      "4. Fever: 0.0000\n",
      "5. Dry Cough: 0.0000\n",
      "6. Running Nose: 0.0000\n",
      "7. Asthma: 0.0000\n",
      "8. Chronic Lung Disease: 0.0000\n",
      "9. Headache: 0.0000\n",
      "10. Heart Disease: 0.0000\n",
      "\n",
      "Training CNN with features selected by 9. XGBoost Importance\n",
      "Training fold 1/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "\n",
      "Results for 9. XGBoost Importance:\n",
      "Average accuracy: 0.9544 ± 0.0045\n",
      "Average precision: 0.9598 ± 0.0060\n",
      "Average recall: 0.9486 ± 0.0079\n",
      "Average f1: 0.9541 ± 0.0046\n",
      "Average auc: 0.9916 ± 0.0012\n",
      "\n",
      "==================================================\n",
      "Processing 10. LightGBM Importance\n",
      "==================================================\n",
      "Selecting features using 10. LightGBM Importance...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 18514, number of negative: 18514\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 75\n",
      "[LightGBM] [Info] Number of data points in the train set: 37028, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Top 10 features selected by 10. LightGBM Importance:\n",
      "1. Breathing Problem: 276.0000\n",
      "2. Running Nose: 230.0000\n",
      "3. Chronic Lung Disease: 274.0000\n",
      "4. Headache: 264.0000\n",
      "5. Heart Disease: 261.0000\n",
      "6. Diabetes: 227.0000\n",
      "7. Hyper Tension: 263.0000\n",
      "8. Gastrointestinal : 299.0000\n",
      "9. Attended Large Gathering: 223.0000\n",
      "10. Family working in Public Exposed Places: 265.0000\n",
      "\n",
      "Training CNN with features selected by 10. LightGBM Importance\n",
      "Training fold 1/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\n",
      "Results for 10. LightGBM Importance:\n",
      "Average accuracy: 0.9515 ± 0.0130\n",
      "Average precision: 0.9840 ± 0.0041\n",
      "Average recall: 0.9177 ± 0.0232\n",
      "Average f1: 0.9496 ± 0.0138\n",
      "Average auc: 0.9927 ± 0.0025\n",
      "Comparison chart saved as 'feature_selection_comparison.png'\n",
      "\n",
      "==================================================\n",
      "FINAL SUMMARY\n",
      "==================================================\n",
      "\n",
      "Techniques ranked by accuracy:\n",
      "1. 6. Boruta: 0.9635\n",
      "2. 8. Sequential Forward Selection: 0.9624\n",
      "3. 2. Mutual Information: 0.9612\n",
      "4. 7. Correlation-based: 0.9562\n",
      "5. 1. Chi-Square: 0.9561\n",
      "6. 3. Recursive Feature Elimination: 0.9552\n",
      "7. 9. XGBoost Importance: 0.9544\n",
      "8. 5. Random Forest Importance: 0.9525\n",
      "9. 10. LightGBM Importance: 0.9515\n",
      "10. 4. Lasso: 0.9464\n",
      "\n",
      "Best performing technique: 6. Boruta\n",
      "Top features selected by 6. Boruta:\n",
      "- Breathing Problem\n",
      "- Sore throat\n",
      "- Running Nose\n",
      "- Chronic Lung Disease\n",
      "- Headache\n",
      "- Heart Disease\n",
      "- Diabetes\n",
      "- Hyper Tension\n",
      "- Gastrointestinal\n",
      "- Attended Large Gathering\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_selection import (\n",
    "    VarianceThreshold, chi2, f_classif, mutual_info_classif, \n",
    "    SelectKBest, RFE, SelectFromModel, SequentialFeatureSelector\n",
    ")\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from boruta import BorutaPy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Conv1D, MaxPooling1D, Dropout, Flatten, Dense, BatchNormalization\n",
    ")\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "def load_data(file_path):\n",
    "    print(\"Loading dataset...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=['COVID-19'])\n",
    "    y = df['COVID-19']\n",
    "    print(f\"Dataset loaded: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "    print(f\"Class distribution: {dict(y.value_counts())}\")\n",
    "    return X, y\n",
    "\n",
    "# Define all feature selection techniques\n",
    "def get_feature_selectors(X, y, n_features=10):\n",
    "    print(\"Initializing feature selection techniques...\")\n",
    "    feature_selectors = {\n",
    "        \"7. Correlation-based\": None,  # Custom implementation\n",
    "        \"8. Sequential Forward Selection\": SequentialFeatureSelector(\n",
    "            RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "            n_features_to_select=n_features,\n",
    "            direction='forward'\n",
    "        ),\n",
    "        \"9. XGBoost Importance\": SelectFromModel(\n",
    "            XGBClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"10. LightGBM Importance\": SelectFromModel(\n",
    "            LGBMClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # We've already completed these techniques, so let's skip them\n",
    "    completed_techniques = [\n",
    "        \"1. Chi-Square\",\n",
    "        \"2. Mutual Information\",\n",
    "        \"3. Recursive Feature Elimination\",\n",
    "        \"4. Lasso\",\n",
    "        \"5. Random Forest Importance\",\n",
    "        \"6. Boruta\"\n",
    "    ]\n",
    "    \n",
    "    return feature_selectors, completed_techniques\n",
    "\n",
    "# Function to select top features using each technique\n",
    "def select_features(X, y, technique_name, selector, n_features=10):\n",
    "    print(f\"Selecting features using {technique_name}...\")\n",
    "    feature_names = X.columns.tolist()\n",
    "    \n",
    "    # Handle special case for Correlation-based selection\n",
    "    if technique_name == \"7. Correlation-based\":\n",
    "        correlations = []\n",
    "        for col in X.columns:\n",
    "            try:\n",
    "                # Fixed code to handle features with only one unique value\n",
    "                cross_tab = pd.crosstab(X[col], y, normalize='columns')\n",
    "                # Check if there are enough rows in the crosstab\n",
    "                if cross_tab.shape[0] > 1 and 1 in cross_tab.index and 0 in cross_tab.index:\n",
    "                    corr = np.abs(cross_tab.loc[1, 1] - cross_tab.loc[1, 0])\n",
    "                else:\n",
    "                    # If not enough rows, use a small correlation value\n",
    "                    corr = 0.0001\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing feature {col}: {str(e)}\")\n",
    "                corr = 0.0001\n",
    "                \n",
    "            correlations.append((col, corr))\n",
    "        \n",
    "        correlations.sort(key=lambda x: x[1], reverse=True)\n",
    "        selected_features = [item[0] for item in correlations[:n_features]]\n",
    "        feature_importances = [item[1] for item in correlations[:n_features]]\n",
    "        \n",
    "    elif technique_name == \"6. Boruta\":\n",
    "        X_array = X.values\n",
    "        selector.fit(X_array, y)\n",
    "        selected_mask = selector.support_\n",
    "        ranking = selector.ranking_\n",
    "        \n",
    "        feature_ranking = [(feature, rank) for feature, rank, mask in \n",
    "                          zip(feature_names, ranking, selected_mask) if mask]\n",
    "        feature_ranking.sort(key=lambda x: x[1])\n",
    "        \n",
    "        if len(feature_ranking) < n_features:\n",
    "            additional = [(f, r) for f, r, m in \n",
    "                         zip(feature_names, ranking, selected_mask) if not m]\n",
    "            additional.sort(key=lambda x: x[1])\n",
    "            feature_ranking.extend(additional[:n_features-len(feature_ranking)])\n",
    "        \n",
    "        feature_ranking = feature_ranking[:n_features]\n",
    "        selected_features = [item[0] for item in feature_ranking]\n",
    "        feature_importances = [1.0/item[1] for item in feature_ranking]\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            selector.fit(X, y)\n",
    "            selected_mask = selector.get_support()\n",
    "            selected_features = [f for f, selected in zip(feature_names, selected_mask) if selected]\n",
    "            \n",
    "            if hasattr(selector, 'estimator_') and hasattr(selector.estimator_, 'feature_importances_'):\n",
    "                feature_importances = selector.estimator_.feature_importances_[selected_mask]\n",
    "            elif hasattr(selector, 'scores_'):\n",
    "                feature_importances = selector.scores_[selected_mask]\n",
    "            else:\n",
    "                feature_importances = np.ones(len(selected_features))\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error with {technique_name}: {str(e)}\")\n",
    "            selected_features = feature_names[:n_features]\n",
    "            feature_importances = np.ones(n_features)\n",
    "    \n",
    "    if len(selected_features) > n_features:\n",
    "        selected_features = selected_features[:n_features]\n",
    "        feature_importances = feature_importances[:n_features]\n",
    "    elif len(selected_features) < n_features:\n",
    "        remaining = [f for f in feature_names if f not in selected_features]\n",
    "        selected_features.extend(remaining[:n_features-len(selected_features)])\n",
    "        feature_importances = list(feature_importances) + [0] * (n_features - len(feature_importances))\n",
    "    \n",
    "    print(f\"Top {len(selected_features)} features selected by {technique_name}:\")\n",
    "    for i, (feature, importance) in enumerate(zip(selected_features, feature_importances)):\n",
    "        print(f\"{i+1}. {feature}: {importance:.4f}\")\n",
    "    \n",
    "    return selected_features, feature_importances\n",
    "\n",
    "# Build the CNN model for a specific set of features\n",
    "def build_cnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu', padding='same', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2, padding='same'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2, padding='same'),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(32, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train and evaluate model with k-fold cross validation\n",
    "def train_and_evaluate(X, y, selected_features, technique_name, k=5):\n",
    "    print(f\"\\nTraining CNN with features selected by {technique_name}\")\n",
    "    \n",
    "    X_selected = X[selected_features].values\n",
    "    X_selected = X_selected.reshape(X_selected.shape[0], X_selected.shape[1], 1)\n",
    "    y_values = y.values\n",
    "    \n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    metrics = {\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': [],\n",
    "        'auc': []\n",
    "    }\n",
    "    \n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X_selected)):\n",
    "        print(f\"Training fold {fold+1}/{k}...\")\n",
    "        \n",
    "        X_train, X_test = X_selected[train_idx], X_selected[test_idx]\n",
    "        y_train, y_test = y_values[train_idx], y_values[test_idx]\n",
    "        \n",
    "        model = build_cnn_model((X_selected.shape[1], 1))\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            verbose=0,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[early_stop]\n",
    "        )\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "        \n",
    "        metrics['accuracy'].append(accuracy_score(y_test, y_pred_classes))\n",
    "        metrics['precision'].append(precision_score(y_test, y_pred_classes))\n",
    "        metrics['recall'].append(recall_score(y_test, y_pred_classes))\n",
    "        metrics['f1'].append(f1_score(y_test, y_pred_classes))\n",
    "        try:\n",
    "            metrics['auc'].append(roc_auc_score(y_test, y_pred))\n",
    "        except:\n",
    "            metrics['auc'].append(0.5)\n",
    "    \n",
    "    avg_metrics = {metric: np.mean(values) for metric, values in metrics.items()}\n",
    "    std_metrics = {metric: np.std(values) for metric, values in metrics.items()}\n",
    "    \n",
    "    print(f\"\\nResults for {technique_name}:\")\n",
    "    for metric, value in avg_metrics.items():\n",
    "        print(f\"Average {metric}: {value:.4f} ± {std_metrics[metric]:.4f}\")\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "# Function to add previously completed results\n",
    "def get_completed_results():\n",
    "    # Create dictionary of results from the completed techniques\n",
    "    completed_results = {\n",
    "        \"1. Chi-Square\": {\n",
    "            'accuracy': 0.9561, \n",
    "            'precision': 0.9794, \n",
    "            'recall': 0.9319,\n",
    "            'f1': 0.9550,\n",
    "            'auc': 0.9955\n",
    "        },\n",
    "        \"2. Mutual Information\": {\n",
    "            'accuracy': 0.9612,\n",
    "            'precision': 0.9805,\n",
    "            'recall': 0.9411,\n",
    "            'f1': 0.9603,\n",
    "            'auc': 0.9958\n",
    "        },\n",
    "        \"3. Recursive Feature Elimination\": {\n",
    "            'accuracy': 0.9552,\n",
    "            'precision': 0.9767,\n",
    "            'recall': 0.9327,\n",
    "            'f1': 0.9541,\n",
    "            'auc': 0.9938\n",
    "        },\n",
    "        \"4. Lasso\": {\n",
    "            'accuracy': 0.9464,\n",
    "            'precision': 0.9675,\n",
    "            'recall': 0.9241,\n",
    "            'f1': 0.9449,\n",
    "            'auc': 0.9924\n",
    "        },\n",
    "        \"5. Random Forest Importance\": {\n",
    "            'accuracy': 0.9525,\n",
    "            'precision': 0.9686,\n",
    "            'recall': 0.9352,\n",
    "            'f1': 0.9516,\n",
    "            'auc': 0.9926\n",
    "        },\n",
    "        \"6. Boruta\": {\n",
    "            'accuracy': 0.9635,\n",
    "            'precision': 0.9770,\n",
    "            'recall': 0.9495,\n",
    "            'f1': 0.9630,\n",
    "            'auc': 0.9950\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create dictionary of top features from completed techniques\n",
    "    completed_features = {\n",
    "        \"1. Chi-Square\": [\n",
    "            \"Breathing Problem\", \"Sore throat\", \"Running Nose\", \"Headache\", \n",
    "            \"Heart Disease\", \"Diabetes\", \"Hyper Tension\", \"Gastrointestinal\",\n",
    "            \"Attended Large Gathering\", \"Family working in Public Exposed Places\"\n",
    "        ],\n",
    "        \"2. Mutual Information\": [\n",
    "            \"Breathing Problem\", \"Sore throat\", \"Running Nose\", \"Headache\", \n",
    "            \"Heart Disease\", \"Diabetes\", \"Hyper Tension\", \"Gastrointestinal\",\n",
    "            \"Attended Large Gathering\", \"Family working in Public Exposed Places\"\n",
    "        ],\n",
    "        \"3. Recursive Feature Elimination\": [\n",
    "            \"Breathing Problem\", \"Fever\", \"Dry Cough\", \"Sore throat\", \n",
    "            \"Running Nose\", \"Headache\", \"Hyper Tension\", \"Fatigue\",\n",
    "            \"Attended Large Gathering\", \"Family working in Public Exposed Places\"\n",
    "        ],\n",
    "        \"4. Lasso\": [\n",
    "            \"Breathing Problem\", \"Sore throat\", \"Hyper Tension\",\n",
    "            \"Attended Large Gathering\", \"Family working in Public Exposed Places\",\n",
    "            \"Fever\", \"Dry Cough\", \"Running Nose\", \"Asthma\", \"Chronic Lung Disease\"\n",
    "        ],\n",
    "        \"5. Random Forest Importance\": [\n",
    "            \"Breathing Problem\", \"Sore throat\", \"Attended Large Gathering\", \n",
    "            \"Family working in Public Exposed Places\", \"Fever\", \"Dry Cough\",\n",
    "            \"Running Nose\", \"Asthma\", \"Chronic Lung Disease\", \"Headache\"\n",
    "        ],\n",
    "        \"6. Boruta\": [\n",
    "            \"Breathing Problem\", \"Sore throat\", \"Running Nose\", \"Chronic Lung Disease\",\n",
    "            \"Headache\", \"Heart Disease\", \"Diabetes\", \"Hyper Tension\", \"Gastrointestinal\",\n",
    "            \"Attended Large Gathering\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return completed_results, completed_features\n",
    "\n",
    "# Plot comparison bar chart\n",
    "def plot_comparison(all_results):\n",
    "    metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
    "    \n",
    "    sorted_techniques = sorted(\n",
    "        all_results.keys(),\n",
    "        key=lambda x: all_results[x]['accuracy'],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    bar_width = 0.15\n",
    "    index = np.arange(len(sorted_techniques))\n",
    "    \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    \n",
    "    for i, metric in enumerate(metrics_to_plot):\n",
    "        values = [all_results[technique][metric] for technique in sorted_techniques]\n",
    "        plt.bar(\n",
    "            index + i * bar_width, \n",
    "            values, \n",
    "            bar_width, \n",
    "            label=metric.capitalize(),\n",
    "            color=colors[i]\n",
    "        )\n",
    "    \n",
    "    plt.xlabel('Feature Selection Technique', fontsize=12)\n",
    "    plt.ylabel('Score', fontsize=12)\n",
    "    plt.title('Comparison of Feature Selection Techniques', fontsize=14)\n",
    "    plt.xticks(\n",
    "        index + bar_width * 2, \n",
    "        [t.split('. ')[1] if '. ' in t else t for t in sorted_techniques],\n",
    "        rotation=45,\n",
    "        ha='right'\n",
    "    )\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=5)\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('feature_selection_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Comparison chart saved as 'feature_selection_comparison.png'\")\n",
    "    plt.close()\n",
    "\n",
    "# Main function to run the whole process\n",
    "def main():\n",
    "    file_path = \"OneDrive/Desktop/Research_Capstone_Project/preprocessed_covid500_final.csv\"  # Update with your path\n",
    "    X, y = load_data(file_path)\n",
    "    \n",
    "    feature_selectors, completed_techniques = get_feature_selectors(X, y)\n",
    "    completed_results, completed_features = get_completed_results()\n",
    "    \n",
    "    all_results = completed_results.copy()\n",
    "    all_selected_features = completed_features.copy()\n",
    "    \n",
    "    for technique_name, selector in feature_selectors.items():\n",
    "        if technique_name in completed_techniques:\n",
    "            print(f\"\\nSkipping {technique_name} - already completed\")\n",
    "            continue\n",
    "            \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Processing {technique_name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        selected_features, _ = select_features(X, y, technique_name, selector)\n",
    "        all_selected_features[technique_name] = selected_features\n",
    "        \n",
    "        results = train_and_evaluate(X, y, selected_features, technique_name)\n",
    "        all_results[technique_name] = results\n",
    "    \n",
    "    plot_comparison(all_results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    sorted_techniques = sorted(\n",
    "        all_results.keys(),\n",
    "        key=lambda x: all_results[x]['accuracy'],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTechniques ranked by accuracy:\")\n",
    "    for i, technique in enumerate(sorted_techniques):\n",
    "        print(f\"{i+1}. {technique}: {all_results[technique]['accuracy']:.4f}\")\n",
    "    \n",
    "    best_technique = sorted_techniques[0]\n",
    "    print(f\"\\nBest performing technique: {best_technique}\")\n",
    "    print(f\"Top features selected by {best_technique}:\")\n",
    "    for feature in all_selected_features[best_technique]:\n",
    "        print(f\"- {feature}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847c0a21-4698-4a83-93e6-c41ca77e5910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
