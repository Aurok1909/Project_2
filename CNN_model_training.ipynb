{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc96f6e-2308-428b-82cd-c182dbd83c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output directory: covid_cnn_results\n",
      "Results will be saved in: covid_cnn_results\n",
      "Loading dataset...\n",
      "Dataset loaded: 37028 samples, features shaped as 2x5\n",
      "Class distribution: {1: 18514, 0: 18514}\n",
      "Selected features: Sore throat, Breathing Problem, Attended Large Gathering, Family working in Public Exposed Places, Heart Disease, Hyper Tension, Chronic Lung Disease, Fever, Dry Cough, Running Nose\n",
      "\n",
      "Fold 1/10\n",
      "==================================================\n",
      "Epoch 1/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9217 - loss: 0.2096 - val_accuracy: 0.9536 - val_loss: 0.1231\n",
      "Epoch 2/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9505 - loss: 0.1287 - val_accuracy: 0.9569 - val_loss: 0.1285\n",
      "Epoch 3/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9514 - loss: 0.1182 - val_accuracy: 0.9548 - val_loss: 0.1303\n",
      "Epoch 4/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9553 - loss: 0.1127 - val_accuracy: 0.9466 - val_loss: 0.1458\n",
      "Epoch 5/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.1084 - val_accuracy: 0.9523 - val_loss: 0.1170\n",
      "Epoch 6/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 0.1069 - val_accuracy: 0.9515 - val_loss: 0.1280\n",
      "Epoch 7/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9585 - loss: 0.1044 - val_accuracy: 0.9608 - val_loss: 0.1188\n",
      "Epoch 8/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.0972 - val_accuracy: 0.9559 - val_loss: 0.1236\n",
      "Epoch 9/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.0993 - val_accuracy: 0.9500 - val_loss: 0.1277\n",
      "Epoch 10/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9606 - loss: 0.0981 - val_accuracy: 0.9422 - val_loss: 0.1279\n",
      "Epoch 11/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.0957 - val_accuracy: 0.9451 - val_loss: 0.1166\n",
      "Epoch 12/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.0948 - val_accuracy: 0.9440 - val_loss: 0.1295\n",
      "Epoch 13/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.0924 - val_accuracy: 0.9383 - val_loss: 0.1287\n",
      "Epoch 14/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.0910 - val_accuracy: 0.9395 - val_loss: 0.1202\n",
      "Epoch 15/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.0925 - val_accuracy: 0.9436 - val_loss: 0.1194\n",
      "Epoch 16/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.0900 - val_accuracy: 0.9455 - val_loss: 0.1178\n",
      "Epoch 17/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0907 - val_accuracy: 0.9616 - val_loss: 0.1115\n",
      "Epoch 18/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.0898 - val_accuracy: 0.9440 - val_loss: 0.1203\n",
      "Epoch 19/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.0897 - val_accuracy: 0.9458 - val_loss: 0.1141\n",
      "Epoch 20/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.0891 - val_accuracy: 0.9575 - val_loss: 0.1187\n",
      "Epoch 21/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0899 - val_accuracy: 0.9440 - val_loss: 0.1224\n",
      "Epoch 22/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.0885 - val_accuracy: 0.9440 - val_loss: 0.1232\n",
      "Epoch 23/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0872 - val_accuracy: 0.9440 - val_loss: 0.1204\n",
      "Epoch 24/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0897 - val_accuracy: 0.9443 - val_loss: 0.1198\n",
      "Epoch 25/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.0864 - val_accuracy: 0.9307 - val_loss: 0.1428\n",
      "Epoch 26/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0888 - val_accuracy: 0.9391 - val_loss: 0.1175\n",
      "Epoch 27/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.0838 - val_accuracy: 0.9391 - val_loss: 0.1268\n",
      "Epoch 28/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.0869 - val_accuracy: 0.9566 - val_loss: 0.1129\n",
      "Epoch 29/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.0865 - val_accuracy: 0.9391 - val_loss: 0.1318\n",
      "Epoch 30/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.0861 - val_accuracy: 0.9440 - val_loss: 0.1195\n",
      "Epoch 31/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0872 - val_accuracy: 0.9496 - val_loss: 0.1178\n",
      "Epoch 32/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.0850 - val_accuracy: 0.9437 - val_loss: 0.1179\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Metrics for fold 1:\n",
      "accuracy: 0.9617\n",
      "precision: 0.9745\n",
      "recall: 0.9497\n",
      "f1: 0.9619\n",
      "mcc: 0.9236\n",
      "auc: 0.9955\n",
      "fpr: 0.0259\n",
      "specificity: 0.9741\n",
      "lr_plus: 36.6547\n",
      "lr_minus: 0.0516\n",
      "\n",
      "Fold 2/10\n",
      "==================================================\n",
      "Epoch 1/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9260 - loss: 0.1990 - val_accuracy: 0.9475 - val_loss: 0.1237\n",
      "Epoch 2/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9512 - loss: 0.1330 - val_accuracy: 0.9562 - val_loss: 0.1217\n",
      "Epoch 3/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9543 - loss: 0.1189 - val_accuracy: 0.9526 - val_loss: 0.1327\n",
      "Epoch 4/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9567 - loss: 0.1133 - val_accuracy: 0.9584 - val_loss: 0.1133\n",
      "Epoch 5/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.1075 - val_accuracy: 0.9587 - val_loss: 0.1116\n",
      "Epoch 6/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.1031 - val_accuracy: 0.9595 - val_loss: 0.1118\n",
      "Epoch 7/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.1029 - val_accuracy: 0.9595 - val_loss: 0.1197\n",
      "Epoch 8/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.0991 - val_accuracy: 0.9566 - val_loss: 0.1203\n",
      "Epoch 9/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.0984 - val_accuracy: 0.9574 - val_loss: 0.1213\n",
      "Epoch 10/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.0972 - val_accuracy: 0.9494 - val_loss: 0.1288\n",
      "Epoch 11/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.0965 - val_accuracy: 0.9599 - val_loss: 0.1203\n",
      "Epoch 12/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0951 - val_accuracy: 0.9580 - val_loss: 0.1087\n",
      "Epoch 13/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.0949 - val_accuracy: 0.9523 - val_loss: 0.1154\n",
      "Epoch 14/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.0923 - val_accuracy: 0.9440 - val_loss: 0.1142\n",
      "Epoch 15/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.0954 - val_accuracy: 0.9407 - val_loss: 0.1214\n",
      "Epoch 16/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.0922 - val_accuracy: 0.9581 - val_loss: 0.1181\n",
      "Epoch 17/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.0911 - val_accuracy: 0.9647 - val_loss: 0.1197\n",
      "Epoch 18/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0909 - val_accuracy: 0.9581 - val_loss: 0.1164\n",
      "Epoch 19/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0907 - val_accuracy: 0.9440 - val_loss: 0.1282\n",
      "Epoch 20/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.0914 - val_accuracy: 0.9581 - val_loss: 0.1149\n",
      "Epoch 21/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0859 - val_accuracy: 0.9599 - val_loss: 0.1147\n",
      "Epoch 22/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.0865 - val_accuracy: 0.9598 - val_loss: 0.1079\n",
      "Epoch 23/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0867 - val_accuracy: 0.9598 - val_loss: 0.1058\n",
      "Epoch 24/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0882 - val_accuracy: 0.9581 - val_loss: 0.1122\n",
      "Epoch 25/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.0866 - val_accuracy: 0.9626 - val_loss: 0.1146\n",
      "Epoch 26/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9651 - loss: 0.0862 - val_accuracy: 0.9698 - val_loss: 0.1102\n",
      "Epoch 27/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.0868 - val_accuracy: 0.9602 - val_loss: 0.1108\n",
      "Epoch 28/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.0871 - val_accuracy: 0.9469 - val_loss: 0.1134\n",
      "Epoch 29/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9648 - loss: 0.0868 - val_accuracy: 0.9613 - val_loss: 0.1157\n",
      "Epoch 30/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0883 - val_accuracy: 0.9650 - val_loss: 0.1078\n",
      "Epoch 31/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.0841 - val_accuracy: 0.9626 - val_loss: 0.1111\n",
      "Epoch 32/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0841 - val_accuracy: 0.9413 - val_loss: 0.1226\n",
      "Epoch 33/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9648 - loss: 0.0844 - val_accuracy: 0.9581 - val_loss: 0.1128\n",
      "Epoch 34/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0857 - val_accuracy: 0.9469 - val_loss: 0.1134\n",
      "Epoch 35/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.0848 - val_accuracy: 0.9626 - val_loss: 0.1042\n",
      "Epoch 36/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9673 - loss: 0.0826 - val_accuracy: 0.9626 - val_loss: 0.1077\n",
      "Epoch 37/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.0867 - val_accuracy: 0.9605 - val_loss: 0.1091\n",
      "Epoch 38/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.0829 - val_accuracy: 0.9544 - val_loss: 0.1139\n",
      "Epoch 39/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.0853 - val_accuracy: 0.9406 - val_loss: 0.1214\n",
      "Epoch 40/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.0840 - val_accuracy: 0.9602 - val_loss: 0.1176\n",
      "Epoch 41/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.0833 - val_accuracy: 0.9602 - val_loss: 0.1109\n",
      "Epoch 42/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9661 - loss: 0.0836 - val_accuracy: 0.9469 - val_loss: 0.1144\n",
      "Epoch 43/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.0844 - val_accuracy: 0.9487 - val_loss: 0.1182\n",
      "Epoch 44/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0847 - val_accuracy: 0.9410 - val_loss: 0.1151\n",
      "Epoch 45/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.0826 - val_accuracy: 0.9605 - val_loss: 0.1091\n",
      "Epoch 46/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9661 - loss: 0.0824 - val_accuracy: 0.9415 - val_loss: 0.1171\n",
      "Epoch 47/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9654 - loss: 0.0827 - val_accuracy: 0.9469 - val_loss: 0.1102\n",
      "Epoch 48/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9669 - loss: 0.0805 - val_accuracy: 0.9602 - val_loss: 0.1124\n",
      "Epoch 49/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.0811 - val_accuracy: 0.9410 - val_loss: 0.1150\n",
      "Epoch 50/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9648 - loss: 0.0836 - val_accuracy: 0.9410 - val_loss: 0.1132\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Metrics for fold 2:\n",
      "accuracy: 0.9608\n",
      "precision: 0.9577\n",
      "recall: 0.9634\n",
      "f1: 0.9605\n",
      "mcc: 0.9217\n",
      "auc: 0.9949\n",
      "fpr: 0.0417\n",
      "specificity: 0.9583\n",
      "lr_plus: 23.1218\n",
      "lr_minus: 0.0382\n",
      "\n",
      "Fold 3/10\n",
      "==================================================\n",
      "Epoch 1/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9236 - loss: 0.2040 - val_accuracy: 0.9598 - val_loss: 0.1276\n",
      "Epoch 2/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9480 - loss: 0.1296 - val_accuracy: 0.9479 - val_loss: 0.1450\n",
      "Epoch 3/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9525 - loss: 0.1185 - val_accuracy: 0.9511 - val_loss: 0.1400\n",
      "Epoch 4/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9532 - loss: 0.1166 - val_accuracy: 0.9589 - val_loss: 0.1353\n",
      "Epoch 5/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9552 - loss: 0.1117 - val_accuracy: 0.9415 - val_loss: 0.1339\n",
      "Epoch 6/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1050 - val_accuracy: 0.9614 - val_loss: 0.1254\n",
      "Epoch 7/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.1046 - val_accuracy: 0.9524 - val_loss: 0.1209\n",
      "Epoch 8/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.1002 - val_accuracy: 0.9580 - val_loss: 0.1167\n",
      "Epoch 9/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.0987 - val_accuracy: 0.9511 - val_loss: 0.1189\n",
      "Epoch 10/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.0971 - val_accuracy: 0.9622 - val_loss: 0.1162\n",
      "Epoch 11/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.0944 - val_accuracy: 0.9583 - val_loss: 0.1112\n",
      "Epoch 12/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.0953 - val_accuracy: 0.9691 - val_loss: 0.1117\n",
      "Epoch 13/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.0945 - val_accuracy: 0.9643 - val_loss: 0.1038\n",
      "Epoch 14/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.0930 - val_accuracy: 0.9611 - val_loss: 0.1024\n",
      "Epoch 15/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.0932 - val_accuracy: 0.9508 - val_loss: 0.1199\n",
      "Epoch 16/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.0918 - val_accuracy: 0.9497 - val_loss: 0.1137\n",
      "Epoch 17/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0919 - val_accuracy: 0.9569 - val_loss: 0.1070\n",
      "Epoch 18/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0893 - val_accuracy: 0.9625 - val_loss: 0.1073\n",
      "Epoch 19/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9631 - loss: 0.0903 - val_accuracy: 0.9514 - val_loss: 0.1131\n",
      "Epoch 20/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.0897 - val_accuracy: 0.9514 - val_loss: 0.1142\n",
      "Epoch 21/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9632 - loss: 0.0880 - val_accuracy: 0.9566 - val_loss: 0.1169\n",
      "Epoch 22/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0872 - val_accuracy: 0.9566 - val_loss: 0.1100\n",
      "Epoch 23/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9651 - loss: 0.0880 - val_accuracy: 0.9497 - val_loss: 0.1106\n",
      "Epoch 24/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0878 - val_accuracy: 0.9442 - val_loss: 0.1146\n",
      "Epoch 25/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9636 - loss: 0.0882 - val_accuracy: 0.9514 - val_loss: 0.1102\n",
      "Epoch 26/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9657 - loss: 0.0877 - val_accuracy: 0.9527 - val_loss: 0.1148\n",
      "Epoch 27/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0845 - val_accuracy: 0.9574 - val_loss: 0.1068\n",
      "Epoch 28/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0855 - val_accuracy: 0.9569 - val_loss: 0.1092\n",
      "Epoch 29/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.0833 - val_accuracy: 0.9500 - val_loss: 0.1152\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Metrics for fold 3:\n",
      "accuracy: 0.9638\n",
      "precision: 0.9659\n",
      "recall: 0.9606\n",
      "f1: 0.9632\n",
      "mcc: 0.9276\n",
      "auc: 0.9953\n",
      "fpr: 0.0330\n",
      "specificity: 0.9670\n",
      "lr_plus: 29.0656\n",
      "lr_minus: 0.0408\n",
      "\n",
      "Fold 4/10\n",
      "==================================================\n",
      "Epoch 1/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9275 - loss: 0.1959 - val_accuracy: 0.9179 - val_loss: 0.1726\n",
      "Epoch 2/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9506 - loss: 0.1280 - val_accuracy: 0.9424 - val_loss: 0.1536\n",
      "Epoch 3/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.1191 - val_accuracy: 0.9518 - val_loss: 0.1453\n",
      "Epoch 4/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9569 - loss: 0.1118 - val_accuracy: 0.9512 - val_loss: 0.1445\n",
      "Epoch 5/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.1080 - val_accuracy: 0.9355 - val_loss: 0.1465\n",
      "Epoch 6/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9557 - loss: 0.1054 - val_accuracy: 0.9476 - val_loss: 0.1348\n",
      "Epoch 7/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1038 - val_accuracy: 0.9416 - val_loss: 0.1356\n",
      "Epoch 8/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1011 - val_accuracy: 0.9464 - val_loss: 0.1355\n",
      "Epoch 9/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.0974 - val_accuracy: 0.9416 - val_loss: 0.1236\n",
      "Epoch 10/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9616 - loss: 0.0972 - val_accuracy: 0.9380 - val_loss: 0.1198\n",
      "Epoch 11/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9609 - loss: 0.0969 - val_accuracy: 0.9446 - val_loss: 0.1230\n",
      "Epoch 12/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9614 - loss: 0.0949 - val_accuracy: 0.9365 - val_loss: 0.1188\n",
      "Epoch 13/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9618 - loss: 0.0931 - val_accuracy: 0.9421 - val_loss: 0.1225\n",
      "Epoch 14/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9630 - loss: 0.0957 - val_accuracy: 0.9428 - val_loss: 0.1170\n",
      "Epoch 15/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9626 - loss: 0.0909 - val_accuracy: 0.9368 - val_loss: 0.1283\n",
      "Epoch 16/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9607 - loss: 0.0938 - val_accuracy: 0.9403 - val_loss: 0.1306\n",
      "Epoch 17/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9632 - loss: 0.0909 - val_accuracy: 0.9278 - val_loss: 0.1318\n",
      "Epoch 18/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.0893 - val_accuracy: 0.9290 - val_loss: 0.1270\n",
      "Epoch 19/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9614 - loss: 0.0920 - val_accuracy: 0.9368 - val_loss: 0.1332\n",
      "Epoch 20/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9646 - loss: 0.0894 - val_accuracy: 0.9364 - val_loss: 0.1216\n",
      "Epoch 21/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0885 - val_accuracy: 0.9422 - val_loss: 0.1212\n",
      "Epoch 22/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.0875 - val_accuracy: 0.9347 - val_loss: 0.1391\n",
      "Epoch 23/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.0893 - val_accuracy: 0.9365 - val_loss: 0.1183\n",
      "Epoch 24/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9648 - loss: 0.0875 - val_accuracy: 0.9502 - val_loss: 0.1171\n",
      "Epoch 25/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.0878 - val_accuracy: 0.9349 - val_loss: 0.1217\n",
      "Epoch 26/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.0854 - val_accuracy: 0.9419 - val_loss: 0.1136\n",
      "Epoch 27/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0864 - val_accuracy: 0.9418 - val_loss: 0.1167\n",
      "Epoch 28/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.0851 - val_accuracy: 0.9553 - val_loss: 0.1094\n",
      "Epoch 29/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9643 - loss: 0.0863 - val_accuracy: 0.9349 - val_loss: 0.1261\n",
      "Epoch 30/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.0843 - val_accuracy: 0.9419 - val_loss: 0.1182\n",
      "Epoch 31/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9637 - loss: 0.0845 - val_accuracy: 0.9400 - val_loss: 0.1229\n",
      "Epoch 32/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9648 - loss: 0.0848 - val_accuracy: 0.9416 - val_loss: 0.1171\n",
      "Epoch 33/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9640 - loss: 0.0845 - val_accuracy: 0.9496 - val_loss: 0.1131\n",
      "Epoch 34/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9641 - loss: 0.0852 - val_accuracy: 0.9412 - val_loss: 0.1195\n",
      "Epoch 35/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9663 - loss: 0.0871 - val_accuracy: 0.9349 - val_loss: 0.1228\n",
      "Epoch 36/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.0846 - val_accuracy: 0.9422 - val_loss: 0.1178\n",
      "Epoch 37/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9659 - loss: 0.0819 - val_accuracy: 0.9422 - val_loss: 0.1203\n",
      "Epoch 38/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9672 - loss: 0.0832 - val_accuracy: 0.9427 - val_loss: 0.1177\n",
      "Epoch 39/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9649 - loss: 0.0854 - val_accuracy: 0.9413 - val_loss: 0.1142\n",
      "Epoch 40/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.0853 - val_accuracy: 0.9440 - val_loss: 0.1150\n",
      "Epoch 41/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9648 - loss: 0.0855 - val_accuracy: 0.9422 - val_loss: 0.1145\n",
      "Epoch 42/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9662 - loss: 0.0814 - val_accuracy: 0.9409 - val_loss: 0.1116\n",
      "Epoch 43/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9647 - loss: 0.0855 - val_accuracy: 0.9413 - val_loss: 0.1149\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Metrics for fold 4:\n",
      "accuracy: 0.9657\n",
      "precision: 0.9803\n",
      "recall: 0.9517\n",
      "f1: 0.9658\n",
      "mcc: 0.9318\n",
      "auc: 0.9940\n",
      "fpr: 0.0198\n",
      "specificity: 0.9802\n",
      "lr_plus: 48.1124\n",
      "lr_minus: 0.0493\n",
      "\n",
      "Fold 5/10\n",
      "==================================================\n",
      "Epoch 1/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9256 - loss: 0.2016 - val_accuracy: 0.9202 - val_loss: 0.1564\n",
      "Epoch 2/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9514 - loss: 0.1233 - val_accuracy: 0.9535 - val_loss: 0.1354\n",
      "Epoch 3/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9563 - loss: 0.1124 - val_accuracy: 0.9469 - val_loss: 0.1322\n",
      "Epoch 4/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9603 - loss: 0.1008 - val_accuracy: 0.9469 - val_loss: 0.1400\n",
      "Epoch 5/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9608 - loss: 0.0964 - val_accuracy: 0.9442 - val_loss: 0.1340\n",
      "Epoch 6/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9600 - loss: 0.0983 - val_accuracy: 0.9412 - val_loss: 0.1502\n",
      "Epoch 7/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9621 - loss: 0.0931 - val_accuracy: 0.9530 - val_loss: 0.1317\n",
      "Epoch 8/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9629 - loss: 0.0921 - val_accuracy: 0.9443 - val_loss: 0.1322\n",
      "Epoch 9/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9644 - loss: 0.0908 - val_accuracy: 0.9560 - val_loss: 0.1231\n",
      "Epoch 10/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9633 - loss: 0.0905 - val_accuracy: 0.9443 - val_loss: 0.1241\n",
      "Epoch 11/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9647 - loss: 0.0857 - val_accuracy: 0.9395 - val_loss: 0.1340\n",
      "Epoch 12/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.0877 - val_accuracy: 0.9560 - val_loss: 0.1313\n",
      "Epoch 13/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.0868 - val_accuracy: 0.9487 - val_loss: 0.1298\n",
      "Epoch 14/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9654 - loss: 0.0856 - val_accuracy: 0.9487 - val_loss: 0.1206\n",
      "Epoch 15/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9655 - loss: 0.0856 - val_accuracy: 0.9490 - val_loss: 0.1212\n",
      "Epoch 16/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.0839 - val_accuracy: 0.9443 - val_loss: 0.1261\n",
      "Epoch 17/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.0841 - val_accuracy: 0.9586 - val_loss: 0.1247\n",
      "Epoch 18/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.0846 - val_accuracy: 0.9476 - val_loss: 0.1325\n",
      "Epoch 19/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.0833 - val_accuracy: 0.9443 - val_loss: 0.1290\n",
      "Epoch 20/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.0844 - val_accuracy: 0.9505 - val_loss: 0.1256\n",
      "Epoch 21/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9655 - loss: 0.0830 - val_accuracy: 0.9298 - val_loss: 0.1348\n",
      "Epoch 22/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.0815 - val_accuracy: 0.9448 - val_loss: 0.1214\n",
      "Epoch 23/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9674 - loss: 0.0805 - val_accuracy: 0.9403 - val_loss: 0.1262\n",
      "Epoch 24/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9653 - loss: 0.0814 - val_accuracy: 0.9491 - val_loss: 0.1184\n",
      "Epoch 25/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.0791 - val_accuracy: 0.9383 - val_loss: 0.1300\n",
      "Epoch 26/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9680 - loss: 0.0804 - val_accuracy: 0.9568 - val_loss: 0.1147\n",
      "Epoch 27/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9669 - loss: 0.0785 - val_accuracy: 0.9509 - val_loss: 0.1279\n",
      "Epoch 28/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9675 - loss: 0.0809 - val_accuracy: 0.9565 - val_loss: 0.1200\n",
      "Epoch 29/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9660 - loss: 0.0781 - val_accuracy: 0.9515 - val_loss: 0.1256\n",
      "Epoch 30/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.0780 - val_accuracy: 0.9500 - val_loss: 0.1258\n",
      "Epoch 31/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9659 - loss: 0.0815 - val_accuracy: 0.9446 - val_loss: 0.1239\n",
      "Epoch 32/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9681 - loss: 0.0780 - val_accuracy: 0.9511 - val_loss: 0.1222\n",
      "Epoch 33/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9670 - loss: 0.0794 - val_accuracy: 0.9452 - val_loss: 0.1240\n",
      "Epoch 34/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9670 - loss: 0.0804 - val_accuracy: 0.9431 - val_loss: 0.1236\n",
      "Epoch 35/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9673 - loss: 0.0774 - val_accuracy: 0.9490 - val_loss: 0.1186\n",
      "Epoch 36/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9680 - loss: 0.0789 - val_accuracy: 0.9368 - val_loss: 0.1278\n",
      "Epoch 37/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.0787 - val_accuracy: 0.9424 - val_loss: 0.1199\n",
      "Epoch 38/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.0768 - val_accuracy: 0.9479 - val_loss: 0.1231\n",
      "Epoch 39/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9668 - loss: 0.0778 - val_accuracy: 0.9328 - val_loss: 0.1268\n",
      "Epoch 40/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9674 - loss: 0.0776 - val_accuracy: 0.9544 - val_loss: 0.1230\n",
      "Epoch 41/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9674 - loss: 0.0777 - val_accuracy: 0.9421 - val_loss: 0.1265\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Metrics for fold 5:\n",
      "accuracy: 0.9635\n",
      "precision: 0.9777\n",
      "recall: 0.9503\n",
      "f1: 0.9638\n",
      "mcc: 0.9275\n",
      "auc: 0.9953\n",
      "fpr: 0.0227\n",
      "specificity: 0.9773\n",
      "lr_plus: 41.9542\n",
      "lr_minus: 0.0508\n",
      "\n",
      "Fold 6/10\n",
      "==================================================\n",
      "Epoch 1/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9238 - loss: 0.2026 - val_accuracy: 0.9296 - val_loss: 0.1647\n",
      "Epoch 2/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9503 - loss: 0.1339 - val_accuracy: 0.9313 - val_loss: 0.1555\n",
      "Epoch 3/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9513 - loss: 0.1222 - val_accuracy: 0.9344 - val_loss: 0.1440\n",
      "Epoch 4/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9557 - loss: 0.1121 - val_accuracy: 0.9373 - val_loss: 0.1422\n",
      "Epoch 5/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9573 - loss: 0.1105 - val_accuracy: 0.9398 - val_loss: 0.1381\n",
      "Epoch 6/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9582 - loss: 0.1050 - val_accuracy: 0.9439 - val_loss: 0.1399\n",
      "Epoch 7/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9570 - loss: 0.1062 - val_accuracy: 0.9341 - val_loss: 0.1410\n",
      "Epoch 8/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1014 - val_accuracy: 0.9325 - val_loss: 0.1476\n",
      "Epoch 9/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9593 - loss: 0.1012 - val_accuracy: 0.9427 - val_loss: 0.1423\n",
      "Epoch 10/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9631 - loss: 0.0957 - val_accuracy: 0.9385 - val_loss: 0.1352\n",
      "Epoch 11/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9611 - loss: 0.0943 - val_accuracy: 0.9425 - val_loss: 0.1419\n",
      "Epoch 12/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.0943 - val_accuracy: 0.9332 - val_loss: 0.1325\n",
      "Epoch 13/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.0957 - val_accuracy: 0.9425 - val_loss: 0.1262\n",
      "Epoch 14/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.0985 - val_accuracy: 0.9382 - val_loss: 0.1353\n",
      "Epoch 15/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.0934 - val_accuracy: 0.9328 - val_loss: 0.1423\n",
      "Epoch 16/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9617 - loss: 0.0946 - val_accuracy: 0.9385 - val_loss: 0.1292\n",
      "Epoch 17/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.0941 - val_accuracy: 0.9328 - val_loss: 0.1265\n",
      "Epoch 18/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9623 - loss: 0.0928 - val_accuracy: 0.9430 - val_loss: 0.1198\n",
      "Epoch 19/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.0917 - val_accuracy: 0.9371 - val_loss: 0.1200\n",
      "Epoch 20/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.0915 - val_accuracy: 0.9446 - val_loss: 0.1317\n",
      "Epoch 21/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.0897 - val_accuracy: 0.9328 - val_loss: 0.1368\n",
      "Epoch 22/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.0890 - val_accuracy: 0.9373 - val_loss: 0.1273\n",
      "Epoch 23/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.0907 - val_accuracy: 0.9376 - val_loss: 0.1182\n",
      "Epoch 24/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0890 - val_accuracy: 0.9373 - val_loss: 0.1273\n",
      "Epoch 25/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.0911 - val_accuracy: 0.9368 - val_loss: 0.1234\n",
      "Epoch 26/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9634 - loss: 0.0891 - val_accuracy: 0.9373 - val_loss: 0.1284\n",
      "Epoch 27/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9631 - loss: 0.0880 - val_accuracy: 0.9388 - val_loss: 0.1343\n",
      "Epoch 28/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9644 - loss: 0.0880 - val_accuracy: 0.9365 - val_loss: 0.1316\n",
      "Epoch 29/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9625 - loss: 0.0897 - val_accuracy: 0.9376 - val_loss: 0.1305\n",
      "Epoch 30/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9638 - loss: 0.0862 - val_accuracy: 0.9586 - val_loss: 0.1173\n",
      "Epoch 31/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9643 - loss: 0.0881 - val_accuracy: 0.9481 - val_loss: 0.1198\n",
      "Epoch 32/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9635 - loss: 0.0862 - val_accuracy: 0.9376 - val_loss: 0.1221\n",
      "Epoch 33/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9633 - loss: 0.0863 - val_accuracy: 0.9373 - val_loss: 0.1266\n",
      "Epoch 34/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9631 - loss: 0.0885 - val_accuracy: 0.9490 - val_loss: 0.1261\n",
      "Epoch 35/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9634 - loss: 0.0880 - val_accuracy: 0.9395 - val_loss: 0.1188\n",
      "Epoch 36/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0854 - val_accuracy: 0.9398 - val_loss: 0.1222\n",
      "Epoch 37/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9634 - loss: 0.0881 - val_accuracy: 0.9331 - val_loss: 0.1224\n",
      "Epoch 38/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9638 - loss: 0.0873 - val_accuracy: 0.9371 - val_loss: 0.1235\n",
      "Epoch 39/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9655 - loss: 0.0846 - val_accuracy: 0.9371 - val_loss: 0.1270\n",
      "Epoch 40/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9642 - loss: 0.0860 - val_accuracy: 0.9428 - val_loss: 0.1204\n",
      "Epoch 41/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9638 - loss: 0.0865 - val_accuracy: 0.9371 - val_loss: 0.1178\n",
      "Epoch 42/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9652 - loss: 0.0863 - val_accuracy: 0.9317 - val_loss: 0.1287\n",
      "Epoch 43/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9643 - loss: 0.0848 - val_accuracy: 0.9376 - val_loss: 0.1195\n",
      "Epoch 44/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9651 - loss: 0.0834 - val_accuracy: 0.9371 - val_loss: 0.1214\n",
      "Epoch 45/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0861 - val_accuracy: 0.9466 - val_loss: 0.1224\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Metrics for fold 6:\n",
      "accuracy: 0.9649\n",
      "precision: 0.9709\n",
      "recall: 0.9582\n",
      "f1: 0.9645\n",
      "mcc: 0.9299\n",
      "auc: 0.9945\n",
      "fpr: 0.0285\n",
      "specificity: 0.9715\n",
      "lr_plus: 33.6281\n",
      "lr_minus: 0.0430\n",
      "\n",
      "Fold 7/10\n",
      "==================================================\n",
      "Epoch 1/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9232 - loss: 0.2070 - val_accuracy: 0.9410 - val_loss: 0.1505\n",
      "Epoch 2/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9458 - loss: 0.1323 - val_accuracy: 0.9379 - val_loss: 0.1524\n",
      "Epoch 3/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9510 - loss: 0.1194 - val_accuracy: 0.9709 - val_loss: 0.1180\n",
      "Epoch 4/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9526 - loss: 0.1175 - val_accuracy: 0.9506 - val_loss: 0.1198\n",
      "Epoch 5/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9563 - loss: 0.1110 - val_accuracy: 0.9562 - val_loss: 0.1334\n",
      "Epoch 6/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9575 - loss: 0.1091 - val_accuracy: 0.9532 - val_loss: 0.1366\n",
      "Epoch 7/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9573 - loss: 0.1039 - val_accuracy: 0.9611 - val_loss: 0.1172\n",
      "Epoch 8/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9587 - loss: 0.1022 - val_accuracy: 0.9479 - val_loss: 0.1245\n",
      "Epoch 9/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9583 - loss: 0.1010 - val_accuracy: 0.9433 - val_loss: 0.1309\n",
      "Epoch 10/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9614 - loss: 0.0974 - val_accuracy: 0.9424 - val_loss: 0.1318\n",
      "Epoch 11/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9595 - loss: 0.0989 - val_accuracy: 0.9506 - val_loss: 0.1067\n",
      "Epoch 12/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9612 - loss: 0.0966 - val_accuracy: 0.9391 - val_loss: 0.1286\n",
      "Epoch 13/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9616 - loss: 0.0947 - val_accuracy: 0.9515 - val_loss: 0.1193\n",
      "Epoch 14/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9608 - loss: 0.0953 - val_accuracy: 0.9629 - val_loss: 0.1115\n",
      "Epoch 15/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9612 - loss: 0.0939 - val_accuracy: 0.9433 - val_loss: 0.1324\n",
      "Epoch 16/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9628 - loss: 0.0921 - val_accuracy: 0.9401 - val_loss: 0.1272\n",
      "Epoch 17/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9628 - loss: 0.0908 - val_accuracy: 0.9188 - val_loss: 0.1596\n",
      "Epoch 18/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9609 - loss: 0.0922 - val_accuracy: 0.9404 - val_loss: 0.1220\n",
      "Epoch 19/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.0921 - val_accuracy: 0.9554 - val_loss: 0.1135\n",
      "Epoch 20/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.0900 - val_accuracy: 0.9361 - val_loss: 0.1346\n",
      "Epoch 21/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0887 - val_accuracy: 0.9374 - val_loss: 0.1273\n",
      "Epoch 22/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.0887 - val_accuracy: 0.9374 - val_loss: 0.1218\n",
      "Epoch 23/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9636 - loss: 0.0872 - val_accuracy: 0.9490 - val_loss: 0.1132\n",
      "Epoch 24/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.0880 - val_accuracy: 0.9389 - val_loss: 0.1206\n",
      "Epoch 25/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0875 - val_accuracy: 0.9400 - val_loss: 0.1132\n",
      "Epoch 26/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0875 - val_accuracy: 0.9374 - val_loss: 0.1233\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Metrics for fold 7:\n",
      "accuracy: 0.9706\n",
      "precision: 0.9840\n",
      "recall: 0.9552\n",
      "f1: 0.9694\n",
      "mcc: 0.9414\n",
      "auc: 0.9966\n",
      "fpr: 0.0148\n",
      "specificity: 0.9852\n",
      "lr_plus: 64.6465\n",
      "lr_minus: 0.0455\n",
      "\n",
      "Fold 8/10\n",
      "==================================================\n",
      "Epoch 1/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.1949 - val_accuracy: 0.9641 - val_loss: 0.1222\n",
      "Epoch 2/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9508 - loss: 0.1264 - val_accuracy: 0.9641 - val_loss: 0.1199\n",
      "Epoch 3/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9541 - loss: 0.1189 - val_accuracy: 0.9503 - val_loss: 0.1314\n",
      "Epoch 4/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9550 - loss: 0.1121 - val_accuracy: 0.9677 - val_loss: 0.1218\n",
      "Epoch 5/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1041 - val_accuracy: 0.9631 - val_loss: 0.1179\n",
      "Epoch 6/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9567 - loss: 0.1048 - val_accuracy: 0.9613 - val_loss: 0.1248\n",
      "Epoch 7/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.0997 - val_accuracy: 0.9487 - val_loss: 0.1361\n",
      "Epoch 8/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.1001 - val_accuracy: 0.9497 - val_loss: 0.1234\n",
      "Epoch 9/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9590 - loss: 0.0989 - val_accuracy: 0.9536 - val_loss: 0.1190\n",
      "Epoch 10/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9599 - loss: 0.0997 - val_accuracy: 0.9550 - val_loss: 0.1179\n",
      "Epoch 11/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.0975 - val_accuracy: 0.9421 - val_loss: 0.1301\n",
      "Epoch 12/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.0938 - val_accuracy: 0.9415 - val_loss: 0.1237\n",
      "Epoch 13/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0929 - val_accuracy: 0.9607 - val_loss: 0.1045\n",
      "Epoch 14/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.0944 - val_accuracy: 0.9508 - val_loss: 0.1271\n",
      "Epoch 15/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0900 - val_accuracy: 0.9488 - val_loss: 0.1258\n",
      "Epoch 16/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.0930 - val_accuracy: 0.9434 - val_loss: 0.1312\n",
      "Epoch 17/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.0932 - val_accuracy: 0.9430 - val_loss: 0.1262\n",
      "Epoch 18/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.0913 - val_accuracy: 0.9568 - val_loss: 0.1167\n",
      "Epoch 19/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.0939 - val_accuracy: 0.9626 - val_loss: 0.1095\n",
      "Epoch 20/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.0919 - val_accuracy: 0.9484 - val_loss: 0.1234\n",
      "Epoch 21/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.0916 - val_accuracy: 0.9599 - val_loss: 0.1161\n",
      "Epoch 22/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.0913 - val_accuracy: 0.9617 - val_loss: 0.1107\n",
      "Epoch 23/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.0904 - val_accuracy: 0.9683 - val_loss: 0.1042\n",
      "Epoch 24/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.0892 - val_accuracy: 0.9572 - val_loss: 0.1144\n",
      "Epoch 25/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.0893 - val_accuracy: 0.9302 - val_loss: 0.1231\n",
      "Epoch 26/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.0898 - val_accuracy: 0.9676 - val_loss: 0.1083\n",
      "Epoch 27/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0889 - val_accuracy: 0.9649 - val_loss: 0.1142\n",
      "Epoch 28/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.0878 - val_accuracy: 0.9674 - val_loss: 0.1007\n",
      "Epoch 29/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0873 - val_accuracy: 0.9401 - val_loss: 0.1243\n",
      "Epoch 30/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.0866 - val_accuracy: 0.9244 - val_loss: 0.1310\n",
      "Epoch 31/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9636 - loss: 0.0863 - val_accuracy: 0.9476 - val_loss: 0.1181\n",
      "Epoch 32/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.0868 - val_accuracy: 0.9665 - val_loss: 0.1154\n",
      "Epoch 33/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.0867 - val_accuracy: 0.9419 - val_loss: 0.1217\n",
      "Epoch 34/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.0884 - val_accuracy: 0.9373 - val_loss: 0.1260\n",
      "Epoch 35/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9648 - loss: 0.0846 - val_accuracy: 0.9725 - val_loss: 0.0986\n",
      "Epoch 36/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.0877 - val_accuracy: 0.9244 - val_loss: 0.1266\n",
      "Epoch 37/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0873 - val_accuracy: 0.9385 - val_loss: 0.1211\n",
      "Epoch 38/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0867 - val_accuracy: 0.9559 - val_loss: 0.1172\n",
      "Epoch 39/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.0890 - val_accuracy: 0.9322 - val_loss: 0.1260\n",
      "Epoch 40/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.0859 - val_accuracy: 0.9232 - val_loss: 0.1302\n",
      "Epoch 41/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9661 - loss: 0.0835 - val_accuracy: 0.9388 - val_loss: 0.1214\n",
      "Epoch 42/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0853 - val_accuracy: 0.9575 - val_loss: 0.1084\n",
      "Epoch 43/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.0854 - val_accuracy: 0.9446 - val_loss: 0.1247\n",
      "Epoch 44/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.0824 - val_accuracy: 0.9428 - val_loss: 0.1234\n",
      "Epoch 45/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.0847 - val_accuracy: 0.9376 - val_loss: 0.1139\n",
      "Epoch 46/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0831 - val_accuracy: 0.9302 - val_loss: 0.1231\n",
      "Epoch 47/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.0844 - val_accuracy: 0.9361 - val_loss: 0.1250\n",
      "Epoch 48/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9636 - loss: 0.0853 - val_accuracy: 0.9265 - val_loss: 0.1329\n",
      "Epoch 49/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.0827 - val_accuracy: 0.9425 - val_loss: 0.1178\n",
      "Epoch 50/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.0840 - val_accuracy: 0.9311 - val_loss: 0.1229\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Metrics for fold 8:\n",
      "accuracy: 0.9700\n",
      "precision: 0.9645\n",
      "recall: 0.9772\n",
      "f1: 0.9708\n",
      "mcc: 0.9401\n",
      "auc: 0.9961\n",
      "fpr: 0.0375\n",
      "specificity: 0.9625\n",
      "lr_plus: 26.0833\n",
      "lr_minus: 0.0237\n",
      "\n",
      "Fold 9/10\n",
      "==================================================\n",
      "Epoch 1/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9204 - loss: 0.2019 - val_accuracy: 0.9230 - val_loss: 0.1620\n",
      "Epoch 2/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9493 - loss: 0.1226 - val_accuracy: 0.9269 - val_loss: 0.1509\n",
      "Epoch 3/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1137 - val_accuracy: 0.9308 - val_loss: 0.1478\n",
      "Epoch 4/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9549 - loss: 0.1089 - val_accuracy: 0.9467 - val_loss: 0.1387\n",
      "Epoch 5/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9594 - loss: 0.1042 - val_accuracy: 0.9391 - val_loss: 0.1461\n",
      "Epoch 6/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.1018 - val_accuracy: 0.9409 - val_loss: 0.1443\n",
      "Epoch 7/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.1019 - val_accuracy: 0.9470 - val_loss: 0.1339\n",
      "Epoch 8/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.0979 - val_accuracy: 0.9322 - val_loss: 0.1408\n",
      "Epoch 9/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.0967 - val_accuracy: 0.9337 - val_loss: 0.1407\n",
      "Epoch 10/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.0948 - val_accuracy: 0.9347 - val_loss: 0.1341\n",
      "Epoch 11/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.0926 - val_accuracy: 0.9350 - val_loss: 0.1370\n",
      "Epoch 12/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.0930 - val_accuracy: 0.9341 - val_loss: 0.1388\n",
      "Epoch 13/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.0936 - val_accuracy: 0.9361 - val_loss: 0.1310\n",
      "Epoch 14/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.0918 - val_accuracy: 0.9326 - val_loss: 0.1358\n",
      "Epoch 15/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.0900 - val_accuracy: 0.9341 - val_loss: 0.1301\n",
      "Epoch 16/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.0914 - val_accuracy: 0.9304 - val_loss: 0.1250\n",
      "Epoch 17/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.0898 - val_accuracy: 0.9359 - val_loss: 0.1303\n",
      "Epoch 18/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.0906 - val_accuracy: 0.9371 - val_loss: 0.1329\n",
      "Epoch 19/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.0870 - val_accuracy: 0.9308 - val_loss: 0.1313\n",
      "Epoch 20/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.0886 - val_accuracy: 0.9595 - val_loss: 0.1155\n",
      "Epoch 21/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9636 - loss: 0.0874 - val_accuracy: 0.9371 - val_loss: 0.1298\n",
      "Epoch 22/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0867 - val_accuracy: 0.9233 - val_loss: 0.1265\n",
      "Epoch 23/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.0868 - val_accuracy: 0.9298 - val_loss: 0.1278\n",
      "Epoch 24/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0880 - val_accuracy: 0.9286 - val_loss: 0.1307\n",
      "Epoch 25/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.0856 - val_accuracy: 0.9379 - val_loss: 0.1261\n",
      "Epoch 26/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.0864 - val_accuracy: 0.9295 - val_loss: 0.1280\n",
      "Epoch 27/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.0876 - val_accuracy: 0.9329 - val_loss: 0.1315\n",
      "Epoch 28/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.0867 - val_accuracy: 0.9371 - val_loss: 0.1262\n",
      "Epoch 29/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9662 - loss: 0.0852 - val_accuracy: 0.9308 - val_loss: 0.1322\n",
      "Epoch 30/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.0825 - val_accuracy: 0.9221 - val_loss: 0.1332\n",
      "Epoch 31/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.0841 - val_accuracy: 0.9374 - val_loss: 0.1301\n",
      "Epoch 32/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9657 - loss: 0.0833 - val_accuracy: 0.9421 - val_loss: 0.1267\n",
      "Epoch 33/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.0844 - val_accuracy: 0.9362 - val_loss: 0.1296\n",
      "Epoch 34/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.0842 - val_accuracy: 0.9425 - val_loss: 0.1296\n",
      "Epoch 35/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.0817 - val_accuracy: 0.9197 - val_loss: 0.1350\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Metrics for fold 9:\n",
      "accuracy: 0.9633\n",
      "precision: 0.9662\n",
      "recall: 0.9599\n",
      "f1: 0.9630\n",
      "mcc: 0.9265\n",
      "auc: 0.9954\n",
      "fpr: 0.0334\n",
      "specificity: 0.9666\n",
      "lr_plus: 28.7651\n",
      "lr_minus: 0.0415\n",
      "\n",
      "Fold 10/10\n",
      "==================================================\n",
      "Epoch 1/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9210 - loss: 0.2047 - val_accuracy: 0.9353 - val_loss: 0.1605\n",
      "Epoch 2/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9474 - loss: 0.1336 - val_accuracy: 0.9392 - val_loss: 0.1445\n",
      "Epoch 3/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 0.1188 - val_accuracy: 0.9325 - val_loss: 0.1462\n",
      "Epoch 4/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9545 - loss: 0.1153 - val_accuracy: 0.9379 - val_loss: 0.1386\n",
      "Epoch 5/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.1114 - val_accuracy: 0.9308 - val_loss: 0.1534\n",
      "Epoch 6/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9585 - loss: 0.1057 - val_accuracy: 0.9424 - val_loss: 0.1245\n",
      "Epoch 7/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.1026 - val_accuracy: 0.9313 - val_loss: 0.1403\n",
      "Epoch 8/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1038 - val_accuracy: 0.9563 - val_loss: 0.1259\n",
      "Epoch 9/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1034 - val_accuracy: 0.9479 - val_loss: 0.1291\n",
      "Epoch 10/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.0972 - val_accuracy: 0.9374 - val_loss: 0.1341\n",
      "Epoch 11/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.0965 - val_accuracy: 0.9332 - val_loss: 0.1283\n",
      "Epoch 12/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.0947 - val_accuracy: 0.9490 - val_loss: 0.1327\n",
      "Epoch 13/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.0954 - val_accuracy: 0.9406 - val_loss: 0.1277\n",
      "Epoch 14/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.0983 - val_accuracy: 0.9389 - val_loss: 0.1185\n",
      "Epoch 15/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.0949 - val_accuracy: 0.9442 - val_loss: 0.1229\n",
      "Epoch 16/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.0923 - val_accuracy: 0.9374 - val_loss: 0.1269\n",
      "Epoch 17/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.0916 - val_accuracy: 0.9442 - val_loss: 0.1265\n",
      "Epoch 18/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.0911 - val_accuracy: 0.9385 - val_loss: 0.1274\n",
      "Epoch 19/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.0923 - val_accuracy: 0.9463 - val_loss: 0.1339\n",
      "Epoch 20/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.0918 - val_accuracy: 0.9463 - val_loss: 0.1228\n",
      "Epoch 21/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.0884 - val_accuracy: 0.9442 - val_loss: 0.1218\n",
      "Epoch 22/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0896 - val_accuracy: 0.9442 - val_loss: 0.1303\n",
      "Epoch 23/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9631 - loss: 0.0893 - val_accuracy: 0.9463 - val_loss: 0.1165\n",
      "Epoch 24/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.0888 - val_accuracy: 0.9463 - val_loss: 0.1189\n",
      "Epoch 25/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0873 - val_accuracy: 0.9347 - val_loss: 0.1277\n",
      "Epoch 26/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.0878 - val_accuracy: 0.9442 - val_loss: 0.1216\n",
      "Epoch 27/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9651 - loss: 0.0877 - val_accuracy: 0.9385 - val_loss: 0.1238\n",
      "Epoch 28/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.0886 - val_accuracy: 0.9332 - val_loss: 0.1271\n",
      "Epoch 29/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.0889 - val_accuracy: 0.9404 - val_loss: 0.1276\n",
      "Epoch 30/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9631 - loss: 0.0881 - val_accuracy: 0.9463 - val_loss: 0.1204\n",
      "Epoch 31/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.0864 - val_accuracy: 0.9442 - val_loss: 0.1178\n",
      "Epoch 32/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0882 - val_accuracy: 0.9448 - val_loss: 0.1210\n",
      "Epoch 33/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0863 - val_accuracy: 0.9391 - val_loss: 0.1205\n",
      "Epoch 34/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.0856 - val_accuracy: 0.9442 - val_loss: 0.1231\n",
      "Epoch 35/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0840 - val_accuracy: 0.9385 - val_loss: 0.1224\n",
      "Epoch 36/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.0874 - val_accuracy: 0.9391 - val_loss: 0.1232\n",
      "Epoch 37/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.0856 - val_accuracy: 0.9353 - val_loss: 0.1292\n",
      "Epoch 38/200\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.0847 - val_accuracy: 0.9412 - val_loss: 0.1245\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Metrics for fold 10:\n",
      "accuracy: 0.9627\n",
      "precision: 0.9810\n",
      "recall: 0.9419\n",
      "f1: 0.9611\n",
      "mcc: 0.9260\n",
      "auc: 0.9963\n",
      "fpr: 0.0174\n",
      "specificity: 0.9826\n",
      "lr_plus: 54.0608\n",
      "lr_minus: 0.0591\n",
      "\n",
      "Training final model on entire dataset...\n",
      "Epoch 1/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9204 - loss: 0.2075 - val_accuracy: 0.9051 - val_loss: 0.1843\n",
      "Epoch 2/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9500 - loss: 0.1259 - val_accuracy: 0.9086 - val_loss: 0.1895\n",
      "Epoch 3/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9532 - loss: 0.1146 - val_accuracy: 0.9264 - val_loss: 0.1873\n",
      "Epoch 4/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9543 - loss: 0.1128 - val_accuracy: 0.9337 - val_loss: 0.1667\n",
      "Epoch 5/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.1058 - val_accuracy: 0.9415 - val_loss: 0.1580\n",
      "Epoch 6/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.1012 - val_accuracy: 0.9206 - val_loss: 0.1806\n",
      "Epoch 7/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1027 - val_accuracy: 0.9071 - val_loss: 0.1773\n",
      "Epoch 8/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1010 - val_accuracy: 0.9502 - val_loss: 0.1343\n",
      "Epoch 9/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.0973 - val_accuracy: 0.9326 - val_loss: 0.1666\n",
      "Epoch 10/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.0986 - val_accuracy: 0.9422 - val_loss: 0.1482\n",
      "Epoch 11/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.0938 - val_accuracy: 0.9373 - val_loss: 0.1426\n",
      "Epoch 12/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.0950 - val_accuracy: 0.9373 - val_loss: 0.1422\n",
      "Epoch 13/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.0926 - val_accuracy: 0.9373 - val_loss: 0.1357\n",
      "Epoch 14/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.0936 - val_accuracy: 0.9318 - val_loss: 0.1532\n",
      "Epoch 15/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.0918 - val_accuracy: 0.9369 - val_loss: 0.1286\n",
      "Epoch 16/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.0947 - val_accuracy: 0.9180 - val_loss: 0.1448\n",
      "Epoch 17/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.0938 - val_accuracy: 0.9280 - val_loss: 0.1322\n",
      "Epoch 18/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.0926 - val_accuracy: 0.9367 - val_loss: 0.1327\n",
      "Epoch 19/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.0896 - val_accuracy: 0.9243 - val_loss: 0.1410\n",
      "Epoch 20/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.0915 - val_accuracy: 0.9247 - val_loss: 0.1388\n",
      "Epoch 21/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.0890 - val_accuracy: 0.9299 - val_loss: 0.1402\n",
      "Epoch 22/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.0914 - val_accuracy: 0.9355 - val_loss: 0.1306\n",
      "Epoch 23/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0897 - val_accuracy: 0.9299 - val_loss: 0.1324\n",
      "Epoch 24/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.0898 - val_accuracy: 0.9355 - val_loss: 0.1354\n",
      "Epoch 25/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.0906 - val_accuracy: 0.9364 - val_loss: 0.1284\n",
      "Epoch 26/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.0913 - val_accuracy: 0.9414 - val_loss: 0.1283\n",
      "Epoch 27/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.0870 - val_accuracy: 0.9240 - val_loss: 0.1366\n",
      "Epoch 28/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0893 - val_accuracy: 0.9388 - val_loss: 0.1205\n",
      "Epoch 29/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.0904 - val_accuracy: 0.9209 - val_loss: 0.1318\n",
      "Epoch 30/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.0895 - val_accuracy: 0.9403 - val_loss: 0.1357\n",
      "Epoch 31/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.0853 - val_accuracy: 0.9351 - val_loss: 0.1305\n",
      "Epoch 32/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.0872 - val_accuracy: 0.9299 - val_loss: 0.1242\n",
      "Epoch 33/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.0861 - val_accuracy: 0.9247 - val_loss: 0.1351\n",
      "Epoch 34/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.0879 - val_accuracy: 0.9367 - val_loss: 0.1207\n",
      "Epoch 35/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0871 - val_accuracy: 0.9247 - val_loss: 0.1337\n",
      "Epoch 36/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.0911 - val_accuracy: 0.9247 - val_loss: 0.1274\n",
      "Epoch 37/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.0845 - val_accuracy: 0.9326 - val_loss: 0.1284\n",
      "Epoch 38/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.0862 - val_accuracy: 0.9367 - val_loss: 0.1269\n",
      "Epoch 39/200\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9660 - loss: 0.0852 - val_accuracy: 0.9247 - val_loss: 0.1376\n",
      "Epoch 40/200\n",
      "\u001b[1m620/926\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.0906"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, matthews_corrcoef\n",
    ")\n",
    "from keras.models import Sequential, save_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load dataset\n",
    "def load_data(file_path):\n",
    "    print(\"Loading dataset...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Use only the specified features\n",
    "    selected_features = [\n",
    "        'Sore throat', 'Breathing Problem', 'Attended Large Gathering', \n",
    "        'Family working in Public Exposed Places', 'Heart Disease', \n",
    "        'Hyper Tension', 'Chronic Lung Disease', 'Fever', \n",
    "        'Dry Cough', 'Running Nose'\n",
    "    ]\n",
    "    \n",
    "    # Check if all selected features are in the dataframe\n",
    "    missing_features = [f for f in selected_features if f not in df.columns]\n",
    "    if missing_features:\n",
    "        raise ValueError(f\"The following features are missing from the dataset: {missing_features}\")\n",
    "    \n",
    "    # For CNN, reshape to have a proper 2D structure (2x5 feature grid)\n",
    "    X = df[selected_features].values.reshape(-1, 2, 5, 1)\n",
    "    y = df['COVID-19'].values\n",
    "    \n",
    "    print(f\"Dataset loaded: {X.shape[0]} samples, features shaped as {X.shape[1]}x{X.shape[2]}\")\n",
    "    print(f\"Class distribution: {dict(pd.Series(y).value_counts())}\")\n",
    "    print(f\"Selected features: {', '.join(selected_features)}\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Build the CNN model with appropriate parameters\n",
    "def create_cnn_model():\n",
    "    model = Sequential([\n",
    "        # First Convolutional Layer\n",
    "        Conv2D(32, kernel_size=(2, 2), activation='relu', padding='same', input_shape=(2, 5, 1)),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        # Second Convolutional Layer\n",
    "        Conv2D(64, kernel_size=(2, 2), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(1, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Flatten the output and feed to dense layer\n",
    "        Flatten(),\n",
    "        \n",
    "        # Dense layers\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        # Output layer\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Calculate additional metrics\n",
    "def calculate_metrics(y_true, y_pred, y_pred_proba):\n",
    "    # Basic metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    \n",
    "    # AUC-ROC\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    except:\n",
    "        roc_auc = 0.5\n",
    "    \n",
    "    # Confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    # False Positive Rate\n",
    "    fpr = fp / (fp + tn)\n",
    "    \n",
    "    # Likelihood Ratios\n",
    "    sensitivity = recall\n",
    "    specificity = tn / (tn + fp)\n",
    "    lr_plus = sensitivity / (1 - specificity) if (1 - specificity) > 0 else float('inf')\n",
    "    lr_minus = (1 - sensitivity) / specificity if specificity > 0 else float('inf')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'mcc': mcc,\n",
    "        'auc': roc_auc,\n",
    "        'fpr': fpr,\n",
    "        'specificity': specificity,\n",
    "        'lr_plus': lr_plus,\n",
    "        'lr_minus': lr_minus\n",
    "    }\n",
    "\n",
    "# Create output directory\n",
    "def create_output_directory():\n",
    "    # Create a local directory for outputs\n",
    "    output_dir = \"covid_cnn_results\"\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Created output directory: {output_dir}\")\n",
    "    else:\n",
    "        print(f\"Output directory already exists: {output_dir}\")\n",
    "    \n",
    "    return output_dir\n",
    "\n",
    "def main():\n",
    "    # Create output directory\n",
    "    output_dir = create_output_directory()\n",
    "    print(f\"Results will be saved in: {output_dir}\")\n",
    "    \n",
    "    # Load data - using your local path\n",
    "    file_path = \"OneDrive/Desktop/Research_Capstone_Project/preprocessed_covid500_final.csv\"\n",
    "    X, y = load_data(file_path)\n",
    "    \n",
    "    # 10-fold cross-validation\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Store results\n",
    "    all_metrics = []\n",
    "    all_fold_histories = []\n",
    "    \n",
    "    # For each fold\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"\\nFold {fold+1}/10\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Create model\n",
    "        model = create_cnn_model()\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,\n",
    "            verbose=1,\n",
    "            mode='min',\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=200,\n",
    "            batch_size=32,  # Smaller batch size for CNN\n",
    "            validation_split=0.2,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        all_fold_histories.append(history.history)\n",
    "        \n",
    "        # Generate predictions\n",
    "        y_pred_proba = model.predict(X_test).flatten()\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        fold_metrics = calculate_metrics(y_test, y_pred, y_pred_proba)\n",
    "        all_metrics.append(fold_metrics)\n",
    "        \n",
    "        # Print metrics for this fold\n",
    "        print(f\"\\nMetrics for fold {fold+1}:\")\n",
    "        for metric, value in fold_metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # Train final model on the entire dataset\n",
    "    print(\"\\nTraining final model on entire dataset...\")\n",
    "    final_model = create_cnn_model()\n",
    "    \n",
    "    # Train the final model\n",
    "    final_early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        verbose=1,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    final_history = final_model.fit(\n",
    "        X, y,\n",
    "        epochs=200,\n",
    "        batch_size=32,\n",
    "        verbose=1,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[final_early_stopping]\n",
    "    )\n",
    "    \n",
    "    # Save only the final model\n",
    "    model_path = os.path.join(output_dir, \"final_model.h5\")\n",
    "    save_model(final_model, model_path)\n",
    "    print(f\"Final model saved to {model_path}\")\n",
    "    \n",
    "    # Calculate and print average metrics\n",
    "    metrics_df = pd.DataFrame(all_metrics)\n",
    "    avg_metrics = metrics_df.mean()\n",
    "    std_metrics = metrics_df.std()\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"\\nModel Architecture:\")\n",
    "    final_model.summary()\n",
    "    \n",
    "    print(\"\\nCNN Parameters Used:\")\n",
    "    print(\"- First Conv layer: 32 filters, (2,2) kernel\")\n",
    "    print(\"- Second Conv layer: 64 filters, (2,2) kernel\")\n",
    "    print(\"- MaxPooling: (1,2) pool size\")\n",
    "    print(\"- Dropout rates: 0.25 (conv layers), 0.5 (dense layer)\")\n",
    "    print(\"- Batch Normalization: Applied after each layer\")\n",
    "    print(\"- Learning rate: 0.001\")\n",
    "    print(\"- Batch size: 32\")\n",
    "    print(\"- Early stopping patience: 15 epochs\")\n",
    "    print(\"- Max epochs: 200\")\n",
    "    \n",
    "    print(\"\\nAverage metrics across all folds:\")\n",
    "    for metric in metrics_df.columns:\n",
    "        print(f\"{metric}: {avg_metrics[metric]:.4f} ± {std_metrics[metric]:.4f}\")\n",
    "    \n",
    "    # Save metrics to CSV\n",
    "    metrics_df.to_csv(os.path.join(output_dir, \"all_fold_metrics.csv\"), index=False)\n",
    "    \n",
    "    # Save summary metrics\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Metric': metrics_df.columns,\n",
    "        'Mean': avg_metrics.values,\n",
    "        'Std': std_metrics.values\n",
    "    })\n",
    "    summary_df.to_csv(os.path.join(output_dir, \"summary_metrics.csv\"), index=False)\n",
    "    \n",
    "    # Plot training history for final model\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(final_history.history['loss'], label='Training Loss')\n",
    "    plt.plot(final_history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss Curves')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(final_history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(final_history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy Curves')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"training_history.png\"))\n",
    "    \n",
    "    # Create a fold comparison plot\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot metrics across folds\n",
    "    metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
    "    for i, metric in enumerate(metrics_to_plot):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        plt.bar(range(1, 11), metrics_df[metric], color='skyblue')\n",
    "        plt.axhline(avg_metrics[metric], color='red', linestyle='--', label=f'Mean: {avg_metrics[metric]:.4f}')\n",
    "        plt.title(f'{metric.capitalize()} by Fold')\n",
    "        plt.xlabel('Fold')\n",
    "        plt.ylabel(metric.capitalize())\n",
    "        plt.xticks(range(1, 11))\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"fold_comparison.png\"))\n",
    "    \n",
    "    print(f\"\\nAll results and model saved to: {output_dir}\")\n",
    "    print(f\"\\nFull path to output directory: {os.path.abspath(output_dir)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed6401d-233a-414b-9919-2ae1eabb6cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
