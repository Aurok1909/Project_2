{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab13bbe7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-07T10:04:43.665379Z",
     "iopub.status.busy": "2025-03-07T10:04:43.665129Z",
     "iopub.status.idle": "2025-03-07T10:04:48.089536Z",
     "shell.execute_reply": "2025-03-07T10:04:48.088511Z"
    },
    "papermill": {
     "duration": 4.429259,
     "end_time": "2025-03-07T10:04:48.091614",
     "exception": false,
     "start_time": "2025-03-07T10:04:43.662355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\r\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\r\n",
      "Requirement already satisfied: boruta in /usr/local/lib/python3.10/dist-packages (0.4.3)\r\n",
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\r\n",
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.5.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\r\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\r\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\r\n",
      "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\r\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.19.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas tensorflow scikit-learn boruta xgboost lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63bbb899",
   "metadata": {
    "papermill": {
     "duration": 1520.213921,
     "end_time": "2025-03-07T10:30:08.308284",
     "exception": false,
     "start_time": "2025-03-07T10:04:48.094363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded: 37028 samples, 20 features\n",
      "Class distribution: {1: 18514, 0: 18514}\n",
      "Initializing feature selection techniques...\n",
      "\n",
      "==================================================\n",
      "Processing 1. Chi-Square\n",
      "==================================================\n",
      "Selecting features using 1. Chi-Square...\n",
      "Top 10 features selected by 1. Chi-Square:\n",
      "1. Breathing Problem: 10855.6785\n",
      "2. Sore throat: 13892.5526\n",
      "3. Chronic Lung Disease: 3.2782\n",
      "4. Heart Disease: 4165.5609\n",
      "5. Hyper Tension: 3684.8322\n",
      "6. Attended Large Gathering: 9772.7294\n",
      "7. Visited Public Exposed Places: nan\n",
      "8. Family working in Public Exposed Places: 8644.1025\n",
      "9. Wearing Masks: nan\n",
      "10. Sanitization from Market: nan\n",
      "\n",
      "Training ANN with features selected by 1. Chi-Square\n",
      "Training fold 1/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Results for 1. Chi-Square:\n",
      "Average accuracy: 0.9574 ± 0.0045\n",
      "Average precision: 0.9792 ± 0.0170\n",
      "Average recall: 0.9353 ± 0.0204\n",
      "Average f1: 0.9564 ± 0.0048\n",
      "Average auc: 0.9943 ± 0.0013\n",
      "\n",
      "==================================================\n",
      "Processing 2. Mutual Information\n",
      "==================================================\n",
      "Selecting features using 2. Mutual Information...\n",
      "Top 10 features selected by 2. Mutual Information:\n",
      "1. Breathing Problem: 0.3342\n",
      "2. Fever: 0.0019\n",
      "3. Sore throat: 0.4491\n",
      "4. Chronic Lung Disease: 0.0020\n",
      "5. Headache: 0.0046\n",
      "6. Heart Disease: 0.0910\n",
      "7. Hyper Tension: 0.0835\n",
      "8. Gastrointestinal : 0.0056\n",
      "9. Attended Large Gathering: 0.2515\n",
      "10. Family working in Public Exposed Places: 0.2349\n",
      "\n",
      "Training ANN with features selected by 2. Mutual Information\n",
      "Training fold 1/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "Results for 2. Mutual Information:\n",
      "Average accuracy: 0.9539 ± 0.0052\n",
      "Average precision: 0.9807 ± 0.0047\n",
      "Average recall: 0.9261 ± 0.0081\n",
      "Average f1: 0.9526 ± 0.0052\n",
      "Average auc: 0.9939 ± 0.0012\n",
      "\n",
      "==================================================\n",
      "Processing 3. Recursive Feature Elimination\n",
      "==================================================\n",
      "Selecting features using 3. Recursive Feature Elimination...\n",
      "Top 10 features selected by 3. Recursive Feature Elimination:\n",
      "1. Breathing Problem: 1.0000\n",
      "2. Sore throat: 1.0000\n",
      "3. Chronic Lung Disease: 1.0000\n",
      "4. Heart Disease: 1.0000\n",
      "5. Hyper Tension: 1.0000\n",
      "6. Abroad travel: 1.0000\n",
      "7. Contact with COVID Patient: 1.0000\n",
      "8. Attended Large Gathering: 1.0000\n",
      "9. Visited Public Exposed Places: 1.0000\n",
      "10. Family working in Public Exposed Places: 1.0000\n",
      "\n",
      "Training ANN with features selected by 3. Recursive Feature Elimination\n",
      "Training fold 1/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "Results for 3. Recursive Feature Elimination:\n",
      "Average accuracy: 0.9575 ± 0.0031\n",
      "Average precision: 0.9785 ± 0.0139\n",
      "Average recall: 0.9359 ± 0.0117\n",
      "Average f1: 0.9566 ± 0.0029\n",
      "Average auc: 0.9946 ± 0.0010\n",
      "\n",
      "==================================================\n",
      "Processing 4. Lasso\n",
      "==================================================\n",
      "Selecting features using 4. Lasso...\n",
      "Top 10 features selected by 4. Lasso:\n",
      "1. Breathing Problem: 1.0000\n",
      "2. Sore throat: 1.0000\n",
      "3. Hyper Tension: 1.0000\n",
      "4. Attended Large Gathering: 1.0000\n",
      "5. Family working in Public Exposed Places: 1.0000\n",
      "6. Fever: 0.0000\n",
      "7. Dry Cough: 0.0000\n",
      "8. Running Nose: 0.0000\n",
      "9. Asthma: 0.0000\n",
      "10. Chronic Lung Disease: 0.0000\n",
      "\n",
      "Training ANN with features selected by 4. Lasso\n",
      "Training fold 1/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "Results for 4. Lasso:\n",
      "Average accuracy: 0.9522 ± 0.0034\n",
      "Average precision: 0.9637 ± 0.0049\n",
      "Average recall: 0.9399 ± 0.0116\n",
      "Average f1: 0.9515 ± 0.0038\n",
      "Average auc: 0.9922 ± 0.0009\n",
      "\n",
      "==================================================\n",
      "Processing 5. Random Forest Importance\n",
      "==================================================\n",
      "Selecting features using 5. Random Forest Importance...\n",
      "Top 10 features selected by 5. Random Forest Importance:\n",
      "1. Breathing Problem: 0.2089\n",
      "2. Sore throat: 0.3411\n",
      "3. Heart Disease: 0.0591\n",
      "4. Attended Large Gathering: 0.1686\n",
      "5. Family working in Public Exposed Places: 0.1519\n",
      "6. Fever: 0.0000\n",
      "7. Dry Cough: 0.0000\n",
      "8. Running Nose: 0.0000\n",
      "9. Asthma: 0.0000\n",
      "10. Chronic Lung Disease: 0.0000\n",
      "\n",
      "Training ANN with features selected by 5. Random Forest Importance\n",
      "Training fold 1/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "Results for 5. Random Forest Importance:\n",
      "Average accuracy: 0.9526 ± 0.0036\n",
      "Average precision: 0.9675 ± 0.0090\n",
      "Average recall: 0.9369 ± 0.0157\n",
      "Average f1: 0.9518 ± 0.0044\n",
      "Average auc: 0.9921 ± 0.0006\n",
      "\n",
      "==================================================\n",
      "Processing 6. Boruta\n",
      "==================================================\n",
      "Selecting features using 6. Boruta...\n",
      "Top 10 features selected by 6. Boruta:\n",
      "1. Breathing Problem: 1.0000\n",
      "2. Sore throat: 1.0000\n",
      "3. Chronic Lung Disease: 1.0000\n",
      "4. Heart Disease: 1.0000\n",
      "5. Hyper Tension: 1.0000\n",
      "6. Attended Large Gathering: 1.0000\n",
      "7. Family working in Public Exposed Places: 1.0000\n",
      "8. Fever: 0.5000\n",
      "9. Dry Cough: 0.5000\n",
      "10. Running Nose: 0.5000\n",
      "\n",
      "Training ANN with features selected by 6. Boruta\n",
      "Training fold 1/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Results for 6. Boruta:\n",
      "Average accuracy: 0.9512 ± 0.0037\n",
      "Average precision: 0.9791 ± 0.0096\n",
      "Average recall: 0.9223 ± 0.0086\n",
      "Average f1: 0.9498 ± 0.0035\n",
      "Average auc: 0.9936 ± 0.0010\n",
      "\n",
      "==================================================\n",
      "Processing 7. Correlation-based\n",
      "==================================================\n",
      "Selecting features using 7. Correlation-based...\n",
      "Top 10 features selected by 7. Correlation-based:\n",
      "1. Breathing Problem: 0.7606\n",
      "2. Fever: nan\n",
      "3. Dry Cough: nan\n",
      "4. Sore throat: 0.8628\n",
      "5. Running Nose: nan\n",
      "6. Asthma: nan\n",
      "7. Chronic Lung Disease: 0.0115\n",
      "8. Headache: nan\n",
      "9. Heart Disease: 0.4180\n",
      "10. Diabetes: nan\n",
      "\n",
      "Training ANN with features selected by 7. Correlation-based\n",
      "Training fold 1/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "Results for 7. Correlation-based:\n",
      "Average accuracy: 0.9382 ± 0.0015\n",
      "Average precision: 0.9435 ± 0.0048\n",
      "Average recall: 0.9323 ± 0.0078\n",
      "Average f1: 0.9378 ± 0.0020\n",
      "Average auc: 0.9743 ± 0.0011\n",
      "\n",
      "==================================================\n",
      "Processing 8. Sequential Forward Selection\n",
      "==================================================\n",
      "Selecting features using 8. Sequential Forward Selection...\n",
      "Top 10 features selected by 8. Sequential Forward Selection:\n",
      "1. Breathing Problem: 1.0000\n",
      "2. Fever: 1.0000\n",
      "3. Dry Cough: 1.0000\n",
      "4. Sore throat: 1.0000\n",
      "5. Running Nose: 1.0000\n",
      "6. Asthma: 1.0000\n",
      "7. Headache: 1.0000\n",
      "8. Diabetes: 1.0000\n",
      "9. Fatigue : 1.0000\n",
      "10. Attended Large Gathering: 1.0000\n",
      "\n",
      "Training ANN with features selected by 8. Sequential Forward Selection\n",
      "Training fold 1/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Results for 8. Sequential Forward Selection:\n",
      "Average accuracy: 0.9297 ± 0.0064\n",
      "Average precision: 0.9606 ± 0.0162\n",
      "Average recall: 0.8970 ± 0.0284\n",
      "Average f1: 0.9272 ± 0.0076\n",
      "Average auc: 0.9838 ± 0.0013\n",
      "\n",
      "==================================================\n",
      "Processing 9. XGBoost Importance\n",
      "==================================================\n",
      "Selecting features using 9. XGBoost Importance...\n",
      "Top 10 features selected by 9. XGBoost Importance:\n",
      "1. Sore throat: 0.8620\n",
      "2. Breathing Problem: 0.0000\n",
      "3. Fever: 0.0000\n",
      "4. Dry Cough: 0.0000\n",
      "5. Running Nose: 0.0000\n",
      "6. Asthma: 0.0000\n",
      "7. Chronic Lung Disease: 0.0000\n",
      "8. Headache: 0.0000\n",
      "9. Heart Disease: 0.0000\n",
      "10. Diabetes: 0.0000\n",
      "\n",
      "Training ANN with features selected by 9. XGBoost Importance\n",
      "Training fold 1/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Results for 9. XGBoost Importance:\n",
      "Average accuracy: 0.9385 ± 0.0022\n",
      "Average precision: 0.9496 ± 0.0035\n",
      "Average recall: 0.9261 ± 0.0029\n",
      "Average f1: 0.9377 ± 0.0022\n",
      "Average auc: 0.9745 ± 0.0012\n",
      "\n",
      "==================================================\n",
      "Processing 10. LightGBM Importance\n",
      "==================================================\n",
      "Selecting features using 10. LightGBM Importance...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 18514, number of negative: 18514\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 14\n",
      "[LightGBM] [Info] Number of data points in the train set: 37028, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Top 10 features selected by 10. LightGBM Importance:\n",
      "1. Breathing Problem: 357.0000\n",
      "2. Sore throat: 232.0000\n",
      "3. Chronic Lung Disease: 565.0000\n",
      "4. Heart Disease: 614.0000\n",
      "5. Hyper Tension: 557.0000\n",
      "6. Attended Large Gathering: 245.0000\n",
      "7. Family working in Public Exposed Places: 430.0000\n",
      "8. Fever: 0.0000\n",
      "9. Dry Cough: 0.0000\n",
      "10. Running Nose: 0.0000\n",
      "\n",
      "Training ANN with features selected by 10. LightGBM Importance\n",
      "Training fold 1/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 2/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Training fold 3/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 4/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training fold 5/5...\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Results for 10. LightGBM Importance:\n",
      "Average accuracy: 0.9531 ± 0.0024\n",
      "Average precision: 0.9752 ± 0.0109\n",
      "Average recall: 0.9302 ± 0.0155\n",
      "Average f1: 0.9520 ± 0.0034\n",
      "Average auc: 0.9940 ± 0.0007\n",
      "Comparison chart saved as 'feature_selection_comparison_ANN.png'\n",
      "Heatmap saved as 'feature_selection_heatmap_ANN.png'\n",
      "\n",
      "==================================================\n",
      "FINAL SUMMARY\n",
      "==================================================\n",
      "\n",
      "Techniques ranked by accuracy:\n",
      "1. 3. Recursive Feature Elimination: 0.9575\n",
      "2. 1. Chi-Square: 0.9574\n",
      "3. 2. Mutual Information: 0.9539\n",
      "4. 10. LightGBM Importance: 0.9531\n",
      "5. 5. Random Forest Importance: 0.9526\n",
      "6. 4. Lasso: 0.9522\n",
      "7. 6. Boruta: 0.9512\n",
      "8. 9. XGBoost Importance: 0.9385\n",
      "9. 7. Correlation-based: 0.9382\n",
      "10. 8. Sequential Forward Selection: 0.9297\n",
      "\n",
      "Best performing technique: 3. Recursive Feature Elimination\n",
      "Top 10 features selected by 3. Recursive Feature Elimination:\n",
      "1. Breathing Problem\n",
      "2. Sore throat\n",
      "3. Chronic Lung Disease\n",
      "4. Heart Disease\n",
      "5. Hyper Tension\n",
      "6. Abroad travel\n",
      "7. Contact with COVID Patient\n",
      "8. Attended Large Gathering\n",
      "9. Visited Public Exposed Places\n",
      "10. Family working in Public Exposed Places\n"
     ]
    }
   ],
   "source": [
    "# Dependencies installation (run these commands in your terminal)\n",
    "# pip install pandas numpy scikit-learn tensorflow keras matplotlib seaborn xgboost lightgbm boruta\n",
    "# pip install imbalanced-learn statsmodels scipy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Feature Selection Libraries\n",
    "from sklearn.feature_selection import (\n",
    "    VarianceThreshold, chi2, f_classif, mutual_info_classif, \n",
    "    SelectKBest, RFE, SelectFromModel\n",
    ")\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from boruta import BorutaPy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# ML and Evaluation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Dense, Dropout, BatchNormalization\n",
    ")\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "def load_data(file_path):\n",
    "    print(\"Loading dataset...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=['COVID-19'])\n",
    "    y = df['COVID-19']\n",
    "    print(f\"Dataset loaded: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "    print(f\"Class distribution: {dict(y.value_counts())}\")\n",
    "    return X, y\n",
    "\n",
    "# Define all feature selection techniques\n",
    "def get_feature_selectors(X, y, n_features=10):\n",
    "    print(\"Initializing feature selection techniques...\")\n",
    "    feature_selectors = {\n",
    "        \"1. Chi-Square\": SelectKBest(chi2, k=n_features),\n",
    "        \"2. Mutual Information\": SelectKBest(mutual_info_classif, k=n_features),\n",
    "        \"3. Recursive Feature Elimination\": RFE(\n",
    "            estimator=LogisticRegression(solver='liblinear', max_iter=1000, random_state=42),\n",
    "            n_features_to_select=n_features\n",
    "        ),\n",
    "        \"4. Lasso\": SelectFromModel(\n",
    "            Lasso(alpha=0.01, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"5. Random Forest Importance\": SelectFromModel(\n",
    "            RandomForestClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"6. Boruta\": BorutaPy(\n",
    "            RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            n_estimators='auto', verbose=0, random_state=42\n",
    "        ),\n",
    "        \"7. Correlation-based\": None,  # Custom implementation\n",
    "        \"8. Sequential Forward Selection\": SequentialFeatureSelector(\n",
    "            RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "            n_features_to_select=n_features,\n",
    "            direction='forward'\n",
    "        ),\n",
    "        \"9. XGBoost Importance\": SelectFromModel(\n",
    "            XGBClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"10. LightGBM Importance\": SelectFromModel(\n",
    "            LGBMClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        )\n",
    "    }\n",
    "    return feature_selectors\n",
    "\n",
    "# Function to select top features using each technique\n",
    "def select_features(X, y, technique_name, selector, n_features=10):\n",
    "    print(f\"Selecting features using {technique_name}...\")\n",
    "    feature_names = X.columns.tolist()\n",
    "    \n",
    "    # Handle special case for Correlation-based selection\n",
    "    if technique_name == \"7. Correlation-based\":\n",
    "        # Calculate correlation of each feature with target\n",
    "        correlations = []\n",
    "        for col in X.columns:\n",
    "            corr = np.abs(X[col].corr(y))\n",
    "            correlations.append((col, corr))\n",
    "        \n",
    "        # Sort by correlation and select top n_features\n",
    "        correlations.sort(key=lambda x: x[1], reverse=True)\n",
    "        selected_features = [item[0] for item in correlations[:n_features]]\n",
    "        feature_importances = [item[1] for item in correlations[:n_features]]\n",
    "        \n",
    "    # Handle special case for Boruta\n",
    "    elif technique_name == \"6. Boruta\":\n",
    "        # Boruta requires array input\n",
    "        X_array = X.values\n",
    "        selector.fit(X_array, y)\n",
    "        \n",
    "        # Get the selected features\n",
    "        selected_mask = selector.support_\n",
    "        ranking = selector.ranking_\n",
    "        \n",
    "        # Sort by ranking and select top features\n",
    "        feature_ranking = [(feature, rank) for feature, rank, mask in \n",
    "                          zip(feature_names, ranking, selected_mask) if mask]\n",
    "        feature_ranking.sort(key=lambda x: x[1])\n",
    "        \n",
    "        # If Boruta selected fewer than n_features, add more by ranking\n",
    "        if len(feature_ranking) < n_features:\n",
    "            additional = [(f, r) for f, r, m in \n",
    "                         zip(feature_names, ranking, selected_mask) if not m]\n",
    "            additional.sort(key=lambda x: x[1])\n",
    "            feature_ranking.extend(additional[:n_features-len(feature_ranking)])\n",
    "        \n",
    "        feature_ranking = feature_ranking[:n_features]\n",
    "        selected_features = [item[0] for item in feature_ranking]\n",
    "        feature_importances = [1.0/item[1] for item in feature_ranking]  # Invert ranking for visualization\n",
    "    \n",
    "    else:\n",
    "        # Standard scikit-learn selectors\n",
    "        try:\n",
    "            selector.fit(X, y)\n",
    "            \n",
    "            # Different selector types have different ways to get selected features\n",
    "            if hasattr(selector, 'get_support'):\n",
    "                selected_mask = selector.get_support()\n",
    "                selected_features = [f for f, selected in zip(feature_names, selected_mask) if selected]\n",
    "                \n",
    "                # Get feature importances if available\n",
    "                if hasattr(selector, 'estimator_') and hasattr(selector.estimator_, 'feature_importances_'):\n",
    "                    feature_importances = selector.estimator_.feature_importances_[selected_mask]\n",
    "                elif hasattr(selector, 'scores_'):\n",
    "                    feature_importances = selector.scores_[selected_mask]\n",
    "                else:\n",
    "                    feature_importances = np.ones(len(selected_features))\n",
    "                    \n",
    "            elif hasattr(selector, 'coef_'):\n",
    "                # For models with coefficients like Lasso\n",
    "                coefs = np.abs(selector.coef_)\n",
    "                indices = np.argsort(coefs)[::-1][:n_features]\n",
    "                selected_features = [feature_names[i] for i in indices]\n",
    "                feature_importances = [coefs[i] for i in indices]\n",
    "                \n",
    "            else:\n",
    "                # Get features from the model itself\n",
    "                try:\n",
    "                    importances = getattr(selector, 'feature_importances_', \n",
    "                                         getattr(selector, 'coef_', None))\n",
    "                    if importances is None:\n",
    "                        importances = np.ones(len(feature_names))\n",
    "                    \n",
    "                    # For 2D coefficients (like in multiclass), take the mean\n",
    "                    if importances.ndim > 1:\n",
    "                        importances = np.mean(np.abs(importances), axis=0)\n",
    "                    \n",
    "                    # Select top features\n",
    "                    indices = np.argsort(np.abs(importances))[::-1][:n_features]\n",
    "                    selected_features = [feature_names[i] for i in indices]\n",
    "                    feature_importances = [np.abs(importances)[i] for i in indices]\n",
    "                    \n",
    "                except:\n",
    "                    # Fallback for other selectors\n",
    "                    indices = getattr(selector, 'support_', np.arange(min(n_features, len(feature_names))))\n",
    "                    if len(indices) > n_features:\n",
    "                        indices = indices[:n_features]\n",
    "                    selected_features = [feature_names[i] for i in indices]\n",
    "                    feature_importances = np.ones(len(selected_features))\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error with {technique_name}: {str(e)}\")\n",
    "            # Default to the first n_features if there's an error\n",
    "            selected_features = feature_names[:n_features]\n",
    "            feature_importances = np.ones(n_features)\n",
    "    \n",
    "    # Ensure exactly n_features are selected (truncate or pad if necessary)\n",
    "    if len(selected_features) > n_features:\n",
    "        selected_features = selected_features[:n_features]\n",
    "        feature_importances = feature_importances[:n_features]\n",
    "    elif len(selected_features) < n_features:\n",
    "        # Add remaining features based on variance\n",
    "        remaining = [f for f in feature_names if f not in selected_features]\n",
    "        selected_features.extend(remaining[:n_features-len(selected_features)])\n",
    "        feature_importances = list(feature_importances) + [0] * (n_features - len(feature_importances))\n",
    "    \n",
    "    # Print selected features\n",
    "    print(f\"Top {len(selected_features)} features selected by {technique_name}:\")\n",
    "    for i, (feature, importance) in enumerate(zip(selected_features, feature_importances)):\n",
    "        print(f\"{i+1}. {feature}: {importance:.4f}\")\n",
    "    \n",
    "    return selected_features, feature_importances\n",
    "\n",
    "# Build the ANN model for a specific set of features\n",
    "def build_ann_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        BatchNormalization(),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        BatchNormalization(),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train and evaluate model with k-fold cross validation\n",
    "def train_and_evaluate(X, y, selected_features, technique_name, k=5):\n",
    "    print(f\"\\nTraining ANN with features selected by {technique_name}\")\n",
    "    \n",
    "    # Prepare data for ANN\n",
    "    X_selected = X[selected_features].values\n",
    "    y_values = y.values\n",
    "    \n",
    "    # K-Fold validation\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    metrics = {\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': [],\n",
    "        'auc': []\n",
    "    }\n",
    "    \n",
    "    # Define early stopping\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Train and evaluate for each fold\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X_selected)):\n",
    "        print(f\"Training fold {fold+1}/{k}...\")\n",
    "        \n",
    "        X_train, X_test = X_selected[train_idx], X_selected[test_idx]\n",
    "        y_train, y_test = y_values[train_idx], y_values[test_idx]\n",
    "        \n",
    "        # Build and train model\n",
    "        model = build_ann_model((X_selected.shape[1],))\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=50,  # Reduced from 100 for faster execution\n",
    "            batch_size=32,\n",
    "            verbose=0,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[early_stop]\n",
    "        )\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics['accuracy'].append(accuracy_score(y_test, y_pred_classes))\n",
    "        metrics['precision'].append(precision_score(y_test, y_pred_classes))\n",
    "        metrics['recall'].append(recall_score(y_test, y_pred_classes))\n",
    "        metrics['f1'].append(f1_score(y_test, y_pred_classes))\n",
    "        try:\n",
    "            metrics['auc'].append(roc_auc_score(y_test, y_pred))\n",
    "        except:\n",
    "            metrics['auc'].append(0.5)  # Default for failed AUC calculation\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {metric: np.mean(values) for metric, values in metrics.items()}\n",
    "    std_metrics = {metric: np.std(values) for metric, values in metrics.items()}\n",
    "    \n",
    "    print(f\"\\nResults for {technique_name}:\")\n",
    "    for metric, value in avg_metrics.items():\n",
    "        print(f\"Average {metric}: {value:.4f} ± {std_metrics[metric]:.4f}\")\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "# Plot comparison bar chart\n",
    "def plot_comparison(all_results):\n",
    "    metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
    "    \n",
    "    # Sort techniques by accuracy\n",
    "    sorted_techniques = sorted(\n",
    "        all_results.keys(),\n",
    "        key=lambda x: all_results[x]['accuracy'],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Set width of bars\n",
    "    bar_width = 0.15\n",
    "    index = np.arange(len(sorted_techniques))\n",
    "    \n",
    "    # Colors for different metrics\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    \n",
    "    # Plot bars for each metric\n",
    "    for i, metric in enumerate(metrics_to_plot):\n",
    "        values = [all_results[technique][metric] for technique in sorted_techniques]\n",
    "        plt.bar(\n",
    "            index + i * bar_width, \n",
    "            values, \n",
    "            bar_width, \n",
    "            label=metric.capitalize(),\n",
    "            color=colors[i]\n",
    "        )\n",
    "    \n",
    "    # Add labels and legend\n",
    "    plt.xlabel('Feature Selection Technique', fontsize=12)\n",
    "    plt.ylabel('Score', fontsize=12)\n",
    "    plt.title('Comparison of Feature Selection Techniques', fontsize=14)\n",
    "    plt.xticks(\n",
    "        index + bar_width * 2, \n",
    "        [t.split('. ')[1] if '. ' in t else t for t in sorted_techniques],\n",
    "        rotation=45,\n",
    "        ha='right'\n",
    "    )\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=5)\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig('feature_selection_comparison_ANN.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Comparison chart saved as 'feature_selection_comparison_ANN.png'\")\n",
    "    plt.close()\n",
    "\n",
    "# Plot feature heatmap\n",
    "def plot_feature_heatmap(all_features, X):\n",
    "    # Create a matrix of features vs techniques\n",
    "    techniques = list(all_features.keys())\n",
    "    all_unique_features = list(set(feature for features in all_features.values() for feature in features))\n",
    "    \n",
    "    # Create a matrix with 1 if feature is selected by technique, 0 otherwise\n",
    "    matrix = np.zeros((len(techniques), len(all_unique_features)))\n",
    "    \n",
    "    for i, technique in enumerate(techniques):\n",
    "        for j, feature in enumerate(all_unique_features):\n",
    "            if feature in all_features[technique]:\n",
    "                matrix[i, j] = 1\n",
    "    \n",
    "    # Sort features by frequency of selection\n",
    "    feature_counts = matrix.sum(axis=0)\n",
    "    sorted_indices = np.argsort(feature_counts)[::-1]\n",
    "    sorted_features = [all_unique_features[i] for i in sorted_indices]\n",
    "    sorted_matrix = matrix[:, sorted_indices]\n",
    "    \n",
    "    # Create heatmap\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    sns.heatmap(\n",
    "        sorted_matrix,\n",
    "        cmap='Blues',\n",
    "        xticklabels=sorted_features,\n",
    "        yticklabels=[t.split('. ')[1] if '. ' in t else t for t in techniques],\n",
    "        cbar_kws={'label': 'Selected'}\n",
    "    )\n",
    "    plt.title('Feature Selection by Different Techniques', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig('feature_selection_heatmap_ANN.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Heatmap saved as 'feature_selection_heatmap_ANN.png'\")\n",
    "    plt.close()\n",
    "\n",
    "# Main function to run the whole process\n",
    "def main():\n",
    "    # Load data\n",
    "    file_path = \"OneDrive/Desktop/Research_Capstone_Project/preprocessed_covid500_final.csv\"  # Update with your path\n",
    "    X, y = load_data(file_path)\n",
    "    \n",
    "    # Get feature selectors\n",
    "    feature_selectors = get_feature_selectors(X, y)\n",
    "    \n",
    "    # Store results\n",
    "    all_results = {}\n",
    "    all_selected_features = {}\n",
    "    \n",
    "    # For each technique, select features and train model\n",
    "    for technique_name, selector in feature_selectors.items():\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Processing {technique_name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Select features\n",
    "        selected_features, _ = select_features(X, y, technique_name, selector)\n",
    "        all_selected_features[technique_name] = selected_features\n",
    "        \n",
    "        # Train and evaluate\n",
    "        results = train_and_evaluate(X, y, selected_features, technique_name)\n",
    "        all_results[technique_name] = results\n",
    "    \n",
    "    # Plot comparison\n",
    "    plot_comparison(all_results)\n",
    "    \n",
    "    # Plot feature heatmap\n",
    "    plot_feature_heatmap(all_selected_features, X)\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Sort techniques by accuracy\n",
    "    sorted_techniques = sorted(\n",
    "        all_results.keys(),\n",
    "        key=lambda x: all_results[x]['accuracy'],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTechniques ranked by accuracy:\")\n",
    "    for i, technique in enumerate(sorted_techniques):\n",
    "        print(f\"{i+1}. {technique}: {all_results[technique]['accuracy']:.4f}\")\n",
    "    \n",
    "    best_technique = sorted_techniques[0]\n",
    "    print(f\"\\nBest performing technique: {best_technique}\")\n",
    "    print(f\"Top 10 features selected by {best_technique}:\")\n",
    "    for i, feature in enumerate(all_selected_features[best_technique]):\n",
    "        print(f\"{i+1}. {feature}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b66ef5-3afc-4806-8221-a6d400c37103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6811653,
     "sourceId": 10950666,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1530.336004,
   "end_time": "2025-03-07T10:30:11.352484",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-07T10:04:41.016480",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
