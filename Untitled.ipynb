{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf1d8090-e184-43f7-a10e-33eb1faae65d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (2830213039.py, line 279)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 279\u001b[1;36m\u001b[0m\n\u001b[1;33m    file_path = \"C:\\Users\\aurok\\OneDrive\\Desktop\\Research_Capstone_Project\\preprocessed_covid500_final.csv\"  # Update with your path\u001b[0m\n\u001b[1;37m                                                                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_selection import (\n",
    "    VarianceThreshold, chi2, f_classif, mutual_info_classif, \n",
    "    SelectKBest, RFE, SelectFromModel, SequentialFeatureSelector\n",
    ")\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from boruta import BorutaPy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Conv1D, MaxPooling1D, Dropout, Flatten, Dense, BatchNormalization\n",
    ")\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "def load_data(file_path):\n",
    "    print(\"Loading dataset...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=['COVID-19'])\n",
    "    y = df['COVID-19']\n",
    "    print(f\"Dataset loaded: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "    print(f\"Class distribution: {dict(y.value_counts())}\")\n",
    "    return X, y\n",
    "\n",
    "# Define all feature selection techniques\n",
    "def get_feature_selectors(X, y, n_features=10):\n",
    "    print(\"Initializing feature selection techniques...\")\n",
    "    feature_selectors = {\n",
    "        \"1. Chi-Square\": SelectKBest(chi2, k=n_features),\n",
    "        \"2. Mutual Information\": SelectKBest(mutual_info_classif, k=n_features),\n",
    "        \"3. Recursive Feature Elimination\": RFE(\n",
    "            estimator=LogisticRegression(solver='liblinear', max_iter=1000, random_state=42),\n",
    "            n_features_to_select=n_features\n",
    "        ),\n",
    "        \"4. Lasso\": SelectFromModel(\n",
    "            Lasso(alpha=0.01, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"5. Random Forest Importance\": SelectFromModel(\n",
    "            RandomForestClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"6. Boruta\": BorutaPy(\n",
    "            RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            n_estimators='auto', verbose=0, random_state=42\n",
    "        ),\n",
    "        \"7. Correlation-based\": None,  # Custom implementation\n",
    "        \"8. Sequential Forward Selection\": SequentialFeatureSelector(\n",
    "            RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "            n_features_to_select=n_features,\n",
    "            direction='forward'\n",
    "        ),\n",
    "        \"9. XGBoost Importance\": SelectFromModel(\n",
    "            XGBClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        ),\n",
    "        \"10. LightGBM Importance\": SelectFromModel(\n",
    "            LGBMClassifier(n_estimators=100, random_state=42), max_features=n_features\n",
    "        )\n",
    "    }\n",
    "    return feature_selectors\n",
    "\n",
    "# Function to select top features using each technique\n",
    "def select_features(X, y, technique_name, selector, n_features=10):\n",
    "    print(f\"Selecting features using {technique_name}...\")\n",
    "    feature_names = X.columns.tolist()\n",
    "    \n",
    "    # Handle special case for Correlation-based selection\n",
    "    if technique_name == \"7. Correlation-based\":\n",
    "        correlations = []\n",
    "        for col in X.columns:\n",
    "            corr = np.abs(pd.crosstab(X[col], y, normalize='columns').iloc[1, 1] - \n",
    "                          pd.crosstab(X[col], y, normalize='columns').iloc[1, 0])\n",
    "            correlations.append((col, corr))\n",
    "        \n",
    "        correlations.sort(key=lambda x: x[1], reverse=True)\n",
    "        selected_features = [item[0] for item in correlations[:n_features]]\n",
    "        feature_importances = [item[1] for item in correlations[:n_features]]\n",
    "        \n",
    "    elif technique_name == \"6. Boruta\":\n",
    "        X_array = X.values\n",
    "        selector.fit(X_array, y)\n",
    "        selected_mask = selector.support_\n",
    "        ranking = selector.ranking_\n",
    "        \n",
    "        feature_ranking = [(feature, rank) for feature, rank, mask in \n",
    "                          zip(feature_names, ranking, selected_mask) if mask]\n",
    "        feature_ranking.sort(key=lambda x: x[1])\n",
    "        \n",
    "        if len(feature_ranking) < n_features:\n",
    "            additional = [(f, r) for f, r, m in \n",
    "                         zip(feature_names, ranking, selected_mask) if not m]\n",
    "            additional.sort(key=lambda x: x[1])\n",
    "            feature_ranking.extend(additional[:n_features-len(feature_ranking)])\n",
    "        \n",
    "        feature_ranking = feature_ranking[:n_features]\n",
    "        selected_features = [item[0] for item in feature_ranking]\n",
    "        feature_importances = [1.0/item[1] for item in feature_ranking]\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            selector.fit(X, y)\n",
    "            selected_mask = selector.get_support()\n",
    "            selected_features = [f for f, selected in zip(feature_names, selected_mask) if selected]\n",
    "            \n",
    "            if hasattr(selector, 'estimator_') and hasattr(selector.estimator_, 'feature_importances_'):\n",
    "                feature_importances = selector.estimator_.feature_importances_[selected_mask]\n",
    "            elif hasattr(selector, 'scores_'):\n",
    "                feature_importances = selector.scores_[selected_mask]\n",
    "            else:\n",
    "                feature_importances = np.ones(len(selected_features))\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error with {technique_name}: {str(e)}\")\n",
    "            selected_features = feature_names[:n_features]\n",
    "            feature_importances = np.ones(n_features)\n",
    "    \n",
    "    if len(selected_features) > n_features:\n",
    "        selected_features = selected_features[:n_features]\n",
    "        feature_importances = feature_importances[:n_features]\n",
    "    elif len(selected_features) < n_features:\n",
    "        remaining = [f for f in feature_names if f not in selected_features]\n",
    "        selected_features.extend(remaining[:n_features-len(selected_features)])\n",
    "        feature_importances = list(feature_importances) + [0] * (n_features - len(feature_importances))\n",
    "    \n",
    "    print(f\"Top {len(selected_features)} features selected by {technique_name}:\")\n",
    "    for i, (feature, importance) in enumerate(zip(selected_features, feature_importances)):\n",
    "        print(f\"{i+1}. {feature}: {importance:.4f}\")\n",
    "    \n",
    "    return selected_features, feature_importances\n",
    "\n",
    "# Build the CNN model for a specific set of features\n",
    "def build_cnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu', padding='same', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2, padding='same'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2, padding='same'),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(32, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train and evaluate model with k-fold cross validation\n",
    "def train_and_evaluate(X, y, selected_features, technique_name, k=5):\n",
    "    print(f\"\\nTraining CNN with features selected by {technique_name}\")\n",
    "    \n",
    "    X_selected = X[selected_features].values\n",
    "    X_selected = X_selected.reshape(X_selected.shape[0], X_selected.shape[1], 1)\n",
    "    y_values = y.values\n",
    "    \n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    metrics = {\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': [],\n",
    "        'auc': []\n",
    "    }\n",
    "    \n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X_selected)):\n",
    "        print(f\"Training fold {fold+1}/{k}...\")\n",
    "        \n",
    "        X_train, X_test = X_selected[train_idx], X_selected[test_idx]\n",
    "        y_train, y_test = y_values[train_idx], y_values[test_idx]\n",
    "        \n",
    "        model = build_cnn_model((X_selected.shape[1], 1))\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            verbose=0,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[early_stop]\n",
    "        )\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "        \n",
    "        metrics['accuracy'].append(accuracy_score(y_test, y_pred_classes))\n",
    "        metrics['precision'].append(precision_score(y_test, y_pred_classes))\n",
    "        metrics['recall'].append(recall_score(y_test, y_pred_classes))\n",
    "        metrics['f1'].append(f1_score(y_test, y_pred_classes))\n",
    "        try:\n",
    "            metrics['auc'].append(roc_auc_score(y_test, y_pred))\n",
    "        except:\n",
    "            metrics['auc'].append(0.5)\n",
    "    \n",
    "    avg_metrics = {metric: np.mean(values) for metric, values in metrics.items()}\n",
    "    std_metrics = {metric: np.std(values) for metric, values in metrics.items()}\n",
    "    \n",
    "    print(f\"\\nResults for {technique_name}:\")\n",
    "    for metric, value in avg_metrics.items():\n",
    "        print(f\"Average {metric}: {value:.4f} ± {std_metrics[metric]:.4f}\")\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "# Plot comparison bar chart\n",
    "def plot_comparison(all_results):\n",
    "    metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
    "    \n",
    "    sorted_techniques = sorted(\n",
    "        all_results.keys(),\n",
    "        key=lambda x: all_results[x]['accuracy'],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    bar_width = 0.15\n",
    "    index = np.arange(len(sorted_techniques))\n",
    "    \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    \n",
    "    for i, metric in enumerate(metrics_to_plot):\n",
    "        values = [all_results[technique][metric] for technique in sorted_techniques]\n",
    "        plt.bar(\n",
    "            index + i * bar_width, \n",
    "            values, \n",
    "            bar_width, \n",
    "            label=metric.capitalize(),\n",
    "            color=colors[i]\n",
    "        )\n",
    "    \n",
    "    plt.xlabel('Feature Selection Technique', fontsize=12)\n",
    "    plt.ylabel('Score', fontsize=12)\n",
    "    plt.title('Comparison of Feature Selection Techniques', fontsize=14)\n",
    "    plt.xticks(\n",
    "        index + bar_width * 2, \n",
    "        [t.split('. ')[1] if '. ' in t else t for t in sorted_techniques],\n",
    "        rotation=45,\n",
    "        ha='right'\n",
    "    )\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=5)\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('feature_selection_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Comparison chart saved as 'feature_selection_comparison.png'\")\n",
    "    plt.close()\n",
    "\n",
    "# Main function to run the whole process\n",
    "def main():\n",
    "    file_path = \"C:\\Users\\aurok\\OneDrive\\Desktop\\Research_Capstone_Project\\preprocessed_covid500_final.csv\"  # Update with your path\n",
    "    X, y = load_data(file_path)\n",
    "    \n",
    "    feature_selectors = get_feature_selectors(X, y)\n",
    "    \n",
    "    all_results = {}\n",
    "    all_selected_features = {}\n",
    "    \n",
    "    for technique_name, selector in feature_selectors.items():\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Processing {technique_name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        selected_features, _ = select_features(X, y, technique_name, selector)\n",
    "        all_selected_features[technique_name] = selected_features\n",
    "        \n",
    "        results = train_and_evaluate(X, y, selected_features, technique_name)\n",
    "        all_results[technique_name] = results\n",
    "    \n",
    "    plot_comparison(all_results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    sorted_techniques = sorted(\n",
    "        all_results.keys(),\n",
    "        key=lambda x: all_results[x]['accuracy'],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTechniques ranked by accuracy:\")\n",
    "    for i, technique in enumerate(sorted_techniques):\n",
    "        print(f\"{i+1}. {technique}: {all_results[technique]['accuracy']:.4f}\")\n",
    "    \n",
    "    best_technique = sorted_techniques[0]\n",
    "    print(f\"\\nBest performing technique: {best_technique}\")\n",
    "    print(f\"Top features selected by {best_technique}:\")\n",
    "    for feature in all_selected_features[best_technique]:\n",
    "        print(f\"- {feature}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3250f3c8-5d94-493e-9ebc-afe723b4c749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
